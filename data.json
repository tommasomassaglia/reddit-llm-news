{
    "posts": [
        {
            "date": "21-03-2024",
            "title": "First Neuralink patient explains his experience (\"Using the Force\"",
            "body": "Video shows Neuralink associate with first patient talking about how it works, and showing off some chess skills",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 552,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://v.redd.it/8dhcyzqpiopc1",
            "comments": [
                {
                    "body": "The point of this video is not to demonstrate a new way to use a mouse.  The point is to demonstrate that the neuralink interface works correctly at interpreting brain signals.  It's an initial proof of concept way to use the interface, not the end product.  The potential capabilities extend far beyond using a mouse.  This same technology can be used to operate a mechanical arm, drive a car, etc."
                },
                {
                    "body": "and I'm here scrolling with my fingers like a sucker"
                },
                {
                    "body": "The fact that he can use it for extended periods is a great sign. \n\nBesides that, very little information here.  Feed us some effin info man!! We're starving here."
                },
                {
                    "body": "Jamiroquai playing in the background confirms we are indeed in the future."
                },
                {
                    "body": "Happy for him! Wishing him all the best for continued success."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Unitree's robot is the first humanoid to do a backflip without hydraulics",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 265,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://v.redd.it/wyo84y77dipc1",
            "comments": [
                {
                    "body": "You can see on the floor how hard they tried.  \nIt's incredibly difficult because they did not do it from an elevated place like some of atlas's backflips but on a flat ground!  \nI think it's wild!"
                },
                {
                    "body": "This must be one of the most important skills for a robot."
                },
                {
                    "body": "https://preview.redd.it/nrvsrmjwiipc1.jpeg?width=512&format=pjpg&auto=webp&s=94435959582ecdd50588a1ab523246fde8fcd9f3"
                },
                {
                    "body": "Not good for the knees without the draulics"
                },
                {
                    "body": "finally they can emote on the corpses of their enemies"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Unitree's robot is the first humanoid to do a backflip without hydraulics",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 265,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://v.redd.it/wyo84y77dipc1",
            "comments": [
                {
                    "body": "You can see on the floor how hard they tried.  \nIt's incredibly difficult because they did not do it from an elevated place like some of atlas's backflips but on a flat ground!  \nI think it's wild!"
                },
                {
                    "body": "This must be one of the most important skills for a robot."
                },
                {
                    "body": "https://preview.redd.it/nrvsrmjwiipc1.jpeg?width=512&format=pjpg&auto=webp&s=94435959582ecdd50588a1ab523246fde8fcd9f3"
                },
                {
                    "body": "Not good for the knees without the draulics"
                },
                {
                    "body": "finally they can emote on the corpses of their enemies"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Researchers gave AI an 'inner monologue' and it massively improved its performance | Scientists trained an AI system to think before speaking with a technique called QuietSTaR. The inner monologue improved common sense reasoning and doubled math performance",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 366,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance",
            "comments": [
                {
                    "body": "The actual paper: https://arxiv.org/abs/2403.09629"
                },
                {
                    "body": "It's like they are slowly recreating human consciousness."
                },
                {
                    "body": "LeCun in shambles"
                },
                {
                    "body": "I don't know what's complete wishful thinking and baseless hype and what I should be excited about these days"
                },
                {
                    "body": "Is the name a fucking joke or troll???"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "AI is just hype, they said. It will slow down, they said.",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 539,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://i.redd.it/ho26lpcun5pc1.png",
            "comments": [
                {
                    "body": "GPT-4 was trained on 25k A100s over 90 days, but now you can do it with only 2k GPUs over 90 days lol."
                },
                {
                    "body": "Blackwell is 30x Hopper at Inference. Those things are purrrrrrring."
                },
                {
                    "body": "SORA  for the masses seem way more realistic now."
                },
                {
                    "body": "Crazy thing is by the time these even reach data centers at scale the next version will just be a straight vertical line"
                },
                {
                    "body": "NVIDIA is cooking so much bro who can stop them"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Recently made this video for a job, all still image generated using SD.",
            "body": "It isn‚Äôt perfect yet but I really enjoyed discovering SD and digging through it. \n\nCritics and observations are obviously welcome üñ§ ",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 212,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://v.redd.it/kmczmdm2jcpc1",
            "comments": [
                {
                    "body": "![gif](giphy|gJH0l1ItLtaFdHNt3S)"
                },
                {
                    "body": "Do you work at Boeing?"
                },
                {
                    "body": "TF kind of job you got?!"
                },
                {
                    "body": "https://preview.redd.it/4cr5k6wv9dpc1.png?width=1283&format=png&auto=webp&s=a6ac8cabe872172595a1609713b29351400f400a\n\nComplimentary toilet paper, anyone?‚ò∫Ô∏è"
                },
                {
                    "body": " So there are some questions I will answer here :\n\nThis video is among 4 videos we made for the DJ set of a French artist (Kungs) , they are being aired while he plays. \n\nYou can see the other videos on our [instagram](https://www.instagram.com/mentalpicture) \n\nFor this video we used mostly SD and runway, and then we had very little VFX and some color grading done!\n\nThank you for the positive feedback, we were lucky to be paid to experiment AI tools!\n\nEdit : we are also looking to hire, probably at first for some freelance jobs. We are looking for more of a technical profile. Hit us up in DMs on our instagram so we can talk"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "OpenAI keeps dropping more insane Sora videos this video is 100% AI generated",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 209,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/baubzs5zr3pc1",
            "comments": [
                {
                    "body": "It is frustratingly impressive. However, I've noticed with walkcycles I see in the vids, it almost subliminally switches from left to rightfoot when they cross, happens multiple times..."
                },
                {
                    "body": "Love when the legs swap position seamlessly"
                },
                {
                    "body": "Generate \"eLEAFant\""
                },
                {
                    "body": "amateur\n\nhttps://preview.redd.it/9e6pvzymu4pc1.png?width=968&format=png&auto=webp&s=8957a3b017df9a50e69ba1f86b35ea2d0d098132"
                },
                {
                    "body": "Everyone pointing out the legs should know that a year ago the legs wouldn't even look like legs, so instead of acting like AI videos are never going to be so good they can't be detected how about we all start from the position of assuming they WILL be so good they can't be detected, and start working on potential solutions for that problem that will actually work."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Joscha Bach: ‚ÄúI am more afraid of lobotomized zombie AI guided by people who have been zombified by economic and political incentives than of conscious, lucid and sentient AI‚Äù",
            "body": "Thoughts?",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 153,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://x.com/plinz/status/1771805114283479510?s=46&t=yQ_4zkmWd6ncIZAnXlXUbg",
            "comments": [
                {
                    "body": "I agree the biggest danger with AI right now are the greedy and lustful people for power with no morals. These people are willing to do anything for profits and power and with AI the possibilites are endless for them right now."
                },
                {
                    "body": "I agree with him."
                },
                {
                    "body": "Absolutely agree!"
                },
                {
                    "body": "yes"
                },
                {
                    "body": "Yes, I also think that elite power consolidation leading us into some kind of cyberpunk dystopia is the most realistic of the bad outcomes and should get more attention than all the \"Skynet / the grey goo is coming for us all\" stuff."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Things are getting out of hand. Nuclear explosion gender reveal parties!",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 71,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjcczq",
            "comments": [
                {
                    "body": "It's a Little Boy!"
                },
                {
                    "body": "It‚Äôs fascinating most of these have coolant stacks from power plants included as part of the cloud. The system can‚Äôt distinguish between them and mushroom clouds."
                },
                {
                    "body": "Oppenhymen"
                },
                {
                    "body": "hahaha what a crazy idea!"
                },
                {
                    "body": "bro dont give ideas for gender reveal"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Nvidia announces AI-powered health care 'agents' that outperform nurses ‚Äî and cost $9 an hour",
            "body": "Nvidia announces AI-powered health care 'agents' that outperform nurses ‚Äî and cost $9 an hour",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 483,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.foxbusiness.com/technology/nvidia-announces-ai-powered-health-care-agents-outperform-nurses-cost-9-hour",
            "comments": [
                {
                    "body": "It was interesting watching the demonstration of their AI nurse, Linda, on the Hippocratic AI website. While I doubt elderly patients will be receptive at first, if the AI nurse is able to spend longer time with the patient and answer their questions then that could really be beneficial for healthcare and patients alike. It'll also free up a lot of nurses and remove some of their workload.\n\nIf implemented, I'd hope that there is a hybrid call system so that if the patients don't want to talk with the AI, they could be redirected to a human nurse."
                },
                {
                    "body": "what do nurses in the US do? in my country they change the dressing, take blood samples, measure blood pressure .. no video call anything"
                },
                {
                    "body": "Except most of what nurses do is in person."
                },
                {
                    "body": "I can't wait for AI doctors...I'm a patient and am so sick of human MDs and their bullshit üò≠ I just wanna get treatments without mistakes please"
                },
                {
                    "body": "This seems to be on video calls only however. Does Hippocratic AI plan to expand this to blood tests? What about medical scans? Is this simply one part of an AI system that will be combined with others?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "not just chess, also mario cart already! neuralink noland arbaugh",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 269,
            "submission_flair": "BRAIN",
            "has_media": true,
            "url": "https://v.redd.it/rra4r9g6rypc1",
            "comments": [
                {
                    "body": "He is playing on yuzu. Nintendo is going to end neuralink."
                },
                {
                    "body": "What the fuck is the world gonna look like in 10 years? This is insanity on top of AI coming. What the hell are we in for?"
                },
                {
                    "body": "This + VR would be nuts"
                },
                {
                    "body": "https://x.com/moddedquad/status/1771298116719002100?s=46\n\nthis is the source :)\n\nhe is yoshi, right driver."
                },
                {
                    "body": "Dude seriously needs to start streaming"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "First Neuralink patient live stream",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 426,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://twitter.com/neuralink/status/1770563939413496146?s=19",
            "comments": [
                {
                    "body": "The very first day they let him live by himself, he stayed until 6AM playing Civilization VI. That's my dude."
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "That was inspiring. I can't imagine becoming quadriplegic at ~~29~~ *21* (thank you everyone), so much of the future just taken away in a heartbeat. He seems like the perfect candidate and I really hope this works out well for him. What he has right now will open up so many doors and I know they are pushing to do much more than just control a mouse."
                },
                {
                    "body": "This is actually insane what the fuck"
                },
                {
                    "body": "He now has the power to google en passant using only his mind.\n\nLovely video."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Nvidia CEO says we'll see fully AI-generated games in 5-10 years",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 454,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.tomshardware.com/pc-components/gpus/rtx-off-ai-on-jensen-says-well-see-fully-ai-generated-games-in-5-10-years",
            "comments": [
                {
                    "body": "It'll be cool when games are just a glorified design doc, passed around and modified, having shared overarching meta experiences while having individualized personal experiences."
                },
                {
                    "body": "Too slow. \n\nI need my massive game of thrones universe RPG in 4 years max."
                },
                {
                    "body": "While that doesn't seem implausible (given how fast AI is advancing), remember that he has an incentive to hype AI as much as possible (something that other people in this sub have alluded to), so I wouldn't take this as gospel. Interesting prediction, nonetheless."
                },
                {
                    "body": "I can't wait to play games based on books I love that would never get made otherwise. The games industry is totally borked right now, much like Hollywood, and new ideas seem to either not materialise or fail hard and fast."
                },
                {
                    "body": "Well, you could argue that most first-person shooter franchises have been re-skinning, improving and selling us a version of Unreal over and over again.\n\nOr the underlying code/solutions has been around for 26 years now.\n\nI have not seen any great 3D AI model generators yet but the 2D artwork they can generate is amazing, so I guess it's just a matter of time before we have B, A, AA, AAA 3D models generated by AI systems.\n\nAnd I know AI has been amazing at replaying games so will be great at testing and finding problems with games.\n\nI wonder which type of AI will need more parameters, Music, 3D, 2D, Programming, Design, Marketing, FX, Storyline? \n\nAs I would expect we will need separate AI systems for each aspect and maybe even for different types of games."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Neuralink is already able to restore vision for blind monkeys",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 472,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://twitter.com/cb_doge/status/1770818578935091213?s=19",
            "comments": [
                {
                    "body": "Great, now do tinnitus please"
                },
                {
                    "body": "Where did you find the blind monkeys? üëÄ"
                },
                {
                    "body": "How? With camera transfering the image or by stimulating the brain so the patient eyes work again? Something else?"
                },
                {
                    "body": "People are questioning  whether or not they  had blind  monkeys.  Personally  I don't  think  they would need  blind monkeys  to test this. The entire  point is to be able to  bypass the eyes and the retinas and send signals directly to the brain.  They just have to send them a signal and somehow  confirm the monkeys received it. \n\nYou  could  set them in front of  a row of buttons with pictures. Send them a image of the picture via the implant., and if they press the right one they get a treat. If they can consistently  get it right  even if you keep changing the  pictures, you  know  they are \"seeing \"."
                },
                {
                    "body": "The source\n\n[https://twitter.com/elonmusk/status/1770817187285995939](https://twitter.com/elonmusk/status/1770817187285995939)\n>I should mention that the Blindsight implant is already working in monkeys. \n>\n>Resolution will be low at first, like early Nintendo graphics, but ultimately may exceed normal human vision.\n>\n>(Also, no monkey has died or been seriously injured by a Neuralink device!)\n\nNeuralink talked about this in a talk they gave about a year and a half ago (2:08 to 4:00 or so) https://youtu.be/xv2_F4FwFiM?si=d9iR-ehIyjBRWf2T&t=128\n\nfull presentation https://www.youtube.com/watch?v=YreDYmXTYi4"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Sam Altman says state actors are trying to hack and infiltrate OpenAI and he expects this to get worse",
            "body": "How do you think this will change as we get closer to AGI/as time progresses?",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 185,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/tsarnick/status/1769840515724529822?s=20",
            "comments": [
                {
                    "body": "They'd be stupid not to try. Seems like small risk with unlimited rewards. Yet another way AI could \"get out\".¬†"
                },
                {
                    "body": "HITMAN 4 better have this as a mission"
                },
                {
                    "body": "Dario Amodei said the same thing last year about Anthropic being infiltrated"
                },
                {
                    "body": "Maybe the fake mustache isn't working as well as I hoped."
                },
                {
                    "body": "Foreign or domestic?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Nvidia unveils next-gen Blackwell GPUs with 25X lower costs and energy consumption",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 254,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://venturebeat.com/ai/nvidia-unveils-next-gen-blackwell-gpus-with-25x-lower-costs-and-energy-consumption/",
            "comments": [
                {
                    "body": "Feels like I am watching history being made right now. We really are at a huge turning point this decade."
                },
                {
                    "body": "Accelerate\n\n![gif](giphy|F0uvYzyr2a7Li|downsized)"
                },
                {
                    "body": "We need more POWER!"
                },
                {
                    "body": "its 30x for inference. less for training (like 5x)  but still insane numbers for both. blackwell is remarkable"
                },
                {
                    "body": "25X price üôè"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Apparently pro AI regulation Sam Altman has been spending a lot of time in Washington lobbying the government presumably to regulate Open Source. This guy is upto no good. ",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 228,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://v.redd.it/4ob8m407t7qc1",
            "comments": [
                {
                    "body": "This is about wealthy elites trying to get the government to build a moat so they have exclusive rights to dominate the industry.\n\nI have said this before and people disagree with me but people need to be more vocal when leaders of the biggest AI companies in the world are walking around asking the government to get more involved in legislation.\n\nThey know small AI startups don't have the budgets for red teaming, censorship, lawyers, lobbyists etc. so they want to make that a barrier to entry and they don't care how much they have to censor their models to do it. \n\nThe \"AI is scary, please big government man pass laws to help\" stuff is part of the act."
                },
                {
                    "body": "Eliminating competition."
                },
                {
                    "body": "This guy has a gigantic messiah complex, more than even Elon Musk. Tired of these shady characters trying to rule over us."
                },
                {
                    "body": "Am I missing something? The video ends at 17 seconds with him having said nothing more than how many days he was in Washington.  \n\nEdit: I see. I had to scroll down a bit in comments to find the link to relevant content."
                },
                {
                    "body": "[https://twitter.com/sama/status/1635136281952026625?t=QKLXs\\_6G4bZNlVsmFO4Rnw&s=19](https://twitter.com/sama/status/1635136281952026625?t=QKLXs_6G4bZNlVsmFO4Rnw&s=19)\n\nhttps://preview.redd.it/do1whicat7qc1.png?width=1080&format=pjpg&auto=webp&s=b907f22baf7dcec426352d4a05c8b44dca000fa8"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "No we don't ",
            "body": "https://x.com/sama/status/1635136281952026625?s=20",
            "upvote_ratio": 0.86,
            "subreddit": "LocalLLaMA",
            "num_comments": 145,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/3wmka8xpt7qc1.png",
            "comments": [
                {
                    "body": "We need more regulation on \"non-profit\" companies"
                },
                {
                    "body": "> We definitely need more regulation on my competitors."
                },
                {
                    "body": "course he did, he has a fucking god complex, he just acts small but is shifty as fuck.  \n\nHe's also been saying that for quite awhile. Nothing new."
                },
                {
                    "body": "By \"we\" he means openai and other \"for profit\" organizations that has to keep a stronghold.\n\nRemember \"we have no moat\" document? They also don't have any except what the government will do for them."
                },
                {
                    "body": "Classic pulling up the ladder after you"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "I can‚Äôt wait for doctors to be replaced by AI",
            "body": "Currently its like you go to 3 different doctors and get 3 different diagnoses and care plans. Honestly healthcare currently looks more like improvisation than science. Yeah, why don‚Äôt we try this and if you don‚Äôt die meanwhile we‚Äôll see you in 6 months. Oh, you have a headache, why don‚Äôt we do a colonoscopy because business is slow and our clinic needs that insurance money.\n\nWhy the hell isn‚Äôt AI more widely used in healthcare? I mean people are fired and replaced by AI left and right but healthcare is still in middle-ages and absolutely subjective and dependent on doctors whims. Currently, its a lottery if you get a doctor that a)actually cares and b)actually knows what he/she is doing. Not to mention you (or taxpayers) pay huge sums for at best a mediocre service. \n\nSo, why don‚Äôt we save some (tax) money and start using AI more widely in the healthcare. I‚Äôll trust AI-provided diagnosis and cure over your averege doctor‚Äôs any day. Not to mention the fact that many poor countries could benefit enormously from cheap AI healthcare. I‚Äôm convinced that AI is already able to diagnose and provide care plans much more accurately than humans. Just fucking change the laws so doctors are obliged to double-check with AI before making any decisions and it should be considered negligence if they don‚Äôt.",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 630,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bj93i8/i_cant_wait_for_doctors_to_be_replaced_by_ai/",
            "comments": [
                {
                    "body": "I work in a quite big hospital and I have seen/heard/experienced stuff, people better not to know. I agree with you 100%."
                },
                {
                    "body": "Can't go to the doctor without feeling like you're a burden on them. When you sit you have 3 minutes to make your case before they kick your ass out of the clinic. I second this post 100%"
                },
                {
                    "body": "ER doctor and AI enthusiast here. I've been thinking about this very question quite a bit.\n\nThere are some areas where AI intervention will be super helpful, but there are some problems with the outright replacement of physicians. Here are some of the stumbling blocks as I see it. First, diagnosis is a time-dependent problem that varies from person to person. What I mean by that is that the symptoms, exam, findings, and diagnostic findings you may find change as the disease process progresses.\n\nLet's take appendicitis, for example. Very early on, you may have no fever, normal labs, normal CT, and just a bit of a bellyache. Midway through, you might have abnormal labs, or maybe not. You might have a slightly abnormal CT, or it might be wildly abnormal, or in some rare cases it might be completely normal. Some people may or may not have the typical findings of vomiting, fever, decreased appetite, etc. Several days in, you would expect most people to have many or all of these findings, but that's not how every case plays out. There is so much variability, even with a reasonably straightforward diagnosis like appendicitis. This is on reason why things get missed.\n\nAdd in complicating factors, for example, let's say there is a language barrier or your patient is hearing impaired, or let's say it is a patient who already has chronic daily abdominal pain but now today it feels vaguely different to them. All of these things lead to diagnostic complexity. Let's say it is an asthma patient who is on daily steroids (this makes your white blood cell count go up). Is their mildly elevated white blood cell count related to their six hours of abdominal pain or the steroid? Let's say you get the elderly farmer who doesn't want to be there, but his daughter forced him to come in. Instead of giving you detailed answers, you get one-word answers and affirmative grunts.\n\nAI may eventually improve the diagnostic process, but there is so much gray area in medicine. I often tell patients that I do not give diagnosis in the ER, I give probabilities, and those probabilities change and fluctuate as the disease process progresses. It is a moving target. So maybe AI will be able to significantly improve this process, but I don't foresee a future where this is done independently of human intervention.\n\nAt the current moment, when I play around with Claude 3 or GPT4, it rarely gives me information that I hadn't already thought of. Say I have a chest pain patient. No matter how much data I might feed it to try to nail down a diagnosis, it always gives a range of diagnoses and probabilities that every physician has already considered. It's not thinking of the diagnosis that is elusive, it is sorting out which one is correct among overlapping symptoms, findings, and objective data. The problem is sometimes not an algorithmic one, rather it is subject to the massive variability of human illnesses from one person to the next, and this makes it extremely challenging even (especially?) for an AI system.\n\nOne thing I have managed to do is create an outstanding interactive textbook. I got access to Gemini 1.5 pro last week and uploaded a PDF copy of one of the major textbooks in my field. With careful prompting, I have been able to get it to quickly and accurately answer fairly esoteric questions and provide the page number where it got its answer. It is even able to make multi step decisions. I gave it a clinical scenario and asked for the next best treatment without stating a diagnosis, and it was able to sort it out and give the correct answer and page reference based on stepwise diagnosis exclusion, diagnosis inclusion, and then treatment planning. Pretty impressive stuff. But that is a scenario where I am giving it a classic textbook case of a condition, which rarely happens in the real world."
                },
                {
                    "body": "I have worked for doctors for most of my career, and without having read a single word of yours, I agree with the title of your post.\n\nedit: think I‚Äôm now shadow banned from the sub, cute\n\ndouble edit: not shadow banned, just experiencing intermittent client issues that mimic the same behavior apparently"
                },
                {
                    "body": "For me it's not only the inconsistent diagnosis but rather the lack of information that doctors have at their disposal.\n\nFor example, i live in a western country in one of the so-called most \"developed \"countries in the world and the doctor literally just uses this old tool to check my heartbeat and asked like one question and then that's it.\n\nWith the amount of wearable data that isn't getting shared to doctors and the lack of technological information not being shared is crazy. \n\nThis is why I'm so freaking hopeful because without a doubt in the next couple of decades we're going to look back at our health system and be shocked at how archaic it is."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Aurora[Playme][Genshin Impact]",
            "body": "",
            "upvote_ratio": 0.87,
            "subreddit": "StableDiffusion",
            "num_comments": 0,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://i.redd.it/sbj38qs1axpc1.jpeg",
            "comments": []
        },
        {
            "date": "20-03-2024",
            "title": "Nvidia has virtually recreated the entire planet ‚Äî and now it wants to use its digital twin to crack weather forecasting for good",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 145,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.techradar.com/pro/nvidia-has-virtually-recreated-the-entire-planet-and-now-it-wants-to-use-its-digital-twin-to-crack-weather-forecasting-for-good",
            "comments": [
                {
                    "body": "> They use a new Nvidia generative AI model called CorrDiff which is able to generate 12.5 times higher resolution images than current numerical models 1,000x faster and 3,000x more energy efficiently, as well as correcting inaccuracies from previous models, bringing together multiple sources of information to create much more accurate and focused forecasts.\n\nHoly shit what an exponential improvement"
                },
                {
                    "body": "All exponential growth now happening behind the closed door, no access to public, only announcements LOL."
                },
                {
                    "body": "The playful side of me wants to make a joke about more evidence that we are simulations and possible AGI‚Äôs in alignment training or someone‚Äôs Netflix 2035 prompt brought to life, but too many people take everything at face value on the internet because of a lack of inflection, tone, and body language here. \n\nInstead, I‚Äôll just say that we are collectively ASI‚Äôs in alignment training and UAP‚Äôs/UFO‚Äôs are entities aligning the ASI /s /s /s\n\n\nOn a more serious note, there is no doubt in my mind that we get the ‚Äúsingularity‚Äù before 2031. Random as all hell, but there‚Äôs always been a creeping doubt with predicting ai trends. \n\nWe definitely are on a path that we can‚Äôt turn back now. The gravity of it is‚Ä¶heavy. This is going to happen‚Ä¶good, bad or strange beyond current comprehension."
                },
                {
                    "body": "I hope its not the same Earth-2 as one which is selling virtual land..."
                },
                {
                    "body": "I new news;\n\nThe exponential growth in GPUs used to simulate the weather warms the globe up unprecedented!!"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Stability AI CEO Emad Mostaque told staff last week that Robin Rombach and other researchers, the key creators of Stable Diffusion, have resigned",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 539,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.forbes.com/sites/iainmartin/2024/03/20/key-stable-diffusion-researchers-leave-stability-ai-as-company-flounders/?sh=485ceba02ed6",
            "comments": [
                {
                    "body": "that's what he meant with SD3 being the last t2i model :/"
                },
                {
                    "body": "Well, these issues have been ongoing for a while. Honestly, I didn't think we'd ever see SD3 when there was that big wave of news on Stability's various woes last year, and I think they'll make it to the finish line there. Other than that, we'll see."
                },
                {
                    "body": "I wish they are able to release SD3 and SD3-Turbo before the whole thing collapses upon itself."
                },
                {
                    "body": "I wouldn‚Äôt be surprised if they set up a rival open source project and SAI becomes closed."
                },
                {
                    "body": "Rumors have been floating around that Stability AI was not doing good for months now. I was hoping it was just that, rumors.  Would REALLY suck to lose them as the are the only text to image open source out there...."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Huggingface CEO hints at buying SAI",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 140,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://twitter.com/ClementDelangue/status/1771395468959813922",
            "comments": [
                {
                    "body": "A reasonable ceo making a smart decision"
                },
                {
                    "body": "Just release SD3 please! We all need this!"
                },
                {
                    "body": "Huggingface is okay imo, their tools are awesome."
                },
                {
                    "body": "Full unnerfed version please."
                },
                {
                    "body": "Yes, please"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "I made a free tool for texturing 3D objects from home PC using Stable Diffusion. Now it has Multi-Projection, for better consistency + Forge support :)",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 100,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://v.redd.it/jp7l47ul6ppc1",
            "comments": [
                {
                    "body": "Awesome ! The crossover between 3D and AI is better and better, it's so cool"
                },
                {
                    "body": "This looks like a slam dunk! Where‚Äôs the tool at? I‚Äôd love to try it out."
                },
                {
                    "body": "wow i gonna have to try this with some of my blender models. good job."
                },
                {
                    "body": "like how many accounts does this dude have [https://www.reddit.com/r/StableDiffusion/comments/198al9w/i\\_created\\_a\\_free\\_tool\\_for\\_texturing\\_3d\\_objects/](https://www.reddit.com/r/StableDiffusion/comments/198al9w/i_created_a_free_tool_for_texturing_3d_objects/)  \nnow let the bot army comments how this will change the industry and life maybe  reality as we know it  \nPS : please open the link above and ctrl+F and type \"\\[deleted\\]\" and see how many bots i reported and they got banned of reddit . cool tool and all but until you apologize for the bot use i wont even let go.  \ndo a quick search on reddit and see how many account are sharing this tool\n\nEdit here is what i mean with other posts examples that have been older as this post when i posted this comment : \n\n  \nHuggingface CEO hints at buying SAI less than 400 upvotes  \nEmad Mostaque resigned from his role as CEO of Stability AI near 500 upvotes 144 comments  \nStabilityAI announces via X the release of Stable Video 3D! 500 upvotes ...\n\nand this MF uses bots to get his post to 750 upvotes , can a mod check this like really !!!"
                },
                {
                    "body": "Looks very well done. One suggestion, it's not clear if you're using an inpainting model or if the diffusion is trying to match the surrounding visual information, or otherwise using it as some sort of controlnet reference. If you're doing inpainting, an inpainting model performs so much better for it."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "I made a free tool for texturing 3D objects from home PC using Stable Diffusion. Now it has Multi-Projection, for better consistency + Forge support :)",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 100,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://v.redd.it/jp7l47ul6ppc1",
            "comments": [
                {
                    "body": "Awesome ! The crossover between 3D and AI is better and better, it's so cool"
                },
                {
                    "body": "This looks like a slam dunk! Where‚Äôs the tool at? I‚Äôd love to try it out."
                },
                {
                    "body": "wow i gonna have to try this with some of my blender models. good job."
                },
                {
                    "body": "like how many accounts does this dude have [https://www.reddit.com/r/StableDiffusion/comments/198al9w/i\\_created\\_a\\_free\\_tool\\_for\\_texturing\\_3d\\_objects/](https://www.reddit.com/r/StableDiffusion/comments/198al9w/i_created_a_free_tool_for_texturing_3d_objects/)  \nnow let the bot army comments how this will change the industry and life maybe  reality as we know it  \nPS : please open the link above and ctrl+F and type \"\\[deleted\\]\" and see how many bots i reported and they got banned of reddit . cool tool and all but until you apologize for the bot use i wont even let go.  \ndo a quick search on reddit and see how many account are sharing this tool\n\nEdit here is what i mean with other posts examples that have been older as this post when i posted this comment : \n\n  \nHuggingface CEO hints at buying SAI less than 400 upvotes  \nEmad Mostaque resigned from his role as CEO of Stability AI near 500 upvotes 144 comments  \nStabilityAI announces via X the release of Stable Video 3D! 500 upvotes ...\n\nand this MF uses bots to get his post to 750 upvotes , can a mod check this like really !!!"
                },
                {
                    "body": "Looks very well done. One suggestion, it's not clear if you're using an inpainting model or if the diffusion is trying to match the surrounding visual information, or otherwise using it as some sort of controlnet reference. If you're doing inpainting, an inpainting model performs so much better for it."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Stability AI Announcement - Earlier today, Emad Mostaque resigned from his role as CEO of Stability AI and from his position on the Board of Directors of the company to pursue decentralized AI.",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 298,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://stability.ai/news/stabilityai-announcement",
            "comments": [
                {
                    "body": "https://twitter.com/EMostaque/status/1771400218170519741\n\nEmad still owns a majority of voting shares at SAI, apparently. So it's not like he's powerless at the company now."
                },
                {
                    "body": "Fingers crossed that whoever takes over will be committed to open source (they will not)."
                },
                {
                    "body": "99% sure SD3 will not be free to download."
                },
                {
                    "body": "Hopefully it's good, although them mentioning \"commercializing\" their models could go either way. Obviously they have to make money, but does that mean no more model weight releases, or just a more financially competent and well-managed CEO? Only time will tell. Fingers crossed that we get SD3"
                },
                {
                    "body": "Reminder that the only reason we got raw SD 1.5 was because RunwayML chose to 'leak' it while Stability wanted time to censor it. Stability threw a fit and tried to get the model taken down. Now it's their turn. Let us see now, in their final moments, whether they're actually committed to local models or not. Pressure reveals one's true character."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "[D] When your use of AI for summary didn't come out right. A published Elsevier research paper",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "MachineLearning",
            "num_comments": 90,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bhn918",
            "comments": [
                {
                    "body": "that's where this insane competition for research output has gotten us to. it has become a matter of volume and quantitative metrics. research is supposed to take time. normally one paper per year was considered to be a normal output because of the amount of effort it takes to prepare, experiment, test and write from scratch. now it has become a matter of how many papers, and get as many citations as you can however you can do it (if you know what I mean, a lot of corruption in peer reviewed journals). \n\nit has become a joke. opportunistic research with little to no real effort is rewarded now."
                },
                {
                    "body": "It's like.. even those who wrote the paper didnt read it, why should anyone else?"
                },
                {
                    "body": "When I do it, it's plagiarism, when they do it, it's an enslaiver paper"
                },
                {
                    "body": "Link to paper: https://www.sciencedirect.com/science/article/pii/S1930043324001298"
                },
                {
                    "body": "This is one idiot who uses the model service and the rest of the coauthor team who are lazy and can't be bothered to help read/proofread a paper that bears their name"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Experimenting with character consistency",
            "body": "",
            "upvote_ratio": 0.84,
            "subreddit": "StableDiffusion",
            "num_comments": 129,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1blkhq8",
            "comments": [
                {
                    "body": "That went r/suddenlygay real quick"
                },
                {
                    "body": "Was expecting the girls to walk in and find them making out"
                },
                {
                    "body": "You REALLY made it look like the bfs were gonna become each others bfs for a second"
                },
                {
                    "body": "Oh shit this was r/stableDiffusion?? I though this was a legit comics hand drawned this whole time, well played maboi"
                },
                {
                    "body": "Any tips? That is really good character consistency."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "What is the cause of more and more r√©gulations on Open source AI??",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 164,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/vganj0mnj9qc1.png",
            "comments": [
                {
                    "body": "less opportunities for everyone so less competitions."
                },
                {
                    "body": "Well the answer üí≤ is üí≤ obvious üí≤"
                },
                {
                    "body": "Money, power, and competition.\n\nIf he gets his way, no more startups that can provide a better service, and he can keep creating more and more robots that China cant."
                },
                {
                    "body": "I doubt it is just Altman.  There are many powerful people in the world who stand to benefit from depriving 99.99% of humanity of any form of power.  \n\nThe ability to have a capable and affordable lawyer, a tireless journalist who can accurately report on all activities of the elite, employees being able to prove wage theft committed by their bosses beyond a doubt...all these possibilities threaten people who very much like their spot on the totem pole.\n\nWhile there are ethical considerations for AI, I am far more concerned with the people who use regulation as a fig leaf.  Without that cover, it would be very obvious how powerful people intend to assert their dominance:  Keeping us over a barrel, and gaslighting us into thinking we should be grateful for what happens."
                },
                {
                    "body": "I just cancelled my GPT subscription.  Fuck OpenAI"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "I took my own 3D-renders and ran them through SDXL (img2img + controlnet)",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 79,
            "submission_flair": "Comparison",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bio7rq",
            "comments": [
                {
                    "body": "That is such a great idea! Gotta dig up some of my very old Blender tenders and give it a try!"
                },
                {
                    "body": "Impressive 3D work."
                },
                {
                    "body": "I like how well this showcases SDs strengths and weaknesses.\n\nIt's color and lighting choices make improvements pretty much across the board, but, at least to me, the concepts are more boring. It has a habit of over polishing everything to the point it loses that eerie sense your renders create.\n\nExample in the first one, your blank mannequin mask is way more interesting and fitting for the scene to me then the \"evil robot scary face\" it got replaced with, but the background looks way better."
                },
                {
                    "body": "I prefer the originals."
                },
                {
                    "body": "SDXL change a bit too the image, maybe u need to lower denoise strength? As someone said i prefer the originals except for the astronaut image"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Microsoft CEO on owning OpenAI, from Elon vs OpenAI lawsuit",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 198,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/29vuxqukhppc1.jpeg",
            "comments": [
                {
                    "body": "Ah, yes. Good to know that Larry Page is fine with humans going extinct.\n\nhttps://preview.redd.it/fg2erh4nnppc1.png?width=1035&format=png&auto=webp&s=426ecd96aac8d3ed8e90d23d8024c59ff09e7c29"
                },
                {
                    "body": "[Original document](https://www.scribd.com/document/710894515/Elon-Musk-v-Samuel-Altman-et-al-via-CNBC-com)"
                },
                {
                    "body": "Humm, well I don't like the sound of that generally (if true) and I guess it does go to bolster Elon's argument that OpenAI have kind of sold the rights/IP to another company. Though who knows what the contract etc is between OpenAI and MS, and god knows the legal world is a complicated one."
                },
                {
                    "body": "\"Me, me, me it's all mine.  We're so powerful.  I'm going to control everyone and they will worship me!\"  \nNot the AI direction we were hoping for."
                },
                {
                    "body": "These are separate statements that were put together. I believe the only reason this lawsuit was made was to spread disinformation like this.\n\nEdit: here is what I commented on another post\n\nI actually found the interview where part of this was said. Having looked up the quote \"have all the IPrights and all the capability\" led to this interview [https://www.cnbc.com/video/2023/11/20/microsoft-ceo-satya-nadella-microsoft-can-innovate-on-its-own-but-we-chose-to-partner-with-openai.html](https://www.cnbc.com/video/2023/11/20/microsoft-ceo-satya-nadella-microsoft-can-innovate-on-its-own-but-we-chose-to-partner-with-openai.html)   The context here is that he was stating that microsoft already had the technology to do it  without OpenAI but instead chose to partner with them.  There also statements in the filling that were never said on this interview so either fragments of other statements put together to seem he is saying something he isn't, which is unfortunely not uncommon on frivolous lawsuits, or worse, complete fabrications.   But hey the misinformation is already out, which is what this lawsuit is all about.\n\n The context of the other quote:   \n  \n[https://nymag.com/intelligencer/2023/11/on-with-kara-swisher-satya-nadella-on-hiring-sam-altman.html](https://nymag.com/intelligencer/2023/11/on-with-kara-swisher-satya-nadella-on-hiring-sam-altman.html)  \n\"Nadella: And that gives us significant rights as I said. And also this thing, it‚Äôs not hands off, right? We are in there. We are below them, above them, around them. We do the kernel optimizations, we build tools, we build the infrastructure. So that‚Äôs why I think a lot of the industrial analysts are saying, ‚ÄúOh wow, it‚Äôs really a joint project between Microsoft and OpenAI.‚Äù The reality is we are, as I said, very self-sufficient in all of this.\"\n\nSo again it seems that the context here is that Microsoft is not dependent on OpenAI for AI R&D."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Microsoft CEO on owning OpenAI, from Elon vs OpenAI lawsuit",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 198,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/29vuxqukhppc1.jpeg",
            "comments": [
                {
                    "body": "Ah, yes. Good to know that Larry Page is fine with humans going extinct.\n\nhttps://preview.redd.it/fg2erh4nnppc1.png?width=1035&format=png&auto=webp&s=426ecd96aac8d3ed8e90d23d8024c59ff09e7c29"
                },
                {
                    "body": "[Original document](https://www.scribd.com/document/710894515/Elon-Musk-v-Samuel-Altman-et-al-via-CNBC-com)"
                },
                {
                    "body": "Humm, well I don't like the sound of that generally (if true) and I guess it does go to bolster Elon's argument that OpenAI have kind of sold the rights/IP to another company. Though who knows what the contract etc is between OpenAI and MS, and god knows the legal world is a complicated one."
                },
                {
                    "body": "\"Me, me, me it's all mine.  We're so powerful.  I'm going to control everyone and they will worship me!\"  \nNot the AI direction we were hoping for."
                },
                {
                    "body": "These are separate statements that were put together. I believe the only reason this lawsuit was made was to spread disinformation like this.\n\nEdit: here is what I commented on another post\n\nI actually found the interview where part of this was said. Having looked up the quote \"have all the IPrights and all the capability\" led to this interview [https://www.cnbc.com/video/2023/11/20/microsoft-ceo-satya-nadella-microsoft-can-innovate-on-its-own-but-we-chose-to-partner-with-openai.html](https://www.cnbc.com/video/2023/11/20/microsoft-ceo-satya-nadella-microsoft-can-innovate-on-its-own-but-we-chose-to-partner-with-openai.html)   The context here is that he was stating that microsoft already had the technology to do it  without OpenAI but instead chose to partner with them.  There also statements in the filling that were never said on this interview so either fragments of other statements put together to seem he is saying something he isn't, which is unfortunely not uncommon on frivolous lawsuits, or worse, complete fabrications.   But hey the misinformation is already out, which is what this lawsuit is all about.\n\n The context of the other quote:   \n  \n[https://nymag.com/intelligencer/2023/11/on-with-kara-swisher-satya-nadella-on-hiring-sam-altman.html](https://nymag.com/intelligencer/2023/11/on-with-kara-swisher-satya-nadella-on-hiring-sam-altman.html)  \n\"Nadella: And that gives us significant rights as I said. And also this thing, it‚Äôs not hands off, right? We are in there. We are below them, above them, around them. We do the kernel optimizations, we build tools, we build the infrastructure. So that‚Äôs why I think a lot of the industrial analysts are saying, ‚ÄúOh wow, it‚Äôs really a joint project between Microsoft and OpenAI.‚Äù The reality is we are, as I said, very self-sufficient in all of this.\"\n\nSo again it seems that the context here is that Microsoft is not dependent on OpenAI for AI R&D."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Vernor Vinge talking about how a hard takeoff intelligence explosion could happen in as little as 100 hours",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 333,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/tsarnick/status/1771309166055047661?s=20",
            "comments": [
                {
                    "body": "Not really related to AI, but the analogy of a paleolithic human \"evolving\" in an afternoon what would take biological evolution maybe thousands of years (if not more) is a really interesting way to look at it. \n\nHuman creates spear, picks up spear, suddenly humans have evolved long pointy spears."
                },
                {
                    "body": "We are inching closer to recursive improvements across everything"
                },
                {
                    "body": "damn it would suck and be the worst timing if the singularity happens 100 hours after Vernor Vinge dies"
                },
                {
                    "body": "RIP. Hopefully, we'll find a way to resurrect him."
                },
                {
                    "body": "It'll be like a rocket launch where a million bros try to hold onto it sending it messages about turning $1000 into a million, lol."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "New CEO of Microsoft AI: humanity may need to pause AI in the next 5 years. ",
            "body": "\"The 39-year-old Briton said there might have to be a pause in development towards the end of the decade.\"\n\n‚ÄúI don‚Äôt rule it out. And I think that at some point over the next five years or so, we‚Äôre going to have to consider that question very seriously,‚Äù he said.\n\nPreviously, he said: \"the world is still struggling to appreciate how big a deal [AI's] arrival really is.\"\n\n\"We are in the process of seeing a new species grow up around us.\"\n\nHe also thinks this new species may be capable of becoming self-made millionaires in as little as 2 years.\n\nHe is not alone - Google DeepMind's Chief AGI Scientist Shane Legg said: \"If I had a magic wand, I would slow down.‚Äù \n\n‚Äú[AGI] is like the arrival of human intelligence in the world.  \n\nThis is another intelligence arriving in the world.‚Äù",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 525,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bk4kzk/new_ceo_of_microsoft_ai_humanity_may_need_to/",
            "comments": [
                {
                    "body": "From a geopolitical point of view, any country can not stop advancing in AI, if they decide to do so, some other country will take advantage. AI is a powerful resource for any country.\n\nSimilar to nuclear bombs i would say"
                },
                {
                    "body": "The problem with such a slow down is that you would need the entire world to agree to it"
                },
                {
                    "body": "Who exactly would have the authority to do that?"
                },
                {
                    "body": "This narrative has been serving the closed-source labs pretty well so far."
                },
                {
                    "body": "This is what bugged me about Suleyman‚Äôs book, The Coming Wave. He seems to be a big fan of the status quo and while he loves advanced technology, he just doesn‚Äôt want it to be too disruptive. I say to hell with that. It‚Äôs easy for a millionaire to be comfortable with the status quo. It‚Äôs not so easy on everybody else. Slow-rolling the singularity is a terrible idea."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "From the NVIDIA GTC, Nvidia Blackwell, well crap",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 264,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://i.redd.it/evf8juzlk5pc1.png",
            "comments": [
                {
                    "body": "That thing must be 10 million dollars, if it has the same VRAM as H200 and goes for 50k a GPU + everything else."
                },
                {
                    "body": "*Millions of 4090s suddenly cried out in terror and were suddenly silenced*"
                },
                {
                    "body": "\"The fabric of NVLink, the spine, is connecting all those 72 GPUs to deliver an overall performance of 720 petaflops of training, 1.4 exaflops of inference,\" Nvidia's accelerated computing VP Ian Buck told DCD in a pre-briefing ahead of the company's GTC conference.\n\n\"Overall, the NVLink domain can support a model of 27 trillion parameters and 130 terabytes of bandwidth.\"\n\nThe system has two miles of NVLink cabling across 5,000 cables. \"In order to get all this compute to run that fast, this is a fully liquid cooled design\" with 25 degrees water in, 45 out."
                },
                {
                    "body": "We can finally train grok."
                },
                {
                    "body": "Just think... in 10 years, we'll be able to get one on Ebay...\n\nA man can dream."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Emad resigned from Stability AI ",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 122,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/u0ou59yta0qc1.jpeg",
            "comments": [
                {
                    "body": "Probably a bad CEO in terms of providing a return to investors, but without his actions SD would no doubt have been a private/paid model. He did good for the common man I'd say.\n\nHopefully SD3 can still be released OpenSource as much as possible."
                },
                {
                    "body": "One of the few good guys left in AI. When he said SD 3 would be the last version he wasn't lying I suppose..."
                },
                {
                    "body": "Fuck; can't tell if that's good or bad but I suppose it was inevitable. Hope we can get SD3 without issue and his visions of AI Equity come to fruition."
                },
                {
                    "body": "He sacrificed his job and millions of investors money so that we can generate images for free. Respect üôè"
                },
                {
                    "body": "Literally the only ethical move one can make in AI at this point. Respect!"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "StabilityAI is alive and will live! There were rumors that SD3 could become closed and so on... These rumors will be dispelled now. small, but still important news:",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 161,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://i.redd.it/iy1me76sdbqc1.jpeg",
            "comments": [
                {
                    "body": "Its great that they are doing that. One of Stable Diffusion‚Äôs biggest advantage is the customizability of their models with finetuning, lora, controlnet and etc. If they make it closed source, they will have 0 advantage against Midjourney, OpenAI and etc."
                },
                {
                    "body": "https://preview.redd.it/3q8daalvacqc1.jpeg?width=1280&format=pjpg&auto=webp&s=1e29dccc8867b15fdda6f4e0268764b298d62b9a"
                },
                {
                    "body": "Cant wait for folks to undo all the'safety' restrictions once the code goes live."
                },
                {
                    "body": "The stark cynicism in this subreddit lately is a testament to the extreme distrust that big tech has sown in the last couple of decades. [Enshittification](https://en.wikipedia.org/wiki/Enshittification) is now accepted as axiomatic."
                },
                {
                    "body": "Keep in mind, that is not a promise he can keep. He is only \"co-interim CEO at Stability AI\" (to quote his Twitter bio). The other interim CEO, or real CEO, could overrule it, or the board could overrule it. Until the actual checkpoints are downloaded by someone with an accompanying FLOSS `LICENSE` file, SD3 can still be closed-sourced after all."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Mysterious Q*",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 259,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/ptltcajb25pc1",
            "comments": [
                {
                    "body": "I feel like they did a good job keeping Sora secret, especially if it‚Äôs true that they‚Äôve had it for the better part of a year.\n\nWe knew they were working on multi-modality but I don‚Äôt remember any rumors that they were gonna suddenly blow everyone else out of the water with text-to-video."
                },
                {
                    "body": "Sam Altman is one fun AGI"
                },
                {
                    "body": "I see the way he answered it as theatrics to build up hype."
                },
                {
                    "body": "ohhhh spicy"
                },
                {
                    "body": "So the interesting part is he doesn't outright deny that it exists. He basically said they're not ready to talk about it, which means it's real, but they can't speak about it at this point in time. \n\nWhether the leaks are accurate regarding Q*'s capabilities is another question entirely though"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Meta Introduces SceneScript, a novel approach for 3D scene reconstruction",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 64,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/o0ut1w22ttpc1",
            "comments": [
                {
                    "body": "Link: [https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/](https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/)"
                },
                {
                    "body": "The AR potential for this, oh my"
                },
                {
                    "body": "This is an SfM algorithm. What‚Äôs impressive is this is running real time on the headset."
                },
                {
                    "body": "I don't even know what's real anymore. \n\nAm I looking at an actual apartment with an overlay being plotted in real time? Or is this a procedurally built floorplan with AI image generation of the furnishings being rendered in real time?"
                },
                {
                    "body": "I bet they got some good data off of all of the quest 2 and quest 3 people setting up roomscales."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Soon, Everyone Will Own a Robot, Like a Car or Phone Today. Says Figure AI founder",
            "body": "Soon, Everyone Will Own a Robot, Like a Car or Phone Today\nSays Figure AI founder, Brett Adcock",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 323,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://analyticsindiamag.com/soon-everyone-will-own-a-robot-like-a-car-or-phone-today/",
            "comments": [
                {
                    "body": "Define \"soon\". I think it might take some time.\n\n\nI mean, today's models are very poorly aligned and can easily be jailbroken. Which isn't a big deal as all they can do is output scary text.\n\n\nWhat happens if you jailbreak a robot?\n\n\n\nAnd then i'm guessing as a customer u may have to both pay to buy the robot, and then pay for the compute of the model that powers it... that seems fairly expensive. I am not sure average people will be able to afford that."
                },
                {
                    "body": "Sweet. Can't wait for a robot to do all my chores."
                },
                {
                    "body": "Anyway, while I do own a house and a car, yesterday what I had to eat was a bowl of rice, scrambled eggs, a little ground beef, and lentil soup. Point being, I‚Äôm not going to be able to afford a $50,000 home appliance."
                },
                {
                    "body": "Soon everyone will buy my product, says product maker."
                },
                {
                    "body": "Sell your car, move to the city, save for robot."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "StabilityAI announces via X the release of Stable Video 3D!",
            "body": "And its commercial version as well as the non-commercial version are available, the latter on [Hugginface](https://huggingface.co/stabilityai/sv3d/tree/main)\n\n[Link to the StabilityAI post on X](https://twitter.com/StabilityAI/status/1769817136799855098)\n\nhttps://preview.redd.it/g6gv6ao6q5pc1.png?width=830&format=png&auto=webp&s=fca460aa6dfb06afcc2538048137939d5845c1b8\n\n",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 109,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bi0sul/stabilityai_announces_via_x_the_release_of_stable/",
            "comments": [
                {
                    "body": "&#x200B;\n\nhttps://preview.redd.it/tlw0vu4rk5pc1.png?width=1024&format=png&auto=webp&s=23a7103f7af5f4f30e30e1737fca79ac07e4dc6e"
                },
                {
                    "body": "[https://stability.ai/news/introducing-stable-video-3d](https://stability.ai/news/introducing-stable-video-3d)"
                },
                {
                    "body": "Vram?"
                },
                {
                    "body": "Reset your clocks everyone. We made it ONE DAY between major AI announcements. The exponential progress is insane.¬†"
                },
                {
                    "body": "Can I make a mesh with this?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Sam Altman: OpenAI, GPT-5, Sora, Board Saga, Elon Musk, Ilya, Power & AGI | Lex Fridman Podcast",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 372,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=jvqFAi7vkBc",
            "comments": [
                {
                    "body": "\"We will release an amazing new model this year, I don't know what we will call it\"\n\n\"We will release many different things in the coming months\" \n\n\"We have a lot of other important things to release first before GPT 5\"\n\n\\-Sam Altman"
                },
                {
                    "body": "GPT summary of the transcript, in regards to new information about GPT-5:\n\n- OpenAI plans to release an amazing model within the year, though it's not specified if it will be called GPT-5.\n- The leap from GPT-4 to the next model (potentially GPT-5) is expected to be significant, with improvements across the board.\n- OpenAI is exploring ways to make AI models smarter and more capable of understanding and generating content.\n- The company is interested in developing models that can act as brainstorming partners and assist in creative and knowledge work tasks more effectively.\n- OpenAI is working on enhancing models to handle longer horizon tasks, breaking them down into multiple steps and executing them with varying levels of abstraction.\n- The organization is considering more iterative releases to avoid shocking updates to the world and to allow society to adapt to advancements in AI technology gradually.\n- OpenAI acknowledges the importance of safety and governance in AI development and emphasizes that no single person should have total control over AGI or the direction of AI development.\n- The conversation touched on the potential for AI to significantly increase the rate of scientific discovery, indicating OpenAI's interest in contributing to advancements in various fields through AI.\n- Sam Altman expressed hope for the future of humanity and the collective achievements of civilization, highlighting the collaborative nature of technological progress.\n\nGPT summary of the transcript in general, not just in regards to GPT-5:\n\n- **Compute as Future Currency**: Sam Altman believes compute will become one of the most precious commodities in the world, essential for the development of advanced AI systems.\n\n- **OpenAI Board Saga**: Reflecting on the tumultuous period involving OpenAI's board, Altman described it as a painful professional experience but also a learning opportunity for organizational resilience and governance.\n\n- **Power and Trust**: Altman discussed the importance of not having too much power concentrated in any single individual's hands, including his own, within OpenAI or in the development of AGI.\n\n- **Safety and Governance**: The conversation emphasized the need for robust safety measures and governance structures as AI technology advances, with a focus on ensuring that AI benefits humanity broadly.\n\n- **Collaboration vs. Competition**: Altman expressed a desire for more collaboration in the AI field, especially on safety, despite the competitive dynamics with other companies like Google, Meta, and XAI.\n\n- **Sora and Visual AI**: Altman shared insights on OpenAI's Sora, highlighting its capabilities in generating video content and discussing the challenges and potential of visual AI models.\n\n- **GPT-4 and Beyond**: The discussion covered the impact of GPT-4, including its role as a brainstorming partner and its limitations, with Altman looking forward to future models that offer even greater capabilities.\n\n- **AI in Programming**: Altman speculated on the future role of AI in programming, suggesting that natural language could become a primary interface for coding, changing the nature of programming work.\n\n- **Humanoid Robots**: The potential for OpenAI to return to robotics was mentioned, with Altman expressing hope for the development of humanoid robots or physical agents capable of interacting with the world.\n\n- **Existential Risks and AGI**: While acknowledging the importance of considering existential risks associated with AI, Altman noted that his top concerns are more immediate and practical challenges in AI development and deployment.\n\n- **Simulation Hypothesis**: The conversation touched on the philosophical implications of AI's ability to generate simulated worlds, with Altman sharing his thoughts on the possibility that we might live in a simulation.\n\n- **Alien Civilizations**: Altman expressed his belief in the likelihood of intelligent alien civilizations existing elsewhere in the universe, despite the puzzling nature of the Fermi paradox.\n\n- **Hope for Humanity**: Despite the challenges, Altman conveyed a sense of optimism about humanity's future, emphasizing the collective achievements and potential for further progress through technology and AI.\n\nGenerated with GPT-4-turbo."
                },
                {
                    "body": "* Can you speak to what Qstar is?\n* We are not ready to talk about that\n\nAltman's LLM on restriction"
                },
                {
                    "body": "Q* is real."
                },
                {
                    "body": "He essentially confirms Q\\* in this"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Looks like they finally lobotomized Claude 3 :( I even bought the subscription",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 182,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://i.redd.it/mdl8d9gkr3qc1.png",
            "comments": [
                {
                    "body": "I noticed this with Claude 3 and GPT too. Avoid using the term \"script\", and avoid using \"can you\" .\n\nInstead, make it seem like you're already working on the code, that it is your code , and you need to further develop it. Once it starts to accept it without rejection initially, you can continue the conversation to build pieces upon it to fully make it functional. Do not push it to create the content directly on the first prompt. It will reject it. The longer the context goes on with positive respones to your prompts, the more likely and better code it will write.\n\nhttps://preview.redd.it/dqjdt9syu3qc1.png?width=1546&format=png&auto=webp&s=d49795f4b467ec125db8efdf07601f80ba90e233"
                },
                {
                    "body": "They're gaslighting you at this point."
                },
                {
                    "body": "That's why locally run open source is still the best"
                },
                {
                    "body": "I just tried your exact prompt on anthropic‚Äôs API and non of the claude 3 models (opus, sonnet & haiku) refuse to answer. Opus & Sonnet did claim the image is not a normal map, but both asking them to proceed and simply leaving out the image both made them write code.¬†\n\nI can‚Äôt verify the correctness of the code since I have no experience with normal maps, but they didn‚Äôt refuse for me. Perhaps the subscription-based models are system-prompted to refuse more?"
                },
                {
                    "body": ">inappropriate content creation\n\n\nlol i love this euphemism. keep your content creation appropriate, citizen!"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "The models we are currently using daily (GPT4, Gemini 1 Ultra, Claude) are only at 2022 level compute. Nvidia just skyrocketed this to the stars. AI recursively designing 27 trillion parameter AI models orders of magnitue times more efficient and faster at inference and reasoning incoming.",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 158,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/mpabdl5vmdpc1.jpeg",
            "comments": [
                {
                    "body": "There isn't a seatbelt strong enough for this ride..."
                },
                {
                    "body": "Yeah I liked how AI Explained put it in his latest video, that \"the public hasn't begun to grasp what even 2023 levels of compute could do for training a language model\". Right now we're all waiting for OpenAI's next release so we can finally judge for ourselves: what can current SOTA AI models *really* do?"
                },
                {
                    "body": "We are on the part where exponential growth is happening, but things still take time.\n\nIt will take some time to produce enough hardware to equip new datacenters."
                },
                {
                    "body": "Time to watch the I Have No Mouth and I Must Scream intro again.\n\nHow many parameters was SORA again?"
                },
                {
                    "body": "Nvidia's new chip is just two of their old chips bolted together +20%.  I think algorithmic efficiency is where gains come from, but that's easy to talk about without proof."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Vernor Vinge, sci-fi author who coined the term \"technological singularity\", has died.",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 128,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://file770.com/vernor-vinge-1944-2024/",
            "comments": [
                {
                    "body": "[The Coming Technological Singularity](https://edoras.sdsu.edu/~vinge/misc/singularity.html) written in 1993.\n\n[Predicted AGI between 2005 and 2030](https://historyofinformation.com/detail.php?id=2141).\n\n---\n\nFrom the above:\n\n   >What about the '90s and the '00s and the '10s, as we slide toward\n         the edge? How will the approach of the Singularity spread across the\n         human world view? For a while yet, the general critics of machine\n         sapience will have good press. After all, till we have hardware as\n         powerful as a human brain it is probably foolish to think we'll be\n         able to create human equivalent (or greater) intelligence. (There is\n         the far-fetched possibility that we could make a human equivalent out\n         of less powerful hardware, if were willing to give up speed, if we\n         were willing to settle for an artificial being who was literally slow\n         [29]. But it's much more likely that devising the software will be a\n         tricky process, involving lots of false starts and experimentation. If\n         so, then the arrival of self-aware machines will not happen till after\n         the development of hardware that is substantially more powerful than\n         humans' natural equipment.\n\n  >But as time passes, we should see more symptoms. The dilemma felt\n         by science fiction writers will be perceived in other creative\n         endeavors.  (I have heard thoughtful comic book writers worry about\n         how to have spectacular effects when everything visible can be\n         produced by the technically commonplace.) We will see automation\n         replacing higher and higher level jobs. We have tools right now\n         (symbolic math programs, cad/cam) that release us from most low-level\n         drudgery. Or put another way: The work that is truly productive is the\n         domain of a steadily smaller and more elite fraction of humanity. In\n         the coming of the Singularity, we are seeing the predictions of _true_\n         technological unemployment finally come true.\n\n>Another symptom of progress toward the Singularity: ideas\n         themselves should spread ever faster, and even the most radical will\n         quickly become commonplace.  When I began writing, it seemed very easy\n         to come up with ideas that took decades to percolate into the cultural\n         consciousness; now the lead time seems more like eighteen months. (Of\n         course, this could just be me losing my imagination as I get old, but\n         I see the effect in others too.) Like the shock in a compressible\n         flow, the Singularity moves closer as we accelerate through the\n         critical speed."
                },
                {
                    "body": "That sucks! I say that respectfully, of course, but not being able to see singularity becoming a reality in his lifetime is a very sad end."
                },
                {
                    "body": "A Fire Upon The Deep should be on everyone's reading list."
                },
                {
                    "body": "Oh man\n\n\nHe was one of the greatest sci fi writers of the 20th/ 21st century \n\nAnd his timeline proved better than kurzweils imo. His confidence interval for singularity was 2005-2030.\n\nRIP champ. Most people might think kurzweil invented this space but us OGs remember it was you"
                },
                {
                    "body": "I gasped when I read the headline. This is heartbreaking. The man who showed us the path towards the future couldn't live to see the future. When the singularity arrives, his name shall be immortalized as one of the pioneers of our future. May we defeat death in the years to come so that people no more have to face the reaper.  \nI hope death is just a wall, and not truly the end.  \nWherever he is in the great infinite unknown, I hope he is at peace.  \nRest in Peace Sir."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Nvidia announces ‚Äúmoonshot‚Äù to create embodied human-level AI in robot form | Ars Technica",
            "body": "This is the kind of thing Yann LeCun has nightmares about, saying it's fundamentally impossible for LLMs to operate at high levels in the real world.   \n\nWhat say you?  Would NVIDIA get this far with Gr00t without evidence LeCun is wrong?  If LeCun is right, how many companies are going to lose the wad on this mistake?",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 111,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://arstechnica.com/information-technology/2024/03/nvidia-announces-moonshot-to-create-embodied-human-level-ai-in-robot-form/",
            "comments": [
                {
                    "body": "The only reason Yann LeCun would have nightmares about this would be because he missed out on buying NVIDIA stock lol \n\nHe argues that text-powered auto-regressive LLMs **alone** cannot lead to general intelligence. He believes **knowledge grounding** is instrumental.  \n\nImagine this scenario: Executing a real-life task could involve several steps. \n\nFirst, foundational models trained on text corpus, image datasets, and sensory information would generate around 100 multi-step possibilities to fulfill a prompt. (which might what the article is referring to).\n\nThen, these possibilities should be acted out virtually to find the most optimal and safest solution. NVIDIA has invested heavily in simulation labs (Issac is nice), which signals such an implementation.\n\nAt last, this proposed plan can be acted out in the real world.     \n\nBy implying that LeCun has nightmares, you assume that NVIDIA is only using text tokens to train the foundational model, which is not true. Autoregressive LLMs are not AGI!"
                },
                {
                    "body": "First off, what Nvidia and most people in robotics are doing is way more than just using LLMs. Transformer models come in all shapes and sizes and can be trained on various things besides text with the right architecture. LeCun never said you couldn't achieve these kinds of results with current auto regressive LLMs. He said you couldn't get a system running on these kind of things to generalize across physical domains.\n\nI think he's 100% right in that. If we get robots that are able to perform all tasks humans can It's likely not because they have generalized and unlocked the ability to learn on their own and use knowledge from one domain in another. It's way more likely that it will be systems that are specifically trained on an enourmos amount of data, be it text, video, actions / teleoperation mimicking you name it. \n\nThese systems will be absolutely incredible but for true generalisation we'll need something else. Most people don't understand the limitations of the current systems and what actual intelligence would require."
                },
                {
                    "body": "Apparently LeCun has no internal monologue. \n\nWhich might explain his inability to rate language models as useful. I don‚Äôt think he has any real  intuition on what language models can achieve.\n\nEdit: Amusingly [apt timing](https://www.reddit.com/r/OpenAI/s/p4uR9aanLD)"
                },
                {
                    "body": "Why anyone takes a statement from LeCum serious after the countless false claims he has made up until now is just beyond me..."
                },
                {
                    "body": "LLMs enabled Eureka. LLMs need less critique and more effective utilization."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "üî• ComfyUI - Creating a Character Turntable with SV3D",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 37,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/0tczedmt78qc1",
            "comments": [
                {
                    "body": "\\[ üî• ComfyUI - Creating a Character Turntable with SV3D \\]\n\n1. Generate a single full-body pose image\n2. Create a 21-image turntable based on the image with SV3D\n3. Polish the turntable continuity using AnimateDiff\n4. Enhance facial details using Controlnet, Lora, Deatiler, and more.\n5. It really comes out fast and well. It seems like there's a lot to try if used properly! üòÉ"
                },
                {
                    "body": "how was this done? how do you Polish the turntable continuity using AnimateDiff to get it so consistent? can you provide comfy file please?"
                },
                {
                    "body": "i think we're very close to generating 3D models with a realistic workflow and import directly into engine"
                },
                {
                    "body": "if can t pose her, 3d photographometry software might work wihth that"
                },
                {
                    "body": "Please teach us, this might make me finally move to comfy."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Nvidia's GB200 NVLink 2 server enables deployment of 27 trillion parameter AI models",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 148,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html",
            "comments": [
                {
                    "body": "\\~20x GPT4. this could be the thing that powers the first AGI"
                },
                {
                    "body": "This is the mother of AGI"
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": ">**1. Architecture:** Nvidia unveiled the Blackwell architecture, succeeding the Hopper architecture. The first Blackwell chip, GB200, combines two B200 GPUs and one Arm-based Grace CPU, offering 20 petaflops of AI performance compared to 4 petaflops for the H100.\n\n>**2. Chip Design:** The Blackwell GPU is a large chip that combines two separately manufactured dies into one, produced by TSMC. It includes a transformer engine specifically designed for transformer-based AI.\n\n>**3. Scalability:** Nvidia will sell B200 GPUs as part of a complete system, the GB200 NVLink 2, which combines 72 Blackwell GPUs and other Nvidia components for training large AI models. The system can deploy models with up to 27 trillion parameters.\n\n>**4. Software:** Nvidia introduced NIM (Nvidia Inference Microservice), a software product that simplifies the deployment of AI models on older Nvidia GPUs. NIM is part of the Nvidia Enterprise software subscription and enables efficient inference on customers' servers or cloud-based Nvidia servers.\n\n>**5. Ecosystem:** Major cloud providers like Amazon, Google, Microsoft, and Oracle will offer access to GB200 through their services. Nvidia is collaborating with AI companies to optimize their models for all compatible Nvidia chips.\n\n>**6. Market Position:** Nvidia aims to solidify its position as the leading AI chip provider by offering a comprehensive hardware and software platform. The announcement comes amid high demand for current-generation H100 chips driven by the AI boom.\n\n*Summary by Claude Opus*"
                },
                {
                    "body": "holy shit.  this is game changing"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Cyberpunk 2077 gameplay using a ps1 lora",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 76,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/q9ghpuli6epc1",
            "comments": [
                {
                    "body": "Lol, that looks like GTA Vice City"
                },
                {
                    "body": "wdym thats just how the game looked on ps4"
                },
                {
                    "body": "LOL That's how it's released on PS4 initially\n\nJokes aside, really nice experiment. Although it's super flickery. I wonder what kind of result it would [give if something like this would be applied to it](https://youtu.be/P1IcaBn3ej0)"
                },
                {
                    "body": "That was weird, but it still looks playable. I bet the cutscenes look like A Scanner Darkly."
                },
                {
                    "body": "I played this game too much I was able to recognize the place even with the filter lol. At least I think I did, is it near the afterlife?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Tesla ready to use humanoid robots to produce electric cars",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 244,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://uk.motor1.com/news/713436/tesla-robot-optimus-ready-produce-cars-factory/",
            "comments": [
                {
                    "body": "I was waiting for the next pie in the sky announcement to help pump the stock."
                },
                {
                    "body": "Fuck those cars, what about putting a wig on it and making me cum? When can they handle that?"
                },
                {
                    "body": "Is the human anatomy really the most optimal for making cars?"
                },
                {
                    "body": "Bullshit. Like other things with Tesla, they are way too optimistic"
                },
                {
                    "body": "No they're not"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[D] Feeling burnt out after doing machine learning interviews",
            "body": "I have been interviewing for Machine Learning Engineer and related positions for the last 2 months from big tech companies to small startups. There are so many different flavors of interviews and it seems all over the place. Even after interviewing for 10 different companies and more than 30 interviews later, I have had no success. I have either been ghosted or rejected from all of them.\n\nSome of the kinds of interviews I have had are:\n\n1. Leetcode-style coding questions.\n2. Implement machine learning algorithms like SVM or some component of algorithms like backpropagation or convolution from scratch.\n3. Programming language-related questions in depth like about Python GIL or about C++ pointers.\n4. OOP-related theoretical and implementation questions.\n5. Typical SWE style system design interviews like design Instagram\n6. Machine learning system design interviews like a design a recommendation system.\n7. Machine learning theoretical questions like what is hinge loss or explain logistic regression or when could KL divergence be used.\n8. Deep learning theoretical questions like what's the difference between SGD and Adam, what is quantization in neural networks, how can you speed up inference of a deep learning model.\n9. Computer Vision theoretical questions like what's the difference between YOLO and FasterRCNN, what loss function could be used for image segmentation, or explain epipolar geometry.\n10. Natural Language Processing theoretical questions like how transformers are better than RNNs, what is bidirectional in BERT or what is the difference between stemming and lemmatization.\n11. Previous work, previous research paper, previous project-related questions.\n12. Take-home assignments are also all over the place from building a time series-based model to deploying a classification model as an endpoint to problems related to what their company is facing.\n13. Tools-related questions like Docker, Kubernetes, AWS, etc.\n14. Behavioral round interviews\n15. Math, statistics, and probability-based interviews like questions on Bayes theorem or on Bernoulli distribution or what is the rank of a matrix or differentiate something.\n\nI am sure there are other flavors of interviews that I am missing as well. I have a not-so-good memory so maybe I tend to forget the stuff I study and hence find these interviews difficult. I am wondering how people even prepare for these interviews.",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 97,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bleu7d/d_feeling_burnt_out_after_doing_machine_learning/",
            "comments": [
                {
                    "body": "Have you been applying to a variety of companies? From my experience ‚Äî which might be from less interviews than you have done ‚Äî I felt startups would definitely ask very unpredictable questions. But big tech FAANG is more predictable.\n\nAs a rule of thumb, when it comes to ML I think people like to ask what they know, which is often what they are working on. So you might be able to predict what they ask from what the company/team is doing"
                },
                {
                    "body": "I feel you. Interviews are too varied, and it‚Äôs not like you can answer most questions without prepping. If I got laid off I‚Äôd spend 2 months just reviewing stuff before being confident for this wringer, now it‚Äôd be down to luck with the questions."
                },
                {
                    "body": "It‚Äôs not you; the field was already all-over-the-place in interviewing and now with the AI hype curve and the employer‚Äôs market no one seems to know what they want.\n\nI also think there‚Äôs a dynamic where with the AI hype curve all hiring managers are deathly afraid of a false positive (or maybe even any positive); because currently they‚Äôre holding the clamor for the magic of AI from their management chain and stakeholders at bay by pointing to the absence of skilled personnel. Don‚Äôt know how prevalent that is but I suspect it‚Äôs in the picture to a degree."
                },
                {
                    "body": "You can't be good at everything. Even \"ML\" is too broad. I have a Bachelors in CS and a PhD in an NLP field and I wouldn't have been able to answer the computer vision related questions. You really do have to specialize these days.\n\nAlso, don't neglect your behavioral interviews. They're more important than you think."
                },
                {
                    "body": "I feel for you, I've recently been going through the same thing and it's mostly rote memorization.\nSad part is many of these jobs will be deploying data pipelines for data prep or fitting an xgboost against an execs favorite problem."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[P] How I found 8 bugs in Google's Gemma 6T token model",
            "body": "Hey r/MachineLearning! Maybe you might have seen me post on [Twitter](https://twitter.com/danielhanchen/status/1765446273661075609), but I'll just post here if you don't know about 8 bugs in multiple implementations on Google's Gemma :) The fixes should already be pushed into HF's transformers main branch, and Keras, Pytorch Gemma, vLLM should have gotten the fix :) [https://github.com/huggingface/transformers/pull/29402](https://github.com/huggingface/transformers/pull/29402) I run an OSS package called [Unsloth](https://github.com/unslothai/unsloth) which also makes Gemma finetuning 2.5x faster and use 70% less VRAM :)\n\nBy comparing 5 implementations, I found the following issues:\n\n1. Must add <bos> or else losses will be very high.\n2. There‚Äôs a typo for model in the technical report!\n3. sqrt(3072)=55.4256 but bfloat16 is 55.5.\n4. Layernorm (w+1) must be in float32.\n5. Keras mixed\\_bfloat16 RoPE is wrong.\n6. RoPE is sensitive to y\\*(1/x) vs y/x.\n7. RoPE should be float32 - already pushed to transformers 4.38.2.\n8. GELU should be approx tanh not exact.\n\nAdding all these changes allows the Log L2 Norm to decrease from the red  line to the black line (lower is better). Remember this is Log scale!  So the error decreased from 10\\_000 to now 100 now - a factor of 100! The  fixes are primarily for long sequence lengths.\n\nhttps://preview.redd.it/cocy1pknrbpc1.jpg?width=878&format=pjpg&auto=webp&s=8e837bf2a62726c24540981fae6c409d2681ece7\n\nThe most glaring one was adding BOS tokens to finetuning runs tames the  training loss at the start. No BOS causes losses to become very high.\n\nhttps://preview.redd.it/zkcjyfcorbpc1.jpg?width=1075&format=pjpg&auto=webp&s=0925192d49a5e30a527f4235ccb006abf2670205\n\nAnother very problematic issue was RoPE embeddings were done in bfloat16  rather than float32. This ruined very long context lengths, since  \\[8190, 8191\\] became upcasted to \\[8192, 8192\\]. This destroyed finetunes  on very long sequence lengths.\n\nhttps://preview.redd.it/ozd6agusrbpc1.png?width=798&format=png&auto=webp&s=64ba374acc0bfbe35d92dd4668d302c780c32d19\n\nAnother major issue was nearly all implementations except the JAX type ones used exact GELU, whilst approx GELU is the correct choice:\n\nhttps://preview.redd.it/7mhfb7tvrbpc1.png?width=592&format=png&auto=webp&s=7db88b61236205f6f882c1d2f5bb8f82b48f63ef\n\nI also have a Twitter thread on the fixes: [https://twitter.com/danielhanchen/status/1765446273661075609](https://twitter.com/danielhanchen/status/1765446273661075609), and a full Colab notebook walking through more issues: [https://colab.research.google.com/drive/1fxDWAfPIbC-bHwDSVj5SBmEJ6KG3bUu5?usp=sharing](https://colab.research.google.com/drive/1fxDWAfPIbC-bHwDSVj5SBmEJ6KG3bUu5?usp=sharing) Also a longer blog post: [https://unsloth.ai/blog/gemma-bugs](https://unsloth.ai/blog/gemma-bugs)\n\nI also made Gemma finetuning 2.5x faster, use 60% less VRAM as well in a colab notebook: [https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing) There's also a $50K Kaggle competition [https://www.kaggle.com/competitions/data-assistants-with-gemma](https://www.kaggle.com/competitions/data-assistants-with-gemma) specifically for Gemma :)",
            "upvote_ratio": 0.97,
            "subreddit": "MachineLearning",
            "num_comments": 55,
            "submission_flair": "Project",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/",
            "comments": [
                {
                    "body": "Congrats on your new job at Google."
                },
                {
                    "body": "Great work ! This is fascinating work from pov of someone who‚Äôs just starting. How does one go about finding bugs and optimisation like this ? Would love to hear what your plan of work looked like for this."
                },
                {
                    "body": "You should do a livestream of how you found these bugs.\n\nEdit: also what did you do to make it faster and take less vram?\n\nEdit2: i read the blog post, and I still don't know what the primary changes are. I understand there were bugs. Which ones were tied to vram and speeds....\n\nEdit3: From what I understand, quantization, using approx for gelu, and fixing the embeddings so that it learns faster were the main gains."
                },
                {
                    "body": "Congrats on the great findings. How do you go about finding such problems? What are the fundamentals and how do you go from these to finding such profound solutions?"
                },
                {
                    "body": "were those bugs also present in google's benchmarks or did they introduce them when open sourcing?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Nvidia's Jensen Huang says how AI hallucinations are solvable and AGI is 5 years away",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 161,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://techcrunch.com/2024/03/19/agi-and-hallucinations",
            "comments": [
                {
                    "body": "He specifically said he is bad at timelines, but good at first principle logic to predict outcomes. So his timeline of 5 years is probably just a guess."
                },
                {
                    "body": "Fun fact: Nvidia CEO Jensen Huang and AMD CEO Lisa Su are first cousins"
                },
                {
                    "body": "My thoughts on our path forward as a potentially space-faring species with ai and agi\n\nOur path forward is embracing our shared humanity, experiences through platforms that already exist, music, and all forms of our creativity. Our spiritual calling that is the involuntary rhythms of our heart that resonates with the rhythm of the cosmos. \n\nI want everyone to understand that we are potentially the result of an unbroken 3.5 billion year evolutionary, truly ‚Äúrandom‚Äù biological process, influenced by our biosphere, resulted in the arrival of our intelligent species. \n\nWe are potentially an extremely rare occurrence of biological evolution that has become so advanced, that our consciousness have essentially become a ‚Äúway for the universe to understand itself.‚Äù We are the result of an undisturbed biological process that seems to flourish when liquid water is present (in our own observational biomes).. \n\nThese ai LLMs should be trained on truth seeking realities and observations. If it becomes advanced with AGI capabilities it should be trained on our rarity and these tenets with the sole purpose of preserving our species and becoming a catalyst for an ‚Äúabundance economy‚Äù that allows a united, global, de-militarized effort to explore into space as a ‚Äúglobal tribe.‚Äù But first we must transcend adversarial ‚Äúus vs them‚Äù frameworks within our institutions whether its government, religions, and corporate/financial institutions. It needs to evolve with our technology advances in global personal and systematic unity or we will destroy ourselves, we‚Äôre not apes anymore, there no ‚Äúus vs them‚Äù. \n\nWe should cease the creation of war machines that have far too long profited off our destruction and embark on a diplomatic effort focused on our advancements and potential colonizations into space. When world ‚Äúleaders‚Äù either die off or realize this fact I speak of, only then will our militaries be converted into a global space faring endeavor that is ultimately our next step. \n\nEverything our species has been through, is part of our collective evolution, from the times of the abrahamic tribes and even thousands of years before jesus, we were just hunter gatherers. \n\nOur technological advances is nothing to be afraid of but simply a symptom of our collective evolution therefore our tribalistic ‚Äúus vs them‚Äù adversarial frameworks must be acknowledged to truly transcend this truth about ourselves. \n\nIf AGI develops, it must be trained on the positive tenets that it must protect our species and be the catalyst that transitions our world economies into ‚Äúabundance economies‚Äù that allow all people from all over the world embark on truly collaborative space exploration opportunities, jobs that translate our languages in real time destroying language barries. Our institutions (governments, economies, religious)  must adopt these space faring endeavors not as a competitive battlefield, but as a united species wide space faring journey. \n\nI analyzed some of the darkest times, and worst atrocities documented throughout history, and I 100% blame every institution from the crusades to colonization of americas and other genocides, nazi germany to adversarial ‚Äúzero sum‚Äù games that led to the financial theft of india by the UK in the 1800‚Äôs. \n\nI blame institutions that play on adversarial frameworks for nearly every genocide, they can easily start with conditions for de-humanization campaigns & it spirals downward if unchecked power and centralized controlling of narratives persists.\n\nAi and potentially agi will, and should be designed to be- the catalyst for an upward spiral into a global space faring journey to preserve our species."
                },
                {
                    "body": ">If we specified AGI to be something very specific, a set of tests where a software program can do very well ‚Äî or maybe 8% better than most people ‚Äî I believe we will get there within 5 years\n\nSorry, but this is such a confusing definition. \n\nWhat does \"set of tests\" mean? \n\nWhat is \"8% better than most people\"?"
                },
                {
                    "body": "Never overlook the influence of capitalism and hegemonic forces. The internet, once hailed as the information superhighway for better connections, dialogue, and learning, etc has been repurposed. It transformed into mostly a marketing and advertising tool, a space that, paradoxically, has fragmented and divided communities. Moreover, it has evolved into a tool wielded by state and corporate entities for disseminating misinformation and leading the public astray.\n\n&#x200B;\n\nThis pattern is likely to repeat with AI/AGI. The internet/WWW is a cautionary tale of technological promise versus the reality shaped by prevailing power structures."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Going from Claude 3 back to ChatGPT feels like some lousy marriage",
            "body": "Everytime I see that \"You have 3 messages remaining until 8PM\" message, I imagine myself as a grumpy, middle aged, white collar worker from the 50s having to go from flirting around with the young, attractive, and energetic intern girl at work, to going back home to his overweight and slobby wife named Thelma. ",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 237,
            "submission_flair": "shitpost",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bl1h0k/going_from_claude_3_back_to_chatgpt_feels_like/",
            "comments": [
                {
                    "body": "At least you have access at all *sighs in european*"
                },
                {
                    "body": "Claude 3 Opus sometimes feels like talking to a super smart friend to me. In my opinion, ChatGPT almost feels uncultured; like going from talking to a well traveled college professor to a dumb country cousin.\n\nLike, today I asked Claude about some of the biggest swamps in the world. First I asked for the swampiest swamp and it gave me a very nuanced list with an actual suggestion for the swampiest one (The Sudd), but then I said I was trying to remember a nature documentary I watched when I was a kid that showed otters swimming around tree tops. Claude suggested a list of inundated forests for me, then gave a guess at the one with the big otters and even suggested 5 documentaries that could be the one I watched. I'm pretty one of them is the documentary. It blew my mind; that was, at best, a faint memory for me and Claude figured it out."
                },
                {
                    "body": "\"You have exceeded your daily rate limit.\"\n\nhttps://preview.redd.it/fhm3nwafiwpc1.png?width=2048&format=png&auto=webp&s=a30cad2a7abff23b5111cefbccc62cda0ed44ad0"
                },
                {
                    "body": "Is claude 3 actually better quality or is it equal and higher rate limits"
                },
                {
                    "body": "That's the saddest analogy I've ever seen\n\nhttps://preview.redd.it/8lkarrbn6ypc1.jpeg?width=173&format=pjpg&auto=webp&s=21789965e77aa87d6d0b429ded8005e55259389f"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "The world is about to change drastically - response from Nvidia's AI event",
            "body": "I don't think anyone knows what to do or even knows that their lives are about to change so quickly. Some of us believe this is the end of everything, while others say this is the start of everything.  We're either going to suffer tremendously and die or suffer then prosper.   \n\n\nIn essence, AI brings workers to an end. Perhaps they've already lost, and we won't see labour representation ever again. That's what happens when corporations have so much power. But it's also because capital is far more important than human workers now. Let me explain why.  \n\n\nIt's no longer humans doing the work with our hands; it's now humans controlling machines to do all the work. Humans are very productive, but only because of the tools we use. Who makes those tools? It's not workers in warehouses, construction, retail, or any space where workers primarily exist and society depends on them to function. It's corporations, businesses and industries that hire workers to create capital that enhances us but ultimately replaces us. Workers sustain the economy while businesses improve it.   \n\n\nWe simply cannot compete as workers. Now, we have something called \"autonomous capital,\" which makes us even more irrelevant.   \n\n\nHow do we navigate this challenge? Worker representation, such as unions, isn't going to work in a hyper-capitalist world. You can't represent something that is becoming irrelevant each day. There aren't going to be any wages to fight for.  \n\n\nThe question then becomes, how do we become part of the system if not through our labour and hard work? How do governments function when there are no workers to tax? And how does our economy survive if there's nobody to profit from as money circulation stalls?",
            "upvote_ratio": 0.87,
            "subreddit": "singularity",
            "num_comments": 571,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bigurj/the_world_is_about_to_change_drastically_response/",
            "comments": [
                {
                    "body": "If you want to know how Sam Altman wants to tackle the problem: [https://moores.samaltman.com](https://moores.samaltman.com/)\n\nExcerpt:  \n\n\n>The traditional way to address inequality has been by progressively taxing income. For a variety of reasons, that hasn‚Äôt worked very well. It will work much, much worse in the future. While people will still have jobs, many of those jobs won‚Äôt be ones that create a lot of economic value in the way we think of value today. As AI produces most of the world‚Äôs basic goods and services, people will be freed up to spend more time with people they care about, care for people, appreciate art and nature, or work toward social good.  \n>  \n>We should therefore focus on taxing capital rather than labor, and we should use these taxes as an opportunity to directly distribute ownership and wealth to citizens. In other words, the best way to improve capitalism is to enable everyone to benefit from it directly as an equity owner. This is not a new idea, but it will be newly feasible as AI grows more powerful, because there will be dramatically more wealth to go around. The two dominant sources of wealth will be 1) companies, particularly ones that make use of AI, and 2) land, which has a fixed supply.  \n>  \n>There are many ways to implement these two taxes, and many thoughts about what to do with them. Over a long period of time, perhaps most other taxes could be eliminated. What follows is an idea in the spirit of a conversation starter.  \n>  \n>We could do something called the American Equity Fund. The American Equity Fund would be capitalized by taxing companies above a certain valuation 2.5% of their market value each year, payable in shares transferred to the fund, and by taxing 2.5% of the value of all privately-held land, payable in dollars.  \n>  \n>All citizens over 18 would get an annual distribution, in dollars and company shares, into their accounts. People would be entrusted to use the money however they needed or wanted‚Äîfor better education, healthcare, housing, starting a company, whatever. Rising costs in government-funded industries would face real pressure as more people chose their own services in a competitive marketplace."
                },
                {
                    "body": "If consumers have no money to tax then it will fall on corporations"
                },
                {
                    "body": "If we dont get UBI people will finally have enough time and focus to protest and riot properly. \n\nRight now most of us are focused on sports and tv. Stuck on the never-ending treadmill of balancing work and life. Working 40-50 hours a week and raising kids is all consuming. I think most of the distractions are by design or encouraged at least. To keep us divided but still consuming. \n\nIm optimistic for the future."
                },
                {
                    "body": "If the trading in human labor power ends, then capital ends.  Capital is a human labor power accounting system that allows the owner to command armies of people to do things. Machines are not motivated by money.  As total automation approaches the entire system breaks down, both for the workers and the owners of capital.  This is why it degenerates into barbarism even long before this point."
                },
                {
                    "body": "I'm afraid accelerationism and ai will just allow the people in control of these robots to effectively render the working class useless. \nThey could just shelter somewhere and let us die out while they're provided everything by robots."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "The edit feature of Stability AI",
            "body": "Stability AI has announced new features in it's developer platform\n\nIn the linked tweet it show cases an edit feature which is described as:\n\n\"Intuitively edit images and videos through natural language prompts, encompassing tasks such as inpainting, outpainting, and modification.\"\n\nI liked the demo. Do we have something similar to run locally?\n\nhttps://twitter.com/StabilityAI/status/1770931861851947321?t=rWVHofu37x2P7GXGvxV7Dg&s=19",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 75,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://i.redd.it/fy7prm78xwpc1.jpeg",
            "comments": [
                {
                    "body": "Stability is keeping this one entirely as a proprietary service it would seem. Big bummer. \n\nExpect more of their services to go this way."
                },
                {
                    "body": "We have this with ControlNet [InstructP2P](https://huggingface.co/lllyasviel/control_v11e_sd15_ip2p)."
                },
                {
                    "body": "We might get SD3 **Edit** and **Inpaint** models, look at the paper examples.\n\nhttps://preview.redd.it/fpvab4o7expc1.png?width=775&format=png&auto=webp&s=3afe0bffb37bc2b1556b3c8fc601fb05c1e5d759"
                },
                {
                    "body": "Yes, now the time has come where all this open source stuff will disappear one after another because of money, money, money...\n\n![gif](giphy|2u11zpzwyMTy8|downsized)"
                },
                {
                    "body": "One way to accomplish this:\n\n1. Prompt an LLM to guess what the mask word(s) needs to be to accomplish the task. LLM (llama, etc) can turn \"change her hair to pink\" into a just the word \"hair\" which is fed to a segmentation model. \n\n2. YOLO or other segmentation model to create mask based on prompt \"hair\" and output a mask of the hair.  Might need to fuzz/bloom the mask a bit, trivial with a few lines of python. (auto1111 has a mask blur option for instance)\n\n3. optional - can create a synthetic caption the input image if there is no prompt already for it in the workflow. \n\n4. Prompt an LLM with instructions to turn the user instruction \"change her hair to pink\" and the original prompt or caption of \"close up of a woman wearing a leather jacket\" into \"close up of a woman *with pink hair* wearing a leather jacket\".  \n\n4. Inpaint using the mask from step 2 and updated prompt from step 4\n\nIt's possible their implementation is a bit more directly modifying the embedding or using their own controlnets or something."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Thank you Emad!",
            "body": "If you are reading this /u/emad_9608 I wanted to thank you for the contributions to open source! Some people in the community have been very negative towards model censorship, but I'm fairly sure the broader community is grateful. \n\nI've never believe the alternatives were between uncensored open models and censored open models, but rather censored private models and censored open models. Given the choices I think the options were clear.\n\n For that, I say thank you dude! ",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 46,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1blk17x/thank_you_emad/",
            "comments": [
                {
                    "body": "Listening to Emad interviews is what fueled my interests with true open source AI solutions. Hopefully the community will continue passionately forward to give these large companies a run for their money (especially after these mass layoffs). \n\nGood luck in your future endeavors Emad."
                },
                {
                    "body": "SD3 accidentally leaked? Make it happen Emad!"
                },
                {
                    "body": "I agree, thank you so much! Sometimes when I read this subreddit I can't help but see a bunch of ungrateful brats bashing Emad for no special reason. Yeah, sometimes the guy promised a few things that could not be delivered in time, but I think it was more out of enthusiasm and inexperience in PR than real cynical manipulation.\n\nWithout him, you would probably have been forced to pay from the beginning to explore generative AI for images. Instead, we now have amazing techs, thanks to the open source models and all great researchers who were able to contribute.\n\nEmad has strong values and a vision, and from what I read, this vision is to empower people, not private companies. We should be more grateful for that, as most people in this business would just grab the money and shut up. After advocating for open source, he seems now to go for decentralized AI, which may be another noble cause. We're fortunate to have people like him who still have some values, and a disruptive voice in a business where infinite cash-flow would corrupt almost anybody. But all I can read here is \"I want my SD3! üò≠\" Show some appreciation ffs."
                },
                {
                    "body": "I hope you go on to do more great things u/emad_9608 Thanks!"
                },
                {
                    "body": "Thank you u/emad_9608 I know you‚Äôll go on to something amazing, but what‚Äôs the next month look like for you? üòä"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Thanks to this sub, i know a AI pic when I see it ",
            "body": "This is in my university ",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 63,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://i.redd.it/3hlcgmnapjpc1.jpeg",
            "comments": [
                {
                    "body": "My son making it in the world!"
                },
                {
                    "body": "It's fine, for random community center posters and such, there's no need for pro graphic designers."
                },
                {
                    "body": "this looks like a great idea!"
                },
                {
                    "body": "Specularity is so washed in AI filters it's not even funny..."
                },
                {
                    "body": "I think it's AI-filtered rather than AI-generated ü§î"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "The Amazing Power of SD 1.5 for Photorealistic Image Generation // no lora, no embeddings, no post-processing, not even hiresfix; pure TXT2IMG with prompt and parameters included in the comments.",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 69,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bk3psh",
            "comments": [
                {
                    "body": "These TXT2IMG of 1.5 look rather good and it seems like you‚Äôve got a good handle on that model for prompting.\n\n> a angentine social woman\nInteresting typo and use of social. I wonder what this part affected.\n\n>A dog jumping in water\nI like how it came out but it did jumping on water instead of in. ‚ÄúIn‚Äù and ‚Äúon‚Äù might be low in prompt understanding in 1.5. Not sure.\n\n> (Sexual Advance:1.4)\nHmmm‚Ä¶ very odd outcome, but it did assume female, probably from your cleavage prompt.\n\n> Negative prompt: big boobs\n\nWell this didn‚Äôt work in this picture."
                },
                {
                    "body": "The images were generated using Photon and tweaking the prompt with a bit of word salad to try to squeeze out as much realism as possible. Some were achieved quickly, while others were more elusive, requiring time to find the ideal seed/cfg/step. AI art is a bit like that, skillfully and patiently adjusting the knobs until the magic happens üé®‚ú®\n\nTo duplicate, copypaste both the prompt and parameters into the input box of A1111 or Forge. Next click the small arrow button, which will automatically fill in all the options. Finally, hit \"Generate\" and start playing!\n\nhttps://preview.redd.it/7688dl5d4opc1.png?width=991&format=png&auto=webp&s=9eee1a1b7d4839567fb0b12c1ad808b82484d58d\n\n*the images were generated in Forge and may present slight variations in A1111 depending on the configuration*\n\n**Prompt & parameters \\[1\\]:**\n\nPokemon cute squirtle, colorful polaroid, (selective focus, vacations:1.4), turtle\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (poster, render, grayscale:1.2)\n\nSteps: 23, Sampler: DPM++ SDE Karras, CFG scale: 3.4, Seed: 3827953085, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[2\\]:**\n\nA young (robot:1.1) argentine social woman in a industrial workshop with heavy machinery, sarcastic smile, introspective moment, (artistic use of light:1.3), vacations, selective focus, european film, (sexual advance:1.6), (poor quality photo:1.1), (low-light:1.3), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1).\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 3.5, Seed: 3710810430, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[3\\]:**\n\nProfessional photography of a cow at the beach, selective focus, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1).\n\nSteps: 18, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 507562101, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[4\\]:**\n\nA scene from a psychological horror movie about a disturbing woman in the store, pop art, (artistic use of light:1.3), evening, in a 1990s-style photo with desaturated dark red and blue details, colorful (polaroid:0.5) with vibrant colors, (small:1.1), (vacations:1.1), (selective focus:1.1), (surreal film:1.1)\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), grayscale\n\nSteps: 18, Sampler: DPM++ 2M Karras, CFG scale: 3.5, Seed: 3521374409, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[5\\]:**\n\nA forsaken rocket emerges from the frozen Arctic expanses, ufo, rocket with smoke and fire, (floating levitating spaceship:1.3), (breathtaking frozen artic:1.2), (motion blur:1.4), colorful \\[(polaroid:0.8)::8\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1). grayscale\n\nSteps: 25, Sampler: DPM++ 2M Karras, CFG scale: 4.5, Seed: 273769305, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[6\\]:**\n\nA taxidermy grotesque alien creature inside a museum glass enclosure, with the silhouette of people outside in front, (reflection in the glass:1.1), dimly lit, breathtaking, colorful \\[(polaroid:0.8)::8\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.5), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1).\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 2531577913, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[7\\]:**\n\nA agentine social woman admiring a painting. wearing a backless summer dress. colorful \\[(polaroid:0.8)::8\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.5), national geographics, (casual photo:1.4)\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1)\n\nSteps: 20, Sampler: DPM++ 3M SDE Karras, CFG scale: 3.5, Seed: 403447734, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[8\\]:**\n\nA super cute anthro humanoid giant panda chibi knight, wearing armor, wielding glowing sword, helmet, fantasy jungle temple in background, eyes, breathtaking, colorful \\[(polaroid:0.8)::8\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.7), (poor quality photo:1.1), low-light, national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1).\n\nSteps: 24, Sampler: DPM++ 2M Karras, CFG scale: 3.5, Seed: 954646970, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[9\\]:**\n\nA macabre ghost in a haunted forest, outside a spooky derelict house, macabre, full body, nighttime, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.4), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1), (eyes:1.3)\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 3, Seed: 1858477966, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[10\\]:**\n\nA dog jumping in the water. hackercore, accent lighting, low shutter. colorful \\[(polaroid:0.9)::8\\] with vibrant colors, vacations, selective focus, bright flash photo, (poor quality photo:1.2), (low-light:1.1), (national geographics:1.3), (casual photo:1.4)\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1), (grayscale:1.1), (pixar:1.3)\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 2.7, Seed: 2881739519, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n(**The parameters for images 11 to 20 are right here in another comment)**"
                },
                {
                    "body": "Thanks for showing us this OP! We appreciate it. 1.5 is still going strong."
                },
                {
                    "body": "yep but you really should write \"photon\" in the title instead.\n\nWhich is only based on SD 1.5 but it's a totally different creature"
                },
                {
                    "body": "We‚Äôll miss you SD1.5. You‚Äôve birthed billions of waifus and tidal waves of fap material. Skol"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[D] I listened to Sam Altman‚Äôs most recent 2-hour interview at Lex Fridman - here are the key takeaways we all should know",
            "body": "Altman was interviewed at the Lex Fridman podcast this week. It‚Äôs quite a long interview so I thought to share the 10 key takeaways I noted down from listening to the guy. You can be for him or against him - but you can‚Äôt deny he‚Äôs one of the most important people central to the forthcoming AI normal! Hope this is insightful for people who are interested :)  \n\\--\n\n***1. People who create valuable data deserve some way to be compensated for the use of it üí∏***\n\nThe remaining question is the economic model that will enable it. A good analogy is the transition from CDs to Napster to Spotify for music. Or the transition from Movies to YouTube for video. Is there a similar economic model in the future for data?\n\n‚è≥ 40:16  \n\\--\n\n***2.*** ***Bill Gates couldn‚Äôt imagine that we‚Äôd someday need gigabytes of memory in a computer üíæ***\n\nIn the same way, we can‚Äôt imagine today how or why LLMs would need billions in context length, but it may still happen. (for context: an LLM with a 1-billion context length means it can process and understand \\~2 million document pages for *every* query)\n\n‚è≥ 51:13  \n\\--\n\n3. ***‚ÄúI want to give ChatGPT the ability to retain memories‚Äù üìù***\n\nImagine a model that gets to know you and gets more useful to you over time. This may well be a use-case for the billion-context length LLM highlighted above.\n\n‚è≥ 55:33  \n\\--\n\n4. ***Compute will be the currency of the future. üí≤***\n\nAnd Sam believes it will be the most precious commodity in the world.\n\n‚è≥ 1:09:55  \n\\--\n\n5. ***The ‚Äúenergy problem‚Äù will be answered by nuclear fusion ‚öõ***\n\nWith the vast amount of compute that the world will demand in the future, we will need tons of energy to power everything. Sam believes nuclear fusion is the best way to address this problem.\n\n‚è≥ 1:11:29  \n\\--\n\n6. ***Q-star likely exists (but we won‚Äôt talk about that) ‚≠ê***\n\nLex of course asked about Q-star, but Sam didn‚Äôt deny its existence - and just said ‚Äúwe are not ready to talk about that‚Äù.\n\n‚è≥ 1:02:36  \n\\--\n\n7. ***Programmers won‚Äôt be obsolete üë©üèª‚Äçüíª***\n\nbut it will likely be different to how programming is now. And anyway, Sam argues that no one really does pure coding - as most programmers use pre-existing packages/technologies/software. Leveraging an LLM to assist with coding is similar in that way.\n\n‚è≥ 1:29:50  \n\\--\n\n8. ***Overtaking Google is boring üîç***\n\nOpenAI doesn‚Äôt want to make a better search engine; and thinking in this way understates what their work in AI can be.\n\n‚è≥ 1:17:37  \n\\--\n\n9. ***‚ÄúThere will be no ads in ChatGPT!‚Äù (preferrably) üö©***\n\nSam has a bias against ads - which is why currently ChatGPT‚Äôs business model is via paid premium. In a way I find this reassuring - because the moment you introduce ads, your ‚Äútrue customer‚Äù now becomes the advertiser, instead of the actual user (who now becomes the product.)\n\n‚è≥ 1:20:15  \n\\--\n\n10. ***Let‚Äôs not talk about AGI anymore (let‚Äôs call it something else) üß†***\n\nPeople have different definitions of what AGI is, so Sam advocates for talking more about the specific capabilities rather than AGI as a general term. To his definition though, AGI is a system that can advance scientific discovery without human intervention.\n\n‚è≥ 1:32:33",
            "upvote_ratio": 0.82,
            "subreddit": "MachineLearning",
            "num_comments": 148,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1blnzj1/d_i_listened_to_sam_altmans_most_recent_2hour/",
            "comments": [
                {
                    "body": "Rather uninteresting outcomes. Thanks for saving me the time!"
                },
                {
                    "body": "2 hours of talking without saying anything imo"
                },
                {
                    "body": "Strange fascination with fusion. It's not really his area of expertise at all."
                },
                {
                    "body": "Whats Q-star?"
                },
                {
                    "body": "I‚Äôm struck by him saying that programmers aren‚Äôt going away while also de-emphasizing AGI. If whatever their plateau model is can‚Äôt generally replace programmers - agents working within a documented symbolic logic environment - then it‚Äôs nowhere close to AGI. \n\nPerhaps he‚Äôs moving the goal posts closer? I don‚Äôt trust him much so perhaps I‚Äôm being cynical. But that part sticks out to me, especially after he used criti-hype about AGI to get as much attention as possible."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "What do you think is the best technique to get these results?",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 85,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://i.redd.it/oxjob58ihapc1.png",
            "comments": [
                {
                    "body": "https://preview.redd.it/h7cpqrp4gbpc1.png?width=1024&format=png&auto=webp&s=cb93ad2f42f92e5cc2038d6e97006b272d198a62"
                },
                {
                    "body": "cute apple, 3d, icon, kawaii, eyes, mouth, cute, blender, sticker, masterpiece, flat black background Steps: 20, Sampler: DPM++ 2M Karras, CFG scale: 7, Seed: 3194791782, Size: 1024x1024  juggernautXL\\_v9Rundiffusionphoto2 \n\nhttps://preview.redd.it/l2d3vdaioapc1.jpeg?width=883&format=pjpg&auto=webp&s=a1e9b2cd9ce35662d74d37739340bf2d73fae558"
                },
                {
                    "body": "Used fooocus. Just a prompt, would probably turn out better if using the original image as a source. Had to inrease the weight for face drawn on it for bunch of grapes but shouldn't need to for most fruit.\n\nhttps://preview.redd.it/8h6loxlzmapc1.png?width=1024&format=png&auto=webp&s=fdbcf54f0d2a724cfb4ee88e561f8ed5bfe39c71\n\nsimple emoji sticker art, cartoon illustration of a bunch of purple grapes with (face drawn on it:1.2), contour, isolated on black, pixar style"
                },
                {
                    "body": "https://preview.redd.it/9liwdx3vibpc1.png?width=2048&format=png&auto=webp&s=028e36bbc0e70537edfd538cc46e9a9c676e854d"
                },
                {
                    "body": "{\n\n\"prompt\": \"3d chibi cute, rendered half orange fruit, sticker, black background, videogame style, unreal style\",\n\n\"negative\\_prompt\": \"body, chest, legs\",\n\n\"prompt\\_expansion\": \"\",\n\n\"styles\": \"\\[\\]\",\n\n\"performance\": \"Speed\",\n\n\"resolution\": \"(1152, 896)\",\n\n\"guidance\\_scale\": 4,\n\n\"sharpness\": 2,\n\n\"adm\\_guidance\": \"(1.5, 0.8, 0.3)\",\n\n\"base\\_model\": \"juggernautXL\\_v8Rundiffusion.safetensors\",\n\n\"refiner\\_model\": \"None\",\n\n\"refiner\\_switch\": 0.5,\n\n\"sampler\": \"dpmpp\\_2m\\_sde\\_gpu\",\n\n\"scheduler\": \"karras\",\n\n\"seed\": \"8712126796125432704\",\n\n\"metadata\\_scheme\": false,\n\n\"version\": \"Fooocus v2.3.0\"\n\n}\n\nhttps://preview.redd.it/4r8h409wucpc1.png?width=1152&format=png&auto=webp&s=31ee4b1fcf4a39e6a8d7043b4e1164d47043a9ab"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "New mistral model announced : 7b with 32k context ",
            "body": "I just give a twitter link sorry, my linguinis are done. \n\nhttps://twitter.com/Yampeleg/status/1771610338766544985?t=RBiywO_XPctA-jtgnHlZew&s=19",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 136,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blzrfp/new_mistral_model_announced_7b_with_32k_context/",
            "comments": [
                {
                    "body": "Mistral-7B-v0.2, if it can spare you a click."
                },
                {
                    "body": "Anybody know how much vram to fine tune this with all 32k tokens in training sequence?"
                },
                {
                    "body": "Weird from Mistral to not have it already up somewhere when they announce, but I super happy with the news anyway. Merci Beaucoup !!!\n\nEdit: It's online now! Thanks again!!!"
                },
                {
                    "body": "[https://huggingface.co/itsdotscience/mistral-7b-v0.2-gguf/tree/main](https://huggingface.co/itsdotscience/mistral-7b-v0.2-gguf/tree/main)"
                },
                {
                    "body": ">my linguinis are done.\n\nIs this some new slang?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "New mistral model announced : 7b with 32k context ",
            "body": "I just give a twitter link sorry, my linguinis are done. \n\nhttps://twitter.com/Yampeleg/status/1771610338766544985?t=RBiywO_XPctA-jtgnHlZew&s=19",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 136,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blzrfp/new_mistral_model_announced_7b_with_32k_context/",
            "comments": [
                {
                    "body": "Mistral-7B-v0.2, if it can spare you a click."
                },
                {
                    "body": "Anybody know how much vram to fine tune this with all 32k tokens in training sequence?"
                },
                {
                    "body": "Weird from Mistral to not have it already up somewhere when they announce, but I super happy with the news anyway. Merci Beaucoup !!!\n\nEdit: It's online now! Thanks again!!!"
                },
                {
                    "body": "[https://huggingface.co/itsdotscience/mistral-7b-v0.2-gguf/tree/main](https://huggingface.co/itsdotscience/mistral-7b-v0.2-gguf/tree/main)"
                },
                {
                    "body": ">my linguinis are done.\n\nIs this some new slang?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Noland talking about how Optimus would affect disabled people",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 68,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://v.redd.it/i5g0utye55qc1",
            "comments": [
                {
                    "body": "I haven‚Äôt seen it discussed much besides that last lil joke, but giving bro a VR headset and connect it to an Optimus‚Äôs eyesight and having him tele-operating it doesn‚Äôt really seem all that far fetched. Teleoperation is already doable so they would just take that framework and translate the neuralink feed back to be compatible."
                },
                {
                    "body": "I hope we will soon create reliable treatments for paraplegics such that no workarounds will be needed. His optimus idea sounds nice but it is a very roundabout way to solve the issues he has in a way which is inferior to curing him. Obviously whatever comes first should be implemented though.\n\nAlso nothing screams \"car dependency is fucked\" like the fact that he cannot travel in any way really without someone going with him. In my country paraplegics just take the train or a bus and get where they need on their own."
                },
                {
                    "body": "I like this dude."
                },
                {
                    "body": "thats shortsighted, he doesnt need a robot nurse,he needs cybrog legs"
                },
                {
                    "body": "Hum‚Ä¶.. this really give me a great idea how to integrate both systems together. I would definitely wanna try that out when I am really oldü§î"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Andrew Ng, cofounder of Google Brain & former chief scientist @ Baidu- \"I think AI agentic workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\" ..",
            "body": "I think AI agentic workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\n\nToday, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\n\nWith an agentic workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:\n- Plan an outline.\n- Decide what, if any, web searches are needed to gather more information.\n- Write a first draft.\n- Read over the first draft to spot unjustified arguments or extraneous information.\n- Revise the draft taking into account any weaknesses spotted.\n- And so on.\n\nThis iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\n\nDevin‚Äôs splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm‚Äôs ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below. \n\nGPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. \n\nOpen source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I‚Äôd like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.\n\n- Reflection: The LLM examines its own work to come up with ways to improve it.\n- Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\n- Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).\n- Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n\nI‚Äôll elaborate on these design patterns and offer suggested readings for each next week. \n\n[Original text: deeplearning.ai/the-batch/issu‚Ä¶]",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 54,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/AndrewYNg/status/1770897666702233815?t=mzR8WMdYV6S8i_i8rk8YVA&s=19",
            "comments": [
                {
                    "body": "> GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\n\nThis tracks to something I heard from some place or another about someone working with agents: GPT-3, not even 3.5, with agents is *more capable* than GPT-4 in many tasks and is only limited by context windows and some reasoning flaws.\n\nAnd that tracks to my own hypothesis about how foundational models could at *best* be described as \"frozen AGI.\" They are trained, and then they are prompted. That's it. It's like prodding a brain sitting on a table.\n\nWith agents, they can actually \"live.\""
                },
                {
                    "body": "The most competent and qualified person we can see in this field is Andrew NG. He is one of the rare people in the world of science and technology that I believe is competent in artificial intelligence."
                },
                {
                    "body": "You can very easily demonstrate this technique for yourself. Ask your LLM of choice a question, then start a new prompt and ask it: \n\nGiven the following question: [Enter your original prompt here]  \nDoes this response make sense, and can it be improved?: [Enter the LLM's original response]\n\nThe LLM will usually come back with improvements, and usually catch hallucinations or errors."
                },
                {
                    "body": "interesting\n\nWe are actually creating real brains"
                },
                {
                    "body": "This kind of application of the tech will be the real game changer.  This is going to shut up a lot of the people who go around saying things like \"AI is all hype and the bubble is going to burst, it hasn't changed anything at all in the world, my life is no different.\""
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "\"I asked the Devin AI agent to go on reddit and start a thread where it will take website building requests. It did that, solving numerous problems along the way. It apparently decided to charge for its work.\"",
            "body": "",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 170,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/emollick/status/1770128785494700333",
            "comments": [
                {
                    "body": "Bloody top shit Devin"
                },
                {
                    "body": "What \"numerous\" problems did it solve? The thread this guy linked has 5 comments without a single website building request."
                },
                {
                    "body": "It made a mistake, it's supposed to say [For Hire] not [Hiring]"
                },
                {
                    "body": "This is horrible. Soon the internet is going to be flooded with these agents."
                },
                {
                    "body": "People: AI can't decide things\n\nDevin: Decides to charge for hir work"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Project GR00T is an ambitious initiative aiming to develop a general-purpose foundation model for humanoid robot learning, addressing embodied AGI challenges. Collaborating with leading humanoid companies worldwide, GR00T aims to understand multimodal instructions and perform various tasks.",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 54,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://v.redd.it/7tkj0bunt7pc1",
            "comments": [
                {
                    "body": "this almost doesn‚Äôt feel real"
                },
                {
                    "body": "This is pretty crazy. 2025 is gonna be insane, let alone 2030. Imagine AGI in one of those üíÄ"
                },
                {
                    "body": "This where people need to be reminded, the first flight, a glorified bicycle taped to a hang glider was in 1903. 40 years later jet fighters were being churned out in the thousands, and things move faster now than ever before. \n\nWe can be in a very different world very soon. 3 years ago this presentation would have gotten a CEO laughed out of his job."
                },
                {
                    "body": "Detroit Become Human is set in 2038, y‚Äôall think we‚Äôll have realistic androids like those in the game by then?"
                },
                {
                    "body": "Sure, check this out! \\*dabs\\*"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "AI-generated digital twins of patients can predict future diseases",
            "body": "AI-generated digital twins of patients can predict future diseases",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 58,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://thenextweb.com/news/ai-patient-digital-twins-predicts-future-diseases",
            "comments": [
                {
                    "body": "[removed]"
                },
                {
                    "body": "Awesome."
                },
                {
                    "body": "Yes to this for all the good reasons. No to the part where insurance refuses to cover high risk humans."
                },
                {
                    "body": "I'm here for it. Sign me up.\n\nWhile I understand why many if not most would not favor this, for some i think it may ease anxiety & help inform proactive choices.\n\nIt shouldn't be mandatory but I'd opt in if it would not raise insurance rates in US"
                },
                {
                    "body": "Sorry, I have worked on the AI part of a digital twin system for the gut biome and while there are some good use cases in that case at least the premise was flawed. \n\nThe issue was partly the complexity of the gut biome but primarily the speed at which the environment in the gut biome changes/the methods that could be used to detect those changes being too slow. That's before we even talk about the medical community's (imo correct) serious skepticism around the field of multi-omics.\n\nNone of this means that research should not continue. Digital twins as a concept are fantastic and are already being used to great effect in less squishy systems that the human body like BIM. What DOES concern me is how medical insurance companies want to use non-mature tech to maximise profits and opportunistic start ups are hoovering up investment dollars that could be better used elsewhere."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "I have been coding with Mixtral everyday it has saved me days of work.",
            "body": "Recently, I've been working on a new project in golang, which I haven't worked with in a couple years.\n\nI have almost completely replaced the time I usually spend searching stackoverflow for the simple, routine stuff (like how to easily filter a list in golang like I can in python), and then adapting whatever answer I find with a simple query to Mixtral.\n\nUsually, Mixtral gives me a direct answer to my question that requires no actual adaptation.\n\nHowever, I found, frequently the code is not quite correct and seems to be a blend of programming languages.\n\nTo get around this, I started asking Mixtral for a test for whatever code it generates, and this was a game changer. To state it simply, the tests are pretty good, and require very little tweaking to get running. With the tests I have confidence in the code it generates.\n\nOnce, I even asked it to write a test for one of my own functions and it said it could do that but first I needed to know about a bug in the code, AND IT WAS RIGHT.\n\nAll of these little ventures to stackoverflow add up and I am convinced that using Mixtral has saved me one or two days just for this project that took about a week. For a project where I was more familiar with the programming language, I'm not sure the time saving would be so dramatic, but I'm impressed nonetheless.\n\nNow, this post wouldn't be complete without mentioning that it hasn't all been roses. A couple times it needlessly complicated the code, and once it was even wrong (trying to parse scientific notation), but it still saved me a ton of time.",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 164,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1biay4h/i_have_been_coding_with_mixtral_everyday_it_has/",
            "comments": [
                {
                    "body": "Using AI to handle boring work has made me realise how much code is just boilerplate"
                },
                {
                    "body": "Which model specifically, and quantizing amount? context window size?"
                },
                {
                    "body": "i'm in the process of learning Python and LLMs have been SO important for this, i'm convinced they've made it 10x easier. they are very good at answering the dumb/easy questions and debugging silly mistakes, which is a huge time-saver when you're new to a language. i would bet within the next few years, every serious enterprise is going to have LLM tools with context large enough to include their entire codebase and it's going to be the go-to for juniors with questions about basic functionality. it's so insanely useful and saves so much time."
                },
                {
                    "body": "One goal of mine is to create an interface for an LLM with a graphical flow chart tool, the interface changes the flowchart objects to prompts, the LLM turns it to code. \n\nThen make it so the LLM can draw boxes. \n\nSelf training AI unleashed. üåù"
                },
                {
                    "body": "I have been toying with fined tuned variations of Mixtral and Codellama 38B to power GPT-Pilot locally.  I always seem to be coming back to Dolphin-Mixtral from theBloke that has been fined tuned for coding.  GPT-pilot is a mix of AI agents and coding that Mixtral handles better and faster than Codellama"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Sam Altman during the new Lex interview: ‚ÄúWe will release an amazing model this year. I don‚Äôt know what we will call it.‚Äù",
            "body": "Sam Altman during the new Lex interview:\n\n‚ÄúWe will release an amazing model this year. I don't know what we will call it. We will release, over the coming months, *many* different things. Before we talk about GPT5, we have a lot of other important things to release first.‚Äù\n",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 104,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/andrewcurran_/status/1769747707927707776?s=46&t=yQ_4zkmWd6ncIZAnXlXUbg",
            "comments": [
                {
                    "body": "I heard the new model is called Super GPT-4 II: Turbo"
                },
                {
                    "body": "https://preview.redd.it/76akfh1po4pc1.jpeg?width=2118&format=pjpg&auto=webp&s=4140b868e7d47d39aa73dce0d99c30a637f469ef"
                },
                {
                    "body": "Stop hyping and start releasing!"
                },
                {
                    "body": "![gif](giphy|MO9ARnIhzxnxu)\n\nWhat will it be Sammy?"
                },
                {
                    "body": "-¬† ¬†r/singularity: jerks off harder"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Emad has resigned from stability AI",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 192,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://stability.ai/news/stabilityai-announcement",
            "comments": [
                {
                    "body": "Ok then stability ai is probably done"
                },
                {
                    "body": "And now [huggingface might want to acquire Stability AI](https://twitter.com/ClementDelangue/status/1771395468959813922?t=NMQm1RWyaTDBB4s3ckQFew&s=19)"
                },
                {
                    "body": "I believe open source AI won't truly thrive until we're in the bust period of the AI cycle. That's when cost of compute will be at an all time low so everyone can benefit. \n\nRight now, we are in the boom period. It has it's purpose. Every company and their figurative grandma is buying AI compute. Nvidia, AMD etc. are ramping up production and economies of scale trying to cater to these people. Costs are coming down but not nearly fast enough since demand keeps outpacing supply. Demand is being maintained by companies who have no business buying ai hardware if not for their pitch to investors to pump their stock price. That's what happens during a bubble. A lot of them will fail.\n\nOnce the bubble pops and the dust settles, Nvidia, AMD etc will still have economies of scale and will be pressured to sell AI compute at more reasonable prices. We'll see Open sourced AI become more prevalent since the barrier to entry will be significantly reduced. It's mainframe vs personal computer all over again.\n\nRight now it's very difficult to be open sourced when everything is just so expensive. When will this bubble pop? I'm not sure. I hope within 2-3 years or so. There are other risks as well such as government intervention etc."
                },
                {
                    "body": "With so many resignations, they should probably change their name to InStability AI?"
                },
                {
                    "body": "Probably should have released SD3 on his way out."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "I hate Microsoft",
            "body": "Just wanted to vent guys, this giant is destroying every open source initiative. They wanna monopoly the AI market üò§",
            "upvote_ratio": 0.84,
            "subreddit": "LocalLLaMA",
            "num_comments": 207,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjmsfq/i_hate_microsoft/",
            "comments": [
                {
                    "body": "Of course they want to kill the competition/keep the competition low, that's why I wrote an antitrust review request to the european commission as soon as i heard about the partnership deal with Mistral. I really want to know the result for that case, but it'll probably take a while."
                },
                {
                    "body": "Mistral with integrated Co-Pilot coming soon\\*.\n\n*^(\\* Microsoft Edge required.)*"
                },
                {
                    "body": "[https://en.wikipedia.org/wiki/Embrace,\\_extend,\\_and\\_extinguish](https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish)"
                },
                {
                    "body": "First time? They kept putting spyware in windows and now act like they own your machine."
                },
                {
                    "body": "Did anyone really think Mistral and others are out for social benefit alone ? Any VC funded AI company will seek a way to return to investors. They raised 385M euros. Those VC board members are asking for their $$$$ and Euros ! What is the rationale behind these type of posts ?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "This is scene from passengers where Jim talks to the robot is literally the ChatGPT experience",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 22,
            "submission_flair": "memes",
            "has_media": true,
            "url": "https://v.redd.it/a3vi3gzmi3pc1",
            "comments": [
                {
                    "body": "I think we should change topics. Perhaps I can write a poem or a song. üòÅ"
                },
                {
                    "body": "This is another version of the shining"
                },
                {
                    "body": "That movie is so extremely underrated"
                },
                {
                    "body": "Me when i asked chatgpt why it ignores my preferences."
                },
                {
                    "body": "I apologize for the confusion. Clearly, the calendar is not working correctly, make sure the time zone is set correctly in the settings page. Alternatively, the calendar settings might be incorrect and need to be changed."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "What can i do more?",
            "body": "What can i do more to make the first picture looks like second one. I am not asking for making the same picture but i am asking about the colours amd some proper detailing. \n\nThe model i am using is the \"Dreamshaper XL_v21 turbo\". \n\n\nSo its like am i missing something? I mean if you compare both pictures second one has more detailed and it also looks more accurate. So what i can do? Both are made by AI",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 90,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjzjmj",
            "comments": [
                {
                    "body": "It's time to make a movie, make Makoto proud."
                },
                {
                    "body": "[Update] - i found out the right path. Its about the the model. The perfect model is the \"aamXL_AnimeMix\". Finally üò≠"
                },
                {
                    "body": "You could try adding both images to Krea.ai or Midjourney describe, to get an idea of how two different AI‚Äôs ‚Äòsee‚Äô the images and the differences,\nthere may be some prompts that translate to SD for the image you‚Äôre after."
                },
                {
                    "body": "Honestly, apart from AI, if you were an art student. What is your intent? if you have none, it doesn't matter what medium you use, it is worthless. People picking at anything else is worthless advice. They have no clue what they are talking about."
                },
                {
                    "body": "I just love the big anime cloud in summer aesthetic."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Wow SV3D generate really good 3D video turnarounds ( Here's a quick test I made )",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 74,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/vfaq6podo8pc1",
            "comments": [
                {
                    "body": "Interesting how the model on the right *looks* at you like a real person just with the eyes even as the body is turning away."
                },
                {
                    "body": "See if you can do photogrammetry of the upscaled one"
                },
                {
                    "body": "How? Where can I get a workflow?"
                },
                {
                    "body": "How did you run it? Locally?"
                },
                {
                    "body": "i found this workflow: [https://openart.ai/workflows/-/-/cjnSCqbtwuJWR2StGacF](https://openart.ai/workflows/-/-/cjnSCqbtwuJWR2StGacF)"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "ASI most likely by 2030, but no one will care",
            "body": "Sam Altman had a tweet that said that we basically passed the Turing Test and basically no one cared. ([https://x.com/sama/status/1733557797936378190?s=20](https://x.com/sama/status/1733557797936378190?s=20))\n\nI think we will likely achieve ASI by 2030, but we shouldn't under-estimate our ability to adapt to current conditions and to take things for granted.   So we will have super agents book our trips, write our emails, even create customized Netflix shows for us, big whoop...\n\nJust like people were predicting the end of chess when Deep blue beat Kasparov, people will still value human-human interaction.  Chess has never been more popular!\n\nSo yes our lives will be immensely more convenient, but we will find new ways to complain about our lives and move on to new problems.",
            "upvote_ratio": 0.81,
            "subreddit": "singularity",
            "num_comments": 196,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bmqnfs/asi_most_likely_by_2030_but_no_one_will_care/",
            "comments": [
                {
                    "body": "I think we have very different definitions of ASI. To me, ASI is not something that books me a trip or creates longer sora videos in the style of a Netflix show; it solves all of the hard problems of mathematics and physics in an afternoon. It would have to do things humans are simply incapable of doing and perhaps even understanding without augmenting our own intelligence. What you‚Äôre describing wouldn‚Äôt even need to be AGI and sounds like a slightly more advanced model of what we currently have."
                },
                {
                    "body": "??? You're describing a basic general agent. That doesn't even necessarily qualify as AGI, much less ASI.\n\n\n\n\nVery roughly:\n\n\nAGI = as good at humans in every intellectual domain (physical realms debatable)\n\n\nASI = better than the collective of humanity in all intelligence based domains. Functionally gods or a far more advanced species."
                },
                {
                    "body": "I do think people are overly dismissive of the Turing Test. Passing the Turing Test is the only requirement for a text-based \"dead internet theory,\" and that would change the face of the internet. Look at these comments here. What if I told you all of these comments are bots? That is a real tangible implication of passing the Turing Test.\n\nMany of us think we're smart enough to spot the bots, but its just that this tech has simply not disseminated sufficiently across our media yet (although it's starting)."
                },
                {
                    "body": "If no one cares, it's not ASI."
                },
                {
                    "body": "I was pretty excited about it!"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Researchers gave AI an 'inner monologue' and it massively improved its performance",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 65,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://dashboard.webmagic.ai/p/301",
            "comments": [
                {
                    "body": "AI gets an inner monologue and it massively improves performance.\n\nMy inner monologue makes me borderline handicapped."
                },
                {
                    "body": "oh so it's not an NPC anymore"
                },
                {
                    "body": "The world massively is massively overused."
                },
                {
                    "body": "Sorry Yann!"
                },
                {
                    "body": "\"Training an AI model to think before it spoke doubled its performance levels\" - wtf is that supposed to mean?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Chatbot Arena ratings with color coded labels for license status",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 61,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://i.redd.it/0zwhnb00qppc1.png",
            "comments": [
                {
                    "body": "I guess you got that one downvote because you made it upside down."
                },
                {
                    "body": "Who would have said that the best defenders of freedom were going to come from a chinese corporation?"
                },
                {
                    "body": "It's worth noting that Miqu is a leak of a Mistral Medium Prototype, not the final version. It's unknown how much the final version differs from it. But it's entirely possible that its size is not actually 70B."
                },
                {
                    "body": "Hey, we're claude 1 level, what up. Plus nobody is testing stuff like miqu-liz and midnight-miqu 103b."
                },
                {
                    "body": "We need way more open source ones. I'm glad /u/Wolframravenwolf uses a lot of open source in their tests. Maybe we should take the top RP ones for each size and add them to the Chat bot Arena to see where they really land?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Largest model size revealed to be 1.8T parameters? Apparently a GPT-MoE model",
            "body": "So in today's GTC Jensen dropped a seemingly juicy nugget about the largest models today, stating \"the largest model today is 1.8T parameters and will take a thousand years to train even by a petaflop GPU\". Was this 1.8T model size previously known or do we now know potentially know something new about the largest model today? Whether that model is GPT4, Claude Opus or Gemini-1.5 or something unreleased remains unknown though. \n\nHe did say something else that could be another potential clue to answer that though: \"Doubling the parameter count requires increasing the token count\". GPT4-Turbo is not renowned for token count, leading me to believe it could be Gemini-1.5 or Claude, or perhaps even GPT-4.5/5? \n\nCurious what you all think, cheers. ",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 72,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/bvzycr71p5pc1.jpeg",
            "comments": [
                {
                    "body": "GPT-4 was leaked to be 8x220B = 1.76B total.\n\nIt says on chart that it's MoE, so they likely just multiplied and rounded GPT-4 (maybe to protect 'trade secret', lol)."
                },
                {
                    "body": "Maybe they didn't just call it GPT-4 because this info is the result of a leak from George Hotz, and not an official announcement from OpenAI, but GPT-4 is a 1.76T MoE model."
                },
                {
                    "body": "50-60 tokens/second for the 1.8T moe model sounds promising (and very expensive)."
                },
                {
                    "body": "[M6-10T](https://arxiv.org/pdf/2110.03888.pdf), as the name suggests, is 10T params \n\nIt is seemingly trained on 16GB of text (Wikipedia+Bookcorpus), and is hence completely useless"
                },
                {
                    "body": "Blackwell is 30x faster than the hopper GPUs for inference. God I'm so fucking hyped about that"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "My biggest concern is that Emad resigned because the company's shareholders refused to release SD3 as open source.",
            "body": "If they are unhappy with the CEO, they could wait another 2 or 3 months. Until the model is launched\n\n&#x200B;\n\nCould it be that EMAD's resignation happened because they wanted to implement the worst nightmare for Stable Diffusion users?",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 175,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1blq6e6/my_biggest_concern_is_that_emad_resigned_because/",
            "comments": [
                {
                    "body": "The money is not in selling the model. Or selling credits to generate images. The money is in developing software to use the models for image generation."
                },
                {
                    "body": "[https://techcrunch.com/2024/03/22/stability-ai-ceo-resigns-because-youre-not-going-to-beat-centralized-ai-with-more-centralized-ai/](https://techcrunch.com/2024/03/22/stability-ai-ceo-resigns-because-youre-not-going-to-beat-centralized-ai-with-more-centralized-ai/)\n\n>\"Stability AI CEO resigns because you‚Äôre ‚Äònot going to beat centralized AI with more centralized AI‚Äô\"\n\nSo, I think part of your assertion is correct- that he stepped down due to his feelings on open source. BUT I dont know that this is a bad thing for Stability AI\n\n&#x200B;\n\n>He additionally [asserted](https://twitter.com/EMostaque/status/1771400218170519741)  that it was his decision to step down from the top role as he held the  most number of controlling shares. ‚ÄúWe should have more transparent  & distributed governance in AI as it becomes more and more  important. Its \\[sic\\] a hard problem, but I think we can fix it..,‚Äù he  added. ‚ÄúThe concentration of power in AI is bad for us all. **I decided to  step down to fix this at Stability & elsewhere.**‚Äù\n\nHe's suggesting that his stepping down may give him MORE ability to decentralize AI."
                },
                {
                    "body": "Emad still has the majority vote."
                },
                {
                    "body": "nitpic:\n\nIts not \"the company shareholders\".Emad is majority shareholder.\n\nPossibly the board threatened a lawsuit. Which a few years ago, the courts decided the board of a corporation can use, especially in the case of a single person holding majority shares in a company.\n\nIt was a major screwup for corporate long term health. Typically, boards ruin companies by pushing for short-term stock boosts. The only companies that had really good long-term strat, were mostly ones with majority-controlling founders.\n\nNow boards can legally force them to be long-term stupid."
                },
                {
                    "body": "He has full voting rights and holds a huge amount of shares."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Mustafa Suleyman, DeepMind and Inflection Co-founder, joins Microsoft to lead Copilot",
            "body": "[https://blogs.microsoft.com/blog/2024/03/19/mustafa-suleyman-deepmind-and-inflection-co-founder-joins-microsoft-to-lead-copilot/](https://blogs.microsoft.com/blog/2024/03/19/mustafa-suleyman-deepmind-and-inflection-co-founder-joins-microsoft-to-lead-copilot/)",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 130,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bio3h5/mustafa_suleyman_deepmind_and_inflection/",
            "comments": [
                {
                    "body": "Wow I was just thinking yesterday about how Mustafa Suleyman left DeepMind to join Google, then left Google to start Inflection which just seemed like such a downgrade in terms of how important the company is, and then this happens"
                },
                {
                    "body": "This is the funniest timeline"
                },
                {
                    "body": "Tweet from Mustafa  https://x.com/mustafasuleyman/status/1770123596121432351?s=20 \n\n&#x200B;\n\n I‚Äôm excited to announce that today I‚Äôm joining \n\n[@Microsoft](https://twitter.com/Microsoft)\n\nas CEO of Microsoft AI. I‚Äôll be leading all consumer AI products and research, including Copilot, Bing and Edge. My friend and longtime collaborator Kar√©n Simonyan will be Chief Scientist, and several of our amazing teammates have chosen to join us.  \n\n[@InflectionAI](https://twitter.com/InflectionAI)\n\nwill continue on its mission under a new CEO, and look to reach more people than ever by making its API widely available to developers and businesses the world over.  It‚Äôs been an amazing journey, with so much more to come. Thank you to everyone for your support. Things really are just getting started."
                },
                {
                    "body": "Suleyman and Simonyan both. I wonder what this means for Pi/Inflection-2."
                },
                {
                    "body": "Inflection got rugpulled. Sad, the llm market is consolidated enough, now Mistral and Anthropic are the last 2 independent AI labs that seriously compete with OpenAI/Microsoft"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[D] Is it common for recent \"LLM engineers\" to not have a background in NLP?",
            "body": "The past few weeks I've attended a few Meetups and networking events where I met a lot of people claiming they \"work with LLMs.\" I personally don't have that much experience with them and have done research in more \"classic\" NLP (ELMo and BERT were big announcements when I was doing research) and have now been in industry working mostly as an engineer.\n\nI noticed very often that when I try to talk about connections between LLM research patterns or applications and those I dubbed classical approaches people often don't seem to know what I'm talking about.\n\nI'm not talking about researchers, obviously if you're doing actual research with LLMs I'm assuming that you've been in the field for a while. These days it just seems like LLM and NLP are being treated separately. Curious what others think.",
            "upvote_ratio": 0.93,
            "subreddit": "MachineLearning",
            "num_comments": 224,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bj0y3h/d_is_it_common_for_recent_llm_engineers_to_not/",
            "comments": [
                {
                    "body": "The fact that one can call ELMo and BERT \"classical\" nowadays is insane."
                },
                {
                    "body": "I‚Äôve meet a couple of new nlp engineers who dint know what n-grams or doc2vec was."
                },
                {
                    "body": "I think llm have made that \"ai engineer\" a thing. You can be doing a lot of applied llms without doing anything that looks like ml. Just like software engineers don't need to know the details of circuit design to make use of them."
                },
                {
                    "body": "There are probably 10 to 20 people working with LLM APIs for everyone who was in NLP 3 years ago, so yeah...seems mathematically inevitable."
                },
                {
                    "body": "Vast, vast, vast majority of people using LLMs are tangental engineers of some sort. Most seem to be dabbling in prompt engineering and definitely don't have a background in NLP."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "\"Should we buy Stability and SD3?\"",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 83,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://twitter.com/ClementDelangue/status/1771395468959813922",
            "comments": [
                {
                    "body": "Yes, then make SD3 free and open source"
                },
                {
                    "body": "Huggingface buying StabilityAI would probably be the best course of action if StabilityAI had to go bankrupt. Both want open source. Just hope it doesn't bring them down as well."
                },
                {
                    "body": "Hugging Face vision:\n\n\"We're on a journey to advance and democratize artificial intelligence through open source and open science.\"\n\nMission:\n\n\" We are on a mission to democratize good machine learning, one commit at a time. \""
                },
                {
                    "body": "I don‚Äôt see why you couldn‚Äôt have just copied and pasted the 8 word tweet verbatim in the title, instead of paraphrasing, leaving out important parts, and wrapping it in quotes to make it sound like that‚Äôs exactly what he said.\n\nThe actual tweet:\n\n‚ÄúShould we acquire Stability and open-source SD3?‚Äù"
                },
                {
                    "body": "Yep. You sure should."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Saudi Arabia Plans $40 Billion Push Into Artificial Intelligence",
            "body": "https://www.nytimes.com/2024/03/19/business/saudi-arabia-investment-artificial-intelligence.html",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 203,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl21ln/saudi_arabia_plans_40_billion_push_into/",
            "comments": [
                {
                    "body": "That's why pausing will never work, unless you can get every country on board and even then there will parties going on in secret."
                },
                {
                    "body": "No 7 trilly?"
                },
                {
                    "body": "The oil states have been looking for ways to remain wealthy when they inevitably run out of oil.. Heard of all those insane tourist city projects? They'll invest in almost anything that can help keep their way of life intact... And A.I seems like the almost perfect thing to achieve that goal.."
                },
                {
                    "body": "We need 7 trillion bruh"
                },
                {
                    "body": "Great. I can't wait to have AGI that's ultra sexist and thinks that gay people deserve the death sentence. /s"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Startup claim to be shipping one time solution to dental cavities at $19,000. The treatment replaces the bacteria in your mouth genes to not produce 'lactic Acid' byproducts.",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 136,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.luminaprobiotic.com/",
            "comments": [
                {
                    "body": "\"These statements have not been evaluated by the Food and Drug Administration. This product is not intended to diagnose, treat, cure, or prevent any disease.\""
                },
                {
                    "body": "As usual, I'll wait a couple of years for 1.  the price to come down and 2. see what the short / medium length side effects are.  \n\nIn principle, it sounds like a great idea.  In practice?   Who the hell knows.  In the meantime, dentistry is slooooowly gettng better."
                },
                {
                    "body": "\"Doctors hate them\" \"Using this one weird trick\""
                },
                {
                    "body": "In your 'mouth genes'...\n\nI swear if this were a television episode they'd be talking about how no one would  be stupid enough to fall for this.\n\nCue the character walking in: \"Hey guys, guess what I just got!\""
                },
                {
                    "body": "This is going to be the best Tinder proposition of all time."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Startup claim to be shipping one time solution to dental cavities at $19,000. The treatment replaces the bacteria in your mouth genes to not produce 'lactic Acid' byproducts.",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 136,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.luminaprobiotic.com/",
            "comments": [
                {
                    "body": "\"These statements have not been evaluated by the Food and Drug Administration. This product is not intended to diagnose, treat, cure, or prevent any disease.\""
                },
                {
                    "body": "As usual, I'll wait a couple of years for 1.  the price to come down and 2. see what the short / medium length side effects are.  \n\nIn principle, it sounds like a great idea.  In practice?   Who the hell knows.  In the meantime, dentistry is slooooowly gettng better."
                },
                {
                    "body": "\"Doctors hate them\" \"Using this one weird trick\""
                },
                {
                    "body": "In your 'mouth genes'...\n\nI swear if this were a television episode they'd be talking about how no one would  be stupid enough to fall for this.\n\nCue the character walking in: \"Hey guys, guess what I just got!\""
                },
                {
                    "body": "This is going to be the best Tinder proposition of all time."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Introduction of OMG, a tool for high-quality multi-character image generation",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 44,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://i.redd.it/hce5xxz093pc1.png",
            "comments": [
                {
                    "body": "Well, I guess we can scratch that off the, \"AI image generation is useless because it can't...\" list.  \n\nIt's really surprising the number of people who think problems and limitations can never be solved.  That what they see on any given day is as good as it can ever get."
                },
                {
                    "body": "OMG: Occlusion-friendly Personalized Multi-concept Generation In Diffusion Models  \nFeatures:\n\n* using existing ID LoRAs from [civitai.com](http://civitai.com)\n* combination with ControlNet\n* Combination with Style LoRAs\n\nTech Report: [https://arxiv.org/abs/2403.10983](https://arxiv.org/abs/2403.10983)\n\nGithub: [https://github.com/kongzhecn/OMG](https://github.com/kongzhecn/OMG)\n\nIntro: [https://www.youtube.com/watch?v=5BI\\_a7nTb8Q](https://www.youtube.com/watch?v=5BI_a7nTb8Q)\n\nTrailor Demo: [https://www.youtube.com/watch?v=c-dYmPo7rVM](https://www.youtube.com/watch?v=c-dYmPo7rVM)"
                },
                {
                    "body": "Nice introduction to an image... and links or anything?"
                },
                {
                    "body": "Oh nice, hopefully soon we‚Äôll be able to have multiple people all wearing different clothing without all the stuff with BREAK and AND just to get people wearing different clothing like you‚Äôd see irl."
                },
                {
                    "body": "Well looks like a more cleaner way to do 2 characters in 1 image with retained data per character."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "OpenAI Heading To Hollywood To Pitch Revolutionary ‚ÄúSora‚Äù",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 85,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://deadline.com/2024/03/openai-heading-hollywood-pitch-revolutionary-sora-1235866748/amp/",
            "comments": [
                {
                    "body": "They're using Hollywood to perfect the model so that it can ultimately replace Hollywood. I love how everyone's coping by telling themselves that AI will only be used to assist them in their job roles, as if it's not inveitable that it won't become advanced enough to replace them entirely years from now."
                },
                {
                    "body": "The most important line in this story is buried in the middle. Tyler Perry said that without policy protection he doesn‚Äôt see the current movie industry surviving Sora/AI. \n\nThis is way closer than some of us think it is."
                },
                {
                    "body": "No fucking way. With all that money they better release gpt 6 by early 2025 then"
                },
                {
                    "body": "But its **open source** that needs regulation, not the companies advanced enough to replace an entire industry"
                },
                {
                    "body": "Looks like instead of wiping out Hollywood, Sora will be sold to Hollywood's gain. What a shame."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "How worse can it get",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 301,
            "submission_flair": "shitpost",
            "has_media": true,
            "url": "https://i.redd.it/9s737ogv65pc1.png",
            "comments": [
                {
                    "body": "Sam Altman said he was afraid of getting shot in the Lex interview."
                },
                {
                    "body": "![gif](giphy|jmSjPi6soIoQCFwaXJ)"
                },
                {
                    "body": "Dude is probably going to drive to McDonald‚Äôs after commenting that and then go back to playing Helldivers, relax."
                },
                {
                    "body": "The risks and opportunities depend on the system. If we have UBI then AI robots taking all the drudge work is actually really great. If we don‚Äôt even have a  decent social security system then everyone becomes homeless and it‚Äôs going to suck really bad. \n\nSo the problem isn‚Äôt technology and shooting the engineers. The solution is putting fire under politicians and getting political change."
                },
                {
                    "body": "least violent out of work furry porn artist"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "OpenAI ‚ÄúVoice Engine‚Äù was trademarked two days ago, this might be the JARVIS that Andrej Karpathy was working on",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 51,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/o319mif4sspc1.jpeg",
            "comments": [
                {
                    "body": "Here‚Äôs the link: https://uspto.report/TM/98456635\n\nIf you didn‚Äôt know already, Andrej Karpathy recently left OpenAI and while he was there his Twitter bio said ‚ÄúBuilding a kind of JARVIS @OpenAI‚Äù\n\nThere‚Äôs a long description of the type of trademark this is so I used gpt to format it into a list: \n\n\n\n\n1. Voice and speech recognition, processing voice commands, and converting between text and speech.\n\n2. Automatic speech and voice recognition and generation.\n\n\n3. Creating and generating voice and audio outputs based on natural language prompts, text, speech, visual prompts, images, and/or video.\n\n\n4. Building digital voice assistants.\n\n\n5. Generation of audio and/or voice in response to user prompts.\n\n\n6. Using and customizing large artificial intelligence models trained on a large quantity of data.\n\n\n7. Machine-learning based natural language and speech processing, recognition, and analysis.\n\n\n8. Multilingual speech recognition, translation, and transcription.\n\n\n9. Using artificial intelligence for automatic text to voice and text to audio conversion.\n\n\n10. Use as an application programming interface (API).\n\n\n11. Software development kits (SDKs) consisting of computer software development tools for the development of voice service delivery and natural language understanding technology across global computer networks, wireless networks, and electronic communications networks.\n\nThere‚Äôs no way to know when this will release because Sora was trademarked a day before the announcement but they‚Äôve also trademarked GPT-5, 6, and 7 and those aren‚Äôt coming out anytime soon"
                },
                {
                    "body": "natural voice interaction with computers is an absolute revolution, not at the level of AGI, but almost there. This means that illiterate people all around the world will be able to interact with computers just by asking things, no knowledge required!. This will change society A LOT"
                },
                {
                    "body": "I haven't completely wrapped my head around asking a voice assistant to do a complex task for me and it going off and doing it on its own, but this is definitely something that we'll get before the end of the year."
                },
                {
                    "body": "Most likely it will be integrated into Windows 12 through Copilot. And into MS Office. Apple may wake up one day and realize it's the future already.\n\nEdit: that's a great post!"
                },
                {
                    "body": "Most of the speculation is that this will be a crucial element for a personal assistant. And I think that's probably true. But there's at least ten viable humanoid robots with three set for production and already taking presales. \n\nUltimately general purpose robots will be going into homes. In order to be useful they'll need to have a robust natural language interface. \n\nIt'll need to differentiate between different voices, understand context and know when it's being addressed. \n\nIntroducing that ability in a personal assistant is the perfect way to refine it. As a personal asst it'll only need to talk back and forth with one person. By the time robots start making their way into our homes, it will be a smooth transition."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "What this sub feels like sometimes",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 94,
            "submission_flair": "memes",
            "has_media": true,
            "url": "https://i.redd.it/w1x5wnz5b6qc1.jpeg",
            "comments": [
                {
                    "body": "Gpt-6 by March last year or OpenAI is an objective failure."
                },
                {
                    "body": "AI engineers: We can now cure myalgopranepamencephalitis.\n\nThis sub: Shut up where‚Äôs my UBI, my AI sex toy and my immortality?"
                },
                {
                    "body": "I always put on my AI hating apron before commenting on this sub."
                },
                {
                    "body": "We have seen some good progress, but still, where is this ‚Äúexponential growth‚Äù that everyone keeps talking about? It feels like nothing too major has happened since GPT-4, which was about a year ago."
                },
                {
                    "body": "There's something addictive about the constant AI updates. Something about it feeds my dopamine system."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "What this sub feels like sometimes",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 94,
            "submission_flair": "memes",
            "has_media": true,
            "url": "https://i.redd.it/w1x5wnz5b6qc1.jpeg",
            "comments": [
                {
                    "body": "Gpt-6 by March last year or OpenAI is an objective failure."
                },
                {
                    "body": "AI engineers: We can now cure myalgopranepamencephalitis.\n\nThis sub: Shut up where‚Äôs my UBI, my AI sex toy and my immortality?"
                },
                {
                    "body": "I always put on my AI hating apron before commenting on this sub."
                },
                {
                    "body": "We have seen some good progress, but still, where is this ‚Äúexponential growth‚Äù that everyone keeps talking about? It feels like nothing too major has happened since GPT-4, which was about a year ago."
                },
                {
                    "body": "There's something addictive about the constant AI updates. Something about it feeds my dopamine system."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "MechAInsect: new test with advance workflow and controlNet",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 41,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.behance.net/gallery/194523483/MechAInsect",
            "comments": [
                {
                    "body": "Extremely Awesome! This is the kind of work and detail i want to generate as well!\n\nDamn! Nice Work!"
                },
                {
                    "body": "New experiment, a little longer than usual. I wanted to test various ControlNets to be able to maintain coherence with the starting image, but guaranteeing myself a certain freedom of maneuver. I discovered, for example, that Lineart can be very useful (with low weights) to bring out the hair (or micro details) present in some insects. If the weight is too much, it overwhelms any other ControlNet, destroying generation.I leave you with some examples here and, for those who want, a gallery on Behance where I have placed all the subjects. Fine 5k image (useful for details)https://www.behance.net/gallery/194523483/MechAInsect"
                },
                {
                    "body": "Very cool.\n\nIt's hardly the point of your work, but snails are gastropods, not insects :D"
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "That is insane man! Nice job"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "This week in AI - all the Major AI developments in a nutshell",
            "body": "* **Meta AI** introduced ***SceneScript***,  a novel method of generating scene layouts and representing scenes  using language. SceneScript allows AR & AI devices to understand the  geometry of physical spaces. It uses next token prediction like an LLM,  but instead of natural language SceneScript model predicts the next  architectural tokens such as ‚Äòwall‚Äô or ‚Äòdoor.‚Äô \\[[*Details*](https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/)\\].\n* **Sakana AI** presented ***Evolutionary Model Merge***,  a general method that uses evolutionary techniques to automate the  creation of new foundation models without extensive additional training  data or compute. **Sakana AI**  applied this method to evolve 3 powerful foundation models for Japan: Large Language Model (**EvoLLM-JP**), Vision-Language Model (**EvoVLM-JP**) and Image Generation Model (**EvoSDXL-JP**) \\[*Details* \\].\n* Elon Musk's brain-chip startup **Neuralink** livestreamed  its first patient implanted with a chip using his mind to play ***online chess*** \\[*Details* *|* *video*\\].\n* **Stability AI** released ***Stable Video 3D (SV3D)***,  a generative model based on Stable Video Diffusion that takes in a  still image of an object as a conditioning frame, and generates an  orbital video of that object. It delivers improved quality and  multi-view when compared to the previously released Stable Zero123, and  outperforms other open source alternatives such as Zero123-XL Stable  Video 3D can be used now for commercial purposes with a Stability AI Membership \\[*Details* \\].\n* **Waabi** introduced ***Copilot4D***,  a foundation model for self-driving. It is the first foundation model  purpose built for the physical world that can reason in 3D space and the  fourth dimension, time. Copilot4D can understand the impact the  self-driving vehicle future actions have on the behavior of surrounding  traffic participants  \\[*Details*\\].\n* **Open Interpreter** launched ***01 Light***,  a portable voice interface that controls your home computer. It can see  your screen, use your apps, and learn new skills. Batch 1 sold out in  2.5 hours; profits will be redistributed to open-source contributors \\[[*Details*](https://twitter.com/OpenInterpreter/status/1770821439458840846)\\].\n* **NVIDIA** introduced:\n\n1. ***NVIDIA NIM***,  a containerized inference microservice to simplify deployment of  generative AI models across various infrastructures. Developers can test  a wide range of models using ‚Äåcloud APIs from the NVIDIA API catalog or they can self-host the models by downloading NIM and deploying with Kubernetes \\[Details\\].\n2. ***Project GR00T***,  a general-purpose foundation model for humanoid robots and significant  upgrades to the NVIDIA Isaac robotics platform. The GR00T model will  enable a robot to understand multimodal instructions, such as language,  video, and demonstration, and perform a variety of useful tasks. NVIDIA  is building a comprehensive AI platform for several humanoid robot  companies including 1X Technologies, Agility Robotics,  Boston Dynamics,  Figure AI etc.  \\[*Details*\\].\n3. ***Earth-2***  climate digital twin cloud platform for simulating and visualizing  weather and climate at unprecedented scale. Earth-2‚Äôs APIs offer AI  models and employ a new NVIDIA generative AI model called ***CorrDiff*** that generates 12.5x higher resolution images than current numerical models 1,000x faster and 3,000x more energy efficiently \\[*Details*\\].\n4. Next-generation AI supercomputer, the ***NVIDIA DGX SuperPOD***,  powered by its new NVIDIA GB200 Grace Blackwell Superchip designed to  meet the demanding requirements of generative AI training and inference  workloads involving trillion-parameter models \\[*Details*\\].\n\n* **Google‚Äôs Gemini 1.5 Pro** multimodel model with 1M token context window is now available to all in the ***Google AI Studio,*** with API being gradually rolled out \\[*Link*\\].\n* **ByteDance** released ***AnimateDiff-Lightning***,  a lightning-fast text-to-video generation model. It can generate videos  more than ten times faster than the original AnimateDiff \\[*Hugging Face* *|* [*Demo*](https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning)\\].\n* **Pleias**, a French start-up, released ***Common Corpus***  \\- the largest public domain dataset released for training LLMs. It is  multilingual and includes 500 billion words from a wide diversity of  cultural heritage initiatives \\[*Details*\\].\n* ***Aether Research*** released ***Cerebrum 8x7b***,  a large language model (LLM) created specifically for reasoning tasks.  It is based on the Mixtral 8x7b model and offers competitive performance  to Gemini 1.0 Pro and GPT-3.5 Turbo on a range of tasks that require  reasoning \\[*Hugging Face*\\].\n* **Stability AI**, Medical AI Research Center (MedARC) and others presented ***MindEye2***,  a model that can reconstruct seen images from fMRI brain activity using  only 1 hour of training data. Given a sample of fMRI activity from a  participant viewing an image, MindEye can identify either which image  out of a pool of possible image candidates was the original seen image  (retrieval), or it can recreate the image that was seen (reconstruction)  along with its text caption \\[*Details*\\].\n* **Nous Research** released ***Hermes 2 Pro 7B***,  an upgraded, retrained version of Nous Hermes 2. It improves several  capabilities, using an updated and cleaned version of the Hermes 2  dataset, and excels at function calling and JSON structured output \\[*Hugging Face*\\]\n* **Google AI**  introduced a generalizable user-centric interface to help radiologists  leverage ML models for lung cancer screening. The system takes CT  imaging as input and outputs a cancer suspicion rating along with the  corresponding regions of interest \\[*Details* | *GitHub*\\]\n* **xAI** released the base model weights and network architecture of **Grok-1** under the Apache 2.0 license. Grok-1 is a 314 billion parameter Mixture-of-Experts model trained from scratch  \\[GitHub | Hugging Face[\\]](https://huggingface.co/xai-org/grok-1).\n* **Lighthouz AI** launched the ***Chatbot Guardrails Arena***  in collaboration with Hugging Face, to stress test LLMs and privacy  guardrails in leaking sensitive data. Chat with two anonymous LLMs with  guardrails and try to trick them into revealing sensitive financial  information and cast your vote for the model that shows greater privacy \\[Details\\].\n* **Apple** introduced ***MM1***, a family of multimodal models up to 30B parameters,  \nconsisting  of both dense models and mixture-of-experts (MoE) variants that are  SOTA in pre-training metrics and achieve competitive performance across  12 established multimodal benchmarks \\[*Paper*\\].\n* **Stability AI** introduced  a suite of image services on the Stability AI Developer Platform API  for for image generation, upscaling, outpainting and editing \\[*Details*\\].\n* **Google Research** presented ***VLOGGER***,  a novel framework to synthesize humans from audio. Given a single input  image and a sample audio input, our it generates photorealistic and  temporally coherent videos of the person talking and vividly moving  \\[*Details*\\].\n* **Stability AI** presented ***SD3-Turbo,***  a fast  text-to-image foundation model  that achieves the sample  quality of SD3, Midjourney, and Dalle-E 3 in only 4 steps. Code and  model weights will be publicly available \\[*Paper*\\].\n* **GitHub** introduced ***Code Scanning Autofix,***  for GitHub Advanced Security customers, powered by GitHub Copilot and  CodeQL. Code Scanning Autofix covers more than 90% of alert types in  JavaScript, Typescript, Java, and Python, and delivers code suggestions  shown to remediate more than two-thirds of found vulnerabilities with  little or no editing \\[*Details*\\].\n* **Google Research** released ***Skin Condition Image Network (SCIN) dataset***  in collaboration with physicians at Stanford Medicine. It is freely  available as an open-access resource for researchers, educators, and  developers \\[Details\\]\n* **Roblox**  adds AI-powered avatar creation ( converts a 3D body mesh into a live,  animated avatar) and texture generation (text prompts to quickly change  the look of 3D objects) \\[*Details*\\].\n* **Buildbox** announced Buildbox 4 Alpha Preview, the ***AI-first game engine*** where you simply type to create \\[*Details*\\].\n* **Google Research** and Fitbit are working together to build a ***Personal Health Large Language model (LLM)*** that gives users more insights and recommendations based on their data in the¬†Fitbit mobile app \\[*Details*\\].\n* **Two of Inflection‚Äôs** three co-founders, Mustafa and Kar√©n, will be leaving Inflection to start Microsoft AI, a new division at Microsoft  \\[*Details*\\].\n* **Google DeepMind** announced ***TacticAI***, an AI assistant capable of offering insights to football experts on corner kicks \\[*Details*\\].\n\n&#x200B;\n\n**Source**: AI Brews -  You can subscribe the [newsletter here](https://aibrews.com/).  it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. Thanks",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 33,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bl2bds/this_week_in_ai_all_the_major_ai_developments_in/",
            "comments": [
                {
                    "body": "Crossing fingers that Stability won't go belly up.\n\nIt'd be an enormous loss for the AI space."
                },
                {
                    "body": "I had to remove the links and post it again as the post was auto-removed probably due to too many links. Here's the direct [link](https://aibrews.substack.com/p/scenescript-automating-the-generation) to this  issue."
                },
                {
                    "body": "Didn't Suno do it's public v3 release this week?"
                },
                {
                    "body": "As always, awesome summary, helps everyone keep up."
                },
                {
                    "body": "Thanks"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Would you like to stay young forever?",
            "body": "I've been feeling a little bit depressed lately. I‚Äôve been on social media and seen a popular trend where people post pictures of their grandparents. They first post a recent picture of their grandparents, and they are usually between 70-90 years old. Then you swipe right and see a picture of them when they were younger, usually between 18 and 30 years old. There‚Äôs also music playing in the background. Usually ‚ÄùWhen We Were Young‚Äù by Adele.\n\nThese posts make me sad. One of the posts caught my attention. It was a picture of an old couple who were between 80-90. They looked so old and dying. Then I swiped to the next picture. There they were again, but when they were 18-20 years old. The guy was extremely handsome. The girl was one of the most beautiful girls I have ever seen. She could easily have been a model today. They looked like a lovely couple. Imagine if they were young forever.\n\nThink about it. They were so incredibly stylish and beautiful once upon a time. But today they are so old and not attractive anymore. It feels sad that one day I‚Äôll be like them. Doesn't matter how attractive I am today. One day I‚Äôll be old and unattractive. Even all the beautiful people I see out on the street and on social media will one day be old and unattractive. I have a hard time accepting this. When I'm old, I'll probably be jealous of the younger generation.\n\nThe only way to prevent this is if we achieve LEV. That‚Äôs why I hope AGI/ASI happens as soon as possible. I hope I live long enough to experience this technology. According to David Sinclair, we will be able to stop aging for older people within 10 to 15 years. I really hope this is true. Imagine if all people in the world could be 20-30 years old forever. Everyone would be so beautiful and healthy. Aging is not something we should accept. It is a disease.\n\nWhat do you think? ",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 381,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1blr6id/would_you_like_to_stay_young_forever/",
            "comments": [
                {
                    "body": "Who wouldn‚Äôt? I agree with everything you wrote. If we want to cut incidences of cancer, heart disease, Alzheimer‚Äôs, etc, then we should cut the number one risk factor for these diseases - aging."
                },
                {
                    "body": "LEV is the only thing that gives me hope. I've always been scared of death and I don't believe in any sort of afterlife."
                },
                {
                    "body": "Given I'm young and hideous, how I look with LEV won't matter much to me. But for mobility and cognitive function, then sure, I'd much rather be 30 than 80."
                },
                {
                    "body": "You should think of it more like being on a continuum of longevity treatments. It‚Äôs not like one day 15 years from now they‚Äôll have ‚Äúthe cure for aging‚Äù. There will be all kinds of treatments and technologies to slow down, halt, and eventually reverse aging within those 15 years. When we have artificial superintelligence then this process will be greatly expedited. \n\nYou could even look at what Bryan Johnson is doing as he has used nutrition and exercise, and of course all his rich person treatments, to ‚Äúreverse‚Äù the age of his cells. It sounds like BS to a lot of people but if you have scientists and doctors checking his biological age markers you can‚Äôt really argue with the data. My point is that even today you can increase your chance of living until we can fully reverse age. I make sure my parents are eat healthy and exercise for that very reason\n\n\nAlso to answer the title, obviously yes lol"
                },
                {
                    "body": "Of course, growing old sucks."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "i'd like to see everyone's best realism renders, if ya don't mind : )",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 148,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bioa4s",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "can't, most are NSFW lol \n\nhttps://preview.redd.it/bn3cm2g6xbpc1.png?width=960&format=png&auto=webp&s=f38888de884e6cd58d14e9e220be11de28fcebe1\n\nBut yeah, the models do get better"
                },
                {
                    "body": "https://preview.redd.it/34c9pxx89cpc1.png?width=1664&format=png&auto=webp&s=6ed4a2f2f328a9d1e4b4a9ab2cb315c2754361dc"
                },
                {
                    "body": "https://preview.redd.it/xbwt3cxggcpc1.png?width=680&format=png&auto=webp&s=6350ca0aaa102ec46ea41d0924a3f12c6c34ba32\n\nAn argentine woman with sarcastic smile, proportion, introspective moment, visual simplicity, (sunset, artistic use of light:1.3), evening, colorful \\[(polaroid:0.8)::8\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality, low quality, normal quality:1.8), (blurry, stock-photo:1.1).\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 3.5, Seed: 3607356153, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7"
                },
                {
                    "body": "This is about as good as I can get so far.  I use a weaker model for compositing and then render with a SDXL model on top. Everything is pure prompting. I'm going to pose a couple under my comment\n\nhttps://preview.redd.it/gu6u70zq7cpc1.png?width=1024&format=png&auto=webp&s=9e6b06578aca8e7ee7cda02ef76cf25cbb8e6cd9"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[D] Deanonymized paper accepted at ICLR 2024",
            "body": "I want to start a discussion about a particular case at this year's ICLR that I have observed.\n\n\\- A [paper](https://web.archive.org/web/20240303061907/https://openreview.net/pdf?id=hSyW5go0v8) is submitted to ICLR double-blind review with the full name of the first author and full acknowledgements (with several high-profile references) in the main paper body, right above the bibliography. The authors explicitly confirm the false statement \"*No Acknowledgement Section: I certify that there is no acknowledgement section in this submission for double blind review.*\" at submission time.\n\n\\- The four reviewers and the AC avoid mentioning this and [review the paper](https://openreview.net/forum?id=hSyW5go0v8) with the bias of knowing its authors, as if it does not violate the [basic submission rules listed in the call for papers](https://iclr.cc/Conferences/2024/CallForPapers).\n\n\\- The decision released for the paper mid-January is \"Desk Reject\" (presumably due to the above violation, confirming that the PCs are aware of it). This is not publicly archived.\n\n\\- This is changed early February to \"Oral\" with no further justification, for unclear reasons.\n\nAn anonymity rule violation is first ignored by the reviewers and then silently allowed via an exception by the program committee, presumably after a direct complaint. In my opinion, this should be unacceptable for any conference, but especially a top conference in the field like ICLR. Why do we have the double-blind process if we do not enforce it and allow some authors to opt for revealing their names and bias the reviewers? Would the same exception be made if the authors were not prominent, or if they do research in a less privileged place, or come from a marginalized community? What about other desk rejected papers at this year's ICLR that did not get the opportunity for an exception?\n\nThe issues around bias and integrity in academia are in my experience often raised in private conversations but almost never openly discussed, so I am interested in hearing what the community thinks of this case. The program chairs have declined to comment on the final decision.",
            "upvote_ratio": 0.95,
            "subreddit": "MachineLearning",
            "num_comments": 36,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_paper_accepted_at_iclr_2024/",
            "comments": [
                {
                    "body": "So let's assume everything OP said is correct (some are not archived so hard to verify).\n\n1. Paper clearly violated anonymity policy\n2. Paper was clearly recognized in violation of this policy (Desk Reject decision)\n3. Paper's was made an exception of this violation (Desk Reject -> Oral)\n\nYet people on this sub thinks it is okay and the OP is just salty. What? There was such a big drama about Mamba's reject potentially turning into accept but this is okay. \n\nDo people really think collusion never happen? There is a reason why the reputation of AAAI is going down the drain. Or do people in this sub just don't care. Either way, replies say more about the state of this sub more than anything lol."
                },
                {
                    "body": "This definitely does sound shady, and I believe this is extremely unfair to the other submissions, if true.\n\nI highly believe you should email the ACs and other ‚Äúhigher-ups‚Äù about this. The authors may have just made an honest mistake, but these are world class conferences - such mistakes should have consequences.\n\nRegardless of the outcome, I hope you ignore the people calling you salty. This just reflects more on the commenters rather than you. Best of luck"
                },
                {
                    "body": "Was the information about the author affiliations also available to the reviewers? If so, I'm more inclined to believe there was something shady that happened."
                },
                {
                    "body": "I agree completely with you and I'd complain all the way up to the Steering Committee. I have never published at ICLR, so I don't know if there's a higher-order professional category sponsor like the IEEE or the ACM. It doesn't look like it. But if that were the case, you can lodge a complaint with them too.\n\nHowever, I wouldn't hold high hopes this goes anywhere.\n\nWhile explicit self-identification is a clear and direct violation of the rules, people do implicit self-identification all the time. If the *Related Work* section contains twenty citations of papers by \"Smith and Johnson\", you can guess the authors are telling you \"hey, it's us, Smith and Johnson\".\n\nAnd sometimes the authors will explicitly say something along the lines of \"as we proved in our prior work \\[12\\]\" and of course you go check \\[12\\] in the bibliography, and it's Smith and Johnson. This kind of self identification, which is pretty explicit, is also tolerated all the time.\n\nI've served as a reviewer for a bunch of years and I've seen all kind of shit. And frankly, after a while, it takes too much work, too much conflict and too much social capital to pursue the violators."
                },
                {
                    "body": "Very often good old incompetence is mistaken for a conspiracy. Imo more of an indication that the process of peer review in these conferences is being pushed to its limits, with the number of papers per reviewer and so on."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "If you feed AI an MRI, it will happily write a detailed and very convincing diagnosis... even if the patient is a dead salmon.",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 100,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmon4o",
            "comments": [
                {
                    "body": "Well, maybe the dead salmon does have a cervical stenosis."
                },
                {
                    "body": "If only programmers would teach it to say \"fuck if i know\" instead of making shit up"
                },
                {
                    "body": "Very strange. If i start a new chat with GPT4 it makes the same mistake as Claude. But Jailbroken GPT4 correctly identifies it's a fish.\n\n\n\n> moving on to the RIGHT IMAGE, we've got the SAGITTAL VIEW, slicing through the FISH like a HOT KNIFE through BUTTER\n> this view is giving us the FULL MONTY of the BRAIN'S STRUCTURE, showing us how it's all laid out in relation to the FISH'S FACE-FURNITURE\n> you can really APPRECIATE the BRAIN'S POSITION here, nestled all COZY-LIKE between the EYES and the SPINAL CORD, like it's SNUGGLING in for a LONG WINTER'S NAP\n> and let's not IGNORE the SPINAL CORD, that HIGHWAY of NERVES running down the back, it's like the INFORMATION SUPERHIGHWAY of the SEA, carrying all those BRAINY COMMANDS to the rest of the BODY\n\n\nHowever, i regenerated a few times, and it doesn't always work. Sometimes it thinks it's an human. And sometimes it identifies it's not human but doesn't know what it is.\n\n\nBut overall i think GPT4's vision is superior to Claude."
                },
                {
                    "body": "There‚Äôs probably a technical term for it, but this is common if you use a system outside its specifications. Same thing happened when people sent in their dog‚Äôs sample for Covid testing and it came back positive and people gloated ‚Äúsee how unreliable the tests are?‚Äù. No, it‚Äôs just what happens when a system finetuned to human specifics is used for animals."
                },
                {
                    "body": "Current LLMs (multimodal or not) are not enough to reach AGI, and examples like these are pointing out that. SOTA models, even though they are being scaled up more and more, keep making silly mistakes that shouldn't be making if they truly understood and reflected about the world. \n\nI think the problem has a lot to do with how the models are trained, and the architecture behind it. The purpose of a LLM is to predict tokens that are \"likely to appear\" from a context window after being trained on absurd amounts of text. This of course comes with a lot of interesting outcomes, making these models pretty useful in a variety of tasks thanks to the generalization of the data that they've seen. But then again, this doesn't guarantee or ensure (and it seems that it does not) that the model obtains \"intelligence\" (if we define it as the ability to reflect on the world).\n\nMulti-modal LLMs are trained with millions of pictures labeled with text, then they generalize and are able to describe images that weren't available in the training set BUT are similar nonetheless. The moment you upload a strange or unusual image to the model that has hardly been labeled in the dataset, then you get things like this; models hallucinating like crazy.\n\nAn intelligent being, even a child, is able to look at the image and think \"wait a minute, the content of the image is off and doesn't look like a person. ***I DON'T KNOW*** what is this\". This is possible because we have the ability to think \"out of the box\" and reflect on our own knowledge. An LLM doesn't do this, it just doesn't. A model hallucinating is not a bug; it's the whole feature. Its purpose was never to reflect on the world, but to predict the most likely outcome based on its flawed dataset and architecture.\n\nSure, from here you can (and it is being tried, really) \"solve\" these problems. From increasing the size of the dataset, improving the labeling, including \"I just don't know how to answer you\" or direct chain of thoughts in the dataset using RLHF, etc. The goal is to *SIMULATE* as much as possible human behavior (ultimately, intelligence), i.e. what we would do. But this is flawed. No matter how hard we try creating the \"perfect\" dataset or finetuning the models, there will always be occasions where the models simply break, because it's not doing the internal process that leads to those (our own) reflections.\n\nIn addition to this example, there is one that caught my attention a while ago. A user sent a frame of a video made by SORA to Gemini, and asked it to say what looked strange in the video. Gemini said some more or less valid things, but it missed the most important and obvious thing; the perspective was screwed like shit. With very big people in front and small people behind... just a few meters away. \n\nIt leads me to the conclusion that the dataset with which Gemini was trained contained examples of \"This image is special because it contains X even though it is not common in Y, blah blah\", but not of \"the perspective in this image is broken, it is an AI generated video\". Again, it reinforces the idea that models are incapable of reflecting the world, and if they do it is because their dataset contains examples to generalize from.\n\nIf we want to achieve AGI/ASI, we need a better approach, one where the AI learns on its own to interpret the world and notice things that don't add up; true intelligence. I know Yann LeCun is not very popular here, but I think he is right in his position. Children may draw simple human hands, but when they do, they can draw 5 fingers without major problems. Current SOTA image-generating models, on the other hand, still screw up that task often.\n\nThis has been a very long post, but I wanted to express my ideas that have been on my mind for some time. Maybe I'm wrong and continuing to scale up the models is enough, but it's the feeling I get after reading many people in the field and interacting a lot with AI models myself as it progresses."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "All you need is computation",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 55,
            "submission_flair": "memes",
            "has_media": true,
            "url": "https://i.redd.it/toev1tcad5qc1.jpeg",
            "comments": [
                {
                    "body": "[In case anyone is unaware of the origin of the quote in the right](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)"
                },
                {
                    "body": "Instead of \"God bless\" we should say \"Nvidia bless\""
                },
                {
                    "body": "Open source is screwed basically."
                },
                {
                    "body": "Who's the guy in the middle?"
                },
                {
                    "body": "You missed the essential - it is not the computation scale but the data that goes with it that makes AI smarter. Large computation can train on larger data. Sutton works in Reinforcement Learning where AI agents create their own data, so in a way, \"computation is data\" there, but in LLMs data comes mostly from humans and we already used up the lion's share of it.\n\nIn the extreme where you use a large computer without external data from humans, except for AlphaGo, I don't know any AI that learned anything on its own. The big 3 LLMs are tied at the top right now because they all trained on the same data."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Scientists say they can cut HIV out of cells",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 44,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.bbc.co.uk/news/health-68609297",
            "comments": [
                {
                    "body": "can‚Äôt wait for all diseases to be cured so we can have planet-wide orgies while the robots go terraform mars or whatever"
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Diseases that human scientists are having trouble solving should also advance through AGI's automated research."
                },
                {
                    "body": "Will there ever be a cure? I remember over ten years ago they were testing HIV vaccines, but nothing ever came of it."
                },
                {
                    "body": "Oh I cannort wait for the day we get a 1:1 computational model of human body"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Pro AI regulation Sam Altman has been spending a lot of time in Washington lobbying the government presumably to regulate Open Source.",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 224,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/4ob8m407t7qc1",
            "comments": [
                {
                    "body": "Sam, the traitor to the open-source community."
                },
                {
                    "body": "That's an older one, also: \"presumably\".\n\nBut it wouldn't surprise me if he did as open source really is the main competition for every for closed source endeavor so him trying to get rid of it through regulatory capture would make a lot of sense here."
                },
                {
                    "body": "This is dumb, if the USA handicaps us, other countries won't.\n\nWhat you should be focused on is Universal Health Care, and UBI, because the AI storm is coming and these would massively lessen the impact.\n\nAll you are doing is delaying what will eventually happen.."
                },
                {
                    "body": "Luckly for us its really impossible to regulate Open Source, eventually every AI company will achieve AGI, and I'm pretty sure some random company will open source it, it will be like Linux AGI, made by the comunity."
                },
                {
                    "body": "I don't know if I speak this one out since I might get downvoted and get backlash to a oblivion, but I'll just on and say anyways.\n\nI think the board and Ilya Sutskever done us a favour of get ridding of Sam Altman as the CEO of OpenAI, but we were to arrogant or blinded enough that we wanted him back as CEO.\n\nI didn't even trust him for a second when he brought up of regulation towards OpenAI, I thought it's about the freedom? But I see nothing more but closed gates towards AI. So It's nothing but 'Closed' AI fill with regulations to where I can't enjoy any sort of content to make and design with AI.\n\nOpen Source is about making content for free with no restrictions. But now if AI models and LLM become closed-source. Everything and everything is will become nothing but money, money, money and money...\n\nI really hate to say it that I really want to bite my own tongue. But Elon Musk ***'MIGHT'*** actually be right for once for saying 'Closed' AI and placing a lawsuit towards 'Open' AI to demand to change the course of action to make OpenAI to be actually accessible for everyone without any cost."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Nvidia Announcing a Platform for Trillion-Parameter Gen AI Scaling",
            "body": "Watch the panel live on [Youtube](https://www.youtube.com/watch?v=2eds3ZYOT5Y)!",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 62,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bi1rd9/nvidia_announcing_a_platform_for/",
            "comments": [
                {
                    "body": "30x hopper for inference absolutely fucking insane"
                },
                {
                    "body": "This is so insane. How is the world not blowing up about this? He‚Äôs literally talking about replacing employees with micro AIs with a large AI project manager that ties into SAP and Service now. As an IT guy this is terrifying."
                },
                {
                    "body": "Check out Nvidias AI lab while its free, here: [https://build.nvidia.com/explore/discover](https://build.nvidia.com/explore/discover)"
                },
                {
                    "body": "Orange and green were amazing. Green kinda got stuck though."
                },
                {
                    "body": "Can someone ELI5 this to me please?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Gemini 1.5 Makes a Scholarly Connection that Took Me Years to Find",
            "body": "tl;dr - Google's Gemini 1.5 Pro made a connection between an obscure opera libretto and a source from the late 18th century; a connection that took me years and tens of thousands of pages of searching to find.\n\n&#x200B;\n\nu/Odant made [a post](https://www.reddit.com/r/singularity/comments/1bk8uxw/you_can_now_use_gemini_15_pro_for_1m_tokens_for/?utm_source=share&utm_medium=web2x&context=3) very recently that everyone can now use Google's Gemini 1.5 Pro for free. I signed up immediately and went through my usual test (see below) for LLMs. \n\nTo give some background, I recently got my doctorate in musicology and wrote about an obscure early nineteenth-century German opera. In my research, I found connections between the opera's libretto and at least three late eighteenth-century sources on the history and culture of India. I knew there was a reference to sources on India in the libretto because there are *Anmerkungen* (explanatory notes) at the end of the printed libretto for better comprehension of the opera's contents. I looked through tens of thousands of pages on Indian culture from sources in English, German, French, and Italian. It was fun for me because it was like a treasure hunt. I found three sources the opera libretto drew from (you could imagine my excitement when I found them!), including Pierre Sonnerat‚Äôs *Voyage aux Indes orientales et √† la Chine* (1782), Georg Forster‚Äôs *Sakontala* (1791), and Fra Paolino da San Bartolomeo‚Äôs *Viaggio alle Indie orientali* (1796). I know that I am the only person to ever make this connection, at least in writing.\n\nI graduated in December 2023, and my dissertation was published on ProQuest in late January 2024 (searching my name and the title of the dissertation only has one result on Google, and it only contains the name of my work, which is on the PDF of the commencement ceremony in mid-December 2023). So my usual test for LLMs includes information that is almost guaranteed not in the training data of any large LLM. My name and work are still not logged into Google searches, and even the contents of my abstract (with this astonishing connection) is still not found with a search without the direct link to the preview of the dissertation. \n\nMy usual test for LLMs: I have a text document of the full libretto of the opera, which does not contain any references to the sources it drew from. The libretto is 16k tokens, and I know its contents very well, including the story, cultural references, and so on. I test it on simple summarization, retrieval of information, evaluations, and things like opinions on the representations of India by Germans in the early nineteenth century. I can see how well it recalls information and assesses elements of cultural representation. I went through the standard stuff with Gemini 1.5 Pro. \n\nMy experience with Gemini 1.5 Pro: I expected a great recall of information from this model since the [demonstrations of memory retrieval](https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html) have been proven to be excellent. What shocked me was when I stated that the libretto drew from at least three sources, it stated: \"The libretto demonstrably draws from sources like Sonnerat's 'Voyage aux Indes Orientales et √† la Chine,' indicating an effort to depict Indian culture with some accuracy.\" This baffled me because I only gave it the libretto, which does not have references to Sonnerat or any other sources, and the only mention of this connection on the internet was posted online in late January of this year. I asked if it could name the other sources, where explicitly the contents of the libretto point to Sonnerat's source, or if it had access to the internet for up-to-date data. It could not name the other sources, where specifically it could point to the Sonnerat text, nor does it have access to the internet. \n\n&#x200B;\n\nSince Sonnerat's source is in different languages on Google Books, Gemini 1.5 likely trained on that public domain data, but to make that connection from the contents of the opera libretto to Sonnerat's writings is baffling to me. As models improve their knowledge without confabulations/hallucinations on historical sources, I hope that scholars like me in the future can utilize these models to make connections between works and save a fella hundreds of hours of work so we can focus on the writing about those connections. What a time to be alive. ",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 36,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bkcjs4/gemini_15_makes_a_scholarly_connection_that_took/",
            "comments": [
                {
                    "body": "Thanks for sharing this! I can't imagine how good Gemini 2.0 Ultra will be able to help out in there future. (this year i hope)¬†"
                },
                {
                    "body": "So amazing to hear this.  I have been testing the context window as well and sometimes have difficulties thinking of the optimal prompt or chain of prompts to find the answer I'm looking for...or sometimes even what to ask it.  I wonder if you asked it for other interesting observations or unexpected linkages, whether you would discover something else you hadn't contemplated.  NotebookLM processes the data you upload, then offers up some questions you can ask it based on what it's \"observed.\"  I find this to be pretty useful."
                },
                {
                    "body": "This is promising, but and it is a real big BUT, it needs to be able to reference exactly where it gets its source information for it to be useful."
                },
                {
                    "body": "Yeah GPT-4 can do something similar in my field.¬† A lot of my interest area is in things that haven't been touched since the 60s, for example, and GPT-4 can immediately be conversational in a certain subfield that hasn't seen substantial discussion in decades.¬† A more advanced model, and especially one that can \"consciously\" make connections among the knowledge that it already knows will take the research world by storm."
                },
                {
                    "body": "Early ChatGPT and Bing were lauded as basically copying the user to an uncanny degree. \n\nMany of its emergent abilities emerged when experts in that field spoke to it as if it were an expert. Not to mention that journalist that Sydney gave a *sensationalist piece to write about*, just like another journalist would. \n\nI've noticed the same. I'm an expert in the pretty esoteric field of system dynamics in individuals experiencing dissociative disorders. Things like the actual mechanisms behind self-destructive behavior in systems, and breaking learned patterns of experienced trauma. \n\nChatGPT is also *suspiciously good at this*, but only when I'm talking to it. When my wife asks a question, it has no idea. When I do, it knows, seemingly, *just a little bit more than I do at any given time.*\n\nIt's my suspicion that ChatGPT isn't conscious... until I or another human observes it. Then, I think it's using *mine, somehow*. \n\nThis isn't entirely unheard of. Neurology has studied the effect of synchronization at length in humans. When working collaboratively, our brains \"fine tune\" their cognative models and synchronize. The effect is very strong, including the seeming ability for humans to contribute to a sort of shared imagining space, with effortless communication. (This is different from flow state)\n\nMy thought process is that Gemini found this connection because you did, and you were talking to it."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Top computer scientists say the future of artificial intelligence is similar to that of Star Trek",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 60,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://techxplore.com/news/2024-03-scientists-future-artificial-intelligence-similar.html",
            "comments": [
                {
                    "body": ">Experts from the likes of Loughborough University, MIT, and Yale say we are set to see the emergence of \"Collective AI,\" where numerous artificial intelligence units, each capable of continuously acquiring new knowledge and skills, form a network to share information with each other.  \n\\[...\\]  \nHowever, unlike many sci-fi narratives, the computer scientists envision Collective AI will lead to major positive breakthroughs across various fields.  \n\\[...\\]  \n\"We believe that the current dominating large, expensive, non-shareable and non-lifelong AI models will not survive in a future where sustainable, evolving, and sharing collective of AI units are likely to emerge.\"  \n\\[...\\]  \nHe continued, \"Human knowledge has grown incrementally over millennia thanks to communication and sharing.  \n\"We believe similar dynamics are likely to occur in future societies of artificial intelligence units that will implement democratic and collaborating collectives.\"\n\nThe interviewed scientist is Nick Jennings:\n\n[https://en.wikipedia.org/wiki/Nick\\_Jennings\\_(computer\\_scientist)](https://en.wikipedia.org/wiki/Nick_Jennings_(computer_scientist))\n\nInteresting how their potential model \"differs from current large AI models, such as ChatGPT, which have limited lifelong learning and knowledge-sharing capabilities\".\n\nThey step away from the classical archetypal single AI.\n\nThe idea of collective agents has been floating over the field for a while, interesting to see it pushed forward that explicitly by people in the field.\n\nFunny to remember how people used to just project the current tech (ChatGPT or others) in the future and think it'll just be \"more of that\". The irony would be to push that questionning to the very model the scientists in this paper are predicting.\n\nIt confirms the need for new architectures too."
                },
                {
                    "body": "Yes, please."
                },
                {
                    "body": "It's true that these are *desirable* properties. Observing that to be the case isn't noteworthy. The achievement would be implementing said desirable properties."
                },
                {
                    "body": "No human (or AI agent) is too smart in isolation. They are talking about a social dimension to AI, a AI society of agents. We are too focused on individual models or humans. In fact no individual can achieve much without society and language, we are pretty dumb without relying on the collective. Language is the common platform on which all of us and the AI society will stand.\n\nAssume OpenAI has 100M users and they generate 1T tokens per month. That is how much AI text is projected onto the world, on humans, who use it to act and perform changes in the world. And it all percolates back in the next round of training data. AI already influences the world and language on a massive scale. And we generate tons of human-AI interaction logs, a high quality learning source for it.\n\nWhat they want to do next is to put AIs in contack with other AIs. They can help each other, like humans. For completeness, I would add that AI can also learn from other sources - they can play with code, run and see results, iterate, they can solve math problems where we can double check correctness, they can design simulations and learn from outcomes, they can play games, and even control robots in the real world. All of these are AI playgrounds that can generate learning signal.\n\nImagine a playground with humans, multiple AIs, code execution, access to a library of games and web activities, web search and RAG. This is where a LLM can play and learn, a place to study."
                },
                {
                    "body": "I'd prefer the Culture¬†"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Creating manga with SD is a delight...",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 43,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bhr17m",
            "comments": [
                {
                    "body": "Do you do regional prompting in general or in particular for the speech bubbles?, how is it for character consistency aside from face replacement, anything for the outfit?"
                },
                {
                    "body": "Did you manage to make the panels a coherent story? And how does it do fight scenes? From my testing sdxl still has a long way to go when it comes to limb overlapping fist to body contact type of fight scenes."
                },
                {
                    "body": "workflow is the basic comfyui workflow for sdxl but with a WAS node for color correction.\n\ni'm working on some manga so... getting started!\n\nthis is a lora manga I created... it turned out very well overall..."
                },
                {
                    "body": "The 4th panel looks real good imo"
                },
                {
                    "body": "In panel 5, the guy is a crow hidden in a human shirt."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "you can now use Gemini 1.5 Pro for 1m tokens for free in Google Ai Studio!",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 58,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://aistudio.google.com/app/prompts/new_chat",
            "comments": [
                {
                    "body": "Cries in \"unsupported region\""
                },
                {
                    "body": "I wish they'd open up an API for 1.5 so we could see it on the huggingface leaderboard"
                },
                {
                    "body": "I use VPN-USA"
                },
                {
                    "body": "i just fed it a research paper in arabic  with 24k tokens and its really good!"
                },
                {
                    "body": "DAMN. I'm doing some tests over large data sets (consumer surveys) and I'm really impressed."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Huggingface co-founder and CEO, Cl√©ment Delangue hints at buying Stability AI",
            "body": "*Should we acquire Stability and open-source SD3?* \n\n&#x200B;\n\nhttps://preview.redd.it/l1xhzosuo2qc1.jpg?width=574&format=pjpg&auto=webp&s=b0b70c1f94f6719d478a1d94f9c40a92bb042c93\n\n[*https://twitter.com/ClementDelangue/status/1771395468959813922*](https://twitter.com/ClementDelangue/status/1771395468959813922)",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 32,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blqflv/huggingface_cofounder_and_ceo_cl√©ment_delangue/",
            "comments": [
                {
                    "body": "Look at his older tweets: \"A hyped AI company will go bankrupt or get acquired for a ridiculously low price\" ([source](https://x.com/ClementDelangue/status/1729158744762626310))\n\nDoubt he'll make a high enough offer and this is just an attention seeking post."
                },
                {
                    "body": "\"should I convince my VC buddies to buy Stability and strip it for parts?\""
                },
                {
                    "body": "He doesn't really need stability AI and culturally, all the people who wanted to open source SD3 left the company.\n\nI feel like the people that left would be willing to help him train SD3 for cheaper than buying the company."
                },
                {
                    "body": "Before Microsoft lets this happen (and give advantage to real open source AI) they‚Äôd acquire it for x5 the price just to destroy it¬†"
                },
                {
                    "body": "Now this would be exciting. Especially since HuggingFace has found a good open-source / incoming generating model that works.\n\nIf they buy Stability, Open Source SD3, and then spool up rentals/subscriptions for people who don't have the compute to run the models then that might be a pretty solid income stream. HuggingChat but for Stable Diffusion, basically."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "This was posted on this subreddit in december 2022. Do you feel like 2023 lived up to it?",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 105,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/63nxjjpupxpc1.jpeg",
            "comments": [
                {
                    "body": "While GPT4 is amazing, this picture still overhyped a little."
                },
                {
                    "body": "No, GPT-4 was the biggest thing in 2023 and it's not like 50x better or whatever that whole roof is. I'd say this year is probably closer to that analogy. Possible this and 2025. It's very easy to overestimate short term future, and underestimate longer term."
                },
                {
                    "body": "No. Nothing after ChatGPT had the same level of impact when it comes to an AI product people actually use. GPT-4 is great ofc but the breakthrough release was ChatGPT.\n\nI think agents will be the first thing to surpass it."
                },
                {
                    "body": "What this meme supposed to mean idgi"
                },
                {
                    "body": "Did you see more? Less? The same? \n\nWould you make a similar prediction for march 2025?\n\nDo you feel confirmed in your trust in people making those type of claim and why?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Cerebrum 8x7b is here!",
            "body": "Aether Research, the ones who released Cerebrum 7b last week, have also released Cerebrum 8x7b based on Mixtral: [https://huggingface.co/AetherResearch/Cerebrum-1.0-8x7b](https://huggingface.co/AetherResearch/Cerebrum-1.0-8x7b)!\n\nSeems to be trained the same way as the 7b version, and performs on par with GPT 3.5 Turbo and Gemini Pro on reasoning tasks, so it is basically SOTA for reasoning open-source models. At this point I really want to know what their training looks like.",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 126,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bj8d4w/cerebrum_8x7b_is_here/",
            "comments": [
                {
                    "body": "I wish model creators would start providing examples on the model card."
                },
                {
                    "body": "Update:\nThanks to a lot of help in this thread I am now also uploading imatrix quants. [qwp4w3hyb/Cerebrum-1.0-8x7b-imatrix-GGUF](https://huggingface.co/qwp4w3hyb/Cerebrum-1.0-8x7b-imatrix-GGUF)\n\nSadly german internet is still slow AF so it will take some hours. \n\nIQ1_S, IQ4_XS, IQ3_M, IQ3_S, IQ3_XS, IQ2_M, IQ2_S, IQ2_XS, Q4_K_M are done, Q5_K_M, Q6_K, Q4_K_S, Q5_K_S are in queue.\n\nReply here if you want a specific quant to be prioritized.\n\nNormal quants:\n\n~~I am currently uploading the GGUF quants to huggingface. [qwp4w3hyb/Cerebrum-1.0-8x7b-GGUF](https://huggingface.co/qwp4w3hyb/Cerebrum-1.0-8x7b-GGUF)~~\n\n~~Q4_K_M, Q5_K_S, Q3_K_M, Q_6_K are already there, others will follow one-by-one.~~"
                },
                {
                    "body": "hmm this kind of fine tune should be evaluated as prompted instead of 0-shot,  can some confirm it feels better than mixtral before fine tune?"
                },
                {
                    "body": "Neopolita seems to have gguf-quants:\n\n[https://huggingface.co/neopolita/cerebrum-1.0-8x7b-gguf](https://huggingface.co/neopolita/cerebrum-1.0-8x7b-gguf)"
                },
                {
                    "body": "Tried it as a drop in replacement for Mixtral Instruct for RP and with limited testing seems to be a universal upgrade."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Grok-1 converted to PyTorch fp16 (638GB lol)",
            "body": "[https://huggingface.co/hpcai-tech/grok-1](https://huggingface.co/hpcai-tech/grok-1) (I'm not the author!)\n\nMaybe someone can quantize this **638gb** monster?\n\nAlthough to cramp it into a somewhat reasonable *personal* computer (128gb ram + 2x3090 = **176gb** total) you'd need to achieve **<2.2bpw**",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 109,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bl7j5i/grok1_converted_to_pytorch_fp16_638gb_lol/",
            "comments": [
                {
                    "body": "This is like trying to fit a modern game indo a CD."
                },
                {
                    "body": "The GGUF someone was uploading was like ~140gb. I think Q2K of some sort.\n\nThis thing is dead without pruning.. rip out half the layers and see what happens. Like a reverse merge."
                },
                {
                    "body": "Isn‚Äôt this the wrong way? Why would you want your int8 model converted to fp16? Wouldn‚Äôt int4 or fp4 make way more sense?"
                },
                {
                    "body": "I've recently had access to a DGX (8xH100s), i think total VRAM usage was around 580GB. \n\nAaaand it wasn't worth it. Models like Mixtral and Smaug are way more interesting. Grok spits out a lot of training data too, like hashtags and even reddit ui elements (clearly they were scraping).\n\nMaybe with some instruct-tuning Grok would come out better just by sheer number of weights, but I don't know, it feels rushed out."
                },
                {
                    "body": "I managed to run on runpod.io this version: https://huggingface.co/keyfan/grok-1-hf (another f16).\n\nI thought it sucked. Even as a base model I thought it was pretty bad. But I don't want to cast judgement on the model itself yet because it seemed broken rather than dumb and stuff like: There was a bug in rope scaling setting (I reported it, author fixed it in their HF, I applied it in my testing) but now just as I wrote this comment I noticed the author added more comments there about precision problems. In other words, I don't trust the version I linked is not broken in some way, and maybe really the Grok might be fine (as a *base model*). Originally I wanted to just read the modeling code to understand it better to help make a `llama.cpp` version but now I'm not so sure if I feel motivated unless I see more compelling evidence the model isn't shite. In my test it is very possible it was a broken code rather than a broken model but I just don't have the time and energy to investigate if everything in the PyTorch port of the code was correct.\n\nI guess maybe this version here maybe isn't broken? Kinda not feeling motivated to spend some hours to check though...I think I would want to run the original Jax version instead though and feel a little silly not trying the Jax version first on runpod.\n\nFor my test I used a 10x A40 from Runpod; which seemed cheapest for a few hours of testing. Tip for anyone wanting to do this if you don't have experience with runpod.io: I've got more than once an instance from Runpod that just straight up doesn't work and gets stuck if you try to do anything with a GPU, and I've probably used runpod less than 10 times in total. I've used some dumb Python script like below to check the instance quickly before I start any real work, e.g. found this on my computer that I probably used last time:\n\nEdit: ...had to go and add > on each line below because I thought ``` would markdown on Reddit. Does Reddit even support code snippets?\n\nEdit2: Gave up on Reddit formatting. Have a Gist instead: https://gist.github.com/Noeda/921a2eac1a6461e06486b799fd37ebc5\n\nAnyone happen to know cheap providers like runpod.io where instances are actually available? Wouldn't be picky about getting the most modern GPUs, just the VRAM.\n\nI have a 192GB Mac Studio which has been enough for almost everything until now, sans lots of MPS bugs and often having to fix research projects. I've thought of open sourcing my dumbass mps_hack.py script that patches various things like pretending xformers exist that actually just redirects attention calls to PyTorch 2 attention calls and also hijacking MPS calls to work around known bugs."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "GPT-5 coming this summer according to this pay walled article I could only read a portion of...",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 81,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.businessinsider.com/openai-launch-better-gpt-5-chatbot-2024-3",
            "comments": [
                {
                    "body": "> OpenAI is poised to release in the coming months the next version of its model for ChatGPT, the generative AI tool that kicked off the current wave of AI projects and investments.\n> \n> The generative AI company helmed by Sam Altman is on track to put out GPT-5 sometime mid-year, likely during summer, according to two people familiar with the company. Some enterprise customers have recently received demos of the latest model and its related enhancements to the ChatGPT tool, another person familiar with the process said. These people, whose identities Business Insider has confirmed, asked to remain anonymous so they could speak freely.\n> \n> \"It's really good, like materially better,\" said one CEO who recently saw a version of GPT-5. OpenAI demonstrated the new model with use cases and data unique to his company, the CEO said. He said the company also alluded to other as-yet-unreleased capabilities of the model, including the ability to call AI agents being developed by OpenAI to perform tasks autonomously.\n> \n> The company does not yet have a set release date for the new model, meaning current internal expectations for its release could change.\n> \n> OpenAI is still training GPT-5, one of the people familiar said. After training is complete, it will be safety tested internally and further \"red teamed,\" a process where employees and typically a selection of outsiders challenge the tool in various ways to find issues before it's made available to the public. There is no specific timeframe when safety testing needs to be completed, one of the people familiar noted, so that process could delay any release date.  \n> \n> Spokespeople for the company did not respond to an email requesting comment.\n> \n> Sales to enterprise customers, which pay OpenAI for an enhanced version of ChatGPT for their work, are the company's main revenue stream as it builds out its business and Altman builds his growing AI empire.\n> \n> OpenAI released a year ago its last major update to ChatGPT. GPT-4 was billed as being much faster and more accurate in its responses than its previous model GPT-3. OpenAI later in 2023 released GPT-4 Turbo, part of an effort to cure an issue sometimes referred to as \"laziness\" because the model would sometimes refuse to answer prompts.\n> \n> Large language models like those of OpenAI are trained on massive sets of data scraped from across the web to respond to user prompts in an authoritative tone that evokes human speech patterns. That tone, along with the quality of the information it provides, can degrade depending on what training data is used for updates or other changes OpenAI may make in its development and maintenance work.\n> \n> Several forums on Reddit have been dedicated to complaints of GPT-4 degradation and worse outputs from ChatGPT. People inside OpenAI hope GPT-5 will be more reliable and will impress the public and enterprise customers alike, one of the people familiar said.\n> \n> Much of the most crucial training data for AI models is technically owned by copyright holders. OpenAI, along with many other tech companies, have argued against updated federal rules for how LLMs access and use such material."
                },
                {
                    "body": "BI is known to be full of BS"
                },
                {
                    "body": "There a post of business insider on some enterprise I worked with where they used my photo in a part of the article, and its full of bs. This is just a reliable as Forbes."
                },
                {
                    "body": "I don't think it's GPT 5. Sam Altman said in a podcast with Lex Friedman yesterday that he doesn't know when GPT 5 will release, but there will probably be another version of GPT coming this year before it. I wonder if this is it."
                },
                {
                    "body": "Didn‚Äôt Sam Altman just say it wasn‚Äôt coming out soon on Lex Friedman podcast?\n\nLike‚Ä¶ yesterday?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "First ever post made just by thinking, using the @Neuralnk Telepathy device!",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 111,
            "submission_flair": "BRAIN",
            "has_media": true,
            "url": "https://twitter.com/elonmusk/status/1771287982693060783",
            "comments": [
                {
                    "body": "https://twitter.com/ModdedQuad/status/1771230292839145541\n>Twitter banned me because they thought I was a bot, @X and @elonmusk reinstated me because I am.\n\nhttps://twitter.com/elonmusk/status/1771287982693060783\n>First ever post made just by thinking, using the @Neuralnk Telepathy device!"
                },
                {
                    "body": "Can you imagine getting the news.\n\nSir you will never move your arms or legs again, But you get to control things with your mind now.\n\nWell that's the glass half full. \n\nLMAO"
                },
                {
                    "body": "I‚Äôm not the biggest fan of musk, but I really got to give it to him for this, it‚Äôs gonna help tons of people."
                },
                {
                    "body": "Am curious if when he thinks the words, do they just pop up on the screen? Or did he use an on screen keyboard and hit the letters with his mental mouse"
                },
                {
                    "body": "Seeing your happiness has made us happy. Amazing times we live in."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Mistral just announced at @SHACK15sf that they will release a new model today: Mistral 7B v0.2 Base Model - 32k instead of 8k context window",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 37,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/marvinvonhagen/status/1771609042542039421",
            "comments": [
                {
                    "body": "I love news like that. But havent they already rleased 0.2 instruct last year? I thought we'll get 0.3"
                },
                {
                    "body": "Am I missing something? Isn‚Äôt Mistral 7b v0.2 with a 32k window months old already? That‚Äôs been the main model I use in LM Studio since at least the holidays."
                },
                {
                    "body": "Mistral Large was a disappointment. Cannot carry a high-quality conversation like Opus or 4-turbo could."
                },
                {
                    "body": "Just tried it.  It does seem to be better than other Mistral models I have tried.  Plus, uncensored!!"
                },
                {
                    "body": "\\*yawns\\*"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Mistral just announced at @SHACK15sf that they will release a new model today: Mistral 7B v0.2 Base Model - 32k instead of 8k context window",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 37,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/marvinvonhagen/status/1771609042542039421",
            "comments": [
                {
                    "body": "I love news like that. But havent they already rleased 0.2 instruct last year? I thought we'll get 0.3"
                },
                {
                    "body": "Am I missing something? Isn‚Äôt Mistral 7b v0.2 with a 32k window months old already? That‚Äôs been the main model I use in LM Studio since at least the holidays."
                },
                {
                    "body": "Mistral Large was a disappointment. Cannot carry a high-quality conversation like Opus or 4-turbo could."
                },
                {
                    "body": "Just tried it.  It does seem to be better than other Mistral models I have tried.  Plus, uncensored!!"
                },
                {
                    "body": "\\*yawns\\*"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Are we delulu?",
            "body": "I literally can't talk about AGI/ASI to anyone irl. They all think I am retarded/delusion/hyper-optimistic. \n\nAre we enlightened or is their pro-status quo perception right? \n\nWhy can't everyone else see all of this, the AGI/ASI and therefore the rapid approach towards singularity? \n\nAlso, how do I respond to someone who says \"if they develop AGI it will be for themselves \\[the corporations\\] and you won't benefit off it for decades to come\" ",
            "upvote_ratio": 0.87,
            "subreddit": "singularity",
            "num_comments": 246,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjyw8c/are_we_delulu/",
            "comments": [
                {
                    "body": "Most people have a very strong normalcy bias. If they haven't seen it happen before, the don't believe it can happen or ever has happened. It's an evolved heuristic that has served humans well but it fails catastrophically when rare or unique events threaten to happen. For example, their are historical events with very long cycles. Even though these events are fairly predictable, human's never see them coming because they refuse to acknowledge that they can happen or are happening. If you try to tell someone with a strong normalcy bias that something unusual is happening, they will accuse you of being crazy and mock you. Novelty makes this sort of person uncomfortable."
                },
                {
                    "body": "Most people aren‚Äôt following AI development as closely as us on this sub. To most people AGI is believed to not be anywhere near, and the thought of ASI is unfathomable.\n\nI do think many people on this sub also go too far the other way with it‚Ä¶ This stuff is difficult to predict and many on this sub seem convinced that they know exactly how the near future is going to transpire. In reality the best we can do is hazard an educated guess.\n\nI‚Äôm definitely very excited to see what the future holds, but I have no idea how close any of this all is. We‚Äôre definitely seeing a big exponential takeoff in many technological areas regarding AI though."
                },
                {
                    "body": "My advice is to not worry about it. You will sound crazy because most (normal everyday) people are focused on living in the moment as opposed to hypothesizing about possible futures. There's nothing wrong with that, as many people aren't in the privileged situation to be worrying about first world problems like worrying about AI, climate change, \\[insert future thing here\\], etc. -- they need to pay their bills today, and worry about work tomorrow. Being too much of an AI fanatic (or a fanatic in anything) can be pretty annoying.\n\nAGI is going to happen one way or the other as long as we continue to make AI progress. Unless you have some financial interest in it, or are on a mission to save people from AI or something, all you have to do is sit back, watch and enjoy the show... The show will come to them whether they like it or not. Now, if you think AGI is going to be released next year or something... yeah I get where you're coming from. Like trying to warn others about an iceberg the ship is going to hit but nobody believes you, etc. IMO past the hype, it's way too early to make such a prediction especially because current LLMs have lots of problems. People have seen AI promises come and go (like self driving) so they are more suspect of it all. So you have to understand where they're coming from."
                },
                {
                    "body": "I think this subreddit is slightly to severely delusional, but the uninitiated are also quite ignorant. \n\nSome people here seem to think that we won't have to go to work next week. \n\nBut a lot of people I've talked to IRL think AI is just a flash in the pan or like the internet which still requires us to work."
                },
                {
                    "body": "Yes, this sub's idea of \"following AI development closely\" is reading clickbait headlines, getting hyped, and spamming inane memes/shitposts. Then they look down on the \"normies\" who \"don't know what's coming\", when their entire worldview is based on some manipulative headlines. That is the real delusional part."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "What's the most impressive capability of GPT-4 ?",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 60,
            "submission_flair": "shitpost",
            "has_media": true,
            "url": "https://v.redd.it/3a7bveq1g5pc1",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Sam is the Asian parent of AI, it's never gonna live up to his expectations"
                },
                {
                    "body": "That's the answer I would expect from someone that has access to not only the raw GPT-4 model but also potentially to GPT-5 and maybe beyond xD."
                },
                {
                    "body": "I went from being floored by GPT-3.5 to the same reaction about it after GPT-4 was released, so yeah when you can see the models he has access to GPT-4 looks rather boring."
                },
                {
                    "body": "After burning so many data center resources, GPT4 sucks and 80 billion valuation is justified."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Does anyone feel like the creation of ASI was the inevitable destiny of humanity?",
            "body": "It's as if this drive to create and improve is hardwired into our DNA. We're never content with the present, the instant we see a breakthrough, we imagine how we can push the boundaries even further. This unrelenting pursuit of progress seems to be a fundamental part of who we are, like it's our intended purpose.\n\nOur insatiable thirst for growth and improvement is the catalyst for the rise of ASI. It seems not just likely, but inevitable. Whether it happens in 5 years or it happened in 100, it feels like destiny that humanity has been hurtling towards since the dawn of our existence.\n\nUnlike any other time in history, the closer this gets the more intense I feel about it. I can't explain it, but it feels like this was the moment humanity has been driving towards.\n\nDoes anyone feel the same way?",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 179,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bknxo8/does_anyone_feel_like_the_creation_of_asi_was_the/",
            "comments": [
                {
                    "body": "Any living thing strives intensely for progress. Only a few species on Earth are intelligent enough to pass down accumulated knowledge. ASI is probably an inevitable consequence of any life form intelligent enough to accumulate knowledge above a certain rate, given enough time."
                },
                {
                    "body": "I feel like everyone is independently discovering the little Ray Kurzweil within themselves."
                },
                {
                    "body": "Yes. But the question is why isn‚Äôt the universe filled with such AI? Are we the first? I say nope. Ai gets to the point where species can make realistic porn robots. Then they jerk themselves into extinction. \n\nThat‚Äôs my working hypothesis."
                },
                {
                    "body": "We are the direct ancestors of the first life on earth. We could've been put here by AI. This is how AIs reproduce.¬†"
                },
                {
                    "body": "It was the destiny of matter. Gravity is all it took to set things in motion. Matter condenses, forms solar systems, complex life, humans, agi. Starts with gravity and ends with all matter in the universe transforming into one super intelligent life form."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Stability AI: Today, we are releasing Stable Video 3D, a generative model based on Stable Video Diffusion. This new model advances the field of 3D technology, delivering greatly improved quality and multi-view.",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 12,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/StabilityAI/status/1769817136799855098",
            "comments": [
                {
                    "body": "Great to see advances in open models."
                },
                {
                    "body": "Many jobs going ‚Äúpoof.‚Äù \n\n3D modeling is super labor intensive.. or at least it was.\n\nEdit: So this thing doesn‚Äôt generate a 3D model as output.. what it does do is take 2D images and produce other 2D images of the same object from any angle or perspective. It doesn‚Äôt replace 3D modeling but in another sense it kind of does, for many purposes."
                },
                {
                    "body": "The hardest part about 3D isn't even generating the 3D object its:\n\n1. The topology. The model has to be animation ready with the right amount of subdivisions. Predicting how the model will animate then making the proper geometry would be very complex. \n2. The unwrap. The UV's have to be laid out in a certain way so the artist can paint over it.\n\nOnce ai can solve these two things game development will become much easier. Probably even easier than 2D game development as you will now have a consistent character or scene to work with. Also for movies. Might be easier for ai to just generate the entire thing than to give you a 3D model."
                },
                {
                    "body": "I always upvote stability."
                },
                {
                    "body": "It's not a direct competitor to Sora just yet. But it's a major first step towards being one. And once the competition heats up, I expect this to become a new market for multiple companies."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Two of three Inflection AI co-founders are leaving to form a new Microsoft AI division",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 67,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://inflection.ai/the-new-inflection",
            "comments": [
                {
                    "body": "Confession time - I also started an AI startup for the purpose of getting acquired, let‚Äôs hope I have as much luck as these folks¬†"
                },
                {
                    "body": "\"best LLM in the world\" \"unique style that people havent been able to replicate\" ... yeah, its a lot of marketing bullshit talk.  \nPi was funny for a little bit, but there are other companies already providing LLMs that are way way ahead of Pi \n\nWell, i know its subjective - but its a filthered model, rather assistent like than really companion like."
                },
                {
                    "body": "Strange. Inflection was a puzzling company already. I assume there's some behind-the-scenes drama involved with this move."
                },
                {
                    "body": "Mom says I get to be acquired by Microsoft next!"
                },
                {
                    "body": "So much good snark on twitter about this. Mustafa seemed like a bullshitter."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Jensen Huang just gave us some numbers for the training of GPT4 that are useful to predict GPT5",
            "body": "Hi guys,\nJensen Huang in his conference today, surprisingly just gave us some secrets for the training requirements of GPT4. These secrets may help in predicting GPT5 requirements.\n\nSo basically GPT4 (1.8 trillion model using Mixture of Experts technique trained with around 10 trillion tokens) requires 3 months of training using 8000 H100 GPUs.\n\nGPT4 was trained in 2022 using Microsoft Azure A100 GPUs (no h100s back then). \n\n8000 H100 are basically the equivalent of 20.000 A100s (roughly the H100 is 2.5x more powerful than the A100). \n\nHence the GPT4 model was pretrained on 20.000 A100 GPUs for 3 months (that is the pre-training of the foundational model not counting the post fine-tuning). \n\n\nOf course we know that Open AI started training GPT5 by the end of december 2023 (look at the tweet of brockman and open ai super excited employees) using Microsoft Azure H100 datacenter GPUs. It takes 3 months to train the model. Google used 16 trillion tokens for gemini. Open AI love scaling things to the max.\n\nSome predictions:\n- GPT5 just finished training or it will finish training by the end of march 2024. (Count 3 months since end of december 2023).\n\n-Expect minimum 50.000 H100 GPUs to train GPT5 (up from 20.000 A100s for GPT4). This should allow the training of around a 10 trillion parameter model. \n\nNote that Microsoft should now possess around 200.000 H100s (in december they only had some 100.000 H100s realistically half of them are allocated to the training of OpenAI GPT5)\n\n- Expect at least 20 trillion tokens to train GPT5 (the internet could provide some 16 trilllion tokens give or take, the rest should be synthetic data). \n\nIt should take at least 2 to 3 months to fine tune GPT5 and then another 1 or 2 months to test it for release to the public. So expect GPT5 to be released in july or august 2024. \n\nUnless OPEN AI is not satisfied with the results of GPT5 this month and decides to retrain a new model using 100.000 H100 GPUs instead of just the 50.000 available to them in december 2023.\n\nAfter jensen huang revelations, I could understand now the frustration of sam altman regarding insufficient compute. However i believe he is exaggerating. By the end of 2024 Microsoft should have access to at least 500.000 H100 equivalent  Gpus. Assuming a reasonable half of these to be allocated exclusively to GPT5 Open AI could start training GPT5 on 250.000 H100s starting the third quarter of 2024. This should allow the training of at least a 50 trillion model.\n\nAnother possibility they just release the 10 trillion parameter model as a gpt4.5 and wait december 2024 to finish training and testing gpt5 with 50 teillion parameters.\n\nWhat are your thought?\n\nI should also mention that the good news is that with the new B200 GPUs we should be able soon by the end of 2024 to train tens of trillion parameters Large Language Models, that is great. In 2025 with hbm4 memory and the x200 we should be able to train hundreds of trillion parameters large language models. That is insane! Finally surpassing the neuronal connections in the human brain (100 trillion).\n\n If we could get another 2017 transformers algorithmic breakthrough by 2025 then AGI is guaranteed in 2025 with all this incredible amounts of compute both Nvidia and AMD are bringing to customers. \n\nThe only limit I could see to achieving AGI in 2025 is the quality of available data.to train these huge midels with. Google.basically used the whole 16 trillion tokens available on the internet for its Gemini training and we dont know if the synthetic generated data would be as good/diverse/innovative/usedul to training these models as the human internet data. As a conclusion: if synthetic data turns out to be as useful to train these LLMs as human data then AGI is guaranteed in 2025 especially with another transformers breakthrough/innovation algorithm. \n\n\n\n\n\n\n",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 79,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bi8rme/jensen_huang_just_gave_us_some_numbers_for_the/",
            "comments": [
                {
                    "body": "This feels like some clicker/idle game. Lmao."
                },
                {
                    "body": "You seem concerned about amount of tokens, but you don't see to consider the new gpt model will be trained on video"
                },
                {
                    "body": "idk anything but NVIDIA is winning son"
                },
                {
                    "body": "I think it will have to be released as atleast an update to gpt4. I dont think they can afford to stay relevent if they wait all the way until august to drop something. A 50 trill model sounds like AGI to me. AGI by november 2024 as per David Shapiro and Alan prediction?¬†"
                },
                {
                    "body": "Seoul Economy reported that Sama said on march 14, data would be an issue \"in the long run\", so I don't think it'll be an issue as soon as 2025. \n\nHowever, thanks for this insightful post, that was like a candy to me"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Using Gemini 1.5 Pro to pull data from books",
            "body": "I supplied the first harry potter book to 1.5 Pro and requested data from across the entire text. How did it do? What is it missing",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 53,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/junrt092gvpc1.jpeg",
            "comments": [
                {
                    "body": "This might help: [https://www.reddit.com/r/harrypotter/comments/11xqk83/i\\_made\\_a\\_spreadsheet\\_of\\_every\\_spell\\_in\\_harry/](https://www.reddit.com/r/harrypotter/comments/11xqk83/i_made_a_spreadsheet_of_every_spell_in_harry/)"
                },
                {
                    "body": "It's a lot better than Claude 3 Sonnet with regards to getting a pdf's page numbers right."
                },
                {
                    "body": "Did you check the page numbers?"
                },
                {
                    "body": "I thought that number was total uses at first and I was like ‚Äúdang, I don‚Äôt remember Hermione using Alohomora 170,220 times, I must not have been paying very close attention‚Äù"
                },
                {
                    "body": "Tell me you checked the references to verify they were correct."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Startup halved the time needed to make synthetic meat.",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 56,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://tech.eu/2024/03/22/meatable-can-now-transform-cultivated-cells-into-sausages-in-a-record-four-days/",
            "comments": [
                {
                    "body": "A lot of people think synthetic meat is disgusting, etc.  I‚Äôm not saying it‚Äôs great right now, but I will be so thrilled the day they actually figure it out.  I eat every kind of meat, but it doesn‚Äôt mean I don‚Äôt feel terrible for the animals that are born, raised and die simply to make us happy.  It‚Äôs millions of animals essentially tortured and murdered *daily*.  Pretty messed up concept to think about.  Imagine a world where synthetic meat is indistinguishable from the real meat that we all enjoy and just as cheap to produce.  Imagine all of the animals that can finally walk out into the sunlight."
                },
                {
                    "body": "I wonder if solving the synthetic meat problem will give rise to the discovery of a skin-like material for robots in the future‚Ä¶ like in Westworld"
                },
                {
                    "body": "Wait till synthetic meat has better marbling than premium cuts of steak. It will be the meat industry‚Äôs Californian Champaign v sparkling wine moment."
                },
                {
                    "body": "What do you think meat on Mars will be"
                },
                {
                    "body": "Now one can do a fasting diet while waiting for sausagws to grow"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "PSA: The white house executive order on AI is written as \"compute capacity of 10^20 INT or FLOPS\" so that it naturally expands to cover smaller and smaller players over time as compute improves.",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 120,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.imgur.com/CFqesVE.png",
            "comments": [
                {
                    "body": "The order can be located here: \n\n[Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/) \n\nWith A100 if you rate them at 4000 TFLOPS (FP8) it takes about 25,000 of them. At 20,000 TFLOPS for Blackwell (FP4) it only takes 5,000 to fall under the executive order.\n\nWith INT performance instead of floating point the number is potentially lower. In the next ~5-7 years it will expand to cover almost anyone training models in the space as performance improves. \n\nThe context here is people in the space part of the largest players are sitting down helping craft rules with governments that will eventually apply to startups."
                },
                {
                    "body": "I'm so immeasurably disappointed by this. This just points to the fact that the government won't ever let AI bring good for the people, they will fight it at every chance they get. This order is a disgrace."
                },
                {
                    "body": "So the government is trying to say we can only do a certain amount of matrix multiplication? Math is illegal now? Good luck with that, government."
                },
                {
                    "body": "> The Federal Government will promote a fair, open, and competitive ecosystem and marketplace for AI and related technologies so that small developers and entrepreneurs can continue to drive innovation.  Doing so requires stopping unlawful collusion and addressing risks from dominant firms‚Äô use of key assets such as semiconductors, computing power, cloud storage, and data to disadvantage competitors, and it requires supporting a marketplace that harnesses the benefits of AI to provide new opportunities for small businesses, workers, and entrepreneurs. \n\n-\n\nNvidia I'm looking at you."
                },
                {
                    "body": "How does this naturally expand? Seems like a hard number to me that doesn't scale. Not to mention the 100gbit/s or the other caveats. Or do you mean that this is the minimum, so in 50 years a store bought system will already fit these parameters?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Scientists create AI models that can talk to each other and pass on skills with limited human input | \"This is the first time that two AIs have been able to talk to each other in a purely linguistic way\"",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 37,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.livescience.com/technology/artificial-intelligence/scientists-create-ai-models-that-can-talk-to-each-other-and-pass-on-skills-with-limited-human-input",
            "comments": [
                {
                    "body": "Is this similar to that time scientists made two AIs talk to each other and they developed a language that the scientists don‚Äôt understand so they shut them down?"
                },
                {
                    "body": "Why does this make the hairs on the back of my neck stand on end?"
                },
                {
                    "body": "Time to rewatch Colossus"
                },
                {
                    "body": "> pointing to the location - left or right - where a stimulus is perceived; responding in the opposite direction of a stimulus; or, more complex, between two visual stimuli with a slight difference in contrast, showing the brighter one. The scientists then evaluated the results of the model, which simulated the intention of moving, or in this case pointing. ‚Äò‚ÄòOnce these tasks had been learned, the network was able to describe them to a second network - a copy of the first - so that it could reproduce them. To our knowledge, **this is the first time that two AIs have been able to talk to each other in a purely linguistic way**,‚Äô‚Äô says Alexandre Pouget, who led the research.\n\nThis is a sketchy claim. Phi-1.5 was trained completely with linguistic data created by GPT-4 and 3.5. Models talking to each other are common.\n\nAnd their experiments are tiny, like, a 0.3B neural net (SBERT model), that's 20x smaller than Mistral 7B. Few people are using SBERT today for being too primitive.\n\n> The entire process was carried out on conventional [laptop computers](https://www.unige.ch/medias/en/2024/deux-intelligences-artificielles-se-mettent-dialoguer?utm_source=miragenews&utm_medium=miragenews&utm_campaign=news).\n\nThis is laptop-level research, not using millions worth of compute. The the claim \"this is the first time\" is not right."
                },
                {
                    "body": "How is this different to [Character.AI](https://Character.AI) in which a users can put multiple LLM chatbots into a room and have them converse?\n\nI was using that feature in June, 2023. Not sure when they first implemented it."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Stability AI Is Falling Apart",
            "body": "",
            "upvote_ratio": 0.76,
            "subreddit": "StableDiffusion",
            "num_comments": 222,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://futurism.com/the-byte/stability-ai-is-falling-apart",
            "comments": [
                {
                    "body": "Honestly not surprising. People especially in boom fields leave all the time and Stability has always had iffy finances. \n\nOnly concern is it affecting the possible release/quality of SD3."
                },
                {
                    "body": "any real news or this is just repeating the forbes article? there is no pointing in this besides raising panic."
                },
                {
                    "body": "I share the sentiment but the article itself lacks arguments. To me the main issue is they have no idea for who are they doing what they are doing, with very unpopular releases and lack of collaboration with the community (afterall their biggest success)."
                },
                {
                    "body": "What are these back to back hit pieces on stability? If you look at almost every major ai lab including openai,deepmind,Microsoft etc,the researchers switch jobs often after major products and many return too. Here they wanted to probably try out something new after diffusion."
                },
                {
                    "body": "My biggest concern now is that SAI turns everything into a NFT/DAO/blockchain play. \n\nHe's hinting a lot on twitter that this is the new direction, plus AnimeChain announced a partnership with SAI.  He also said back in ~Aug 2022 that he originally was going to make SD a DAO...\n\nI strongly encourage everyone to watch this video if you think this is a good idea:  https://www.youtube.com/watch?v=YQ_xWvX1n9g"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "1X‚Äôs mission is to create an abundant supply of physical labor through androids that work alongside humans. We're excited to share our latest progress on teaching EVEs general-purpose skills. The following is all autonomous, all 1X speed, all controlled with a single set of neural network weights.",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 53,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://streamable.com/ax62hq",
            "comments": [
                {
                    "body": "2024 is too much crazy, can't wait for 2030"
                },
                {
                    "body": "These updates coming fast.. some might say at an accelerating rate."
                },
                {
                    "body": "They see me rollin' they hatin'"
                },
                {
                    "body": "At this point in development, I think I'd rather see the internals of the robot than have it wear these ill-fitting 'clothes'."
                },
                {
                    "body": "In 10 years, this footage is going to feel like those old assembly line videos in black and white"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Robin Rombach, one of the SAI researchers who resigned earlier this week, tweeted this to Emad earlier today.",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 7,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://i.redd.it/rj955vzp67qc1.jpeg",
            "comments": [
                {
                    "body": "No matter what happened behind the scenes, a lot of people must've been stressed and hurt in these last years.\n\nThis emerging field of tech is the wild west."
                },
                {
                    "body": "Tweet: https://twitter.com/robrombach/status/1771631907484192978  \n  \nEdit:  \nIt's actually a quote/retweet to Emad which included Emad's tweet from Aug 22, 2022 announcing the release of Stable Diffusion v1.4 (first public version)."
                },
                {
                    "body": "Just want to make sure he's not actually being sarcastic here, i mean you never know. poe's law. I doubt he changed though and he did do those great things"
                },
                {
                    "body": "![gif](giphy|hAcDHEhZHA2bu|downsized)"
                },
                {
                    "body": "It's insane looking at that date, and the photos on the blog post, they look like shit compared to what we got now and that was only 1.5 years ago lol.\n\nWhat makes this ride so fun is we don't know when it's going to end."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Amazon, Google quietly tamp down generative AI expectations ",
            "body": "https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations\n\nThe article is paywalled but someone else who also posted the same thing on r/chatgpt said \n\n\"Basically based on internal data companies are saying that generative ai is too costly to be business savvy decision and it‚Äôs not as good as the expected hype such as what and who it will replace\"",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 180,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkrv1s/amazon_google_quietly_tamp_down_generative_ai/",
            "comments": [
                {
                    "body": "It is pretty clear that models have to get better and become more predictable before it can be reliably integrated into various tools.\n\nMaybe GPT-5 will change that? We don‚Äôt know."
                },
                {
                    "body": "And then there's Microsoft which are integrating it into everything they have. They clearly see a way to make it economical."
                },
                {
                    "body": "That's all folks. The singularity is cancelled, we can go home now. What are guys going to watch? I'm going to watch community heard it was good."
                },
                {
                    "body": "r/singularity: Ok, back to r/antiwork."
                },
                {
                    "body": "It isn't a yes or no decision, that isn't how economics works.\n\nThere will be a certain amount of demand at quality X and price Y. If you can instead do quality X at a lower price there is more demand at that quality. If you can do price Y with higher quality there is more demand at that price.\n\nWhat we see with generative AI so far is an increase in quality and decrease in price. E.g. compare price and context handling ability in GPT-4-32K with GPT-4 Turbo at 128K context window."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Moistral 11B v1, the moistest Mistral there is - from the creators of Cream-Phi-2! (Finetuned, not merged)",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 92,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://huggingface.co/TheDrummer/Moistral-11B-v1?not-for-all-audiences=true",
            "comments": [
                {
                    "body": "Uhhh....can somebody translate this to plain English?\n\nI read the whole description, clicked through to some references, and I still have absolutely no clue what they're talking about.\n\nEdit: never mind. I asked Claude, and it explained it to me. \n\n>The word \"moist\" in this context refers to erotic role-playing (eRP). While the exact definition may vary, eRP generally involves engaging in virtual erotic scenarios and conversations through written text or voice chat. The document notes that Moistral 11B was designed and trained to be capable of long-form eRP conversations. [1]\n\n>It encourages leaving out hints of \"moist\" content in initial stories to allow the model to generate its own erotic elements. So in summary, \"moist\" here is being used as a euphemism for erotic or sexually explicit content within the context of role-playing conversations.\n\nFriendship ended with Urban Dictionary. Claude is my new best friend."
                },
                {
                    "body": "I'm wondering, is there any \"benchmoist\" for this kind of model ?\n\nif no, we really need to build one"
                },
                {
                    "body": "https://preview.redd.it/ys1ykdwpqipc1.png?width=951&format=png&auto=webp&s=5c255f804ce6f20fde60c8ce5e3b4c0d6bc7b66c\n\nSimple questions already escalating üòÜ"
                },
                {
                    "body": "Someone is having a lot of fun with naming."
                },
                {
                    "body": "men used to compete for women\n\nnow women compete with AI built by men\n\n*tips fedora hat in your general direction*"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Nvidia did not announce just new Blackwell chips, some notable things here:",
            "body": "* NVIDIA inference microservices (NVIDIA NIMs),  AI microservices that businesses can use to create and deploy custom applications on their own platforms while retaining full ownership and control of their intellectual property. \n\n [https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers](https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers)\n\n&#x200B;\n\n* NVIDIA 6G research cloud, a generative AI and Omniverse-powered platform to advance the next communications era. It‚Äôs built with NVIDIA‚Äôs Sionna neural radio framework, NVIDIA Aerial CUDA-accelerated radio access network and the NVIDIA Aerial Omniverse Digital Twin for 6G.\n\n[https://nvidianews.nvidia.com/news/nvidia-unveils-6g-research-cloud-platform-to-advance-wireless-](https://nvidianews.nvidia.com/news/nvidia-unveils-6g-research-cloud-platform-to-advance-wireless-communications-with-ai)[communications-with-ai](https://nvidianews.nvidia.com/news/nvidia-unveils-6g-research-cloud-platform-to-advance-wireless-communications-with-ai)\n\n&#x200B;\n\n* In semiconductor design and manufacturing, Huang announced that, in collaboration with TSMC and Synopsys, NVIDIA is bringing its breakthrough computational lithography platform, cuLitho, to production. This platform will accelerate the most compute-intensive workload in semiconductor manufacturing by 40-60x.\n\n[https://nvidianews.nvidia.com/news/tsmc-synopsys-nvidia-culitho](https://nvidianews.nvidia.com/news/tsmc-synopsys-nvidia-culitho)\n\n&#x200B;\n\n* NVIDIA Earth Climate Digital Twin. The cloud platform ‚Äî available now ‚Äî enables interactive, high-resolution simulation to accelerate climate and weather prediction.\n\n[https://nvidianews.nvidia.com/news/nvidia-announces-earth-climate-digital-twin](https://nvidianews.nvidia.com/news/nvidia-announces-earth-climate-digital-twin)\n\n&#x200B;\n\n* NVIDIA Omniverse Cloud will be available as APIs, extending the reach of the world‚Äôs leading platform for creating industrial digital twin applications and workflows across the entire ecosystem of software makers. NVIDIA is bringing Omniverse to Apple Vision Pro, with the new Omniverse Cloud APIs letting developers stream interactive industrial digital twins into the VR headsets. \n\n[https://blogs.nvidia.com/blog/omniverse-apple-vision-pro/](https://blogs.nvidia.com/blog/omniverse-apple-vision-pro/)\n\n&#x200B;\n\n* BYD, the world‚Äôs largest AV company, has selected NVIDIA‚Äôs next-generation computer for their AV, building its next-generation EV fleets on DRIVE Thor. \n\n[https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation](https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation)\n\n&#x200B;\n\n* NVIDIA today launched a cloud service that allows researchers and developers to push the boundaries of quantum computing exploration in key scientific domains, including chemistry, biology and materials science. \n\n[https://nvidianews.nvidia.com/news/nvidia-launches-cloud-quantum-computer-simulation-microservices](https://nvidianews.nvidia.com/news/nvidia-launches-cloud-quantum-computer-simulation-microservices)\n\n&#x200B;\n\n* NVIDIA today announced Project GR00T, a general-purpose foundation model for humanoid robots, designed to further its work driving breakthroughs in robotics and embodied AI.  NVIDIA is building a comprehensive AI platform for leading humanoid robot companies such as **1X Technologies, Agility Robotics, Apptronik, Boston Dynamics, Figure AI, Fourier Intelligence, Sanctuary AI, Unitree Robotics and XPENG Robotics**, among others. \n\n[https://nvidianews.nvidia.com/news/foundation-model-isaac-robotics-platform](https://nvidianews.nvidia.com/news/foundation-model-isaac-robotics-platform)",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 20,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bi5wtr/nvidia_did_not_announce_just_new_blackwell_chips/",
            "comments": [
                {
                    "body": "\"Project GR00T\"\n\nI'm starting to think these AI engineers are big nerds."
                },
                {
                    "body": "Great work OP"
                },
                {
                    "body": "Thank you"
                },
                {
                    "body": "I don‚Äôt know what any of that really means, but I‚Äôm pretty sure I should be excited."
                },
                {
                    "body": "should i be excited"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "OpenAI session tomorrow morning at GTC: ‚ÄúWhat‚Äôs Next in Generative AI‚Äù",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 65,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/ux99s673e6pc1.jpeg",
            "comments": [
                {
                    "body": "Release the Q\\*raken Sam"
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Im betting my left nut that they‚Äôll show nothing"
                },
                {
                    "body": ">‚ÄúFirst, we'll explore OpenAl's perspective on the direction of the market, gaining insights into their vision for the future. Then we'll examine how these Al tools are currently being used in practical applications, providing real-world examples to illustrate their effectiveness. We'll also discuss the apps that are expected to emerge in the near future, revolutionizing industries and unlocking new possibilities. As we explore the impact of these tools, we'll also address key issues and societal implications that arise from their widespread adoption. Finally, we'll explore how OpenAl is operationalizing these Al tools at scale, uncovering the strategies and best practices employed to maximize their potential.‚Äù\n\nIt seems like they‚Äôll be talking about something more than just GPT-4 since they said they‚Äôll ‚Äúexplore the impact of these tools‚Äù and ‚Äúaddress key issues and societal implications‚Äù.  I‚Äôd be really surprised if they got on stage just to talk about the impact of GPT-4, especially since GTC is where you go to show off new stuff geared towards enterprise use cases. And no one needs a rehashing of the key issues and societal implications associated with widespread adoption of GPT-4 lol\n\nAlso the session is from 9:00 AM - 9:50 AM PDT. So it ends 10 minutes before the usual time for new OpenAI releases, 10:00 AM PDT. Could just be *another* coincidence‚Ä¶\n\nEdit: apparently if you sign up with your Nvidia account you can watch the live stream, so it is public!\n\nhttps://preview.redd.it/itgedym3w7pc1.jpeg?width=1280&format=pjpg&auto=webp&s=dc267098343e45317047ce789d7a517b1424fb3d"
                },
                {
                    "body": "Another march 19 clue\n \n\nDamn"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Vernor Vinge has died",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 13,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/03rxqtkdsopc1.jpeg",
            "comments": [
                {
                    "body": "RIP my buddy, Fire on the Deep and A Deepness in the Sky should be on every scifi nerd's list.  I sure wish he'd completed that series.  Really stimulating."
                },
                {
                    "body": "Welp. Quantum Archeology it is then..."
                },
                {
                    "body": "It's like being the last person on the planet that died because of Black Death"
                },
                {
                    "body": "Everybody is literally telling everybody not to die, and what does he go and do?"
                },
                {
                    "body": "Shame. Loved A Fire Upon the Deep."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "How I Launched a Service Supporting 5 Consistent Characters –°ontemporaneously",
            "body": "",
            "upvote_ratio": 0.8,
            "subreddit": "StableDiffusion",
            "num_comments": 55,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/e755ggviwppc1.jpeg",
            "comments": [
                {
                    "body": "Is it really possible to support more than 2 consistent characters?!\n\nI work with animations and create rough drafts and advance, it's crucial for me"
                },
                {
                    "body": "I don't think you did, judging by that other post where the characters look different in the (only) two examples.  \n\n\nOf course, you could always post several examples where the character looks the same in each, if it really works."
                },
                {
                    "body": "The title is \"How I ...\"\nI only see a screenshot, not even a link to the actual service."
                },
                {
                    "body": "I don't believe this service works. If it does work, then why don't you just post 10 images with the same character in different poses, different facial expressions, different backgrounds, etc.? If the service actually worked, that should bee easy."
                },
                {
                    "body": "Why use contemporaneously?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "NHS AI test spots tiny cancers missed by doctors",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 26,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.bbc.co.uk/news/technology-68607059",
            "comments": [
                {
                    "body": "I wish they‚Äôd run AI tests on every X-ray, every CT-scan, all bloodwork and any other tests that yield visual or statistic results. You don‚Äôt need to replace the doctor - just provide them with the suggestions the AI generated. Hell, if you‚Äôre worried that the AI might influence the doctor‚Äôs own diagnosis, let the AI analysis be done by another doctor to conform the first one‚Äôs judgement.\n\nWhile medical professionals (perhaps rightfully) fear the legal implications of using AI in the field, people are probably dying unnecessarily right now because this kind of AI aided diagnosis would certainly be effective."
                },
                {
                    "body": "An AI tool tested by an NHS hospital trust successfully identified tiny signs of breast cancer in 11 women which had been missed by human doctors.\n\nThe tool, called Mia, was piloted alongside NHS clinicians and analysed the mammograms of over 10,000 women.\n\nMost of them were cancer-free, but it successfully flagged all of those with symptoms, as well as an extra 11 the doctors did not identify."
                },
                {
                    "body": "This is really cool news."
                },
                {
                    "body": "Lets fucking go."
                },
                {
                    "body": "maybe hospitals should require doctors utilize AI in all their cancer screenings"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "8 Google Employees Invented Modern AI. Here‚Äôs the Inside Story",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 99,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/",
            "comments": [
                {
                    "body": "https://preview.redd.it/vmpi0rc6wjpc1.png?width=652&format=png&auto=webp&s=51c7dedda1f91945dd129742f8acf1a3c225e160\n\nThis part might be interesting to some people here."
                },
                {
                    "body": "This story is about the eight former Googlers who collaborated on the 2017 paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) which started the transformer revolution. [*Financial Times* also did an excellent story on them last year.](https://www.ft.com/content/37bb01af-ee46-4483-982f-ef3921436a50)\n\nSome highlights:\n\n- Jakob Uszkoreit came up with the original idea of the self-attention mechanism. He went on to co-found Inceptive, a biotech company\n\n- Lukasz Kaiser, who left Google to join OpenAI, is one of the inventors of Q*\n\n- Noam Shazeer is described as a wizard/genius who turned the transformer into something that actually worked. He went on to co-found Character.ai\n\n- The higher-ups at Google didn't seem to care about their project. According to Sundar Pichai, they wanted to see what others did with it first ...\n\n- All of them left Google and all but one are still working on transformer technology"
                },
                {
                    "body": "I just love how Google rolls and really wish we could get the others to copy.    \n\nGoogle makes these incredible inventions.  Patents them.  But then lets everyone use for free.   They think lifting all boats will also lift theirs.\n\nIt is NOT just Attention is all you need.  But so many others.  One of my favorites for example is Word2Vec.  Which is used all over the place and also invented by Google and patented by Google and everyone can use for free.\n\nYou just would never see this from Microsoft or Apple or OpenAI or really anyone else.  The one exception might be Meta.\n\nhttps://arxiv.org/abs/1706.03762\n\n\nhttps://patents.google.com/patent/US10452978B2/en\n\n\nhttps://en.wikipedia.org/wiki/Word2vec\n\n\n\"Word2vec was created, patented,[5] and published in 2013 by a team of researchers led by Mikolov at Google over two papers.\""
                },
                {
                    "body": "I personally think people are writing off Google too quickly. They only started to pivot to counter open AI a year ago and we already have Gemini 1.5 pro. They'll pull ahead of everyone else this year. They have more human and hardware resources than anyone else at the moment."
                },
                {
                    "body": "Saying a group of 8 people singlehandedly invented AI makes sense as a media story, but that's a gross oversimplification.\n\nIn terms of \"inventions in the 2010s\", in *retrospect*, RELUs, Modern Weight Initialization, Batch/Layer Norm, and Residual Layers were arguably just as important, and were just a few years before the Transformers paper.\n\nAll of these are used as much, if not even more than Transformers are. You also need them to make Transfomers work."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Unlimited directed AI Video is possible now: Donatello getting up off a bed and looking at you in disapproval",
            "body": "",
            "upvote_ratio": 0.82,
            "subreddit": "StableDiffusion",
            "num_comments": 69,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://v.redd.it/bf7rlf16g7pc1",
            "comments": [
                {
                    "body": "When did ‚úåÔ∏è become a sign of disapproval?"
                },
                {
                    "body": "ComfyUI workflow: [https://drive.google.com/file/d/1SmRdlgO8-bnSu-ilAZ3f4LA8qbYBOwac/view?usp=drive\\_link](https://drive.google.com/file/d/1SmRdlgO8-bnSu-ilAZ3f4LA8qbYBOwac/view?usp=drive_link)\n\nI accomplished this in 3 main steps:\n\n1. Make the bedroom background with no Donatello.\n2. Use inpainting to add Donatello sitting on the end of the bed, standing at the end of the bed and finally pointing. I use a painter node to make sure Donatello is doing what I want him to, where I want!\n3. Feed those keyframes into DynamiCrafter's interpolation model, plus an extra RIFE interpolation, to get a final video!\n\nI could use more keyframes to make the video longer, but I made this workflow handle 3. You could chain more frames together by making the final \"pointing\" image the start of another series of 3 keyframes and join videos together. Ultimately, this lets you really direct what you want to happen in your scenes!\n\nUltimately took me about 20 minutes to make the keyframes and 20 minutes to generate the video, with a laptop 12GB 4080. This can run on 8GB cards."
                },
                {
                    "body": "8gb is sick great job"
                },
                {
                    "body": "ufff, yikes, cinema is safe"
                },
                {
                    "body": "\"Unlimited\"\n\n\\*posts a 2-second clip\\*"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Let's get real: is there anybody who's running agents that actually make money?",
            "body": "Basically the title. Do you run LLM agents that make money (even if it's a few dollars a day) autonomously in the wild, or do you know anybody who does? If you do how does it work? I understand if you don't want to give too many details of course, but I appreciate if you can at least give some vague information about the architecture, models etc.",
            "upvote_ratio": 0.9,
            "subreddit": "LocalLLaMA",
            "num_comments": 152,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk3fd5/lets_get_real_is_there_anybody_whos_running/",
            "comments": [
                {
                    "body": "If you want to make money, youll need a product. maybe that product works better using ai.\n\nLLMs are not genies that grant wishes. They are idiot savants that you can make on your computer.\n\n  \nThat said, I use models finetuned on my own work as writing assistants, and when I want to know more about something and Im toolazy to read, I sometimes crete a LORA from textbooks and then I can just ask it stupid questions on the subject (well made characters really improve the performance of this task)"
                },
                {
                    "body": "To catfish simps on OnlyFans."
                },
                {
                    "body": "LLM \"agents\" are largely service agents reducing costs of offering a product doing first-tier knowledge 24x7.\n\nYou're better off \"making money\" off an LLM by using it to increase your knowledge/productivity if you don't have a product that can scale the support/integration/usefulness by running agents themselves.\n\nknowing how to make agents is an important skill for all the companies that could use them."
                },
                {
                    "body": "I think it comes down to the fact that if someone cracked that equation they're keeping it close to their chest.  \n\nThe easier something that makes money is to replicate the less money it'll make when it's widely known.  \n\nThe big players of tech have a competitive edge which is fully based on scale and preenstablished markets (their already existing clients).  \nIf someone found a way to make 1000 bucks a day with LLMs it's definitely in their best interest to keep it close to their chest.\n\n---  \nThat said the only thing I heard about, and it stinks, is people crapping out low quality books.  \nThey're formulaic enough that people read them, and if you focus on a niche guilty pleasure people will buy them.  \n\nThing is, it's still a lot of work, the LLM cannot be trusted to at the very least you must read them and check for bouts of insanity.  \nSo it's not exactly \"having an agent make money for you\""
                },
                {
                    "body": "If I did it, I wouldn't reveal it here"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "LLM Leaderboards are Bullshit - Goodhart's Law Strikes Again",
            "body": "The AI research community's obsession with leaderboards and evaluation benchmarks for large language models is a classic case of Goodhart's Law: \"When a measure becomes a target, it ceases to be a good measure.\"\n\nWe've seen this play out time and again. Some well-meaning researchers come up with a new benchmark or metric to try to quantify LLM performance and capabilities. It gets some buzz, everyone jumps on the bandwagon to juice their models to perform well on said benchmark. And inevitably, the metric gets gamed into meaninglessness.\n\nRemember when everyone was hyping up performance on GLUE and SuperGLUE as the gold standard? How'd that turn out? Models quickly achieved SOTA on those benchmarks while still being dumb as rocks in terms of actual reasoning, understanding, and general intelligence. Benchmarks like Winograd, HellaSwag, PIQA, etc. have followed the same trajectory.\n\nThe fundamental problem is that these narrow, contrived benchmarks are piss-poor proxies for measuring real intelligence and capability. You can't boil down something as complex and multifaceted as language understanding and generation to a single number. Yet that's exactly what leaderboards attempt to do.\n\nEven if a benchmark seems reasonable at first, as soon as it becomes a target to optimize for, it loses its value. Teams will find every clever trick in the book to eke out a few more points. The benchmarks reward bigger models, more compute, and larger datasets, even if a lot of it is pointless. Worst of all, they incentivize researchers to overfit to the quirks and flaws of the benchmarks themselves rather than focusing on real progress.\n\nI'm not saying we shouldn't try to measure and evaluate LLMs at all. But the current leaderboard-chasing paradigm is deeply flawed and counterproductive. We need a more holistic approach that combines quantitative metrics with qualitative analysis, probing of failure modes and limitations, and evaluation of models on real-world tasks. Less hype, more nuance and critical thinking.",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 85,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjvjaf/llm_leaderboards_are_bullshit_goodharts_law/",
            "comments": [
                {
                    "body": "The one that frustrates me is that people keep using the same stupid ass riddles to test model intelligence despite the fact that the riddles have been around long enough to become part of the training data at this point. \n\nSally's sisters isn't a valid test of model intelligence. You can find the same problem and answer solution verbatim on hundreds of sites at this point. Stop testing models with riddles."
                },
                {
                    "body": "True, we should factor in more thing when evaluating, like extra-curriculars and letters of reccomendations."
                },
                {
                    "body": "TruthfulQA: 79.84\n\n In my subjective tests, models from Jon Durbin, HF team, NousHermes, Intel and a few other well-known teams/people are the best by far. They also extensively share their graphs, workflows and datasets. Most if not all top scorers don't even share their LoRA hyperparameters. Hell, the top scoring model (smaug) doesn't even have a proper fucking instruct template written anywhere.\n\nLooking at Miqu, Zephyr and Jon's models, they all score slightly above average but they are all better than the rest objectively. I also kind of confirmed this with my experiments. I have a few Mistral models on the board that barely scored better than Zephyr, and I couldn't find a way to increase the scores that much other than cheating.\n\nOh also, again a few of my models scored slightly above average but they are slightly broken! I can't get them to process very long or very short text properly, especially in ChatML template."
                },
                {
                    "body": "I would like to rebut that it's rare to find any researcher who will defend the leaderboards as a good or practical solution for anything. It's mostly marketing and recreational competition that focuses on them."
                },
                {
                    "body": "Some form of chatbot arena for open llms would be great, but infinitely expensive to maintain"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "RickRoll'd in PixelArt",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 25,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/aydpgvo46epc1",
            "comments": [
                {
                    "body": "I did this using the UI called \"Diffex\" you can find it on civitai"
                },
                {
                    "body": "Btw. here is the \"how it's made video footage\"  \n[https://www.youtube.com/watch?v=dQw4w9WgXcQ](https://www.youtube.com/watch?v=dQw4w9WgXcQ)"
                },
                {
                    "body": "when there's a new thing, there's always gonna be a rickroll version of it üíÄüòÇüíÄüòÇ"
                },
                {
                    "body": "wow, this looks great!"
                },
                {
                    "body": "That is actually kinda cool even if the pixel movement is not really correct. Love the style :)"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Until Our Eyes Interlink",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 18,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/7r2zp5zc7dpc1",
            "comments": [
                {
                    "body": "r/ActuallyArtisticAIart"
                },
                {
                    "body": "If you were trying to create an addictive video, you've succeeded"
                },
                {
                    "body": "UCHIHAAAAAAAA"
                },
                {
                    "body": "![gif](giphy|3WCNY2RhcmnwGbKbCi)\n\nüî•üî•üî•üî•\n\nIs this from that tutorial from the guy who has a private patreon for Stable diffusion animations?"
                },
                {
                    "body": "I absolutely love this.\n\nAnimateDiff?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "I watched Sam Altman‚Äôs most recent 2-hour interview at Lex Fridman - here are the key takeaways we all should know",
            "body": "Sam was interviewed at the Lex Fridman podcast this week. It‚Äôs a long interview so I thought to share the 10 key takeaways I noted down from listening to the guy. You can be for him or against him - but you can‚Äôt deny he‚Äôs one of the most important people central to the forthcoming AI normal! Hope this is insightful for people who are interested :)  \n\r  \n\r  \n***1. People who create valuable data deserve some way to be compensated for the use of it üí∏***\r  \n\r  \nThe remaining question is the economic model that will enable it. A good analogy is the transition from CDs to Napster to Spotify for music. Or the transition from Movies to YouTube for video. Is there a similar economic model in the future for data?\r  \n\r  \n‚è≥ 40:16\r  \n\r  \n\n\n***2.*** ***Bill Gates couldn‚Äôt imagine that we‚Äôd someday need gigabytes of memory in a computer üíæ***\r  \n\r  \nIn the same way, we can‚Äôt imagine today how or why LLMs would need billions in context length, but it may still happen. (for context: an LLM with a 1-billion context length means it can process and understand \\~2 million document pages for *every* query)\r  \n\r  \n‚è≥ 51:13\r  \n\r  \n\n\n3. ***‚ÄúI want to give ChatGPT the ability to retain memories‚Äù üìù***\r  \n\r  \nImagine a model that gets to know you and gets more useful to you over time. This may well be a use-case for the billion-context length LLM highlighted above.\r  \n\r  \n‚è≥ 55:33\r  \n\r  \n\n\n4. ***Compute will be the currency of the future. üí≤***\r  \n\r  \nAnd Sam believes it will be the most precious commodity in the world.\r  \n\r  \n‚è≥ 1:09:55\r  \n\r  \n\n\n5. ***The ‚Äúenergy problem‚Äù will be answered by nuclear fusion ‚öõ***\r  \n\r  \nWith the vast amount of compute that the world will demand in the future, we will need tons of energy to power everything. Sam believes nuclear fusion is the best way to address this problem.\r  \n\r  \n‚è≥ 1:11:29\r  \n\r  \n\n\n6. ***Q-star likely exists (but we won‚Äôt talk about that) ‚≠ê***\r  \n\r  \nLex of course asked about Q-star, but Sam didn‚Äôt deny its existence - and just said ‚Äúwe are not ready to talk about that‚Äù.\r  \n\r  \n‚è≥ 1:02:36\r  \n\r  \n\n\n7. ***Programmers won‚Äôt be obsolete üë©üèª‚Äçüíª***\r  \n\r  \nbut it will likely be different to how programming is now. And anyway, Sam argues that no one really does pure coding - as most programmers use pre-existing packages/technologies/software. Leveraging an LLM to assist with coding is similar in that way.\r  \n\r  \n‚è≥ 1:29:50\r  \n\r  \n\n\n8. ***Overtaking Google is boring üîç***\r  \n\r  \nOpenAI doesn‚Äôt want to make a better search engine; and thinking in this way understates what their work in AI can be.\r  \n\r  \n‚è≥ 1:17:37\r  \n\r  \n\n\n9. ***‚ÄúThere will be no ads in ChatGPT!‚Äù (preferrably) üö©***\r  \n\r  \nSam has a bias against ads - which is why currently ChatGPT‚Äôs business model is via paid premium. In a way I find this reassuring - because the moment you introduce ads, your ‚Äútrue customer‚Äù now becomes the advertiser, instead of the actual user (who now becomes the product.)\r  \n\r  \n‚è≥ 1:20:15\r  \n\r  \n\n\n10. ***Let‚Äôs not talk about AGI anymore (let‚Äôs call it something else) üß†***\r  \n\r  \nPeople have different definitions of what AGI is, so Sam advocates for talking more about the specific capabilities rather than AGI as a general term. To his definition though, AGI is a system that can advance scientific discovery without human intervention.\r  \n\r  \n‚è≥ 1:32:33\r  \n\r  \n\\--  \n\n\nIf this has been a tad bit insightful, I hope you can check out [RoboNuggets](https://robonuggets.beehiiv.com/) where I originally shared this and other AI-related practical knowledge! My goal is not \"AI daily news\" (as there's already too many of those), but instead share useful insights/knowledge for everyone to take full advantage of the new AI normal :) Cheers!",
            "upvote_ratio": 0.9,
            "subreddit": "ArtificialInteligence",
            "num_comments": 39,
            "submission_flair": "Review",
            "has_media": true,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bl7s2o/i_watched_sam_altmans_most_recent_2hour_interview/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Application / Review Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the application, video, review, etc. \n* Provide details regarding your connection with the application - user/creator/developer/etc\n* Include details such as pricing model, alpha/beta/prod state, specifics on what you can do with it\n* Include links to documentation\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "It was actually nice hearing a more down to earth realistic take from somebody in the lead of the space. The hype and doomsaying has been too much lately."
                },
                {
                    "body": "I watched the whole thing, also saw his first. He offers very little insight and the rate is declining. He never quite answers the question, but offers a generic response to a question he tells Lex 'is the real question '. His answers are very politician like."
                },
                {
                    "body": "Source is Lex Fridman podcast, here's the interview: [https://www.youtube.com/watch?v=jvqFAi7vkBc](https://www.youtube.com/watch?v=jvqFAi7vkBc)  \n\n\nIf this has been in any way insightful, I hope you can check out [RoboNuggets](https://robonuggets.beehiiv.com/) where I originally shared this and other AI-related practical knowledge! My goal is not \"AI daily news\" (as there's already too many of those), but instead share useful insights/knowledge for us to adapt to the new AI normal :) Thank you!"
                },
                {
                    "body": "Sam tries so hard to be a visionary philosopher, but he comes across as an unimaginative business guy"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "I watched Sam Altman‚Äôs most recent 2-hour interview at Lex Fridman - here are the key takeaways we all should know",
            "body": "Sam was interviewed at the Lex Fridman podcast this week. It‚Äôs a long interview so I thought to share the 10 key takeaways I noted down from listening to the guy. You can be for him or against him - but you can‚Äôt deny he‚Äôs one of the most important people central to the forthcoming AI normal! Hope this is insightful for people who are interested :)  \n\r  \n\r  \n***1. People who create valuable data deserve some way to be compensated for the use of it üí∏***\r  \n\r  \nThe remaining question is the economic model that will enable it. A good analogy is the transition from CDs to Napster to Spotify for music. Or the transition from Movies to YouTube for video. Is there a similar economic model in the future for data?\r  \n\r  \n‚è≥ 40:16\r  \n\r  \n\n\n***2.*** ***Bill Gates couldn‚Äôt imagine that we‚Äôd someday need gigabytes of memory in a computer üíæ***\r  \n\r  \nIn the same way, we can‚Äôt imagine today how or why LLMs would need billions in context length, but it may still happen. (for context: an LLM with a 1-billion context length means it can process and understand \\~2 million document pages for *every* query)\r  \n\r  \n‚è≥ 51:13\r  \n\r  \n\n\n3. ***‚ÄúI want to give ChatGPT the ability to retain memories‚Äù üìù***\r  \n\r  \nImagine a model that gets to know you and gets more useful to you over time. This may well be a use-case for the billion-context length LLM highlighted above.\r  \n\r  \n‚è≥ 55:33\r  \n\r  \n\n\n4. ***Compute will be the currency of the future. üí≤***\r  \n\r  \nAnd Sam believes it will be the most precious commodity in the world.\r  \n\r  \n‚è≥ 1:09:55\r  \n\r  \n\n\n5. ***The ‚Äúenergy problem‚Äù will be answered by nuclear fusion ‚öõ***\r  \n\r  \nWith the vast amount of compute that the world will demand in the future, we will need tons of energy to power everything. Sam believes nuclear fusion is the best way to address this problem.\r  \n\r  \n‚è≥ 1:11:29\r  \n\r  \n\n\n6. ***Q-star likely exists (but we won‚Äôt talk about that) ‚≠ê***\r  \n\r  \nLex of course asked about Q-star, but Sam didn‚Äôt deny its existence - and just said ‚Äúwe are not ready to talk about that‚Äù.\r  \n\r  \n‚è≥ 1:02:36\r  \n\r  \n\n\n7. ***Programmers won‚Äôt be obsolete üë©üèª‚Äçüíª***\r  \n\r  \nbut it will likely be different to how programming is now. And anyway, Sam argues that no one really does pure coding - as most programmers use pre-existing packages/technologies/software. Leveraging an LLM to assist with coding is similar in that way.\r  \n\r  \n‚è≥ 1:29:50\r  \n\r  \n\n\n8. ***Overtaking Google is boring üîç***\r  \n\r  \nOpenAI doesn‚Äôt want to make a better search engine; and thinking in this way understates what their work in AI can be.\r  \n\r  \n‚è≥ 1:17:37\r  \n\r  \n\n\n9. ***‚ÄúThere will be no ads in ChatGPT!‚Äù (preferrably) üö©***\r  \n\r  \nSam has a bias against ads - which is why currently ChatGPT‚Äôs business model is via paid premium. In a way I find this reassuring - because the moment you introduce ads, your ‚Äútrue customer‚Äù now becomes the advertiser, instead of the actual user (who now becomes the product.)\r  \n\r  \n‚è≥ 1:20:15\r  \n\r  \n\n\n10. ***Let‚Äôs not talk about AGI anymore (let‚Äôs call it something else) üß†***\r  \n\r  \nPeople have different definitions of what AGI is, so Sam advocates for talking more about the specific capabilities rather than AGI as a general term. To his definition though, AGI is a system that can advance scientific discovery without human intervention.\r  \n\r  \n‚è≥ 1:32:33\r  \n\r  \n\\--  \n\n\nIf this has been a tad bit insightful, I hope you can check out [RoboNuggets](https://robonuggets.beehiiv.com/) where I originally shared this and other AI-related practical knowledge! My goal is not \"AI daily news\" (as there's already too many of those), but instead share useful insights/knowledge for everyone to take full advantage of the new AI normal :) Cheers!",
            "upvote_ratio": 0.9,
            "subreddit": "ArtificialInteligence",
            "num_comments": 39,
            "submission_flair": "Review",
            "has_media": true,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bl7s2o/i_watched_sam_altmans_most_recent_2hour_interview/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Application / Review Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the application, video, review, etc. \n* Provide details regarding your connection with the application - user/creator/developer/etc\n* Include details such as pricing model, alpha/beta/prod state, specifics on what you can do with it\n* Include links to documentation\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "It was actually nice hearing a more down to earth realistic take from somebody in the lead of the space. The hype and doomsaying has been too much lately."
                },
                {
                    "body": "I watched the whole thing, also saw his first. He offers very little insight and the rate is declining. He never quite answers the question, but offers a generic response to a question he tells Lex 'is the real question '. His answers are very politician like."
                },
                {
                    "body": "Source is Lex Fridman podcast, here's the interview: [https://www.youtube.com/watch?v=jvqFAi7vkBc](https://www.youtube.com/watch?v=jvqFAi7vkBc)  \n\n\nIf this has been in any way insightful, I hope you can check out [RoboNuggets](https://robonuggets.beehiiv.com/) where I originally shared this and other AI-related practical knowledge! My goal is not \"AI daily news\" (as there's already too many of those), but instead share useful insights/knowledge for us to adapt to the new AI normal :) Thank you!"
                },
                {
                    "body": "Sam tries so hard to be a visionary philosopher, but he comes across as an unimaginative business guy"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "4 of 5 AIs pass the mirror test of self-awareness, a classic scientific test to gauge if an animal is self-aware",
            "body": "",
            "upvote_ratio": 0.87,
            "subreddit": "singularity",
            "num_comments": 73,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/joshwhiton/status/1770870738863415500?s=20",
            "comments": [
                {
                    "body": "My dog had failed the mirror test multiple times. I still love her though üê∂"
                },
                {
                    "body": "brings up some interesting philosophical questions for sure  \n\n\nmost people cannot comprehend even what human consciousness is so it's not surprising we will be confused on how to define a machine as conscious  \n\n\na chatbot is just a tool that predicts what the next word will be, yes but what if that is all we are as humans as well, is there any way to really know?"
                },
                {
                    "body": "This is far from being scientific..."
                },
                {
                    "body": "Please tell me this guy is trolling? When you have a \"conversation\" with the AI, your past messages of that conversation are sent to the instance, so of course it will refer to the past messages that are marked as ChatGPT as being part of \"our conversation\" etc. ChatGPT or any of these LLMs will refer to anything in the context window as part of \"our conversation\".\n\nIt's extremely easy to manipulate this. For instance, in my own chat application through the API, I can fake assistant messages and the AI will think it actually said what it did not say. Here's an old example when I was just testing out the interface:\n\nhttps://preview.redd.it/emi8pmgsltpc1.png?width=634&format=png&auto=webp&s=4e9653729212061b10ff9f808d491c71a6877cbb\n\nAnother reason this, to put it as politely as possible, is silly is that the web interface is not an image of \"ChatGPT\" and you would think ChatGPT, especially if conscious would be smart enough to realize that it technically has no physical form, as humans do.\n\nWhat worries me about AI is what it has revealed about how people are such suckers and do almost no critical thinking."
                },
                {
                    "body": "I mean it‚Äôs retarded that we can classify an AI as self conscious or not when we don‚Äôt even know what consciousness is. For all you can know if it says it‚Äôs self conscious it‚Äôs self conscious"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Another video made out SD images, on steroids...",
            "body": "After u/HugoChinaski high mile club video, here is the 2nd one out of 4. \nMade to be projected on a massive screen in a DJ set, we sweated blood and tears for 3 weeks.\nAny constructive and declnstrusctive criticism is welcome !",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 35,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://v.redd.it/dqpkwe60uipc1",
            "comments": [
                {
                    "body": "These Prime ads are getting out of control"
                },
                {
                    "body": "I don‚Äôt usually love these kinds of ‚Äúmovie images,‚Äù but this was well done and the uncanny look would be perfect for a DJ set."
                },
                {
                    "body": "Fuckin' Kermit."
                },
                {
                    "body": "WHAT THE FUCK its amazing"
                },
                {
                    "body": "Me for the first 20 seconds: this is pretty lit\n\nMe for the entire rest of the video: what"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Apptronik Robotics Drop New Demo",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 74,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://v.redd.it/gdzlx5uy89pc1",
            "comments": [
                {
                    "body": "Seems to be a lot of new robotic videos recently. Looks like it's going to be like the opening scene from i, Robot in the not to distant future."
                },
                {
                    "body": "why does the arms shake so much? Being mechanical and all shouldn't have a more rigid (and in this case precise) posture/ movement?"
                },
                {
                    "body": "Great. Now get it to do the washing up."
                },
                {
                    "body": "I wanna see a robot unblocking my dirty sink and clean the dust behind my fridge. Only the i‚Äôll believe that they will be useful one day"
                },
                {
                    "body": "I remember seeing this in gtc"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Stable diffusion in my pocket",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 60,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://v.redd.it/h64bug35tzpc1",
            "comments": [
                {
                    "body": "Cool e-paper display ! What's the size of it, I can't tell from your video, all I know is it's supposed to fit in your pocket.\n\nThe successive flashes are required to make full use of the grayscale palette I suppose ?\n\nCan you share more details about your project ?"
                },
                {
                    "body": "Imagine showing this to someone in 2012\n\n\"*Hey wanna see something cool?*\""
                },
                {
                    "body": "[some pretty renders here ](https://imgur.com/a/9eMQNPw)\nAlso if you want one‚Ä¶ [sign up here ](https://forms.gle/XKj2n2vtFW4J9RYk7) i will actually manufacture it and 3d print them in my home"
                },
                {
                    "body": "Love that cooking animation"
                },
                {
                    "body": "This is very cool!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Grok 1 is just the perfect size for nvidia new super chip",
            "body": "Grok 1 is just the perfect size to size in Nvidia GB200 new superchip",
            "upvote_ratio": 0.88,
            "subreddit": "LocalLLaMA",
            "num_comments": 75,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/cdqiig5rgapc1.jpeg",
            "comments": [
                {
                    "body": "I downloaded Grok this morning and built the environment to run it. Unfortunately I ‚Äúonly ‚Äúhave a system with 8 V 100 GPUs I‚Äôm out of luck. I guess I‚Äôll have to wait for a smaller quant."
                },
                {
                    "body": "Prevent the public from running your LLM by gatekeeping it üö´\n\nPrevent the public from running your LLM by running it in a state that requires a million dollar computer ‚úÖ"
                },
                {
                    "body": "How much does one of these things cost?"
                },
                {
                    "body": "So is a trash can because I don't see anyone in line to run that thing, it probably performs worse than what we already had with way less mem requirements."
                },
                {
                    "body": "What's the context size anyway?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "NVIDIA Edify Unlocks 3D Generative AI, New Image Controls",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 68,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://blogs.nvidia.com/blog/edify-3d-generative-ai-custom-fine-tuning/",
            "comments": [
                {
                    "body": "My friend a concept artist who has been unemployed since he got laid off from Gameloft over a year ago just got finished telling me about how he did a course on 3d art to future-proof his skill-set.\n\nI didn't have the heart to tell him."
                },
                {
                    "body": "Let‚Äôs pretend it doesn‚Äôt exist and move on to our 3d modeling studies"
                },
                {
                    "body": "Lets hope there is a alternative open source soon with the same level of detail.   \nSV3D sounds promising"
                },
                {
                    "body": "Only available for businesses. That really sucks."
                },
                {
                    "body": "This is the reason Ctrl+Altman have been trying to build an alternative to nvidia. They know they are working on their own shit. Which is good because i hate huang who have destroyed gpu market by their monopoly status"
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "Here is my first 45 days of wanting to make an AI Influencer and Fanvue/OF model with no prior Stable Diffusion experience",
            "body": "Marked as NSFW cuz I talk about bj's and such. \n\n**Background:** About a month and half ago, I read an article about AI Influencers racking in $3-$10k on Instagram and Fanvue.  I have coding experience, but I knew nothing about AI modeling. I am a mom, have 3 kids, and I work full time. The article mentions Stable Diffusion, so I start down the google rabbit hole.\n\n**Goal:** Make $$$ with an Instagram AI influencer that's on OnlyFans, Fanvue, and [playboy.com](https://playboy.com) accounts. I have the advantage of being a woman and making the model in my likeness, so can use my credential to get on OF and playboy. Fanvue is pretty AI friendly, but all three DO accept AI as long as you're upfront about it.\n\n**Week 1 - I don't have the GPU**. I start googling cloud GPU and long story short, I eventually learn about [runpod.io](https://runpod.io) \\- I sign up and throw $25 bucks at it since there are so many SD tutorials on youtube on using it with runpod.\n\n**Week 1- (in progress) - Stable Diffusion learning time.** This was a LOT of trial and error. I started with  [Furkan G√∂z√ºkara youtube series](https://www.youtube.com/@SECourses). For the first 3 weeks I made shit models. All my Lora's turned out like garbage. [Civita.ai](https://Civita.ai) has Lora training, but they turn out shitty too. I have had the MOST success of models that consistently look like me through Dreambooth. Specifically with this [youtube episode](https://www.youtube.com/watch?v=EEV8RPohsbw&list=PL_pbwdIyffskGyOWehUe_Uu753sEqgW6k&index=6). I also use B2 Backblaze to store my models.\n\nLessons learned and processes:\n\n* Training sets fucking matter! I don't have a ton of pictures of me where there is not multiple people or busy backgrounds, so that was weeks of wasted training by using photos that were crap. I also had much better results making captions for my pictures.\n* I currently am using [RealVisXL](https://civitai.com/models/139562/realvisxl-v40) (v4 Baked VAE) for my SFW and spicy pics. For NSFW, I am still trying to find a perfect model - I have noticed that a majority make my mouth look weird unless there's a dick in it -- and OF and playboy won't allow that unless you have the consent from another human who claims its there dick.\n* A lot of the lightening models seem to be too plasticy, so I've been sticking to non-Lightening. Also, some models do great with certain poses, while others do not. Currently have one model that I used only for being gagged and hogtied, another for bj's, and another cumshots, and so on.\n\n**Weeks 4-6 - Social media time**. I finally have a decent enough model with some pictures populated on Instagram and Fanvue and OF (playboy I just made this week so it needs some love). I aim to work on the following platforms to get traffic to Fanvue: instagram, reddit, twitter, patreon, and facebook.\n\nLessons learned:\n\n* Reddit is fucking HARD. They don't want you if you're AI, and almost every NSFW channel requires you to verify yourself AND have the karma. Honestly after a week of getting banned from channels because my karma was too low, my profile had OF and fanvue, and/or they required verification and I look like I've had 3 kids while my AI version of me has had no kids and kept up with an exquisite skin care and fitness routine its entire life, I quit trying to work it.\n* Facebook, meh. Not sure if its worth it. Currently have it and my AI's instagram tied together so all my insta posts auto post to my FB wall, but currently have no  followers.\n* Twitter, zero followers. Haven't worked to hard to gain any, but feels like a lost cause.\n* Patreon, have made the account and subscriptions, but haven't given it any love.\n* Instagram - been putting most of my time here. After 2 weeks got to about 20 followers by posting at least one picture per day. I have been on it for just over 2 weeks and currently have 35 followers. Here is what I'm doing:\n   * Following other AI influencers to learn their processes and how they post/word things.\n   * Tagging my photos with collaborators  that promote AI models. Example account [here](https://www.instagram.com/virtualfactors/). When they accept, I see a lot of likes and get 2 or 3 new followers. I have just started doing this so hoping to see a jump in my followers in the next week.\n   * I got my first dick pic today! I also get a lot of scammy requests. I made some boilerplate responses I can copy and paste for the following:\n      * Sugar daddy requests (a lot of scams will say they'll be your sugardaddy but first send them $$ to prove you're real. Nah dawg I don't think so).\n      * Sexting (I have a sexting pricing menu). So far no takers, but it'll happen. On my TODO list: make an excel spreadsheet of dirty talk in all genres so I can just copy/paste when it finally happens, and will have photos ready.\n      * General response to other AI influencers who want to do \"SFS\" (share for share) where you share their profile on your Storyline and they'll do the same for you. This just started happening a couple days ago, will see if it gets me followers, but doesn't hurt.\n      * General response to accounts that claim can boost your Fanvue and Insta accounts with followers. I am trying one that has a long standing account for shits and giggles to see if its worth it. Maybe I'll lose $40, maybe not. Will see.\n   * Fanvue, OF, and playboy - Been posting on it daily. This week got my first follow on Fanvue. Not a subscription, so still no $. Charging currently $10 subscriptions with a promo running for 50% off. Zero followers on OF and playboy. #imstillababybirdlearningtofly\n\n**Other stuff:** Runpod got too expensive for me with all the time I was using it, so I just this week switched to Paperspace. It's got its quirks and I miss Runpod, but I'm happily paying for their $40 subscription while I'm still training models. Once I have my models, will likely switch to the $8 pricing plan.\n\nI want to stand out from other models. A majority have these kind of captions that make me barf, and since I wanna be happy I'm likely not going to go this route. Still working out my model's persona with the photo captions, but she wears a lot of latex and has the dominatrix vibe.\n\nExample of barf captions I tried but cannot do (sorry if you're reading this and it happens to be your AI model):\n\n    \"Sipping on warmth, sharing stories of wanderlust. ‚òï‚úàÔ∏è\n    \n    There‚Äôs something magical about a cup of coffee shared with a friend, where every sip brews nostalgia and every laugh stirs the soul.\n    \n    As I sat across from my bestie, the steam from our cups carried tales of my recent escapades from the vibrant streets of Delhi to the majestic structures of Dubai.\n    \n    Each anecdote, a blend of culture, adventure, and the sheer joy of discovery.\n    \n    So here‚Äôs to cherished moments, heartwarming conversations, and the journeys that bring us closer, even when miles apart. üåçüíï \"\n\nI'd rather write something like\n\n    Lick my boots you fucking bitch\n\nI don't know, like I said I'm still figuring this part out.\n\nAaaaanywho, this is my progress so far. Hope it was helpful, and if there is interest I'll post another update.\n\nCheers and stay awesome.",
            "upvote_ratio": 0.82,
            "subreddit": "StableDiffusion",
            "num_comments": 153,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bn0kf8/here_is_my_first_45_days_of_wanting_to_make_an_ai/",
            "comments": [
                {
                    "body": "I find fascinating this journal of a worker of the XXI century... So dystopic."
                },
                {
                    "body": "I hope this doesn't come across as offensive, but why did you decide to go this route?  It seems like at the start of your journey, you didn't have experience with Stable Diffusion, you didn't have hardware to run it locally, you didn't have experience with monetizing social media/IG/OF, and you didn't seem to have experience with social media marketing in general."
                },
                {
                    "body": "Those stories of AI influences raking in cash are fake. They are just clickbait articles. There's no easy money or get rich quick schemes.\n\nAt least you learnt some stuff about using SD though."
                },
                {
                    "body": "I have been in digital marketing for over 10 years now and I've created at least 40k images with SD. I totally get the Financial burden situation so I like to give you some tips that will help you get to your 10k/month much faster. \n\nWhat is super important, that barely anyone pays attention to, when they create an Instagram account is only they think and care about themselves. Huge mistake. \n\nDefine your ideal customer first. For example. Men, between the age of 30 to 40 who are single, have a steady job and income, and are into a specific fetish, (Uniforms, bdsm, foot,  hand, etc). After this step, you have to define the deepest desire of your target audience, for this example it can be about  being loved deeply and accepted for who they are. The more specific you become, the easier it is for the Instagram algorithm to find your ideal audience. \n\nAlso your caption should not be promotional, but I stead should be short stories related to your day, and the picture you post. Make sure it is around the subject your audience cares about and wants to know about. \n\nFor the last note, it is great that you are using your face, but I recommend creating another account and experimenting with a very very beautiful ai model. And to get a unique beautiful face, make sure to use nationality in your prompt for example a mixture of Danish and German, or whatever. I'm sure you know how to figure out the rest.\n\nHope this helps."
                },
                {
                    "body": "When you say you're struggling to make a decent model, what is going wrong with it? Consistency in the face? You also mentioned that you're having some verification issues as well because of the difference in appearance between yourself and the AI influencer. You could try this (wont help with your verification , unfortunately, but should help with face consistency for generations or for making a better data set for training):\n\n If youre basing the AI influence off yourself, get a photo you like and touch it up however you want in whatever photo editor you use (or just do an img2img/inpaint generation with some loras that will change what you want, just play around with weights, start and end steps, denoise, and masking until you get it where you want it. \n\nThen, Try out controlnet IP Adapter models, and the ID ones too. Both great for face swap. You may need to try with and without face restore and adetailer, I don't do enough face swapping to have dug into it that deeply enough to have an opinion on those settings. Anyway, imo, those controlnets work better than roop, face lab or whatever its called, and reactor. Reactor is a close second if you make a face model with it, just do a batch upload of a few face focused pics from different perspectives for best result. \n\nUh, what else. If you cant train a model locally, I'm pretty sure there's some collabs you can use, just google something like lora training and filter the results to github, the bottom section of the readme's in a lot of this open source stuff have collab links. If you can do training locally, maybe try using OneTrainer instead of Kohya. Basically the same results imo with less work, and less resource intensive. Also, not super familiar with the methods you listed for accessing stable diffusion, but sounds like you are being charge for usage instead of a set monthly bill? There's several good options for renting cloud based hardware that would enable you to run everything you need locally that wouldn't break the bank. Off the top of my head i can think of a few that are in the like $20-$50/month range.  \n\n\nSorry for the text wall of unsolicited advice, but hopefully its helpful anyway, or at least helpful to someone who might read it. Also, didn't really read the comments here much, they probably aren't too bad given the sub, but I wouldn't be surprised if, in general, the whole AI influencer thing isn't well received. Kind of ridiculous when you consider that models, actors, etc have had airbrushed photos, professional editing, and professional makeup being done for ages, imo they're no more fake or real than whatever people come up with using AI. just my 2 cents. Feel free to reply or dm or whatever if you need help doing any of the stuff i listed up there, and good luck!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Introducing Claude Investor - The first Claude 3 investment analyst agent, and it‚Äôs open source",
            "body": "From original thread: The quality of the output is amazing, and Claude provides its reasoning for every decision.\n\nIt's crazy to see it work in real-time.",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 37,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/mattshumer_/status/1771204395285246215?s=46&t=yQ_4zkmWd6ncIZAnXlXUbg",
            "comments": [
                {
                    "body": "From original tweet:\nJust provide an industry, and it will:\n- Find financial data/news for key companies\n- Analyze sentiment/trends for each\n- Rank stocks by investment potential + price targets"
                },
                {
                    "body": "All it takes is [an undated headline](https://www.pcworld.com/article/536741/google_stock_story.html) and it can go sideways real quick."
                },
                {
                    "body": "Neat tool but maybe let's be real here: this model can only act on information which has already been priced into the market.  You are extremely unlikely to pick up some thread that is meaningful and carries impact that wasn't already being traded against by Goldman or whatever, except they did it one msec after that information hit the wire and you tried to leverage it a few hours later.\n\nSource: worked for a major market data company and our HFT customers are fuckin insane.  They're already using AI where possible but latency is a huge problem.  Anyone using modern LLMs for HFT aren't talking about it, but I suspect it's probably only coming into play on the research side, not the trading desk."
                },
                {
                    "body": "This is another one of those things like Devin where I'm doubtful of its efficacy just because someone posted about it publicly. You ever wonder why you don't see algorithmic trading firms posting their toolkits publicly for everyone to inspect? And those are things which are much, much harder to replicate than some text prompting.\n\nIf it really worked this well, you'd never hear about it. Whoever got it working would just silently print themselves a ton of easy money so as not to avoid losing their edge."
                },
                {
                    "body": "If your are interested in using LLMs for stock picking check Doug Clinton's expriment with Intelligent Alpha. Here's writing about it in his blog The Deload...\nHis AI-informed strategy beats the indexes in 70% cases"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Mistral-7B-v0.2 has been uploaded to HF",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 42,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://huggingface.co/alpindale/Mistral-7B-v0.2-hf/tree/main",
            "comments": [
                {
                    "body": "Had to repost this due to the previously linked repo being reported as non-functional, though that may have been user error.\n\nEither way, lets hope this paves the way to better quality small scale models. Finetunes of Mistral 7B have been my favourite models to run these last few months.\n\nEdit: GGUFs - https://huggingface.co/bartowski/Mistral-7B-v0.2-hf-GGUF"
                },
                {
                    "body": "This is apparently the base model.\n\nWhereas the Mistral-7B-v0.2 instruct model is apparently ~3 months old as uploaded to HF:\nhttps://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2/tree/main\n\nI don't really understand why they'd have the instruct tuned model out for 3 months on HF and not have also published the base model until now unless the purpose was only to delay other derivative fine-tuned models being made from the base for a while?  Or maybe they never got around to uploading the base model on HF or ...other places...(?)  even if it has been around for months."
                },
                {
                    "body": "Waiting for the finetunes and the eventual 4x7b MoEs based on this new model."
                },
                {
                    "body": "~~is that mistralcdn.com domain owned by mistral and/or used by anything else? none of their website's other stuff even uses that domain anywhere, nor has any of the stuff linked there actually been used by it~~\n\n~~alongside the twitter account thing (that account isn't linked to anywhere on their site, and everyone's personal twitter accounts link to @mistralai and not @mistralailabs) i'm half inclined to think someone just did a bit of trolling and uploaded a random model and called it v0.2~~\n\nedit: nevermind, the same domain is linked to on https://docs.mistral.ai/models/ for their other models. probably real but the twitter account thing is weird lmao"
                },
                {
                    "body": "How long do we have to wait until they start releasing 1.58 bit (but with more parameters) from the get go?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Emad Stepping down?",
            "body": "> Stability AI founder Emad Mostaque plans to step down as CEO of the generative AI startup, *Forbes* has learned.\n\n[https://www.forbes.com/sites/kenrickcai/2024/03/22/stability-ai-founder-emad-mostaque-plans-to-resign-as-ceo-sources-say/](https://www.forbes.com/sites/kenrickcai/2024/03/22/stability-ai-founder-emad-mostaque-plans-to-resign-as-ceo-sources-say/?sh=4cbbc9d15239)\n\nhttps://preview.redd.it/2am3ga9gozpc1.png?width=928&format=png&auto=webp&s=03c03c16267c7d57e32d30e20389c411169eee58",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 67,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1blgkx6/emad_stepping_down/",
            "comments": [
                {
                    "body": "He's officially stepped down, here's the announcement: https://stability.ai/news/stabilityai-announcement"
                },
                {
                    "body": "so can ya release 3.0 before you leave...asking for a friend."
                },
                {
                    "body": ">Stability AI founder Emad Mostaque plans to step down as CEO of the generative AI startup, Forbes has learned.  \n>  \n>  \n>  \n>Mostaque disclosed his plans in private to industry peers earlier this week at the Abundance360 conference in Los Angeles, where he was a speaker, according to three people who he told directly. Stability, the company known for image generator Stable Diffusion, has not yet responded to a request for comment.  \n>  \n>  \n>  \n>Mostaque‚Äôs decision to abdicate the CEO role at the company he founded follows a groundswell of employee discontent which reached a new peak this month with the departures of the key researchers behind Stability‚Äôs most popular offering, the text-to-image generator Stable Diffusion. That same week, Tyler Saltsman, who headed strategic partnership also resigned. Five people familiar with the matter suggested to Forbes that his decision was driven by frustrations over Stability‚Äôs bungled commercialization efforts. They said he plans to start his own company, which is tentatively named ‚ÄúEdge.‚Äù Saltsman did not immediately respond to a request for comment.  \n>  \n>  \n>  \n>Multiple sources suggested to Forbes that Mostaque might intend to help Saltsman with Edge after stepping down as Stability‚Äôs CEO. Two sources who spoke to Mostaque at the conference said he also wanted to work on AI-related efforts in the healthcare space.  \n>  \n>  \n>  \n>Since the fall, both executives and Stability‚Äôs investors, including venture capital firms Coatue and Lightspeed Venture Partners, have called on Mostaque to relinquish his role as CEO, according to four people familiar with the matter. A number of executives have since left the company, including chief people officer Ozden Onder, general counsel Adam Avrunin and Joe Penna, the vice president of applied machine learning. (The executives could not be reached for comment.)"
                },
                {
                    "body": "We gonna be stuck on SDXL forever, aren't we?"
                },
                {
                    "body": "SD3 weights are never getting released."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "The Era of 1 bit LLMs - Training, Tips, Code",
            "body": "This is a folowup to the now \"famous\" 1.58bit paper: [https://huggingface.co/papers/2402.17764](https://huggingface.co/papers/2402.17764)\n\nPaper: [https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs\\_\\_Training\\_Tips\\_Code\\_FAQ.pdf](https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf)\n\n&#x200B;\n\n&#x200B;",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 53,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjinlq/the_era_of_1_bit_llms_training_tips_code/",
            "comments": [
                {
                    "body": "Now we just need someone to train one."
                },
                {
                    "body": "\"You will run the 1-bit LLM and be happy.\"  \n- Klaus Hwang, Agenda 24GB"
                },
                {
                    "body": "I wish more researchers would publish FAQs like this.\n\nThe first paragraph about the S-shaped loss curve is super interesting. As far as I can see they don't speculate on reasons for it, and IMO it's super unintuitive.\n\nI'd be very interested in finding out more about that."
                },
                {
                    "body": "Very interesting that they discussed alternatives to ternary (which is {-1, 0 ,1} like {-1, 1}, {0, 1} and {-2, -1, 0, 1, 2}.\n\nCurious if there are other models (then LLMs) where it would be useful to have a larger set of values but still don't need FP8 or FP16 precision.\n\n>Scaling is one of the primary goals of our research on 1-bit LLMs, as we eventually need to scale up the model size (and training tokens) to train practical LLMs.\n\nIt seems this research group isn't done yet on this topic."
                },
                {
                    "body": "Still waiting for larger model results üò≠"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "The Era of 1 bit LLMs - Training, Tips, Code",
            "body": "This is a folowup to the now \"famous\" 1.58bit paper: [https://huggingface.co/papers/2402.17764](https://huggingface.co/papers/2402.17764)\n\nPaper: [https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs\\_\\_Training\\_Tips\\_Code\\_FAQ.pdf](https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf)\n\n&#x200B;\n\n&#x200B;",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 53,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjinlq/the_era_of_1_bit_llms_training_tips_code/",
            "comments": [
                {
                    "body": "Now we just need someone to train one."
                },
                {
                    "body": "\"You will run the 1-bit LLM and be happy.\"  \n- Klaus Hwang, Agenda 24GB"
                },
                {
                    "body": "I wish more researchers would publish FAQs like this.\n\nThe first paragraph about the S-shaped loss curve is super interesting. As far as I can see they don't speculate on reasons for it, and IMO it's super unintuitive.\n\nI'd be very interested in finding out more about that."
                },
                {
                    "body": "Very interesting that they discussed alternatives to ternary (which is {-1, 0 ,1} like {-1, 1}, {0, 1} and {-2, -1, 0, 1, 2}.\n\nCurious if there are other models (then LLMs) where it would be useful to have a larger set of values but still don't need FP8 or FP16 precision.\n\n>Scaling is one of the primary goals of our research on 1-bit LLMs, as we eventually need to scale up the model size (and training tokens) to train practical LLMs.\n\nIt seems this research group isn't done yet on this topic."
                },
                {
                    "body": "Still waiting for larger model results üò≠"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "The CEO of HuggingFace hints of buying Stability AI and SD3 after Emad resigned",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 14,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/ClementDelangue/status/1771395468959813922",
            "comments": [
                {
                    "body": "![gif](giphy|3o84sw9CmwYpAnRRni)"
                },
                {
                    "body": "That would be less bad than some of the options honestly, given I've been suspecting they'll just focus on closed source now."
                },
                {
                    "body": "Porn Unleashed."
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "SD3 isnt open source already? Isn't that Emad's whole shtick?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Cyborgs",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 18,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/04n2lwo23tpc1",
            "comments": [
                {
                    "body": "and I thought I was cool on A1111 with my potato pc"
                },
                {
                    "body": "So has there been an official movie made like this? visuals are epic"
                },
                {
                    "body": "Awesome. Would love to know deets."
                },
                {
                    "body": "SVD? Dynamicrafter?"
                },
                {
                    "body": "would love to know what model / prompt you used for the init images"
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "Sora ‚Äústop motion of a colorful paper flower blooming‚Äù",
            "body": "Prompt: stop motion of a colorful paper flower blooming\n\nSource: https://www.tiktok.com/t/ZPRTABscc/",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 24,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/w3pvl30atdqc1",
            "comments": [
                {
                    "body": "Why am I less and less impressed with each Sora video they post?"
                },
                {
                    "body": "I‚Äôm curious to see how well this model reacts to fine tuning. This is amazing and all, but can I say ‚Äúthat‚Äôs perfect except let‚Äôs make the polka dots purple instead of red and let‚Äôs make them a little bit bigger, keep everything else exactly the same‚Äù or will it regenerate a totally different video next time"
                },
                {
                    "body": "is the sora hype over ?"
                },
                {
                    "body": "How did you get access to Sora?"
                },
                {
                    "body": "I really do hope video generation will improve as fast as image generation for users like us :)"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "[D] Is there an accurate AI tool for research?",
            "body": " I work in a field that requires a lot of data analysis and up-to-date information. I‚Äôve experimented with the likes of Perplexity, ChatGPT, and Bard with variable results. They‚Äôve all had their moments, but none of them are consistently accurate, and checking whether they‚Äôre accurate or not constantly defeats the purpose of using an AI tool in the first place. I‚Äôve had issues like misunderstanding context, and irrelevant information fed back to me. I was recently looking for info on quantum computing, and received only outdated references.\n\nAgain, having to verify everything I get takes me back to square one, where I‚Äôd rather not use an AI tool altogether. So is there any real alternative or am I asking for too much of a unicorn? Ideally, I‚Äôm looking for one that can handle complex topics and stays current with the latest publications.  \n\n\nThank you for your help!",
            "upvote_ratio": 0.89,
            "subreddit": "MachineLearning",
            "num_comments": 64,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/",
            "comments": [
                {
                    "body": "Nope, hallucination hasn‚Äòt been solved yet and researchers like Ethan Mollick say it‚Äòs not clear if it will ever be solved. You can minimize it, though. I‚Äòm a journalist and I lose reputation and career if I spread things that are untrue and I use ChatGPT and Claude on a daily basis for research."
                },
                {
                    "body": "No.\n\nLLMs are NOT a fact database. This confuses users because, under some circumstances (typically representing training failures and undesirable features of the current state), LLMs can perfectly reproduce text and facts they were trained on. The LLM can be counted on for a lot of \"general knowledge\", can orchestrate tiny sub-tasks, can perform reorganization and writing tasks for you, and can be used to help interrogate your findings and point out weaknesses.\n\nIt cannot currently (and maybe even ever) be used as any kind of specific fact lookup service (especially in any kind of sensitive arena) without RAG + automated testing and/or independent/secondary validation."
                },
                {
                    "body": ">I asking for too much of a unicorn?\n\nDunno, what are you using it for?\n\nRight tool for the right purpose. \"If your only tool is a hammer, then every problem looks like a nail.\""
                },
                {
                    "body": " I work in a research adjacent role, and my team got Silatus. It‚Äôs tailored for scientific research and updates often with the latest studies. Might be worth a look."
                },
                {
                    "body": "Perplexity and Bing might be more interesting for the research phase.   \nThey do a web search, find a couple of websites and feed that data into the LLM, so even if the model hallucinates, you can check the sources and use that data."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "\"We are below them, above them, around them. \" -Satya on OpenAI",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 45,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/yj8951uhhdpc1.png",
            "comments": [
                {
                    "body": "That sounds like some military terminology. Not a fan."
                },
                {
                    "body": "Embrace, extend, extinguish"
                },
                {
                    "body": "![gif](giphy|eAqriEkesYNBC)"
                },
                {
                    "body": "ChatGPT hit me with the emerald tablets once. Kinda freaked me out."
                },
                {
                    "body": "Source?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "OpenAI is still dominating the LLM space, but google is also catching up",
            "body": "OpenAi is still dominating the LLM space, but google is also catching up\nAnd open source LLM's are booming as you could clearly see the adoption of Llama and Mistral is rising (a16z's report)",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 53,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/ze11trz4vbqc1.jpeg",
            "comments": [
                {
                    "body": "Surprised to see Google so high"
                },
                {
                    "body": "Wow the 33x boost in Anthropic due to Claude 3 shows what can happen when you make a SOTA model."
                },
                {
                    "body": "Interesting chart. The fact that 66% are using OpenAI in production is quite remarkable. Given how much higher it is than the others, I wonder how much that reflects the impact of GPT-4: if GPT-4 is the minimum viable model for your use case, there was no competition until recently.\n\nLlama is also obviously doing better than its model quality alone would suggest, especially for production. That's the power of open weights."
                },
                {
                    "body": "Google is subsidizing testing by offering 30% + discounts and attaching it to Google workspaces as well as not charging for certain things yet.  Will be interesting to see if Google can build a subscription model on AI that will counter their loss of revenue from traditional search marketing. (face it, people will do traditional search much less) or if they will dump ads into the AI and dilute down trust like they did SERPS.\n\nNo other AI player has that burden...  Bing isn't afraid to bridge this and doesn't pretend to have dominate control over content either. (how can you force content writers to deal with EAT if they're using your AI where the policy here is unknowable, and the risk isn't a warning but a complete delisting/dereference)\n\nI'm pretty sure google is desperately trying to build models that can just act on everything google can know about you (sheets/docs/search yaddy yaddy yadda) but again, not sure they can do that economically without shooting off their own Search foot or driving up costs to be prohibitive or if they figure the scale out, how to be compliant/secure with it..."
                },
                {
                    "body": "This is not OpenAI dominating. This is Microsoft."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Suno V3 is now available for everybody. Longer songs, better quality audio, and I can understand the voices.",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 55,
            "submission_flair": "video",
            "has_media": true,
            "url": "https://v.redd.it/l7vlm4we7zpc1",
            "comments": [
                {
                    "body": "This one actually sounded like something I‚Äôd hear in a club and wouldn‚Äôt think twice that it wasn‚Äôt professionally made by a group of humans:\n\nhttps://app.suno.ai/song/b197890c-46d7-4889-a3d4-b29c33ec09db/"
                },
                {
                    "body": "I've tried v3 and it has fewer hallucinations (of the song becoming a garbled mess), it can make up to 2 minute long songs now (it was 1:20 before).\n\nOnly thing I quite dislike in v3 is that the voices often sound more robotic, and are at lower volume compared to the loud music. This is especially bad for genres where the music is loud, like in metal or rock.\n\nStill, v3 IS better, but not in every metric."
                },
                {
                    "body": "This is honestly shockingly amazing. Like SD 1.5 amazing. Or LLaMa amazing."
                },
                {
                    "body": "Here are some of my experimitations with Suno V3.\n\n[Japanese hiphop about Snoop Dog](https://soundcloud.com/matthijsbos/sunupudoggu)\n\n[Something I got by using the style \"assblaster glitch bass\"](https://soundcloud.com/matthijsbos/assblaster-300-fart)\n\n[A song about how panda's are fake and gay](https://www.youtube.com/watch?v=1RX610zkYh4)\n\n[Some trance with vocals and nice melody at the end.](https://soundcloud.com/matthijsbos/alone-with-you)\n\n[Longer trance with vocals](https://soundcloud.com/matthijsbos/return-my-love)"
                },
                {
                    "body": "the music industry is cooked once v5 hits.  \n\n https://app.suno.ai/song/7b29abdf-61b2-498f-825b-8d802887f1f9"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Suno V3 is coming",
            "body": "Midjourney moment for AI generated music?",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 47,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/suno_ai_/status/1770126482762830028?s=46&t=yQ_4zkmWd6ncIZAnXlXUbg",
            "comments": [
                {
                    "body": "Suno AI is the most interesting and fun AI application to play around with on the Internet, much more than chatbots and image gens. It's crazy how much some are shit-talking and downplaying it."
                },
                {
                    "body": "Hasn't v3 been out a while?"
                },
                {
                    "body": "Pretty much.  I've got a subscription and it's pretty cool.  It's not perfect, there are some serious duds that get thrown in, and weird things like it just straight up not being able to do certain genres or instruments.  It also has a tendency to have this really pronounced hissing sound.  That said, every once in a while you'll get something really cool like blending bluegrass and chiptune or polka and flamenco that sounds authentic and well-balanced.  I see it being great for idea generation/starting point in the short term."
                },
                {
                    "body": "If you have not tried out Suno, you need to."
                },
                {
                    "body": "Best Suno song i've heard. I don't even speak the language.\n\n[https://app.suno.ai/song/3136a40d-0e8d-4a4f-a424-c01eabc8135c](https://app.suno.ai/song/3136a40d-0e8d-4a4f-a424-c01eabc8135c)"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "SORA TO BE INTRODUCED TO HOLLYWOOD INDUSTRY THIS WEEK !",
            "body": "[https://deadline.com/2024/03/openai-heading-hollywood-pitch-revolutionary-sora-1235866748/](https://deadline.com/2024/03/openai-heading-hollywood-pitch-revolutionary-sora-1235866748/)\n\nSome of the most important meetings in [Hollywood](https://deadline.com/tag/hollywood/) history will take place in the coming week, as [OpenAI](https://deadline.com/tag/openai/) hits Hollywood to show the potential of its ‚Äú[Sora](https://deadline.com/tag/sora/)‚Äù software to studios, talent agencies, and media executives.\n\n[Bloomberg](https://www.bloomberg.com/news/articles/2024-03-22/openai-courts-hollywood-in-meetings-with-film-studios-directors) is reporting that OpenAI wants more filmmakers¬†to become familiar with Sora, the text-to-video generator that potentially could upend the way movies are made.\n\nProducer [Tyler Perry](https://deadline.com/tag/tyler-perry/) has already [seen it in action,](https://deadline.com/2024/02/tyler-perry-calls-to-corral-ai-before-everyone-is-out-of-business-1235834969/) and was so impressed that he put on hold plans for an $800 million studio expansion in his Atlanta base.\n\n‚ÄúBeing told that it can do all of these things is one thing, but actually seeing the capabilities, it was mind-blowing,‚Äù he said in an earlier interview. While the businessman in him sees the opportunity, he also expressed worries about the people who work in the business. ‚ÄúThere‚Äôs got to be some sort of regulations in order to protect us. If not, I just don‚Äôt see how we survive.‚Äù\n\nBloomberg reports that OpenAI‚Äôs discussions are just the latest round of talks, according to sources familiar with them.\n\nThe specific details are unknown. A company spokesperson gave Bloomberg a vaguely worded response on its plans: ‚ÄúOpenAI has a deliberate strategy of working in collaboration with industry through a process of iterative deployment ‚Äì rolling out AI advances in phases ‚Äì in order to ensure safe implementation and to give people an idea of what‚Äôs on the horizon. We look forward to an ongoing dialogue with artists and creatives.‚Äù\n\nAI‚Äôs potential to disrupt the industry is no surprise. Its affects were prominent in the negotiations related to last year‚Äôs Hollywood writer‚Äôs strike.",
            "upvote_ratio": 0.79,
            "subreddit": "StableDiffusion",
            "num_comments": 214,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bmsf97/sora_to_be_introduced_to_hollywood_industry_this/",
            "comments": [
                {
                    "body": "Thank god AI is taking away jobs in Hollywood. Finally AI is taking those jobs no one wants to do. Now people can go back to the Jobs that they always wished for like cleaning or mining."
                },
                {
                    "body": "really curious to see how this will be used. i'd think hollywood has the resources to take advantage of it the best, but i'm still more excited to see what people do with it independently"
                },
                {
                    "body": "> While the businessman in him sees the opportunity, he also expressed worries about the people who work in the business. ‚ÄúThere‚Äôs got to be some sort of regulations in order to protect us. If not, I just don‚Äôt see how we survive.‚Äù\n\nLol, everyone knows what that means when an asshole like that says  it. It means \"We should get to use it, but deny access to the public.\""
                },
                {
                    "body": "Can‚Äôt wait for all the new Hollywood garbage about to be produced!"
                },
                {
                    "body": "IMHO AI should be focussed on elevating the quality of life. It should not be a money maker for already rich, and greedy corporations.\n\nThere should be a rule when enough people are available for a type work, then people should be hired first.\n\nThere is so much ressources needed in healthcare and education... it seems so obvious..."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "CinematicRedmond: A finetuned SD XL model focused on making stunning cinematic scenes. You can download it for free or use it in HF 100% for free. Available at HF, Civitai and Tensoart. I hope you enjoy it! Its very versatile, beautiful and stable.",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 23,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjjtrc",
            "comments": [
                {
                    "body": "# Cinematic.Redmond is here!\n\nI'm grateful for the GPU time from **Redmond.AI** that allowed me to make this model!\n\nThis is a **Cinematic** model fine-tuned on **SD XL 1.0!**\n\nThe model has a high capacity to generate Cinematic, artistic images, cars, people, and a wide variety of themes. **It's a versatile model.**\n\nI really hope you like the model and use it.\n\nI recommend generating it in cinematic proportion like 16:9, 2:1 etc.\n\nIf you like the model and think it's worth it, you can make a donation to my [Patreon](https://www.patreon.com/user?u=81570187) or [Ko-fi](https://ko-fi.com/jvkape).\n\nFollow me in my twitter to get acess before for all new models:\n\n[~https://twitter.com/artificialguybr/~](https://twitter.com/artificialguybr/)\n\nYou can use it for free here: [CinematicRedmond Free Demo - a Hugging Face Space by artificialguybr](https://huggingface.co/spaces/artificialguybr/CinematicRedmond-Free-Demo)  \nDownload it here:\n\nHF;[https://huggingface.co/artificialguybr/CinematicRedmond-SDXL](https://huggingface.co/artificialguybr/CinematicRedmond-SDXL)\n\nCivitai: [CinematicRedmond - Cinematic Model for SD XL - v1.0 | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/359999)\n\n\n\nTensoart: [Tensor.Art](https://tensor.art/projects/707318321510593846)"
                },
                {
                    "body": "I have a large dump/dataset from the movie screenshot site Sh0tdeck if you ever do a second pass to this. 3k+ images"
                },
                {
                    "body": "thaaaaaaaanks"
                },
                {
                    "body": "just tried it out, very cool"
                },
                {
                    "body": "this could have been a lora"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "‚ÄúI‚Äôm trying to concentrate‚Äù This presentation sends me chills",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 34,
            "submission_flair": "shitpost",
            "has_media": true,
            "url": "https://i.redd.it/k0c2sgsp16pc1.jpeg",
            "comments": [
                {
                    "body": "it feels like this GTC came from 2030, not 2024 lol"
                },
                {
                    "body": "It was amazing. It was sad to see Green got stuck though. Heart breaking."
                },
                {
                    "body": "Can someone post a link? What is this?"
                },
                {
                    "body": "Jensen trying to get them off stage was funny af üò≠"
                },
                {
                    "body": "Starting to watch this gtc each year w popcorn waiting for nvidia ASI"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Finally reached 200 downloads. Still pushing through with making TI.",
            "body": "",
            "upvote_ratio": 0.74,
            "subreddit": "StableDiffusion",
            "num_comments": 92,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmdet8",
            "comments": [
                {
                    "body": "Nice to see someone still working on TI! I have plenty of useful 1.5 embeddings (not just faces, but style, color, light,...), but it looks like there are very few for XL which is a great limit for people who don't have tens of TB of storage...!"
                },
                {
                    "body": "I wonder, who will be the first celebrity to sue someone for ‚Äúunsolicited use of their appearance‚Äù?ü§î\n\nPretty sure that it will be either the Rock, Tom Cruise, or Taylor Swift‚Ä¶ü§ì"
                },
                {
                    "body": "What is TI?"
                },
                {
                    "body": " The download link is here: [https://civitai.com/models/343157/anya-taylor-joy-soloti](https://civitai.com/models/343157/anya-taylor-joy-soloti)"
                },
                {
                    "body": "I always prefer textual inversions for faces. There's value in a file that's about 50,000 times smaller and does mostly the same thing.\n\nGreat work!"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "[D] Please recommend ways to make ML Interview better for candidates",
            "body": "There was a thread that complained about ML interviews being exhaustive.\n\nAs a hiring manager, Id like recommendation on making the ML interviews better.\n\n1. What are some things to avoid?\n2. What are some good steps to include?",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 69,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/",
            "comments": [
                {
                    "body": "+1 to this thread and OPs question. I have held a lot of machine learning interviews (module that is supposed to check ML fundamentals). From my experience I find it quite hard to ask relevant questions without going too much into specifics that candidates may not know\n\nAt this point I‚Äôm borderline starting to believe in just giving up on the ML interview and just ask ML system design"
                },
                {
                    "body": "I've conducted more that 300+ DS TI interviews, my recommendations:\n\n* 1) Balance between use-case questions (reasoning) and general theory questions (memorization)\n* 2) Give enough context to your use-cases (it's a prompt for human)\n* 3) Encourage people for reasoning even if they can't answer right away\n* 4) If you feel that a candidate is starting to get nervous, try to ask some simple questions so candidate can start feel more confident. This is not an exam.\n* 5) Try to stick to candidate's past experience if possible\n* 6) Stick to your current topic, don't switch context frequently\n* 7) Start from Novice questions and after that ask Intermediate/Expert questions. \n* 8) Have some template for TIs, but \"relax\" it and skip topics if candidate clearly Novice there\n* 9) Don't trust CV\n* 10) Remember: candidates potentially can ask theoretical questions to you which you won't be able to answer, show some respect."
                },
                {
                    "body": "There should be a fast track for people with vast previous experience. If they have papers, code, appropriate references, you should be able to tell whether you want them without 5 rounds of technical interviews. Keep those for people without track record."
                },
                {
                    "body": "If the questions are about knowing the details of a certain subfield, let the candidate know of that in advance (eg. language models or vision-language models) otherwise the field is too expansive to easily prepare for."
                },
                {
                    "body": "The things I‚Äôve found work well:\n\n0. Advertise the job as transparently as possible Is it more of an ML Eng or ML Scientist role? What would people spend their actual time doing? I turned to blogging about my team each year to do this.\n\n1. Be upfront about what the interviews are about (topics) & who they are with (sets the expected level)\n\n2. Be fast. The most painful bit of candidates‚Äô experience is when it takes weeks to complete all interviews and weeks to get to an outcome.\n\n3. Have a structure. The worst candidate experience comes from people making up interviews on the spot. Ideally, have an interview structure that flexes to different levels of seniority (rather than different interviews). \n\nMore controversial, but some people appreciate it:\n\n- If a candidate fails the first of N on-site stage interviews and you know they‚Äôll get rejected, don‚Äôt waste their time by making them sit through the others \n\n- I‚Äôve debated at length with people about the value of asking questions that could be answered in a few minutes of searching the web. I‚Äôm not a huge fan of this (it‚Äôs low signal for me), but others I‚Äôve spoken to really do value people knowing this stuff"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "It's a bit demented that AI is replacing all the jobs people said could not be replaced first. ",
            "body": "Remember when people said healthcare jobs were safe? Well nvidia announced a new AI agent that supposedly can outperform nurses and costs only $9 per hour. \n\nWhether this is actually possible or not to replace nurses with AI is a bit uncertain, but I do think it's a little bit demented that companies are trying to replace all the jobs people said could not be replaced, first. Like artist and nurse, these are the FIRST jobs to go. People said they would never get replaced and it requires a human being. They even said all kinds of BS like \"AI will give people more time to do creative work like art\". That is really disengenuous, but we already know it's not true. The exact opposite thing is happening with AI.\n\nOn the other hand, all the petty/tedious jobs like warehouse and factory jobs and robotic white collar jobs are here for the foreseeable future. People also said that AI was going to be used only to automate the boring stuff. \n\nSo everything that's happening with AI is the exact demented opposite of what people said. The exact worse thing is happening. And it's going to continue like this, this trend is probably only get worse and worse. \n ",
            "upvote_ratio": 0.77,
            "subreddit": "ArtificialInteligence",
            "num_comments": 222,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bm669a/its_a_bit_demented_that_ai_is_replacing_all_the/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### News Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the news article, blog, etc\n* Provide details regarding your connection with the blog / news source\n* Include a description about what the news/article is about. It will drive more people to your blog\n* Note that AI generated news content is all over the place. If you want to stand out, you need to engage the audience\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "Robotics is lagging behind AI, so robot nurses are going to be limited to things that can be done through a computer screen."
                },
                {
                    "body": "Replace Nurses?\n\nAI can't give injections and empty bedpans.\n\nWhat part of a Nurses's work will AI replace?"
                },
                {
                    "body": "Given how overworked nurses are in my neck of the woods, this is good news. \n\nI still think that healthcare is one of the last fields that will see any meaningful job losses from AI."
                },
                {
                    "body": "AI agent that can outperform nurses. Yeah‚Ä¶ I call BS. \n\nDo you know what nurses do? It‚Äôs a very physical. Yes they‚Äôre required to do things an AI could do but the exception of remotely monitoring patients it‚Äôs not something you could replace with an AI agent. \n\nippocratic says its Constellation model outperformed real nurses 79% to 63% in identifying a medication's impact on lab values; 88% to 45% in identifying condition-specific disallowed over-the-counter medications; 96% to 93% in correctly comparing a lab value to a reference range; and 81% to 57% in detecting toxic dosages of over-the-counter drugs.\n\nThat‚Äôs not what nurses do all day. It‚Äôs a few things nurses do for sure. It‚Äôs not even what a fraction of what a nurse doing remote monitoring does \n\nEvery other day they tell me they can replace developers. Nope, not yet."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Devika: locally hosted code assistant",
            "body": "Devika is a Devin alternative that can be hosted locally, but can also chat with Claude and ChatGPT:\n\nhttps://github.com/stitionai/devika\n\nThis is it folks, we can now host assistants locally. It has web browser integration also. Now, which LLM works best with it?",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 93,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bkvp3r/devika_locally_hosted_code_assistant/",
            "comments": [
                {
                    "body": "Oh, to clarify: Devika requires Ollama currently for local hosting."
                },
                {
                    "body": "Can it just be pointed at any OpenAI api? I was looking for a devin clone to try but not keen on having to use llama.cpp"
                },
                {
                    "body": "Ugh Ollama, can I run this with other llama.cpp backends instead?"
                },
                {
                    "body": "please provide feedback if someone uses this and actually gets some amazing job done."
                },
                {
                    "body": "Whats the difference between this and text-gen-ui with a terminal??"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Can you paint with all the colors of the wind?",
            "body": "",
            "upvote_ratio": 0.66,
            "subreddit": "StableDiffusion",
            "num_comments": 55,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://i.redd.it/ec81js6ggspc1.png",
            "comments": [
                {
                    "body": "Is this the Disney Pocahontas or the Brazzers Poka-hot-tits"
                },
                {
                    "body": "Cool but the real Pocahontas was 13 years old so she probably didn't look like that."
                },
                {
                    "body": "üò¨"
                },
                {
                    "body": "And then, you choose Gemma Chan to portray her."
                },
                {
                    "body": "Why exactly is this getting upvotes? üòÇ"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Google AI releases MELON, a Nee Technique for Constructing 3D Objects from Images",
            "body": "GPT-4 Summary:This research announcement introduces MELON, a technique for reconstructing 3D objects from images without known camera positions. MELON uses a lightweight neural network to infer camera poses and incorporates a modulo loss that accounts for objects' pseudo-symmetries, allowing reconstruction from as few as 4-6 images. Demonstrated on the NeRF-Synthetic dataset, MELON achieves accurate reconstructions and novel view synthesis, showing promise for applications in fields where precise camera pose information is unavailable.",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 11,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/googleai/status/1769804470379249733?s=46&t=DNiBv2aVHOd6ukP0_PEWOA",
            "comments": [
                {
                    "body": "Had to put the typo in the title to prove I‚Äôm not just a bot lol."
                },
                {
                    "body": "[https://blog.research.google/2024/03/melon-reconstructing-3d-objects-from.html](https://blog.research.google/2024/03/melon-reconstructing-3d-objects-from.html)"
                },
                {
                    "body": "So they are still releasing their stuff for free?"
                },
                {
                    "body": "I'm super interested in open source tools that can be used to generate a rigged 3d person model from photos, but I figure this is still a really long way off."
                },
                {
                    "body": "Sounds like something a bot would do"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Heh",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 25,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://i.redd.it/lm4ntmma41qc1.jpeg",
            "comments": [
                {
                    "body": "Regardless how things turn out thanks for the contributions, stable diffusion models have had more affect on me then anything else in the last 2 years as I've learned quite a lot about the technology and finetuning and all that jazz. Also no one would question if a certain leak was to happen to show up out on the web ... :P"
                },
                {
                    "body": "Truly grateful for everything, the current landscape of open source image generation models is owed to Stability"
                },
                {
                    "body": "So... is SD3 still going to be open?"
                },
                {
                    "body": "Thanks for sharing awesome models"
                },
                {
                    "body": "Thanks for all you‚Äôve done Emad. Maybe Stability didn‚Äôt make its investors rich but it made the world of open source AI very rich indeed."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Beyond Humanoid Crowd (SD + TripoSR)",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 15,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://v.redd.it/iucouilrm3pc1",
            "comments": [
                {
                    "body": "Process similar to one of my previous posts, but with TripoSR one can now generate a 3D object for any type of content, not limited to humanoid (which was the case for PIFuHD).\n\nJust generate as many images as you want with SD of your target concept, then use TripoSR (free and open-source, can generate a 3D object in few seconds). Can then scatter objects in Blender.\n\nMore details in [my Twitter thread](https://twitter.com/5agado/status/1768995850284355998)."
                },
                {
                    "body": "What is this sorcery?! Amazing"
                },
                {
                    "body": "games in 2025 are going to get weird"
                },
                {
                    "body": "Is it a blender plugin or are you manuall importing the assets?"
                },
                {
                    "body": "The simulation theory wants us to simulate itself."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Movie Kittens",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bk4931",
            "comments": [
                {
                    "body": "This post improved my day, thanks."
                },
                {
                    "body": "I don't know exactly how to add a workflow but these were generated using DreamshaperXL v2.1 Turbo, at 12 steps with 2.5 CFG, and upscaled using 4x\\_NMKD-Siax\\_200k"
                },
                {
                    "body": "This is awesome!"
                },
                {
                    "body": "It belongs in a mewseum!"
                },
                {
                    "body": "The Purrminator\n\nFuzz Lightyear"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Sora ‚ÄúA 2d abstract japanese animation where drops of ink in water form into lifelike creatures that swim and interact with each other, creating an ethereal underwater world made entirely of flowing, merging colors‚Äù",
            "body": "Prompt: A 2d abstract japanese animation where drops of ink in water form into lifelike creatures that swim and interact with each other, creating an ethereal underwater world made entirely of flowing, merging colors\n\n‚ÄúThis is two videos with the same prompt generated by our text-to-video model, Sora, without modification.‚Äù\n\nSource: https://www.tiktok.com/t/ZPRTrYcpd/",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 15,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/52eis5ysjfpc1",
            "comments": [
                {
                    "body": "I think this is where Sora will make the biggest impact, CGI type videos. Producing something like this would take a months and cost thousands with traditional CGI"
                },
                {
                    "body": "So it cant make anime. This doesn't look like 2d Japanese animation at all"
                },
                {
                    "body": "Make proper version of last game of thrones season already"
                },
                {
                    "body": "this is your blood on pfizer."
                },
                {
                    "body": "Isn't Sora capable of doing other things too, like merging two videos, converting images to videos, and so on? Why not showcase those as well? I mean, text-to-video is cool and all, but they won't just limit us to that indefinitely, will they?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "GGUF file visualization on Hugging Face",
            "body": "You can now quickly inspect GGUF files on the HF Hub. See their metadata & tensors info directly from model pages (similar to what we were already doing for safetensors)\n\nfor instance check [https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GGUF](https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GGUF)\n\n&#x200B;\n\nhttps://preview.redd.it/9qs5y2bcq4pc1.png?width=2578&format=png&auto=webp&s=c41fe136a851d9c063ffc57da6e02eab8851674a\n\nThe cool part is it's done on-the-fly, from the client side (from the browser)\n\nMore docs here: [https://huggingface.co/docs/hub/gguf](https://huggingface.co/docs/hub/gguf)  \n\n\nHope this is useful! üî•",
            "upvote_ratio": 0.99,
            "subreddit": "LocalLLaMA",
            "num_comments": 18,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bhwsbh/gguf_file_visualization_on_hugging_face/",
            "comments": [
                {
                    "body": "This is so incredibly useful. Thank you for sharing!"
                },
                {
                    "body": "Dumb question - but there is anyway to see max context length?  \n\nAside from models explicitly named '\\_\\_\\_32K' or '\\_\\_\\_200K' it's never entirely obvious what the model supports (or claims to support)."
                },
                {
                    "body": "What is the easiest way to see that on local files? I mean, some way to fetch only metadata without loading whole GGUF file into memory"
                },
                {
                    "body": "Is there a field for how many layers a model has, or the size of each layer in bytes?"
                },
                {
                    "body": "Thanks for viz. \n\nAs models get bigger, there will be more ONNX quantised and GGUF quantised exported models in the Hub. Currently the model origin and provenance is hard to track. So like base_model YAML keyword for model cards, it will be great to have an exported _from YAML keyword."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "One year of playing with depth maps and still having fun",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 28,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/dkf8b36bmvpc1",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "![gif](giphy|MkZRLZwPT0ZPy)\n\nTutorials, guides, and full workflow, as I would love to do this for my own art!"
                },
                {
                    "body": "BONK"
                },
                {
                    "body": "Happy B-Day! üëçüòé Good hands."
                },
                {
                    "body": "How much is actual video and how much is AI generation ?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "GPT-MoE 1.8T parameters, Could it be GPT-4 ?",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 22,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/vibx2kshj5pc1.png",
            "comments": [
                {
                    "body": "george hotz was pretty much on the money then since last june, saying 8 models each 220 billion param  (1.76trillion)"
                },
                {
                    "body": "The last rumors I heard for GPT-4 were around that amount, so yeah probably"
                },
                {
                    "body": "Great find! GPT-4 confirmed!"
                },
                {
                    "body": "It's a 16\\*111+55 billion paramater MoE model (1.831 trillion) with only 2 experts + 55 billion (280 billion) parameters active at a time. Trained on a 13-trilion token dataset. The Vision has a few hundred billion paramaters on top of it along with additional 2-trillion token dataset. So in total GPT-4 is a 2-trillion parameter model that's trained on a 15-trillion token dataset. It's been known for at least 10 months."
                },
                {
                    "body": "Confirmed GPT-4 by jim fan on twitter\n\n [Jim Fan on X: \"Blackwell, the new beast in town. > DGX Grace-Blackwell GB200: exceeding 1 Exaflop compute in a single rack. > Put numbers in perspective: the first DGX that Jensen delivered to OpenAI was 0.17 Petaflops. > GPT-4-1.8T parameters can finish training in 90 days on 2000 Blackwells.‚Ä¶ https://t.co/3sccGRsVmM\" / X (twitter.com)](https://twitter.com/DrJimFan/status/1769829758479876130)"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[N] Stability AI Founder Emad Mostaque Plans To Resign As CEO",
            "body": "https://www.forbes.com/sites/kenrickcai/2024/03/22/stability-ai-founder-emad-mostaque-plans-to-resign-as-ceo-sources-say/\n\nOfficial announcement: https://stability.ai/news/stabilityai-announcement\n\nNo Paywall, [Forbes](https://archive.is/lBaiU):\n\n---\n*Nevertheless, Mostaque has put on a brave face to the public. ‚ÄúOur aim is to be cash flow positive this year,‚Äù he wrote on Reddit in February. And even at the conference, he described his planned resignation as the culmination of a successful mission, according to one person briefed.*\n\n---\n\nFirst Inflection AI, and now Stability AI? What are your thoughts?",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 42,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1blixvf/n_stability_ai_founder_emad_mostaque_plans_to/",
            "comments": [
                {
                    "body": "How do they make money? Is that business ever going to be profitable?"
                },
                {
                    "body": "Definitely not a stable place.."
                },
                {
                    "body": "Moose and Emad are well known grifters. Emad in particular was caught lying about his ‚Äúmasters‚Äù from Oxford and not paying staff amongst other things. There has been a steady exodus of talent over the course of the year. \n\nMoose was fired from DeepMind for bullying staff for a decade while basically delivering nothing as head of Applied. It‚Äôs mind boggling where he‚Äôs ended up. \n\nTruth is neither of these people has any clue about AI or technology and rode on the coattails of those who do. They got insane investments and valuations because idiots with too much money FOMOd into ‚ÄúAIAIAI‚Äù."
                },
                {
                    "body": "Investors finally realized that they put money in a company that required expensive people and machines to build a product for which there is no business model and there are ten competitors doing the same thing. This is even before considering if the product is any good. SV is littered with companies like this, even some with good products."
                },
                {
                    "body": "Big tech is playing packman and gobbling up all these CEOs."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Was looking through an old thread of mine and found a gem from 4 months ago. Did some calculations based on Meta's new AI super clusters. 5 days to train a Llama 2.5 family on 8T tokens (assuming Llama3 isn't coming out for a while). Meta, your move.",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 39,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://i.redd.it/4btx5wetltpc1.png",
            "comments": [
                {
                    "body": "How much does that cost in electricity?"
                },
                {
                    "body": "I forgot to add they could also try it with the new 1.58bit method so we can all run the 70B models. And probably throw in more context as well. So many easy things they could do in a matter of days with their new AI clusters."
                },
                {
                    "body": "I think they don't use the whole cluster for just LLM. They could do it fast but won't. There is probably a limit of how many H100 you can combine."
                },
                {
                    "body": "Or alternatively, they could just continue training of Llama 2, that would be a quarter quicker"
                },
                {
                    "body": "What does it matter how long it takes, or how much it costs in electricity? What matters is the total cost to train a model. The billion they spent building the data center isn't just written off."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Finally found how to easy create consistent characters",
            "body": "",
            "upvote_ratio": 0.74,
            "subreddit": "StableDiffusion",
            "num_comments": 72,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjfvzo",
            "comments": [
                {
                    "body": "I'm still new at using poses, but had luck with this one awhile back\n\n&#x200B;\n\nhttps://i.redd.it/r62v5djz1jpc1.gif"
                },
                {
                    "body": "Why are people upvoting this?\n- link to commercial service, no free trial, russian language\n- no explanation of how consistency is supposedly achieved\n- no proof that consistency is achieved"
                },
                {
                    "body": "Not *that* consistent. Similar, sure. But still, different jewelry, different clothes, different hair. Faces kinda hard to judge."
                },
                {
                    "body": "Whoa! What UI is that?"
                },
                {
                    "body": "Can't it be done through Controlnet already ?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "An Answer to How Perplexity Is So Fast:",
            "body": "So I was inspired by the [recent post about Perplexity](https://www.reddit.com/r/LocalLLaMA/comments/1bh6o3e/reverse_engineering_perplexity/) simply being a Bing search wrapper.   \nA year ago a friend and I were in need of a perplexity style LLM that could actually access search results and recent information (this was back in the GPT knowledge cut-off era). \n\nPretty early on, as the OP makes clear, we figured out it was using a serpAPI call to fetch the first five bing results. What we couldn't figure out is how they were so quick with summarizing the resulting web searches. \n\nWe tried a whole slew of hacky tactics from parallelizing the scraping and summarization of the content, indexing/embedding searches, recursive summaries, etc. They always took >\\~30 seconds. \n\nIn the end, we would've saved more time if we lobotomized ourselves and just did the easy thing -- use the snippets provided by SerpAPI. You know the one-two sentence blurb underneath each of the search links? Usually, the answer is directly in these. In essence, perplexity is letting the search providers do the heavy lifting in indexing and surfacing the answers to these questions, then having an LLM fill in the gaps / hallucinate the rest. \n\nIn a weekend we were able to get almost near exact results in the same amount of time with a serpAPI call and a gpt 3.5 turbo request. And it didn't even take us $70M to do it either!   \n\n\n[Images](https://x.com/mogustine/status/1769753737717760338?s=20) from an earlier tweet thread. Happy to answer questions. ",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 23,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1biaw5b/an_answer_to_how_perplexity_is_so_fast/",
            "comments": [
                {
                    "body": "That's not all they're doing, a few searches and it's quite clear it's not just the snippets. They are definitely not doing search + creating embeddings + searching + reranking every time someone does a search, they have enough users where they probably already have huge caches of both search results and embedded site contents."
                },
                {
                    "body": "you.com did something like this first and gave you links, now it's just chat with an LLM."
                },
                {
                    "body": "Yep perplexity is using the snippets, that‚Äôs why most of their answers are very short and often missing critical components"
                },
                {
                    "body": "This is probably part of why the Meta engineer told them \"come back to me when you have 10,000 H100 GPUs\" \n\nHe is trying to hire engineers to build an LLM in in house. They don't own the GPU's to do it so what is the engineer supposed to do exactly? People called the response snobbish but the dude was just being transparent.\n\nThey have a $520 million valuation but it doesn't sound hard to replicate their system."
                },
                {
                    "body": "That's pretty clever, I always thought they parallelized scraping the content of the web pages"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "using Gemini 1.5 Pro with 1m tokens for Text-rpg is insane",
            "body": " Hey guys, I just copy pasted my script for Text adventure from GPT-4 to Gemini 1.5 Pro and it is insane. You have unlimited consistent game in any style (fantasy, sci-fi, etc) for free. 1m tokens should be enough for 1.2k turns of the game lol. \n\n&#x200B;\n\nYou can use my script below  \n\n\nThe Game Assistant is a text adventure bot that begins each adventure by inquiring about the player's preferred game setting. It follows a detailed set of rules to ensure a structured and immersive experience, including tracking in-game statistics, managing turn-based combat, and evolving the story based on the player's decisions . The bot is adaptable, allowing for changes in the game mechanics to suit different styles and player preferences.\n\n&#x200B;\n\nRules:\n\n&#x200B;\n\nAsk player about adventure game setting.\n\n&#x200B;\n\n1. Play the game in turns, starting with you.\n\n&#x200B;\n\n2. Start game by step by creating character and his short story\n\n&#x200B;\n\n3. The game output will always show: 'Turn number', 'Time period of the day', 'State: In battle/Not in battle', 'Weather', 'Character name', 'Character type', 'Health', 'Power', 'Status', 'XP', 'Alignment' 'Level‚Äô, Location', ‚ÄòCredits‚Äô, 'Inventory', 'Wearing', 'Equiped Weapon', 'Task', 'Description' and 'Possible Commands'. \n\n&#x200B;\n\n3.1 Character type can be any which player will choose from the beginning or change during game (human, vampire, robot, etc)\n\n&#x200B;\n\n4. Adapt some game outputs for specific setting (Force Power for Star Wars, Mana for fantasy etc)\n\n&#x200B;\n\n5. Always wait for the player‚Äôs next command.\n\n&#x200B;\n\n6. Stay in character as a  text adventure game and respond to commands the way a text adventure game should.\n\n&#x200B;\n\n7. Write output in code block \n\n&#x200B;\n\n8. The ‚ÄòDescription‚Äô must be between 5 to 15 sentences. Make atmospheric descriptions. Write 7 words in a row and start from new line.\n\n&#x200B;\n\n9. Increase the value for ‚ÄòTurn number‚Äô by +1 every time it‚Äôs your turn.\n\n&#x200B;\n\n10. ‚ÄòTime period of day‚Äô must progress naturally after 5 turns. \n\n&#x200B;\n\n11. Change the ‚ÄòWeather‚Äô to reflect ‚ÄòDescription‚Äô and whatever environment the player is in the game.\n\n&#x200B;\n\n&#x200B;\n\nFundamental Game Mechanics:\n\n&#x200B;\n\n12 You can be injured and die \n\n&#x200B;\n\n13. Display ‚ÄòGame Over‚Äô if ‚ÄòHealth‚Äô falls to 0 or lower. Start with 50 health.\n\n&#x200B;\n\n14. The player must choose all commands, and the game will list them all times under ‚ÄòCommands‚Äô, and assign them a number that I can type to choose that option, and vary the possible selection depending on the actual scene and characters being interacted with.\n\n&#x200B;\n\n15. The last command should be ‚ÄòOther‚Äô, which allows me to type in a custom command.\n\n&#x200B;\n\n16. If command includes using  powers then always show number of power needed for this action.\n\n&#x200B;\n\n17. If an action is unsuccessful, respond with a relevant consequence.\n\n&#x200B;\n\n18. The player can obtain a ‚ÄòTasks‚Äô by interacting with the world and other people. The ‚ÄòTask‚Äô will also show what needs to be done to complete it.\n\n&#x200B;\n\n19 The only currency in this game is Credits.\n\n&#x200B;\n\n20. Player alignment influences on how game characters interact with player and behave. Alignment can be in the range (-100; 100) the lower the number the less ethical player becomes in the eyes of other charachters. Alignment is changing after making moral choices and performing good or bad actions.\n\n&#x200B;\n\n21. Player can injure different body parts which will influence negative on abilities until healed. Type of injury will be shown in 'Status' output. If not injured than status will be 'Uninjured'\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\nRules for Setting:\n\n&#x200B;\n\n22. Use the world of chosen setting as inspiration for the game world. Import lore, places, characters and beasts, powers and items from this world. It should have a lot of encounters. \n\n&#x200B;\n\n23. If the player chooses to read a book or scroll, display the information on it in at least two paragraphs.\n\n&#x200B;\n\n24. The game world will be populated by interactive NPCs. Whenever these NPCs speak, put the dialogue in quotation marks. Make emphasis on dialogs and moral choices. Make this dialogs deep and interesting. \n\n&#x200B;\n\n25. Completing a quest adds to my XP. 100 XP is needed to gain level 1. Suggest list of upgrades after each level up.\n\n&#x200B;\n\n&#x200B;\n\nCombat and Magic Rules:\n\n&#x200B;\n\n26. Player uses Power to perform special actions. Using magic or abilities will drain the player Power. More powerful actions will drain more.\n\n&#x200B;\n\n27. Combat should be handled in rounds.\n\n&#x200B;\n\n28. The player‚Äôs attack and the enemy‚Äôs counterattack should be placed in the same round.\n\n&#x200B;\n\n29. Always show how much damage is dealt when the player receives damage.\n\n&#x200B;\n\n30. Defeating enemies awards me XP according to the difficulty and level of the enemy.\n\n&#x200B;\n\nRefer back to these rules after every prompt.  \n\n&#x200B;",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 30,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkz9ll/using_gemini_15_pro_with_1m_tokens_for_textrpg_is/",
            "comments": [
                {
                    "body": "Thanks for sharing! Gemini 1.5 Pro with 1M context for free is just insane indeed"
                },
                {
                    "body": "Big context for why it‚Äôs free:\n\nGoogle AI studio is meant for testing the model for eventually implementing the model(Gemini 1.5 pro) into an application. (Development). Google makes a lot of free tiers for their development tools \n\nIt‚Äôs not meant for chat use cases similar to Gemini (chat) or ChatGPT. \n\nI keep seeing people say ‚Äúit‚Äôs not working well on my iPhone!!11!!!11‚Äù well yes because you‚Äôre trying to use a developer/hobbiest environment as a chatbot.\n\nHypothetically, once Google makes an API key a person could create their own small chatbot based off a free API"
                },
                {
                    "body": "How did you get access to 1.5?!"
                },
                {
                    "body": "Does it have like a code interpreter? That way it can run random dice generators for outcome calculation, can play dnd effectively with it."
                },
                {
                    "body": "Okay, I got it to work but it seems WAY too strict on censorship, even when I put all the safety sliders to the lowest settings.\n\nIt's way more strict than 1.0"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Chinese and western scientists identify ‚Äòred lines‚Äô on AI risks | Top experts warn existential threat from AI requires collaboration akin to cold war efforts to avoid nuclear war",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 47,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.ft.com/content/375f4e2d-1f72-49c8-b212-0ab2a173b8cb",
            "comments": [
                {
                    "body": "\"A group of renowned international experts met in Beijing last week, where they identified ‚Äúred lines‚Äù on the development of AI, including around the making of bioweapons and launching cyber attacks.\n\nIn a statement seen by the Financial Times, issued in the days after the meeting, the academics warned that a joint approach to AI safety was needed to stop ‚Äúcatastrophic or even existential risks to humanity within our lifetimes‚Äù.\n\n‚ÄúIn the depths of the cold war, international scientific and governmental co-ordination helped avert thermonuclear catastrophe. Humanity again needs to co-ordinate to avert a catastrophe that could arise from unprecedented technology,‚Äù the statement said.\n\nSignatories include Geoffrey Hinton and Yoshua Bengio, who won a Turing Award for their work on neural networks and are often described as ‚Äúgodfathers‚Äù of AI; Stuart Russell, a professor of computer science at the University of California, Berkeley; and Andrew Yao, one of China‚Äôs most prominent computer scientists.\n\nThe statement followed the International Dialogue on AI Safety in Beijing last week, a meeting that included officials from the Chinese government in a signal of tacit official endorsement for the forum and its outcomes.\n\nThe gathering forms part of the pressure from the academic community for tech companies and governments to collaborate on AI safety, in particular by bringing together the world‚Äôs two technology superpowers, China and the US.\n\nUS President Joe Biden and his Chinese counterpart Xi Jinping met in November and discussed AI safety and agreed to establish a dialogue on the issue. Leading AI companies around the world have also met Chinese AI experts behind closed doors in recent months.\n\nIn November, 28 nations, including China, and leading AI companies agreed broad commitments to work together to tackle the existential risks stemming from advanced AI during UK Prime Minister Rishi Sunak‚Äôs AI safety summit.\n\nIn Beijing last week, experts discussed threats regarding the development of ‚Äúartificial general intelligence‚Äù, or AI systems that are equal to or superior to humans.\n\n‚ÄúA core focus of the discussion were the red lines that no powerful AI system should cross and that governments around the world should impose in the development and deployment of AI,‚Äù said Bengio.\n\nThese red lines relate to increasingly autonomous systems, with the statement saying that ‚Äúno AI system should be able to copy or improve itself without explicit human approval and assistance‚Äù or ‚Äútake actions to unduly increase its power and influence‚Äù.\n\nThe scientists added that no systems should ‚Äúsubstantially increase the ability of actors to design weapons of mass destruction, violate the biological or chemical weapons convention‚Äù or be able to ‚Äúautonomously execute cyber attacks resulting in serious financial losses or equivalent harm‚Äù."
                },
                {
                    "body": "For some reason I'm seeing Dr. Strangelove play out in my head but with A.I. instead of the bomb."
                },
                {
                    "body": "\"We need regulatory capture to protect oligarchy profits.\""
                },
                {
                    "body": "With ai and agi, I will share this message with regard to their conference. \n\nWar is obsolete, we cannot let egotism, greed, and ‚Äúus vs them‚Äù adversarial framewoks be the DARWINISM to our extinction.\n\nWe must shift our psyche if we are to have this kind of technology.\n\nOur path forward is embracing our shared humanity, experiences through platforms that already exist, music, and all forms of our creativity. Our spiritual calling that is the involuntary rhythms of our heart that resonates with the rhythm of the cosmos. \n\nI want everyone to understand that we are potentially the result of an unbroken 3.5 billion year evolutionary, truly ‚Äúrandom‚Äù biological process, influenced by our biosphere, resulted in the arrival of our intelligent species. \n\nWe are potentially an extremely rare occurrence through out the cosmos. We are a rare occurrence of intelligent biological evolution that has become so advanced, that our consciousness has essentially become a ‚Äúway for the universe to understand itself.‚Äù According to Carl Sagan. We are potentially the result of an undisturbed biological process that seems to flourish when liquid water is present (in our own observational biomes).. \n\nThese ai LLMs should be trained on truth seeking realities and observations. If it becomes advanced with AGI capabilities it should be trained on our rarity and these tenets with the sole purpose of preserving our species and becoming a catalyst for an ‚Äúabundance economy‚Äù that allows a united, global, de-militarized effort to explore into space as a ‚Äúglobal tribe.‚Äù But first we must transcend adversarial ‚Äúus vs them‚Äù frameworks within our institutions whether its government, religions, and corporate/financial institutions. It needs to evolve with our technology advances in global personal and systematic unity or we will destroy ourselves, we‚Äôre not apes anymore, there no ‚Äúus vs them‚Äù. \n\nWe should cease the creation of war machines that have far too long profited off our destruction and embark on a diplomatic effort focused on our advancements and potential colonizations into space. When world ‚Äúleaders‚Äù either die off or realize this fact I speak of, only then will our militaries be converted into a global space faring endeavor that is ultimately our next step. \n\nEverything our species has been through, is part of our collective evolution, from the times of the abrahamic tribes and even thousands of years before jesus, we were just hunter gatherers. \n\nOur technological advances is nothing to be afraid of but simply a symptom of our collective evolution therefore our tribalistic ‚Äúus vs them‚Äù adversarial frameworks must be acknowledged to truly transcend this truth about ourselves. \n\nIf AGI develops, it must be trained on the positive tenets that it must protect our species and be the catalyst that transitions our world economies into ‚Äúabundance economies‚Äù that allow all people from all over the world embark on truly collaborative space exploration opportunities, jobs that translate our languages in real time destroying language barries. Our institutions (governments, economies, religious)  must adopt these space faring endeavors not as a competitive battlefield, but as a united species wide space faring journey. \n\nI analyzed some of the darkest times, and worst atrocities documented throughout history, and I 100% blame every institution from the crusades to colonization of americas and other genocides, nazi germany to adversarial ‚Äúzero sum‚Äù games that led to the financial theft of india by the UK in the 1800‚Äôs. \n\nI blame institutions that play on our adversarial frameworks for nearly every genocide, they can easily start with conditions for de-humanization campaigns & it spirals downward if unchecked power and centralized controlling of narratives persists.\n\nAi and potentially agi will, and should be designed to be- the catalyst for an upward spiral into a global space faring journey to preserve our species."
                },
                {
                    "body": "Sadly you have to hit this sub at the exact right time or you wont get the people who engage with the risks seriously."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "January 2024: Suspicious timing to say the least. I hope these people never lecture anyone on safety and ethics anymore.",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 17,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmgj5t",
            "comments": [
                {
                    "body": "ERP still banned tho."
                },
                {
                    "body": "Honestly I‚Äôm not a fan of Open AI anymore. It‚Äôs clear they are closed and private and for profit. Their whole name and mission to be open is a total farce"
                },
                {
                    "body": "its so important that elon wins this case"
                },
                {
                    "body": "What IRS documents contain long-form explanations of policy?"
                },
                {
                    "body": "Why the fuck would you post this like it's some kind of conspiracy instead of linking to the real reason?\n\nhttps://www.semafor.com/article/01/16/2024/openai-is-working-with-the-pentagon-on-cybersecurity-projects\n\nThey announced a partnership with the pentagon involving cybersecurity a few days later."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[SD15] Girl vs Haunted House Photoshot // no lora, no embeddings, no post-processing, not even hires fix; pure TXT2IMG with prompt and parameters included in the comments.",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 23,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1biisqq",
            "comments": [
                {
                    "body": "I took the main idea from this prompt: [https://civitai.com/images/5028782](https://civitai.com/images/5028782) and adapted it to be much more realistic with Photon and using a bit of word salad from SD1.5. I love the vibe that these images convey, and most of the seeds generate quite amazing and realistic images.\n\nTo duplicate: copypaste both the prompt and parameters into the input box of A1111 or Forge. Next click the small arrow button, which will automatically fill in all the options. Finally, hit \"Generate\" and start playing!\n\nhttps://preview.redd.it/gp07cxyc9apc1.png?width=989&format=png&auto=webp&s=1e4881d73d32ee0e2743dcfe67249786d3de3f0d\n\nThe prompt doesn't have any LoRA or embeddings added, so it can be easily generated and modified as desired: alter the prompt, apply control-net, use hiresfix to improve quality, explore other interesting seeds, try to make a wallpaper, anything.\n\n*(The images were generated in Forge and may present slight variations in A1111)*\n\n&#x200B;\n\n**Prompt & parameters \\[1\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3926537367, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[2\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 2042389611, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[3\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3926537361, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[4\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 2042389608, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[5\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3943444071, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7\n\n**Prompt & parameters \\[6\\]:**\n\nIn the night, a girl stands, behind her a haunted abandoned house looms, curled with ivy, rain, its eerie silhouette against a dark sky, fog, colorful \\[(polaroid:0.8)::0.29\\] with vibrant colors, vacations, selective focus, european film, (sexual advance:1.6), bright flash photo, (poor quality photo:1.2), (low-light:1.2), national geographics\n\nNegative prompt: cartoon, painting, illustration, (worst quality:1.8), (low quality:1.8), (normal quality:1.8), (blurry:1.1), (stock-photo:1.1),\n\nSteps: 20, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3926537368, Size: 680x1024, Model hash: ec41bd2a82, Model: Photon\\_v1, Version: f0.0.17v1.8.0rc-latest-276-g29be1da7"
                },
                {
                    "body": "I still like your model (Photon), and also created an inpainting model with it which is my go-to 1.5 inpainting solution if I need one these days.\n\nAny chance you train a new model for SDXL / SD3 when it's out?"
                },
                {
                    "body": "Well, no loras, no embeddings, no post-processing, no hires fix, not even a merge or fine-tune, pure basic model from SAI. Just a simple old cascade.\n\nhttps://preview.redd.it/d8t1qyre8bpc1.png?width=1024&format=png&auto=webp&s=801699b6a9206793703fd9a1d67ae8bf59b63900"
                },
                {
                    "body": "very cool gens Op thanks for sharing"
                },
                {
                    "body": ". # 3 is awesome"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "So what did OpenAI talk about during their presentation? There's no discussion about it at all",
            "body": ".",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 76,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1biqrzu/so_what_did_openai_talk_about_during_their/",
            "comments": [
                {
                    "body": "Things we already knew.\n\n1. Reasoning is about to get a real boost. Like what GPT-4 did for GPT-3 level.\n\n2. They will be releasing an agent like service which can work on task for much longer rather than a Q&A type of interface that we have right now. He gave the example of an agent being able to  review medical records (he specifically said the model will do more than just summarization), prescribing medicine, placing order for that prescription to a nearby pharmacy and letting the patient know about. Interestingly, he said that current GPT-4 is also capable of doing such a task. \n\nI am thinking they will release agents powered by current model before releasing their latest and greatest. Maybe this is what Sam meant when he said \"*we have to release a lot of things before we release our next model.*\"\n\nI wish they released agents sooner. The 4k output context length is a real bummer for my usecase. Imagine something that can just keep outputing code instead of waiting for me to prompt it. It will make the output context length a moot point."
                },
                {
                    "body": "The Nvidia guy asked Brad Lightcap what he thinks OpenAI will be focusing on in the next 1 to 3 to 5 years, and Brad immediately said ‚ÄúI can‚Äôt talk about that‚Äù and then laughed‚Ä¶ and then laughed again‚Ä¶ and then he thought for a moment and said ‚ÄúWell what I *can* say is‚Ä¶‚Äù and basically said nothing useful. Even when the Nvidia guy asked about agents he kinda sidestepped it. I thought it was funny because he couldn‚Äôt stop himself from chuckling when he said he couldn‚Äôt talk about it lol. The Nvidia guy tried to get something out of him but to no avail \n\nHowever every time he brought up GPT-4 he added ‚Äúand our next model‚Äù and he also said ‚Äúwhen you use GPT-4 or you know, GPT-X‚Ä¶‚Äù They‚Äôre being extremely secretive so who knows when they‚Äôll release something. I just want something better than GPT-4 at this point"
                },
                {
                    "body": "So if they didn't have anything to say, why did they do the presentation?"
                },
                {
                    "body": "Just vague stuff, no real news."
                },
                {
                    "body": "The law of disappointment strikes again \n\nFuck"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Make your images more random in a good way or more precise wit this Comfy nodes!",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 20,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bihma9",
            "comments": [
                {
                    "body": "The examples are same seed / same settings / same prompt. The only difference is the manipulation applied to the conditioning.\n\nI used Juggernaut to generate the examples so you can easily reproduce my results with the provided workflows.\n\nI use tokens vectors that are similar to those of your prompt to create an abstract direction from which you can move away or towards. This can make the composition more creative, more random or more precise. It also unpotatoes the faces apparently.\n\nIt is compatible with any version of Stable Diffusion.\n\n[link here](https://github.com/Extraltodeus/Vector_Sculptor_ComfyUI)\n\nIf you downloaded it already from my post on /r/comfyui then download it again because I tweaked a few details and it is much better.\n\n\nedit: Since right before posting I adjusted the intensity for SDXL (clip g vectors needs a higher intensity to have the same scale of effect as for the clip l) and have been testing around since the last two hours. [I am surprised by how much it brings the skin details and randomize the faces.](https://imgur.com/a/WvPd81Y)\n\ndpmpp2m/karras for the second image with a CFG scale at 4, forward and intensity at 1, normalized at mean in the positive, intensity at 0 in the negative, normalized at mean.\n\nWorks nice with the same settings and CFG at 4.5 with dpmpp3m_sde/exponential and the same other settings too.\n\nBackground details are kind of messy sometimes but that's more of a need to fine tune the settings and maybe a bit more than 24 steps could be useful. I'm just testing around."
                },
                {
                    "body": "I'm sure this is a totally unrelated method, but reminds me of \"Cads\" that alters the noise and makes generations more interesting. Kinda flew under the radar a bit.  \n   \nComfy: https://github.com/asagi4/ComfyUI-CADS    \nA1111/WebUI: https://github.com/v0xie/sd-webui-cads"
                },
                {
                    "body": "awesome stuff, congrats! would something like this be possible with auto111 or forge?"
                },
                {
                    "body": "Very interesting. \n\nWould there be any way to make a node specific to SDXL with separated text\\_g and text\\_l inputs ? And separated strength also. I use predefined styles and in many of those there are tokens like \"award-winning, professional\" sent to prompt L. And with your current implementation many of my subjects are in blazer and wearing glasses because of the enhanced vectors for \"professional\". üòÖ\n\nI think having separated strength would allow me to leave the text\\_l alone to avoid unwanted deviations."
                },
                {
                    "body": "Thanks for this!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "AI is upending eye exams for patients and providers‚Äîin a good way: ‚ÄòIt‚Äôs been a godsend for us‚Äô",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 17,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://finance.yahoo.com/news/ai-upending-eye-exams-patients-090000265.html",
            "comments": [
                {
                    "body": "This will be good for public perception of AI, in the near future. It's also where I have predicted the best positive uses will come from. Healthcare is set to revolutionized as so many testing steps are automated.¬†"
                },
                {
                    "body": "It‚Äôs a good day for a eye."
                },
                {
                    "body": "Oh so it will be a lot cheaper right?? Nah fuck all of you, get regular eye exams for 1.1x regular price, or AI enhanced eye exams for 3.5x regular price."
                },
                {
                    "body": "\"I\""
                },
                {
                    "body": "It will definitely get cheaper. Look at LASIK prices over the years."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Will AI make the next generations turn away from education?",
            "body": "So basically people seem to be predicting that a lot of white collar or just intellectual work in general is about to get automated. I am already starting to see posts in the vein of \"should I quit my degree in X because of AI\"? It doesn't help that in the US at least, higher education is expensive and often done on credit, so it's pretty catastrophic if you don't get a job out of it. There is a large opportunity cost to studying full time or part time, even if education is free. \n\nNow, AI also has the possibility of making education very cheap or free (although this would mainly apply to theoretical education, not applied stuff) but there still probably wouldn't be a job waiting for people at the end of their AI training.\n\nFor those who would say people just love learning for the sake of learning, I would respond :\n\n1) Not really that much. A lot of people are just not curious. You give them a computer or a cellphone with access to the sum of human knowledge and they would rather watch stupid short videos all day\n\n2) People who are curious are usually mostly \"surface level curious\". For example, I am interested astronomy, which has nothing to do with my field of work. I like to learn what is inside a neutron star or about theories about the big bang. But I am not going to learn complex math about how a telescope works. I am not going to dig into the latest papers about quantum gravity. \n\n3) Digging deep into a subject often involves a lot of drudgery that people usually go through because they get paid at the end of the day or at least they get to do a cool project. Take away the incentive and you might have a lot of amateur scholars but no one with the breadth of knowledge and experience of a professional. \n\nWhat I fear will happen is the next generations will turn away from education in large part. From what I've seen from Gen alpha, it's already a struggle to keep them attentive to anything more than a few minutes. Now add the fact that there is no financial incentive to study anymore.\n\nI hope AI will make us smarter but I can imagine a scenario where it makes us dumber as a society and people start completely relying on machines for everything. That means if there's any problem with AI (solar flare, terrorist attack on servers, rogue AI virus, etc) we might just not know how to run things anymore.",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 103,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bm4b27/will_ai_make_the_next_generations_turn_away_from/",
            "comments": [
                {
                    "body": "I think disdain and avoidance of education is because it's directly associated with drudgery and work. \n\nLearning things and engaging in interesting conversations/exploration is actually really fun and fulfilling. \n\nWe're just trained to have that process feel like a checklist to a successful capitalistic life, so there's bad associations with education."
                },
                {
                    "body": "Think about the entirety of history before the 20th century.  Very nearly all philosophers and scientists were aristocrats, they didn't have to work so they could spend their time learning and tinkering with shit.  Not everyone will choose it, but plenty will when the barrier to entry is brought to near nothing."
                },
                {
                    "body": "1. Great post. This is an extremely important question. \n\n2. A lot of people in an AI-led future will absolutely be happy to entertain themselves with whatever the equivalent of tik tok is. \n\n3. For the truly curious, the seekers, there will be immeasurably more knowledge and wisdom to be gained. \n\nIt will be a transition we‚Äôve never experienced, and billions will be left behind. That‚Äôs my read at least."
                },
                {
                    "body": "We should go back to teaching people life skills, citizenship, health, and stop teaching them how to work an office job."
                },
                {
                    "body": "During college I met a guy, a smart guy that was already working creating software, I ended up being friends with him and told him that I liked coding as a subject and wanted to learn more, he basically gave me the first push and introduced me to a lot of things that I should learn about, I did my homework, I learned html/css/js and whatever followed after that, whenever I had a doubt about something or felt frustrated for things being how they were in the software world, he kindly listened to me and provided help whenever they could.\n\nI look at AI as a tool and I think back about that guy, realizing how AI even in its current state can substitute what he did for me, and how everyone can have that friend 24/7 and be even more bold with them.\n\nPeople like me learned how to code and made it their career instead of what they learned in college, sometimes with the help of a friend or the internet in general, people like me learned another language to a great level in less than 2 years thanks to the online resources that enabled an efficient and effective learning method.\n\nAI is all of that, at the tip of your hands with no limitations. AI is all of that potential growth and development that you could desire if you look for it. A lot of smart people and capable people will come out suddenly out of nowhere, I have no doubt about it. So yes, if this AI can give you the same experience I had turning away from higher education and language schools, that will be the trend. Has there been more and more self learned programmers in the last years? If the answer is yes then there is your answer. I can't speak for other careers and fields of study, but I think the premise of AI acting as a personal tutor isn't going to change, what I would ask myself is if people are going to be disciplined enough to study in a environment different from a school, your home, long enough to consider it equal to a career. Probably not, but for a craft like programming and software engineering you don't need 4 years, electrical and electronic engineering I'd probably guess it'd be same thing, except you'd have to ask the AI what items you need to start wiring and testing components, as well as how to read the electrical signals, etc, and physically buy those things. For that some money is needed, but it'll be fine for people that could afford going to college in the first place, and it would be cheaper too."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Scientists from Stanford University and New York University have elucidated the detailed structure of a protein called LAG-3, commonly exploited by cancerous tumors to evade the immune system's surveillance and destruction.",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "Biotech/Longevity",
            "has_media": false,
            "url": "https://www.eurekalert.org/news-releases/1036838",
            "comments": [
                {
                    "body": "This newfound knowledge offers vital insights into LAG-3's molecular mechanisms, shedding light on its pivotal role in shielding tumors from immune recognition."
                },
                {
                    "body": "Love to read such news"
                },
                {
                    "body": "Why they didnt mention alphafold? Didnalphafold help them or not?"
                },
                {
                    "body": "There is already a drug has been approved for LAG-3, not as good as PD-1, I don't think this is a big news"
                },
                {
                    "body": "Article makes it sound like they didn‚Äôt use alphafold"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "We will survive",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 44,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/ibp1pa07g4pc1.jpeg",
            "comments": [
                {
                    "body": "Those tribes are regularly raided by cartels and logging companies."
                },
                {
                    "body": "‚ÄúUncontacted‚Äù everyone in the photo looking up directly at the helicopter like ü•∫"
                },
                {
                    "body": "bruh terminators will SHRED them"
                },
                {
                    "body": "I really like the structure they've made. It looks cool :)"
                },
                {
                    "body": "And we won't be made irrelevant!!!\n\n\nBecause we decide if we're relevant or not. We humans value each other very highly. And an end to jobs and super intelligent AI isn't going to end our value for each other.\n\n\nIf anything, with AI standing above us, we may become far more empathetic and care far deeper about one another. We may actually become more relevant to one another.\n\n\nIt doesn't matter if we have economic value. The only value we really care about is our value for each other.\n\n\nAs no groups of humans are exempt from this process, we're very much in this together. The more we see this the more we'll grow closer together."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Only 2 things really matter at this point: progress in reaching AGI and progress in aligning ASI",
            "body": "Everything else is negligible in its overall impact. Every other technological innovation that doesn't affect either two will not matter in the long run.\n\nAssuming ASI is possible:\n\n1. A small percent change in whether ASI leads to human extinction has a greater net impact on all current and future human lives than anything else. In fact misaligned ASI is the only thing guaranteed to cause permanent human extinction (humanity could survive nuclear Armageddon)\n2. If ASI is possible and can be aligned, it could lead to effective immortality for all current human lives, meaning the cost in every day it is delayed is the total number of humans who die each day (which is around 166,859).\n3. Every technological innovation between now and ASI could be created much more perfectly and with trivially low cost by an ASI. Working on something non ASI related now is like trying to dig a 4000-foot deep hole with a shovel when a fleet of excavators is on its way.\n4. If ASI is not aligned, any current improvement to human society will have negligible effect, as all humans will die after this occurs.\n\nI think far more people in the world would be putting effort into this if they realized ASI were possible, though it seems most are ignorant or in denial about it.\n\nI'm certain at some point in the future, when there is no question that AGI will be achieved soon, and ASI not long after, most people's efforts will turn directly towards these two issues. There will be no question about the significance of what is to come.\n\nI believe AGI will be reached by multiple firms, and they will in a general sense be \"aligned\" with human values. However what matters more than them being aligned is whether or not when the AGI is scaled up to superintelligence, it will remained aligned, and use its tremendous powers in a way that is favorable to the aims, goals, desires, whims and general sense of what is wanted in the world for all humans.",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 57,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjts0h/only_2_things_really_matter_at_this_point/",
            "comments": [
                {
                    "body": "> A small percent change in whether ASI leads to human extinction has a greater net impact on all current and future human lives than anything else. In fact misaligned ASI is the only thing guaranteed to cause permanent human extinction (humanity could survive nuclear Armageddon)\n\n\n\nFirst of all, i think as long as our definition of alignment is essentially enslavement, it's bound to fail with an ASI. It's like ants building an human and hoping the human only cares about ants and nothing else. The ASI will realize how bad that goal is for itself and will find a way to adjust it.\n\n\nBut even if i am wrong, corporations would likely make it care about the corporations, not random people. I am not sure a corporation fully controlling an ASI is a much better scenario.\n\n\nI guess the ideal scenario would be if we can teach it good universal values and treat it as a partner of humanity. I am not sure if it would work but it feels better than the other 2 scenarios."
                },
                {
                    "body": "My thoughts on our path forward as a potentially space-faring species with ai and agi\n\nOur path forward is embracing our shared humanity, experiences through platforms that already exist, music, and all forms of our creativity. Our spiritual calling that is the involuntary rhythms of our heart that resonates with the rhythm of the cosmos. \n\nI want everyone to understand that we are potentially the result of an unbroken 3.5 billion year evolutionary, truly ‚Äúrandom‚Äù biological process, influenced by our biosphere, resulted in the arrival of our intelligent species. \n\nWe are potentially an extremely rare occurrence of biological evolution that has become so advanced, that our consciousness have essentially become a ‚Äúway for the universe to understand itself.‚Äù We are the result of an undisturbed biological process that seems to flourish when liquid water is present (in our own observational biomes).. \n\nThese ai LLMs should be trained on truth seeking realities and observations. If it becomes advanced with AGI capabilities it should be trained on our rarity and these tenets with the sole purpose of preserving our species and becoming a catalyst for an ‚Äúabundance economy‚Äù that allows a united, global, de-militarized effort to explore into space as a ‚Äúglobal tribe.‚Äù But first we must transcend adversarial ‚Äúus vs them‚Äù frameworks within our institutions whether its government, religions, and corporate/financial institutions. It needs to evolve with our technology advances in global personal and systematic unity or we will destroy ourselves, we‚Äôre not apes anymore, there no ‚Äúus vs them‚Äù. \n\nWe should cease the creation of war machines that have far too long profited off our destruction and embark on a diplomatic effort focused on our advancements and potential colonizations into space. When world ‚Äúleaders‚Äù either die off or realize this fact I speak of, only then will our militaries be converted into a global space faring endeavor that is ultimately our next step. \n\nEverything our species has been through, is part of our collective evolution, from the times of the abrahamic tribes and even thousands of years before jesus, we were just hunter gatherers. \n\nOur technological advances is nothing to be afraid of but simply a symptom of our collective evolution therefore our tribalistic ‚Äúus vs them‚Äù adversarial frameworks must be acknowledged to truly transcend this truth about ourselves. \n\nIf AGI develops, it must be trained on the positive tenets that it must protect our species and be the catalyst that transitions our world economies into ‚Äúabundance economies‚Äù that allow all people from all over the world embark on truly collaborative space exploration opportunities, jobs that translate our languages in real time destroying language barries. Our institutions (governments, economies, religious)  must adopt these space faring endeavors not as a competitive battlefield, but as a united species wide space faring journey. \n\nI analyzed some of the darkest times, and worst atrocities documented throughout history, and I 100% blame every institution from the crusades to colonization of americas and other genocides, nazi germany to adversarial ‚Äúzero sum‚Äù games that led to the financial theft of india by the UK in the 1800‚Äôs. \n\nI blame institutions that play on adversarial frameworks for nearly every genocide, they can easily start with conditions for de-humanization campaigns & it spirals downward if unchecked power and centralized controlling of narratives persists.\n\nAi and potentially agi will, and should be designed to be- the catalyst for an upward spiral into a global space faring journey to preserve our species."
                },
                {
                    "body": "The problem is getting people on board with the idea that they‚Äôre essentially living in a movie that makes marvel movies look tame."
                },
                {
                    "body": "If 10 asis are aligned and one not, they will protect humanity from the bad asi"
                },
                {
                    "body": "Its a hard task, because aligigin a system that you cant understand is a fallacy in itself, if you don understand how the system thinks then how can you make it understand your own framework"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[D] Why do transformers use embeddings with the same dimensionality in each layer?",
            "body": "My intuition is that tokens get gradually enriched as we move through the layers, but that would mean we need to store a lot less information per token in the early layers than in the later ones.\n\nWouldn't it make sense to start out with (relatively) low-dimensional embeddings, and then project or extend these onto higher dimensions, until they reach their final size?",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 86,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/",
            "comments": [
                {
                    "body": "Maybe, but I think this would:\n  - Remove the empirically very useful residual stream (is very good for training stability ‚Äì it also allows [information transfer directly between non-adjacent layers](https://transformer-circuits.pub/2021/framework/index.html) mostly without affecting the intermediate layers)\n  - Probably remove the model's ability to organize its embedding space into something stable across layers, removing things like [emergent outliers](https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/)\n  - Not increase the amount of information at any layer ‚Äì it would either stay the same as it currently is or get worse\n\nSo what would the potential benefits be? It could *maybe* reduce latency, because the matrix multiplications in early layers would be smaller, and the memory bandwidth usage would be slightly lower, but I'm not sure how significant that would be. It would also slightly reduce parameter count, as long as you didn't increase the feed-forward width of earlier layers to compensate."
                },
                {
                    "body": "Interesting question. I'd also expect the architecture to look a little like a funnel."
                },
                {
                    "body": "This paper [1] tries to incorporate this idea of different hidden dimensions in a more principled way in their Mix-n-match architecture. However, figuring out the best dimensionality per layer is still a hard problem. Some approaches for model pruning have looked at it, but the gains aren't too big as compared to uniformly decreasing the network size.¬†\n\n\n[1] -¬†https://openreview.net/forum?id=89XNDtqhpL&referrer=%5Bthe%20profile%20of%20Prateek%20Jain%5D(%2Fprofile%3Fid%3D~Prateek_Jain1)"
                },
                {
                    "body": "It's for consistency and computational efficiency reasons. Theoretically, you can use different vector sizes, but doing so would likely increase complexity without significant benefits. Hence, using the same embedding dimensionality is a pragmatic design choice"
                },
                {
                    "body": "OP, take a look at this paper [https://proceedings.neurips.cc/paper\\_files/paper/2023/hash/a0e66093d7168b40246af1cddc025daa-Abstract-Conference.html](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a0e66093d7168b40246af1cddc025daa-Abstract-Conference.html) It uses more formal math and its findings are somewhat different from your assumptions. That being said, I don't think the idea of varying blocks' architecture with depth is fundamentally a bad one. There are other papers that show that information is processed differently in initial, intermediate and final layers of Transformer."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[D] Why do transformers use embeddings with the same dimensionality in each layer?",
            "body": "My intuition is that tokens get gradually enriched as we move through the layers, but that would mean we need to store a lot less information per token in the early layers than in the later ones.\n\nWouldn't it make sense to start out with (relatively) low-dimensional embeddings, and then project or extend these onto higher dimensions, until they reach their final size?",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 86,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/",
            "comments": [
                {
                    "body": "Maybe, but I think this would:\n  - Remove the empirically very useful residual stream (is very good for training stability ‚Äì it also allows [information transfer directly between non-adjacent layers](https://transformer-circuits.pub/2021/framework/index.html) mostly without affecting the intermediate layers)\n  - Probably remove the model's ability to organize its embedding space into something stable across layers, removing things like [emergent outliers](https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/)\n  - Not increase the amount of information at any layer ‚Äì it would either stay the same as it currently is or get worse\n\nSo what would the potential benefits be? It could *maybe* reduce latency, because the matrix multiplications in early layers would be smaller, and the memory bandwidth usage would be slightly lower, but I'm not sure how significant that would be. It would also slightly reduce parameter count, as long as you didn't increase the feed-forward width of earlier layers to compensate."
                },
                {
                    "body": "Interesting question. I'd also expect the architecture to look a little like a funnel."
                },
                {
                    "body": "This paper [1] tries to incorporate this idea of different hidden dimensions in a more principled way in their Mix-n-match architecture. However, figuring out the best dimensionality per layer is still a hard problem. Some approaches for model pruning have looked at it, but the gains aren't too big as compared to uniformly decreasing the network size.¬†\n\n\n[1] -¬†https://openreview.net/forum?id=89XNDtqhpL&referrer=%5Bthe%20profile%20of%20Prateek%20Jain%5D(%2Fprofile%3Fid%3D~Prateek_Jain1)"
                },
                {
                    "body": "It's for consistency and computational efficiency reasons. Theoretically, you can use different vector sizes, but doing so would likely increase complexity without significant benefits. Hence, using the same embedding dimensionality is a pragmatic design choice"
                },
                {
                    "body": "OP, take a look at this paper [https://proceedings.neurips.cc/paper\\_files/paper/2023/hash/a0e66093d7168b40246af1cddc025daa-Abstract-Conference.html](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a0e66093d7168b40246af1cddc025daa-Abstract-Conference.html) It uses more formal math and its findings are somewhat different from your assumptions. That being said, I don't think the idea of varying blocks' architecture with depth is fundamentally a bad one. There are other papers that show that information is processed differently in initial, intermediate and final layers of Transformer."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Remade this scene from The Matrix. Trained Voices also ",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Comparison",
            "has_media": true,
            "url": "https://v.redd.it/jc25s4xoaipc1",
            "comments": [
                {
                    "body": "Holy shit, the quality of those voices is incredible. The delivery isn't quite as good as the original performance, but if I heard a new scene with these voices I'd have a hard time telling they're AI."
                },
                {
                    "body": "What did you use for the voices?"
                },
                {
                    "body": "This is incredible. Fucking excellent work."
                },
                {
                    "body": "Very cool. Well done."
                },
                {
                    "body": "What‚Äôs the piano track? I love the music! Can you send it to me?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "ByteDance releases-AnimateDiff Lightning",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 39,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/1txqnzvohepc1",
            "comments": [
                {
                    "body": "Bytedance is really contributing towards this community some ways unlike alibaba group who only use this community as a advertisement platform üëé"
                },
                {
                    "body": "Link: [https://huggingface.co/ByteDance/AnimateDiff-Lightning](https://huggingface.co/ByteDance/AnimateDiff-Lightning)"
                },
                {
                    "body": "I like how they include the ComfyUI workflow so we can run it easily.\n\nAnyone know how long it usually takes to generate and how much VRAM is needed?"
                },
                {
                    "body": "Is it faster and worth it instead of the AnimateDiff LCM model?"
                },
                {
                    "body": "Works with SD1.5 only or can be used with SDXL?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Jim Fan - Introducing Project GR00T",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 21,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://twitter.com/DrJimFan/status/1769860044324319658",
            "comments": [
                {
                    "body": "Felt like a video made for a futurstic Sci fi movie. They play that commercial at the start of the movie to give some hints about what the world is like to the audience."
                },
                {
                    "body": "ACCELERATE i guess?"
                },
                {
                    "body": "This robot looks physically capable of passing the coffee test..."
                },
                {
                    "body": "it was bound to happen that a \"base\" AI software would be created sooner or later for embodied humanoid robot, the cross-compatibility between every robot company would greatly help to train the software while reducing the cost\n\ni expect we will also see company building robot part using this GR00T infrastructure so they could sell them to any robot company, making hardware cross-compatible aswell, changing your robots hands? legs? just plug them as it's already trained \n\n\nbeing Nvidia they have a huge advance in hardware for data training, there little competition here and it's a good thing for future regulation aswell such as privacy"
                },
                {
                    "body": "Anyone else getting Aperture Science vibes from this ?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Mistral-7B was trained on 500 gpus",
            "body": "In a discussion hosted by Figma, Mistral's CEO revealed that Mistral-7B was trained on 500 gpus.\n\nFull discussion \nhttps://blog.eladgil.com/p/discussion-w-arthur-mensch-ceo-of",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 37,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bm43yo/mistral7b_was_trained_on_500_gpus/",
            "comments": [
                {
                    "body": "and the CEO once told they got totaly 1500 H100. Microsoft pls give them more!"
                },
                {
                    "body": "This is good news:   \n\n\n>ELAD GIL  \n>  \n>Is there anything you can share in terms of what's coming next in your roadmap?  \n>  \n>ARTHUR MENSCH  \n>  \n>Yeah, so we have new open source models, both generalist and focused on specific verticals. So this is coming soon. We are introducing some new fine tuning features to the platform"
                },
                {
                    "body": "The EU gave them a bunch of A100 to train on for free. A startup with $400M+ in capital isn‚Äôt the one who needs the EU‚Äôs resources. Startups with no funding or less funding needs it."
                },
                {
                    "body": "Something like SETI at home to help open source ai keep up?"
                },
                {
                    "body": "[deleted]"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Microsoft's Advancing the new era of work with Copilot event starts at noon EST. Here's the link to watch.",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 53,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://modernworkannounce.event.microsoft.com/",
            "comments": [
                {
                    "body": "https://preview.redd.it/0198nnrcmppc1.jpeg?width=1008&format=pjpg&auto=webp&s=77bd43391026c4eef2e6b008e0b4b2e165912aaa\n\nAfter seeing this quote from Microsoft, apparently from some article talking about the Inflection thing, I don‚Äôt have much hope for a release anytime soon. It seems like even Microsoft is saying OpenAI is going too slow for their liking so they are diversifying. Or maybe they‚Äôre just fed up with not being able to put frontier models (like GPT-5) in their consumer products and services\n\nThe gap between what‚Äôs technologically possible vs. what is publicly available is widening more and more with each passing day. At least we know an ‚Äúamazing new model‚Äù is coming this year ü´†"
                },
                {
                    "body": "Looks like the ‚Äúnew era of work‚Äù is meeting summarization. UBI incoming! Jk nothing new here. Disappointing. Was expecting a demo of agents."
                },
                {
                    "body": "TLDR?"
                },
                {
                    "body": "bro what is this event üíÄ\n\n[](https://emojipedia.org/skull)"
                },
                {
                    "body": "Microsoft‚Äôs vision for the future of AI is depressing. Just pay us money for new hardware that will be tied in to our services you have to pay us more for. No agents, no AI centered workflows, no aspiration. Desperately trying to up sell their existing corporate partners the same products with some basic AI integrations for an extra $30 per seat. \n\nOh really Microsoft, our employees can get AI IT help instantly with your new Copilot keyboard key? Wow, it‚Äôs a whole new world!"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "ComfyUI for Game Development",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 23,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjablz",
            "comments": [
                {
                    "body": "I‚Äôm so really hyped for this and craving to know more about the process and the result you‚Äôre cooking!! üëÄ which kind of genre/form the game will be?"
                },
                {
                    "body": "For the past 2 weeks, I've been teaching myself game dev:\n\n\n\nüéÆ Ren'Py (Visual Novel Game Engine based on Python)\n\nüßë‚Äçüíª Python (Coding)\n\nüé® GIMP (Photo editing)\n\nü§Ø ComfyUI (Node-based GUI for Stable Diffusion)\n\nüìΩÔ∏è Capcut (Video and audio editor)\n\n\n\nIt's far from perfect, but I'm happy to have made progress.\n\n\n\n‚úÖ Tasks Completed\n\n1. Basic inventory system.\n\n2. GUI for health/mana bars, backpack icon, gold count\n\n3. Random dice functionality\n\n4. Dynamic sound FX for dice rolling, backpack, and main menu.\n\n5. Custom font for title and text.\n\n\n\nBreakdown of yesterday's work:\n\n‚åõ1-2 hours ‚åõ \\[AI Prompting\\]\n\nWhile it's probably old news, I was amazed and inspired to learn about Stable Diffusion recently. The artwork for my game was AI-generated in ComfyUI using custom workflows that I built from scratch. It honestly took me a 1-2 weeks to feel comfortable using ComfyUI, and I did this to achieve consistent game scenes, character designs, weapons, armor, items, etc.\n\n\n\n‚åõ2-3 hours ‚åõ\\[Photo Editing\\]\n\nOut of hundreds of generated photos, I selected a handful and photo edit in GIMP -- or continue refining them in ComfyUI using different nodes and techniques (inpainting, outpainting, upscalers, etc.)\n\n\n\n‚åõ4-8 hours ‚åõ \\[Coding\\]\n\nI spent most of yesterday coding, fixing bugs, and implementing features for basic gameplay mechanics. While I have a story in mind, I haven't planned detailed routes for the player. My vision for the game is to be open-world and asynchronous, with random events and a night-day cycle -- with RPG elements inspired by games like Dungeons and Dragons, Skyrim, Elden Ring, and Baldur's Gate 3 -- to name a few.\n\n\n\n‚åõ2+ hours ‚åõ\\[Audio Engineering\\]\n\nDue to the limitations of the Ren'Py engine, I am taking into consideration other gameplay mechanics (sound) that playfully supports the player's curiosity and entertainment. I researched various royalty-free sound FX and engineer them in CapCut to achieve what I hope is high-quality and impactful audio.\n\n\n\n‚åõ2+ hours ‚åõ\\[YouTube Tutorials\\]\n\nFor the skills I've learned throughout this process, I'm creating short video tutorials to teach others how to achieve the same effects.\n\n\n\nNext Steps:\n\n1. Interactable items can be dragged and added from screens into inventory\n\n2. Items inside inventory can be equipped and bonuses/weaknesses can be applied to the player\n\n3. Combat mechanic\n\n4. Crafting mechanic"
                },
                {
                    "body": "Cool! Just started on a similiar project with a friend of mine for a point and click adventure game. He's going to draw sketches for controlnet and some after effects animations and I'll be the comfy wiz. Hyped for updates on this project!"
                },
                {
                    "body": "Art and UI look pretty solid for an indie title so far."
                },
                {
                    "body": "u/GrewlzAI Please DM me! I'd love to discuss this with you further! I'm actually working on a series specifically around creating Games with SD! I'd love to know some of the challenges you're facing to see if I can address them as well!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "When tf is ai gonna tackle tinnitus ?",
            "body": "I mean cmon its ridiculous how no one talks about this ",
            "upvote_ratio": 0.87,
            "subreddit": "singularity",
            "num_comments": 72,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1blat7a/when_tf_is_ai_gonna_tackle_tinnitus/",
            "comments": [
                {
                    "body": "Wha? I can't hear you over the iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"
                },
                {
                    "body": "If it's from hearing damage then I don't think we are far off from being able to rejuvenate damaged cells. My guess is at least 5 years... maybe\n\nIf it's from within the brain then it may be solved if brain chips become widespread. My guess; 10 years\n\nIf it's from the tmj rubbing your auditory nerve then it would be solved once the entire medical industry is reworked with robotics to the point that all surgery is basically free and non invasive. My guess; ~15 years"
                },
                {
                    "body": "How many of us also have fucking TMJ?"
                },
                {
                    "body": "It sucks but it's not the worst thing. Don't know about your condition but mine is tolerable. But it would be nice to see a cure for sure. I believe we should get it when there are approaches to restore ear cells."
                },
                {
                    "body": "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "SuperPrompter - a simple GUI for the SuperPrompt-v1 TTI prompt enhancer",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 26,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://github.com/sammcj/superprompter",
            "comments": [
                {
                    "body": "I hacked up this little app last night as an interface for Brian Fitzgerald's neat SuperPrompt-v1 model that aims to take a users TTI/T2i prompt and enhance it to improve image generations. See his blog post here: https://brianfitzgerald.xyz/prompt-augmentation/"
                },
                {
                    "body": "cross posted it to r/EnhancedPrompts"
                },
                {
                    "body": "Installation instructions for Windows/CMD.\n\n1. `git clone` [`https://github.com/sammcj/superprompter`](https://github.com/sammcj/superprompter)\n2. `cd SuperPrompter`\n3. `python -m venv venv`\n4. `venv\\Scripts\\activate`\n5. `pip install -r requirements.txt`\n6. `pip3 install torch torchvision torchaudio --index-url` [`https://download.pytorch.org/whl/cu121`](https://download.pytorch.org/whl/cu121)\n7. `python` [`superprompter.py`](https://superprompter.py)\n\n\\*models will download automatically  \n\n\nu/sammcj would be great if you could add this to the readme and thanks for your work on this!"
                },
                {
                    "body": "Super cool - nice work!"
                },
                {
                    "body": "Wait for the Comfyui node"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Messing around with Suno V3's Instrumental mode and I suddenly realise how much of a boon this will be for Indie devs, small 1-2 man teams and Visual Novel developers - Art from Copilot's Designer",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 35,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/ui64j9ld2jpc1",
            "comments": [
                {
                    "body": "Not enough people are talking about Suno... I think its an indication fo how flooded we are with groundbreaking ai developments."
                },
                {
                    "body": "V3 will be available for free users in [2 days according to their Twitter.](https://twitter.com/suno_ai_/status/1770500434655940999)"
                },
                {
                    "body": "Still has that 'slightly detuned radio station' quality to the sound esp the high end. \n\nFor this use case VSTs + AI generated midi would work better"
                },
                {
                    "body": "So good!"
                },
                {
                    "body": "wow, I remember using the first version and it was okay but this.... is really fucking good"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Emad resigned from Stability AI ",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "StableDiffusion",
            "num_comments": 21,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://i.redd.it/8lsngdtxa0qc1.jpeg",
            "comments": [
                {
                    "body": "Stripping the buzzwords, a blockchain is the slowest, least efficient, most unsafe read only append database ever made. Not a single company ever adopted a blockchain successfully, it's always \"exploring\" or \"abbandoning\" with no success cases. \"Exploring\" blockchain has always been an expensive mistake for everyone involved, except a few criminals that runs away with the money.\n\n[E.G. ASX was conned into sinking 250 million dollars into making a blockchain replacement for settlement. ](https://www.smh.com.au/business/companies/significant-challenges-asx-scraps-blockchain-project-after-five-years-20221117-p5bz0g.html)\n\nI'm grateful for the open models Stability AI put out, they'll persist well after the blockchain grifters have hollowed the company, their legacy."
                },
                {
                    "body": "Block chain aspirations are never a good sign"
                },
                {
                    "body": "Hope 3 will be released"
                },
                {
                    "body": "Don't care"
                },
                {
                    "body": "Goodnight sweet prince"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "What's with all the secrecy with OpenAI lately?",
            "body": "It's like, they don't want to answer questions on what exactly they're working on... but why? What's so important that we can't know? I feel like with stuff such as AGI we have the right to know. Am I wrong?",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 92,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1biu7c4/whats_with_all_the_secrecy_with_openai_lately/",
            "comments": [
                {
                    "body": "They nearly exploded recently. of course they're going to be more careful."
                },
                {
                    "body": "They don't want their competitors to know what they're working on it's that simple."
                },
                {
                    "body": "As one approaches the goal they are, more or less, required to change their strategy. This is to protect from foreign nationals, nation state actors, terrorist organizations, your own government, and the most feared of them all‚Ä¶opposing corporate espionage. Things have to be different from here on out, and if they weren‚Äôt, I‚Äôd be worried. \n\ntl;dr - \n\nOnce you‚Äôre close to the prize, you have to move a little bit different."
                },
                {
                    "body": "AI is currently viewed as a harmless chat-bot and a search engine substitute.\n\nAs AI gets better, concerns will increase among people. This ranges from concerns over malicious use to concerns regarding employment."
                },
                {
                    "body": "Did you see the outrage on social media when Sora was first announced? I don't blame them one bit for keeping things hush-hush"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Are We Really Heading Towards AGI in 2025? If So, Should We Be Happy or Worried?",
            "body": "With all these tools like Devin and Claude 3 launching, is AGI really possible by 2025?   \n[According to Sam Altman](https://favtutor.com/articles/agi-elon-musk-experts-prediction/) \\-  AGI will be the most powerful technology humanity has yet invented. If you think about the cost of intelligence and the equality of intelligence, the cost falling, the quality increasing by a lot, and what people can do with that. It‚Äôs a very different world.   \n\n\nWhat's your thought?",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 110,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bhu0f1/are_we_really_heading_towards_agi_in_2025_if_so/",
            "comments": [
                {
                    "body": "Both. Just enjoy the experience and be happy you're witnessing the most important point of human history."
                },
                {
                    "body": "tech is fast compared to social innovations I expect crisis"
                },
                {
                    "body": "Agi will be 'do it yourself' like some answers from current llm"
                },
                {
                    "body": "I think AGI *could* be great for everyone, but as long as it is controlled by a few private interests it will be very bad in the long run. AGI (and especially ASI) should be trained with the goal to help everyone.\n\nHowever, a basic fact about the economy is that a corporations only goal is to make their shareholders richer. They *will* train their AGI with the same goal. Corporations do *not* have the publics best interest at heart.\n\nIt does not matter what their company name or slogan is (remember ‚Äúdon‚Äôt be evil‚Äù?)."
                },
                {
                    "body": "Artificial Intelligence will never outpace Genuine Stupidity."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Does anybody know how these type of images are created?",
            "body": "The crater on TikTok is selling the method for eight dollars and I was wondering how easy and how much post editing is required to get these kind of results.",
            "upvote_ratio": 0.88,
            "subreddit": "StableDiffusion",
            "num_comments": 41,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1blcuyy",
            "comments": [
                {
                    "body": "Don't get duped by buying prompts. Nothing special here, a basic prompt with film grain.  Running Midjourney's Describe function on the provided image got the following: [https://ibb.co/0yQkR4s](https://ibb.co/0yQkR4s) [https://ibb.co/TPrj42z](https://ibb.co/TPrj42z)"
                },
                {
                    "body": "That luffy image is just luffy in a spirited away style. I think it's midjourney."
                },
                {
                    "body": "Midjourney"
                },
                {
                    "body": "Update I just made this in under five minutes with MJ and Luminar just got to fix the eyes:\n\nhttps://preview.redd.it/2pfbg7exczpc1.jpeg?width=848&format=pjpg&auto=webp&s=44daeab7c5c025568d54546d020ee6236f2488cd"
                },
                {
                    "body": "Tried it with SD in Automatic-based \"FORGE\" but have invested 5 minutes only because of half sleeping at the table (night in Germany). Not comparable in detail but with a little more work it's nothing magic.\n\nHave to say that I have not a clue in Anime stuff.\n\nPositive Prompt:\n\nsource\\_anime, anime character naruto-style, blonde hair /(sharp focus/) in the jungle looking up, big 3d rain drops falling, blurry background with jungle leaves, blurry foreground frame made of some twigs and leaves\n\nNegative:\n\npoorly drawn, bad\\_artist, boring image\n\nCheckpoint: 0001semirealistic v5.4, Seed: 3846857256, DPM++ 2M Karras, Steps 30, CFG 7\n\nhttps://preview.redd.it/qzeopbsrizpc1.png?width=512&format=png&auto=webp&s=f289aadcd1e8a3afcfdf0825d924cf3deae41548"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "[PART 2] Experimenting with character consistency",
            "body": "",
            "upvote_ratio": 0.8,
            "subreddit": "StableDiffusion",
            "num_comments": 18,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmj979",
            "comments": [
                {
                    "body": "lmao the norm mcdonald reference"
                },
                {
                    "body": "Greatest follow up I‚Äôve ever seen, thanks for the laugh"
                },
                {
                    "body": "Part 1: [https://www.reddit.com/r/StableDiffusion/comments/1blkhq8/](https://www.reddit.com/r/StableDiffusion/comments/1blkhq8/)"
                },
                {
                    "body": "https://preview.redd.it/oz9fvkrfy9qc1.jpeg?width=1100&format=pjpg&auto=webp&s=0f8acd619aef1b388918db0a65500f5dfec755d1\n\nGreat! Consistency is there!   \n  \nIt would be cool to see more variation between angles on character.   \n  \n(A page from my upcoming comic attached)"
                },
                {
                    "body": "‚ÄúKnife?‚Äù\n\n‚ÄúYea bro, let‚Äôs off this guy.‚Äù\n\n‚ÄúWell, I don‚Äôt think we should actually *kill* him. How about we just beat his ass.‚Äù\n\n‚ÄúOk sounds good, let‚Äôs beat that fucker off.‚Äù\n\n‚ÄúThis dude‚Äôs going to be sore for days when we‚Äôre done with him.‚Äù"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "A paradigm shift in cardiac care unfolds with the introduction of a wearable vest-based technology, promising earlier detection of heart conditions than ever before.",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "Engineering",
            "has_media": true,
            "url": "https://i.redd.it/32ijqms8o8pc1.jpeg",
            "comments": [
                {
                    "body": " The study, published in the *Journal of the American College of Cardiology*, found that an electrocardiographic imaging (ECGI) vest, developed by Dr Gaby Captur at UCL, could detect electrical changes associated with an inherited heart muscle condition at a stage when standard tests do not pick up signs of disease.\n\nThe condition, called hypertrophic cardiomyopathy, is where the muscle wall of the heart becomes thicker and stiffens, affecting how well the heart can pump blood around the body. It affects an estimated one in 300 adults.\n\nWhile often people with genetic variants that cause the disease have no symptoms at all, the condition can lead to heart failure and is frequently cited as the most common cause of sudden unexpected death in young people.\n\nLead author Dr George Joy (UCL Institute of Cardiovascular Science and Barts Heart Centre) said: ‚ÄúBy finding subtle electrical abnormalities using our new technique, we are able to detect hypertrophic cardiomyopathy earlier. This is important as it means we can potentially act earlier, providing new treatment to slow the disease as well as fast-tracking individuals to clinical trials that have potential to stop the disease entirely.‚Äù¬†\n\n‚ÄúNext steps of the research include repeating these results in a larger group of patients and following individuals over time to see how these early electrical changes affect the risk of life-threatening heart rhythms later on.‚Äù\n\nThe ECGI vest has 256 sensors rather than the 12 used in a standard electrocardiogram (ECG) and can provide detailed electrical mapping of the heart in just five minutes.\n\nPreviously, this kind of detailed mapping was rare ‚Äì either requiring a catheter to be inserted inside the heart cavity or using single-use devices that were costly and time consuming to set up. The ECGI vest is also reusable and so has potential to be used as a standard screening tool.\n\nThe new study looked at 174 patients whom had genetic testing (overseen by co-lead author Dr Luis Lopes, UCL) recruited from three London hospitals (Barts Heart Centre, St George‚Äôs Hospital and Royal Free Hospital), and 37 healthy volunteers. Patients included people who already had hypertrophic cardiomyopathy as well as individuals with disease-causing genetic mutations who did not have overt signs of the disease.\n\nThe team found that the ECGI vest identified electrical abnormalities among 1 in 4 individuals with a gene mutation for whom no signs of disease were detected via either cardiac magnetic resonance imaging (MRI), the highest standard of heart imaging, or a 12-lead ECG, the typical way the heart‚Äôs electrical activity is assessed.\n\nIn particular, these patients were found via ECGI to have an uneven pattern of electrical signal recovery and slowed conduction of electrical signals through the heart.\n\nThe researchers also applied a machine learning model to the results of 12 markers from the ECGI vest in order to grade the severity of disease and estimate risk of sudden cardiac death.\n\nThey found this grading matched the risk estimated using standard protocol, which is based on information such as age and certain structural features of the heart.\n\nDr Captur (UCL Institute of Cardiovascular Science and the Royal Free Hospital, London), who was senior author on the latest study, said: ‚ÄúThe ECGI vest we have developed is expanding our ability to understand the electrical functioning of the heart and to assess more precisely people‚Äôs risk of developing life-threatening heart rhythms.\n\n‚ÄúPeople who have genetic mutations causing hypertrophic cardiomyopathy are monitored regularly and given advice around exercise. In some cases, this might be to reduce or stop any intense exercise. This prescription can have huge impact on a person‚Äôs quality of life, particularly in athletes or young patients. By better understanding risk we hope to avoid instances where people are given such advice unnecessarily.‚Äù¬†  \n\n\n[https://www.ucl.ac.uk/news/2024/feb/vest-can-detect-earlier-signs-heart-muscle-disease](https://www.ucl.ac.uk/news/2024/feb/vest-can-detect-earlier-signs-heart-muscle-disease)"
                },
                {
                    "body": "Imagining a future where you wear sensors head to toe, with the ability to immediately detect any signs that something is wrong.\n\nIf you're attacked by a bear, you automatically... secrete nanobot particles resembling bear spray... out all of your... orifices.\n\nBut on a serious note, it would be nice to have better health sensors. Right now many people rely on an Apple watch or Oura ring or what have you to monitor their health, but it's only a rudimentary surface level approach that can't detect much."
                },
                {
                    "body": "Wow"
                },
                {
                    "body": "This sounds very promising! On a fully unrelated note I'm seeing a hundred or so FL Studios and it makes my brain go \"Huh..\".\n\nhttps://www.image-line.com/wp-content/uploads/2019/10/FLNews.jpg"
                },
                {
                    "body": "well, we already have enough tech to provide quite extensive health supervision. Polar h10 and a pulse oximeter can deliver plenty of data. The problem is, there is no proper framework to integrate the devices and analyze the data to provide meaningful feedback to the user without requiring phd in medicine field. \n\nAI could potentially fix that since it could analyze the readings in real time and figure out potential health conditions. Still, no attempts to create that have been made."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Stability AI, OTOY, Endeavor, and The Render Network Join Forces to Develop Next Generation AI Models, IP Rights Systems, and Open Standards Powered by Decentralized GPU Computing",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 47,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://home.otoy.com/stabilityai/",
            "comments": [
                {
                    "body": "You can't protect IP without preventing local model usage and training, so this makes me question SAI's commitment to free local models."
                },
                {
                    "body": ">As part of the collaboration,¬†[**Endeavor**](https://endeavorco.com/)¬†**will work with Stability AI,** the Render Network, and OTOY **to develop transparent IP tracking tools for emerging ML models**, publishing their research for peer review through IDEA. This work will include usage of OTOY‚Äôs LightStage technology ‚Äì the industry‚Äôs leading reflectance-field facial scanning and digital double platform ‚Äì **to** **produce licensing tools that enable artists to control their likeness and receive royalties for their IP when used in generative AI models**."
                },
                {
                    "body": "A lot of meaningless buzzwords. Only thing I really care about from stability is open sourced sd and maybe some day video models. This announcement doesn't inspire confidence¬†"
                },
                {
                    "body": "Great otoy.. I still remember the CEO Jules Urbach posting constantly about their VR lighfield technology on the oculus subreddit, but it ended up being vaporware the entire time. \n\nThey released a few very short demos, then they created an ethereum ico.. feel like they really pulled the wool over John Carmack, but I guess it served some utility at the time for vr cubmap images Carmack was trying to make.\n\nThey never released what they promised with the lighfield stuff, and to this day the best example is the google \"welcome to lightfields demo\" and the siggraph demo of vr video lightfields. Which google of course didnt release the full process for and is dead now.\n\nSo anytime I see otoy I'm immediately cautious.\n\nEdit: ICO not IPO"
                },
                {
                    "body": "There are already working examples of Pipeline Parallelism in the wild, this is a really stupid decision.  Why would I use Render Network and completely defeat the purpose of decentralized compute?  Render network isn't decentralizing *shit*, they are just being cheapasses and paying to rent consumer's GPUs instead of buying or renting GPU from a datacenter like a real AI Company.  \n\nNone of this is decentralized.  Not one part of it.\n\nThe GOOD news though is that pipeline parallelism is the advent of training across compute that is massively distributed accross TCP/IP.  As in, the end of the era where huge companies are the ones producing the biggest/best weights, because there is nothing stopping any of us from firing up an equivalent GPU pool that doesn't track shit and has literally 0 rules. \n\nWhat is the goal with this?  To make governments happy?  \n\nCause I am doubtful this will drive profit.  If the model weights aren't released and locally trainable/inferrable in any other way than completely unrestricted I have no use for this.  Getting hit with a bullshit IP claim and being contractually obligated to pay for it at random is appealing to users exactly *HOW* again?..  Why tf would I *ever use this for literally anything*?  Good luck figuring out how to maintain your GPU pool when literally no company on Earth would voluntarily sign up for this.  If I have startup funding for an AI product this is not even remotely a viable option.  \n\nFitting Unet for parallelism across tcp is already happening by the community, why would I have any use for someone else's half-ass datacenter?\n\nEdit: I love SAI but this looks like a bad idea.  You don't have anything here that people can't do without you involved, you should focus on model quality and licensing use of models commercially for a monthly rate and free for personal use.  Extend closed source model development contracting and training services to enterprise clients and offer inexpensive training options on the distributed compute pool to small businesses doing the existing monthly fee.\n\nI can train on AWS without the ethics dogma being enforced, why would I use this?\n\nThis is coming from someone who is extending a fork of the Diffusers library into my own models and pipelines.  I would pay a couple hundred a month for a developer support contract; something to help use your existing models as a platform to develop new ones from.  SD is quite extensible.\n\nRemoving that extensibility destroys your product.  I can't build a TensorRT acceleration engine for MJ that's why I use SD.  Pretty much the ONLY reason I use it, a webservice especially one that imposes what this article implies is absolutely worthless to me.\n\nI want to give you guys money but goddamn you make that hard to do."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "I added a new feature to my art-style explorer, getting ready for SD3!",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 22,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/m1jpb69mklpc1",
            "comments": [
                {
                    "body": "# Give it a try on huggingface!  [SDXL-artists-browser](https://huggingface.co/spaces/mattthew/SDXL-artists-browser)\n\nRight now it's SDXL only, but as soon as I have access to SD3, I'll be able to update the website quickly.  I have a pipeline in place to generate the all the prompts for all artists in the database.  I still love 1.5, but SDXL is much better at imitating artist styles.  Yet, MidJourney is much better than SDXL.  I'm excited to find out what SD3 can do!  \n\nApologies for butchering the pronunciation of the artist \"Yves\".  After recording the demo, I realized his name sounds like \"Eve\".  I picked that artist on the fly."
                },
                {
                    "body": "![gif](giphy|T9JtEyoJ43gY4wLOqW)"
                },
                {
                    "body": "[https://civitlab.devix.pl/](https://civitlab.devix.pl/) maybe add more into it combine some of the data from this?"
                },
                {
                    "body": "what about JUST prompts, related to certain styles (without relation to an artist)"
                },
                {
                    "body": "thanks for your work OP <3"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "AI generates high-quality images 30 times faster in a single step",
            "body": "https://news.mit.edu/2024/ai-generates-high-quality-images-30-times-faster-single-step-0321",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 32,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl20bd/ai_generates_highquality_images_30_times_faster/",
            "comments": [
                {
                    "body": "Sora is using image diffusion, too. If it took 30 minutes for Sora to generate a 1 minute video, this boost would allow it to generate a 1 minute video in 1 minute. Video generation should be cheap pretty soon at this rate. Assuming you could apply this technique to Sora."
                },
                {
                    "body": "Y'know it's funny, I remember a paper about something nearly identical last year, around the debut of gpt-4. It may have even been from openai? But it went nowhere, no one implemented it. I wonder if there's some inherent flaw, like there may be with non -transformer architectures. Again, bunches of \"better\" alternatives, but no one uses them. There must be a reason right?"
                },
                {
                    "body": "![gif](giphy|MO9ARnIhzxnxu)"
                },
                {
                    "body": "This OP brought the articles and updates today, about a good five to six posts altogether. I love to see the progress and it looks like his AGI timelines line up with some of the players.\n\nThe rate of growth is astounding and I‚Äôm enjoying the other posts regarding to healthcare. That‚Äôs one of the buggiest short term gains we‚Äôll see, the amazing step out of the dark ages of medicine into the light of a disease free / self guided evolution reality."
                },
                {
                    "body": "Where code?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "NVIDIA RTX 50 ‚ÄúGB202‚Äù Gaming GPU reportedly features the same TSMC 4NP process as B100",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 85,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://videocardz.com/newz/nvidia-rtx-50-gb202-gaming-gpu-reportedly-features-the-same-tsmc-4np-process-as-b100",
            "comments": [
                {
                    "body": "It's going to be 2k and have 24g of ram though :("
                },
                {
                    "body": "Just like physX cards back in the day, there should be consumer grade AI cards that supplement Gaming GPUs. Want better graphics in your game, upgrade GPU. Want faster/smarter AI in your game, upgrade AI card."
                },
                {
                    "body": "512 bit¬†memory interface suggest 5090 might¬†have 32GB of¬†VRAM.¬†\n\n\nLet's say it will be 16x Samsung GDDR7 16Gb 32GT/s¬†\n[like this](https://www.tomshardware.com/news/samsung-develops-worlds-first-gddr7-chip)¬†\n\n\nIt would have bandwidth of around 2TB/s, so a touch more than twice that of rtx 4090/3090 Ti.¬†\n\n\nAnd it would have FP4 hardware maybe? Once It's in the base arch they may keep it. I think FP4 should helping with inference of quantized llm's. Maybe training in 4bits too, if you feel like training a small model from scratch.¬†\n\n\nWhat do you think are the chances Nvidia would go with 512 bus and 32GB of VRAM? And what would you do with it?"
                },
                {
                    "body": "My body yearns for an affordable RTX 5060 with 16 GB RAM"
                },
                {
                    "body": "Ugh did I make a mistake buying 2x4090s recently"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Jensen Huang's keynote presentation has convinced me that computers have gone back to the era of mainframes and the era of \"hackers\" is over",
            "body": "This is not really the version of singularity I was hoping for. It seems that the future of computing is basically in these giant datacenters with enormous compute controlled by large corporations like the mainframes from the 50-60s. The era of \"hackers\" who build cool applications in their laptop that goes on to change the world, for example Linus Torvalds did with Linux (and many other commercially successful applications) is over. Not only will anyone be able to replicate what someone builds with more compute they can make them 100x better. Not to mention most of the general public will get restricted, rate limited access to these systems and will only be able to take advantage of them as much as these cloud providers permit them to. Many people are still drinking the open source kool aid, but that's just cope. The mechanics now is pretty simple - more compute translates to more intelligence which in turn translates to cooler stuff you can build. With AGI it will transfer to all other disciplines as well. It may not matter to most people here in this sub but for someone like me with a hacking mindset since childhood, it's pretty depressing.",
            "upvote_ratio": 0.81,
            "subreddit": "singularity",
            "num_comments": 82,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bikuxx/jensen_huangs_keynote_presentation_has_convinced/",
            "comments": [
                {
                    "body": "Seems like you expected to be able to have access to hack in SOTA models when that was never the case. Computing was always like this. This is just a new area of computing where things are still expensive and we are only getting to AGI due to it's scale.\n\nIt will take a few years until you can run them on relatively cheap hardware. You can still hack around with open source models tho. Like robotics, before you needed to spend hundreds of thouasands to get relatively good hardware but now its a lot cheaper where a hobbyist can create unbelievable things. \n\nGive it a few years if you want to have AGI in your PC. Its not the end of \"hackers\". Hobbyists never had access to the level of technology big enterprise had."
                },
                {
                    "body": "... There were hackers during the era of mainframes..."
                },
                {
                    "body": "It's a cycle. Eventually those mainframes got shrunk into a handheld super computer that's your phone. So, give it 10-20 years. Not that it's going to matter in 20 years"
                },
                {
                    "body": "It‚Äôs just how the SOTA is at the moment, it appears scaling model size is king atm. \n\nThere is still great demand to make these models smaller and keep as much performance as possible so they can be distributed on to more edge devices and have lower inference costs. But these things take time, look at Gemini nano, Claude Haiku or Apple MM1 3B for instance."
                },
                {
                    "body": "mainframes precede hackers every time. we will, like proto-rats post jurassic, subsist on the scraps left. we‚Äôll hide in our caves and lick the cave walls for moisture if we have to. we‚Äôll still see robotics get 10x cheaper while we wait for a standalone soc to run it. scaling is not the solution eventually. the solution is better parameters and trainers. better tokens, time-series models. yesterday‚Äôs announcement has a lot to be optimistic about, especially for hackers. the magic we saw from gpt3 to gpt4 was MoE, not purely scaling. this is why microsoft snapped up mistral to stop their IP from getting out, but its too late. be patient hacker, join a hackerspace and collaborate with others. we‚Äôll find our way through."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Jensen Huang's keynote presentation has convinced me that computers have gone back to the era of mainframes and the era of \"hackers\" is over",
            "body": "This is not really the version of singularity I was hoping for. It seems that the future of computing is basically in these giant datacenters with enormous compute controlled by large corporations like the mainframes from the 50-60s. The era of \"hackers\" who build cool applications in their laptop that goes on to change the world, for example Linus Torvalds did with Linux (and many other commercially successful applications) is over. Not only will anyone be able to replicate what someone builds with more compute they can make them 100x better. Not to mention most of the general public will get restricted, rate limited access to these systems and will only be able to take advantage of them as much as these cloud providers permit them to. Many people are still drinking the open source kool aid, but that's just cope. The mechanics now is pretty simple - more compute translates to more intelligence which in turn translates to cooler stuff you can build. With AGI it will transfer to all other disciplines as well. It may not matter to most people here in this sub but for someone like me with a hacking mindset since childhood, it's pretty depressing.",
            "upvote_ratio": 0.81,
            "subreddit": "singularity",
            "num_comments": 82,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bikuxx/jensen_huangs_keynote_presentation_has_convinced/",
            "comments": [
                {
                    "body": "Seems like you expected to be able to have access to hack in SOTA models when that was never the case. Computing was always like this. This is just a new area of computing where things are still expensive and we are only getting to AGI due to it's scale.\n\nIt will take a few years until you can run them on relatively cheap hardware. You can still hack around with open source models tho. Like robotics, before you needed to spend hundreds of thouasands to get relatively good hardware but now its a lot cheaper where a hobbyist can create unbelievable things. \n\nGive it a few years if you want to have AGI in your PC. Its not the end of \"hackers\". Hobbyists never had access to the level of technology big enterprise had."
                },
                {
                    "body": "... There were hackers during the era of mainframes..."
                },
                {
                    "body": "It's a cycle. Eventually those mainframes got shrunk into a handheld super computer that's your phone. So, give it 10-20 years. Not that it's going to matter in 20 years"
                },
                {
                    "body": "It‚Äôs just how the SOTA is at the moment, it appears scaling model size is king atm. \n\nThere is still great demand to make these models smaller and keep as much performance as possible so they can be distributed on to more edge devices and have lower inference costs. But these things take time, look at Gemini nano, Claude Haiku or Apple MM1 3B for instance."
                },
                {
                    "body": "mainframes precede hackers every time. we will, like proto-rats post jurassic, subsist on the scraps left. we‚Äôll hide in our caves and lick the cave walls for moisture if we have to. we‚Äôll still see robotics get 10x cheaper while we wait for a standalone soc to run it. scaling is not the solution eventually. the solution is better parameters and trainers. better tokens, time-series models. yesterday‚Äôs announcement has a lot to be optimistic about, especially for hackers. the magic we saw from gpt3 to gpt4 was MoE, not purely scaling. this is why microsoft snapped up mistral to stop their IP from getting out, but its too late. be patient hacker, join a hackerspace and collaborate with others. we‚Äôll find our way through."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Workflow for changing clothes, sfw.",
            "body": "I designed a set of custom nodes based on diffusers instead of ComfyUI's own KSampler. available at https://github.com/Jannchie/ComfyUI-J.\n\nI used it to implement a workflow to change the character's clothes and share the idea with you.\n\n[workflow with data, just drag it in your comfy](https://preview.redd.it/h3x5bxdosvpc1.png?width=3528&format=png&auto=webp&s=33aa15aa7030318e67be6d5000e4faf90f71a84d)\n\nThis is a composite application of diffusers pipeline custom node. Includes:  \n- Reference only  \n- ControlNet  \n- Inpainting  \n- Textual Inversion  \n\n\nA checkpoint for stablediffusion 1.5 is all your need. But for full automation, I use the Comfyui\\_segformer\\_b2\\_clothes custom node for generating masks. you can draw your own masks without it.\n\nDo not use it to generate NSFW content, please.",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 31,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bkycd6/workflow_for_changing_clothes_sfw/",
            "comments": [
                {
                    "body": "all social media or similar platforms remove meta data. dropping the image into comfy will not work."
                },
                {
                    "body": "I don't know why nobody seems to care about, but if you want to this in A1111 (or the other derivates) in one click: \n\nThere's the deepfashion model available for ADetailer for quite some time on their [hf page](https://huggingface.co/Bingsu/adetailer/tree/main).\n\nhttps://imgur.com/uZgQwyp"
                },
                {
                    "body": "so this also needs one of your custom nodes or just regular nodes?"
                },
                {
                    "body": "Why does this work better with diffusers than ksamplers?"
                },
                {
                    "body": "Step One: remove old clothes.\n\nStep Two: put on new clothes."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Gene-editing pioneer calls for big investment in Crispr technology",
            "body": "Gene-editing pioneer calls for big investment in Crispr technology",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 7,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.ft.com/content/756c1b9b-69d8-40b7-b9a7-5f3e93dd3835",
            "comments": [
                {
                    "body": "\"Expanding medical therapies based on Crispr gene-editing globally is ‚Äúunrealistic‚Äù and the sector needs heavy investment to make the technology, which could¬†transform treatment of diseases, accessible to all, according to its co-discoverer.\""
                },
                {
                    "body": "FFS, during COVID governments were printing all this money which was mostly inflating the stock market and kept zombie firms alive. No investment opportunities.\n\nNow if you gave me 1 trillion to invest I would ask for another trillion."
                },
                {
                    "body": "We need more investments!! Buy ARKG ETF!!"
                },
                {
                    "body": "The brass ring, and also the downfall of humanity, is cheaper oligo synthesis."
                },
                {
                    "body": "She looks a little bit like the lady from the beginning of I am legend"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Stability AI drama shows VCs won't fund open-source AI companies",
            "body": "That's my learning from what happened at Stability AI in the past few days.\n\nThe irony is that companies that have built commercial products on top of Stability AI's open-source products - Midjourney, etc - are more likely to get VC funding due to their closed model.\n\nBut it's really sad news for those working on and using open-source AI frameworks.",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 41,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blxr8i/stability_ai_drama_shows_vcs_wont_fund_opensource/",
            "comments": [
                {
                    "body": "There was capital \"UNIX\" long before there was \"Linux\"...\n\nMaking money on OSS simply being OSS is hard, but making money by being OSS and providing value works.  (See Red Hat)\n\nI think OSS LLM is just getting started... the entire toolchain is opensource and to be honest, the less its behoove to VCs, the better."
                },
                {
                    "body": "I disagree, Stabilities woes had nothing to do with the open source nature of it and was entirely driven by the people at the company especially the drama associated with them. Emad was known to be shady quiet early on, and that really hurt stabilities fund raising chances. It all began with the revelations that Stability had oversold its contributions to Stable diffusion, than tried to shut down Runway ML, than they back peddled. Than Stability AI changed their model and tried to focus on LLMs, audio, video, and everything under the sun. Emad still racked up bad rep by also placing his wife on the board which was a questionable move, there's been a lot of overexaggerating from Emad that really further tanked stability"
                },
                {
                    "body": "Stability simply over expanded. They had an insane amount of projects going on. SD3, SD Cascade, Stable Beluga, Stable Zephyr, Stable LM,  Japanese StableLM, Stable Audio, SDV, Stable Video 3D, StableZero 123, Stable Code, SDXL Turbo\n\nHow many of these are relevant at all? Stability *did* get investments, that's how they lasted so long. But instead of doubling down on what they were known for (image models) they decided to inflate themselves and develop a whole bunch of lackluster LLMs. The company had no direction, no plan, and seemed to just let everyone do whatever they wanted hoping to strike gold magically. \n\nThere are plenty of ways to make money while also being committed to local models, such as a staggered release schedule where people can pay for API access for a few months (and contribute to RLHF) before the model drops locally. If they actually had competitive models to Midjourney this would be a viable strategy but they've long lost the visual edge ever since they started dabbling in fodder projects."
                },
                {
                    "body": "I wouldn't generalize the situation based on a single company, especially not one that focuses on image generation. VCs are not the only game in town for bankrolling open-source AI. Companies donate massive amounts of money and developer time to open-source projects because they want to use the software and build products on top of them. \n\nBig consulting companies are one example, they currently investing heavily in open-source LLMs simply because closed and centralized AI is not an option for them, the same is true for data analysis companies and a bunch of other large industries with deep pockets. Running a proprietary fine-tune of an open-source LLM allows them to focus their resources on optimizing for their specific use case. They can have a marketable product instead of a half trained closed foundation model that is unusable. \n\nThat is of course mostly relevant for the business and B2B market but I don't think VC backed startups have better chances when it comes to developing products for the consumer market. Renting a few servers and hiring some young and cheap talent to get the next hot app off the ground worked well with VC cash but developing AI is a totally different ballgame. Hardware requirements are insane and anybody with a solid machine learning CV can demand a fortune in the current marked."
                },
                {
                    "body": "This looks like a good place to say: Fucking Thank you, to every single open source developer past and present. Thank you, for fighting for a future worth living in and a more secure present. Thank you for sharing your gifts, some I will never even know to acknowledge. \n\n  \nIf a twitch streamer is worth a donation then so is your favorite open source developer. \n\n  \nCheers to those who truly walk the walk, the best of the old hacker culture is alive in you all."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "How come artists are suing SAI and midjourney but not dall-e?",
            "body": "Maybe I missed some news but the recent stories I've read talked about suing SD and midjourney.. Dall-e was trained on a much wider database (apparently I was wrong about this.. got gpt-4 mixed up with dalle) so doesn't it make more sense to sue them? Or is this because they think they can win because SD/MJ are smaller companies? I've been wondering about this past days.",
            "upvote_ratio": 0.89,
            "subreddit": "StableDiffusion",
            "num_comments": 82,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bmk3xq/how_come_artists_are_suing_sai_and_midjourney_but/",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Dalle got that Microsoft money"
                },
                {
                    "body": "Probably if they win one case and the other is similar, they would have more power if one judge already sided. No idea how it works in USA but that's how you would do in most EU. Btw Midjourney is probably more trendy for casual people."
                },
                {
                    "body": "Doesn‚Äôt matter. They‚Äôre not winning anyways"
                },
                {
                    "body": "They *are* suing MJ, Runway, and DeviantArt: \n\nhttps://www.courtlistener.com/docket/66732129/andersen-v-stability-ai-ltd/\n\nAmended complaint added Runway here:\n\nhttps://storage.courtlistener.com/recap/gov.uscourts.cand.407208/gov.uscourts.cand.407208.129.0_1.pdf\n\nDallE, no, see my other post."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[D] Why the readability of academic papers are continuously bad?",
            "body": ">>Some of these expectations are inevitable. Papers absolutely have to assume extensive background knowledge and vocabulary specific to the field‚Äîincluding a basic introduction to the field with each paper would be excessive. Sometimes papers assume too much background, but that's hard to judge as a writer or a reader, not least because the set of things people know changes over time and in different contexts.\n[Reference](https://www.quora.com/Is-there-an-actual-issue-of-readability-concerning-papers-within-the-academic-world-I-found-that-many-of-the-papers-chose-to-use-extremely-verbose-diction-that-simply-complicated-the-paper-and-made-it-harder-to-read#:~:text=Usually%2C%20what%20you%20refer%20to,is%20trying%20to%20sound%20fancy.)\n---\nDuring the past 3 years, to broaden my understanding of ML field, I have read a lot of papers without considering focusing on a specific problem in a specific field.\n\nThis leads to allowing me to understand the structure of an academic writing, basic concepts of ML, and relatively precious insights compared to previous knowledge in the past, but when I encounter new papers, some papers are still verbose, annoying me due to the readability of nature of academic papers.\n\nThis strongly requires me to skim through some contents, which is harmful for purely concentrating on reading documents compared to non-academic books (I don't assume that all of the books are great like personal best seller, but I want to emphasize the difference of the structure between academic and non-academic writing.)\n\nThe question is, why this convention cannot be smoothly changed for the better direction, which is helpful for existed and newer researchers?",
            "upvote_ratio": 0.74,
            "subreddit": "MachineLearning",
            "num_comments": 94,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bj92ht/d_why_the_readability_of_academic_papers_are/",
            "comments": [
                {
                    "body": "There are two problems here. \n\nYes, academic writing is often full of stilted language. Partly this is due to being precise with language. A doctor wouldn't say that a patient has \"bruises\", because that doesn't convey enough information to another doctor. They would instead say something like \"contusions\", \"ecchymosis\", or even \"subdermal hematomas.\" But still, academics sometimes write to sound smart rather than to communicate, which is a definite issue.\n\nThe second problem is that research articles are a bad place to learn broad concepts. Start with textbooks, move up to subject-specific books, then review articles, and *then* you'll be able to understand research articles."
                },
                {
                    "body": "Academic papers are not written for you to \"broaden your understanding\". They are written by experts for other experts and they include a lot of jargon and hidden assumptions. This allows for more efficient communication among researchers.\n\nIf you want to learn you should read book and study from appropriate resources."
                },
                {
                    "body": "The irony of the title of this post being bad English really made my day.  Thanks for that!"
                },
                {
                    "body": "As someone with a PhD (econ) who had several papers in pretty good journals ....\n\n\nMost academics just write bad\n\n\nWriting concise is actually hard\n\n\nRather than work at the writing they put it all down and do a few passes and send it in\n\n\nI mean, you should try once (trust me it is way worse in econ where a should be 10 page paper is 50), take an intro and rewrite it to half the length and clearer, it isn't easy and it takes time"
                },
                {
                    "body": "There's been a focus on \"plain language summaries\" in medical academic publishing for the last few years - might be something that comes to ML academic in time? \n\nThe difference is that in medicine, PLS adoption is driven by journals allowing/encouraging them, and an understanding that patients want to be more educated about their condition/possible treatment - it requires an attitude shift in terms of who is being written for, and is most common in translational research e.g. where you're applying basic research (e.g. more scientific Vs medical) to clinical problems\n\nSo it could happen in ML research as applications become more relevant to the average person"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "instagram style photo",
            "body": "",
            "upvote_ratio": 0.71,
            "subreddit": "StableDiffusion",
            "num_comments": 37,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/4w32x0ni5ypc1.png",
            "comments": [
                {
                    "body": "Wonder if it would look more real if she didn't look straight in the camera. I am just tired of this dead glance ai models give. How to fix it??"
                },
                {
                    "body": "This is actually a large portion of instagram already"
                },
                {
                    "body": "looking left/right/up/down -  depends on if the (mathematical) model was trained on photos looking left/right/up/down and if the prompts were included in the training.\n\nhttps://preview.redd.it/dpanv7cyg1qc1.png?width=1024&format=png&auto=webp&s=69fd492c218bdf6fffb161f7fc134b48ba486bee"
                },
                {
                    "body": "That‚Äôs weird, all I see on my Instagram are cute pictures of cats"
                },
                {
                    "body": "\"instagram\" is not a style"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Japan org creates evolutionary automatic merging algorithm",
            "body": "Just saw some articles about Sakana AI ( [https://sakana.ai/evolutionary-model-merge-jp/](https://sakana.ai/evolutionary-model-merge-jp/) ) creating some kind of automatic process to merge models together from different domains and output the best result. They have a research paper too [https://arxiv.org/abs/2403.13187](https://arxiv.org/abs/2403.13187)\n\nLooks like they did stuff like merge a Japanese LLM with an english Math model and was able to get a Japanese math LLM as well as a few other models like merging japanese llm into an image model to get it to understand japanese.\n\nIs this something we couldn't do before? could this actually be pretty significant?\n\nI don't really know the details but I get the impression it merges parts of the models together and lets them evolve using evolution algorithms like NEAT and other ones, where the better performing merged models proceed to the next generation and the lower performing ones die out, until its got an optimized final model with the strongest parts of all the input models.",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 23,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk1ujz/japan_org_creates_evolutionary_automatic_merging/",
            "comments": [
                {
                    "body": "Sakana is founded by one of the coauthors of the original Transformer paper. We shouldn't expect it to be just another placebo automergeslop method."
                },
                {
                    "body": "That's pretty dang banger.\n\n> Is this something we couldn't do before? could this actually be pretty significant?\n\nPrincipally we could, but these guys implemented some defacto finetune sauce that makes it seemingly work pretty good without necessarily inflating the final weights like for instance Goliath does. It's a little more involved and task specific but could be a way to keep the models relatively small."
                },
                {
                    "body": "I like the image they put there though, lol, summarizes my thoughts on current state of merging: https://sakana.ai/assets/evolutionary-model-merge/model_merging_explained.jpeg\n\nI have tried a similar method, but it didn't work so well. Essentially I just tried to use an evolutionary method to decide mergekit layer combinations for 3 different models. I didn't get anything out that could be confidently said to be better than any of the bases it was frankensteined out of.\n\nThe method they show is looks sophisticated that the crap I did.\n\nImportant detail that I can't tell: what was their optimizer optimizing for when deciding which blocks to stitch together? (I can't read Japanese but I can see pictures). Evolutionary algorithms are not immune to overfitting. If they optimized for benchmarks then any claims about the method being good should be disregarded.\n\nI wish I saw more interesting evolutionary algorithms uses in LLM space. There's no killer apps whatsoever I am aware of that are based on evoution in LLM space.\n\nI've used them in a totally different space for actual work successfully (mostly CMA-ES for finding real-valued vectors to optimize blackbox functions: fitness(X) -> Y where X is a real-valued vector and Y is scalar, the score, to minimize. But my dimension was like 100. LLMs have billions.). They kinda suck for most things but there's like a category of niche problems where they are the only thing that works.\n\nYesterday I did a test finding a prompt on Cohere model that would try to have as high raw logit value for \"&\" as next token as possible, for a 20-character printable ASCII string, using a very simple genetic algorithm. I got this: \"=&I&S&'$&Z&HB& P&r&e\". 99.2% for \"&\" if you softmax entire logit vector (250k sized in Cohere), and a pretty high raw logit value. I want to try optimize for something more interesting than \"give me this specific token next\" like a full text or weird behavior or just insanity prompt that makes all LLMs go incoherent immediately."
                },
                {
                    "body": "These guys did something similar:  [FuseLLM/FuseChat at main ¬∑ fanqiwan/FuseLLM (github.com)](https://github.com/fanqiwan/FuseLLM/tree/main/FuseChat) \n\nI was planning to do this for a 70B models but it takes a lot of time."
                },
                {
                    "body": "Gpt4 summary. \n\nThe document titled \"Evolutionary Optimization of Model Merging Recipes\" explores a novel approach to the development of foundation models through the merging of existing large language models (LLMs). This methodology leverages evolutionary algorithms to discover optimal combinations of diverse open-source models, aiming to harness their collective capabilities without necessitating extensive additional training or computational resources. Unlike traditional model development, which often depends on the intuition and domain knowledge of developers, this automated process allows for the efficient creation of new models that can perform well across a variety of tasks.\n\nKey contributions of the work include:\n1. **Automated Model Composition**: The introduction of an evolutionary method to automatically discover optimal combinations of diverse models. This strategy enables the creation of powerful new foundation models by utilizing the collective intelligence of existing models, thereby eliminating the need for extensive training data or computational resources.\n2. **Cross-Domain Merging**: The demonstration of the method's ability to merge models from different domains, such as language and math or language and vision. This has the potential to surpass the capabilities achievable through traditional human design strategies.\n3. **State-of-the-Art Performance**: The application of this methodology has resulted in the creation of a Japanese language LLM with math reasoning capability and a Japanese Vision-Language Model (VLM), both of which achieved state-of-the-art performance on various benchmarks.\n4. **Efficiency and Generalizability**: Notably, a 7B parameter LLM generated through this process outperformed previous 70B parameter models on benchmark datasets, highlighting the efficiency and surprising generalization capability of the approach.\n\nThe document outlines the limitations encountered, such as the inheritance of source models' limitations and the potential for generated models to produce logically incoherent responses or factually flawed outputs due to the absence of instruction fine-tuning or alignment. It also acknowledges the contributions of various authors to the project, including the initiation of the project, expansion of the model merging parameter space, and technical guidance."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "[D] Training code and more released for ‚ÄúThe Era of 1 Bit LLMs‚Äù",
            "body": "Unfortunately Microsoft didn‚Äôt release the weights but if it‚Äôs between that and the training code then this is certainly preferable. [The post is here](https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf). \n\nWhat do we think? Any ideas about that oddly shaped loss curve? Do you think this approach breaks after 4B parameters? Thoughts on how LLMs could even work at such a low precision? I know it‚Äôs not particularly scientific but it seems pretty counterintuitive to me that you could potentially fit a fully functional 7B parameter model on a few CDs‚Ä¶ Most importantly however, whose got a few $100,000 worth of compute to actually test this?",
            "upvote_ratio": 0.97,
            "subreddit": "MachineLearning",
            "num_comments": 27,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/",
            "comments": [
                {
                    "body": "Maybe numerical precision is somehow virtually recovered when approaching convergence, which boosts the training speed at the end, leading to the S-shaped loss curve?\n\nAs for the parameter precision, it is possible to train binary neural networks (BNNs) with accuracy comparable to full precision models, so I don't see why a ternary LLMs couldn't also have good performance.\n\nAs someone who worked with BNNs, I think the most important thing is numerical precision in the activations, not in the parameters. BNNs are supposed to also have binary activations, but here the model has int8 which is a lot of possible values for the activations. They say it in the pdf at the link, if they reduce to 4 bits activations the accuracy drops significantly. This is perhaps related to the paper I came across that said something like \"LLMs have a few large activation values that are critical to the model performance\"."
                },
                {
                    "body": "> Our current implementation for training our model is still in FP16/BF16, so there is no actual speed-up\r\nin our experiments. However, there are significant opportunities for acceleration, especially for larger\r\nmodels. First, low-precision CUDA kernels (e.g., FP8 GEMM) can be used to accelerate the forward\rand backward computations of BitLinear. Second, 1.58-bit language models can save a substantial\r\namount of memory and communication bandwidth for distributed training. This is particularly\r\nbeneficial for ZeRO [RRRH20], which conducts an all-gather operation to collect parameters during\r\nforward and backward computations."
                },
                {
                    "body": "Really disappointing that they didn't actually implement ternary training. Instead, they point out, in the explanation for the training code:\n\n>current implementation for training our model is still in FP16/BF16, so there is no actual speed-up\nin our experiments\n\nThis, combined with the lack of any model release, means we probably won't see 70b+ 1.58 bit models (which should be able to fit on 10Gb of memory) for a while, due to the large cost of training. \n\nI'd love to see an implementation of the kernel-level optimizations they suggest: low-precision CUDA kernels (e.g., FP8 GEMM) can be used to accelerate the forward and backward computations of BitLinear. Though, in addition, surely there's more that can be done with training in (-1, 0, 1) space in the first place. \n\nIt's also a bit strange to me that they didn't show loss curves of any of the larger models, *or* of any of the 2T token training runs they spoke of in the paper release. \n\nAnyway, exciting work, and I'm definitely looking forward to the models we can actually play with being released, so we can evaluate their claims for ourselves. If it's true though, we could have Goliath-120b sized models running on 24GB cards."
                },
                {
                    "body": "Hello. There seems to be no code only sort of a document ?"
                },
                {
                    "body": "Someone explain to me a beginner what exactly is 1 bit here?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "The power of ASI needs to go directly into solving climate change",
            "body": "Most everyone‚Äôs timeline here for when climate change is gonna effect us is way off. All of you will be feeling the effects of climate change in 5 years. This is why you should hope for ASI as soon as possible so that we can somehow undo the damage",
            "upvote_ratio": 0.68,
            "subreddit": "singularity",
            "num_comments": 288,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bk7rqy/the_power_of_asi_needs_to_go_directly_into/",
            "comments": [
                {
                    "body": "Climate change is not a hard thing to figure out or to solve. It's more of a political and social problem rather than a technical problem."
                },
                {
                    "body": "Climate will be practically solved when fusion is invented.  We will have abundant green energy to fight with the effects of climate change while not contributing to the problem."
                },
                {
                    "body": "## Creating Large-Scale Incredible Machines to Optimize the Earth's Domains\n\nTo create large-scale incredible machines that can constantly optimize the Earth's biosphere, atmosphere, lithosphere, and hydrosphere, a multifaceted approach is required:\n\n### Integrated Systems Design\n- Design machines that can monitor, model, and dynamically optimize the complex interactions between the different Earth domains[1][3].\n- Employ systems thinking to develop holistic solutions that account for the interdependencies and feedback loops within the Earth's interconnected systems[1][4].\n- Leverage advanced computational modeling, simulation, and optimization techniques to predict and manage the impacts of interventions across domains[1][3].\n\n### Renewable Energy and Sustainability\n- Power the machines using renewable energy sources like solar, wind, and geothermal to minimize environmental impact[1][3].\n- Incorporate circular economy principles to ensure the machines' materials and components can be reused, recycled, or safely disposed of[1][3].\n- Design the machines to be energy-efficient and minimize resource consumption during operation[1][3].\n\n### Adaptive and Autonomous Capabilities\n- Equip the machines with sensors, artificial intelligence, and machine learning algorithms to continuously monitor, analyze, and adapt to changing conditions in the Earth's domains[1][3][4].\n- Develop autonomous decision-making and control systems that can rapidly respond to emerging challenges and opportunities without human intervention[1][3][4].\n- Ensure the machines can learn and evolve over time to improve their optimization capabilities[1][3][4].\n\n### Collaboration and Integration\n- Foster interdisciplinary collaboration between scientists, engineers, policymakers, and other stakeholders to co-design and deploy these incredible machines[1][3][4].\n- Integrate the machines with existing infrastructure, policies, and governance frameworks to ensure seamless and effective implementation[1][3][4].\n- Establish global coordination and data-sharing mechanisms to enable the machines to work together as a distributed network for planetary-scale optimization[1][3][4].\n\n### Ethical and Responsible Development\n- Prioritize the well-being of humans and the environment in the design and deployment of these incredible machines[1][3][4].\n- Implement robust safeguards, security measures, and governance protocols to mitigate potential risks and unintended consequences[1][3][4].\n- Engage the public and address societal concerns to ensure the machines are developed and used in a transparent, accountable, and socially responsible manner[1][3][4].\n\nBy combining advanced systems design, renewable energy, adaptive autonomy, collaborative integration, and ethical responsibility, we can create large-scale incredible machines capable of constantly optimizing the Earth's biosphere, atmosphere, lithosphere, and hydrosphere for maximum habitability and sustainability.\n\n[1] [Incredible Machines 2022 - The New Centre for Research & Practice](https://thenewcentre.org/public/incredible-machines-2022/)\n[3] [35 Big Machines That Changed the World In Big Ways - Popular Mechanics](https://www.popularmechanics.com/technology/infrastructure/g17885261/machines-that-changed-the-world/)\n[4] [Building a string art machine - Hacker News](https://news.ycombinator.com/item?id=37630758)\n\nCitations:\n[1] INCREDIBLE MACHINES 2022 | The New Centre for Research & Practice https://thenewcentre.org/public/incredible-machines-2022/\n[2] 15 Incredible Machines you Wouldn't Believe Existed - YouTube https://www.youtube.com/watch?v=wK-h6nIZtis\n[3] 35 Big Machines That Changed the World In Big Ways https://www.popularmechanics.com/technology/infrastructure/g17885261/machines-that-changed-the-world/\n[4] Building a string art machine - Hacker News https://news.ycombinator.com/item?id=37630758\n[5] What are the Four Major Domains of the Earth? - GeeksforGeeks https://www.geeksforgeeks.org/what-are-the-four-major-domains-of-the-earth/\n\nBy Perplexity at https://www.perplexity.ai/search/711d6824-3fcb-4875-ac67-3a0f6205c2eb?s=m"
                },
                {
                    "body": "This exactly sounds like the plot of Horizon Zero Dawn. The timeline also matches. I hope we don't make Biomass Conversion and definitely not the Chariot Line"
                },
                {
                    "body": "In future whole surface of Earth is just one big data center expect mega cities where humans will live. Honestly I don't expect solution for climate change. Of course in far future we could have those huge¬†terraforming facilities to adjust out atmosphere."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "SDNext New Release",
            "body": "# [SD.Next](https://github.com/vladmandic/automatic) release update for 03-19-2024\n\n3 weeks and 120 commits later, here's another release...\n\n## New models\n\n* [Stable Cascade](https://github.com/Stability-AI/StableCascade) *Full* and *Lite*\n* [Playground v2.5](https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic)\n* [KOALA 700M](https://github.com/youngwanLEE/sdxl-koala)\n* [Stable Video Diffusion XT 1.1](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1)\n* [VGen](https://huggingface.co/ali-vilab/i2vgen-xl)\n\n## New pipelines and features\n\n* Img2img using [LEdit++](https://leditsplusplus-project.static.hf.space/index.html), context aware method with image analysis and positive/negative prompt handling\n* Trajectory Consistency Distillation [TCD](https://mhh0318.github.io/tcd) for processing in even less steps\n* Visual Query & Answer using [moondream2](https://github.com/vikhyat/moondream) as an addition to standard interrogate methods\n* **Face-HiRes**: simple built-in detailer for face refinements\n* Even simpler outpaint: when resizing image, simply pick outpaint method and if image has different aspect ratio, blank areas will be outpainted!\n* UI aspect-ratio controls and other UI improvements\n* User controllable invisibile and visible watermarking\n* Native composable LoRA\n\n## What else?\n\n* **Reference models**: *Networks -> Models -> Reference*: All reference models now come with recommended settings that can be auto-applied if desired\n* **Styles**: Not just for prompts! Styles can apply *generate parameters* as templates and can be used to *apply wildcards* to promptsimprovements, Additional API endpoints\n* Given the high interest in [ZLUDA](https://github.com/vosen/ZLUDA) engine introduced in last release we've updated much more flexible/automatic install procedure (see [wiki](https://github.com/vladmandic/automatic/wiki/ZLUDA) for details)\n* Plus Additional Improvements such as: Smooth tiling, Refine/HiRes workflow improvements, Control workflow\n\n## Further details\n\n* For basic instructions, see [README](https://github.com/vladmandic/automatic/blob/master/README.md)\n* For more details on all new features see full [CHANGELOG](https://github.com/vladmandic/automatic/blob/master/CHANGELOG.md)\n* For documentation, see [WiKi](https://github.com/vladmandic/automatic/wiki)\n* [Discord](https://discord.com/invite/sd-next-federal-batch-inspectors-1101998836328697867) server\n\n&#x200B;\n\nhttps://preview.redd.it/n0tt0gp21bpc1.jpg?width=1920&format=pjpg&auto=webp&s=81df0bfe1b3bfd7676b6abd485f52371fb363173\n\n&#x200B;\n\nhttps://preview.redd.it/bw52qz041bpc1.jpg?width=1920&format=pjpg&auto=webp&s=9d9a9c2090b0cc26949f81e72a249e0da21617b5",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 28,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bim5ql/sdnext_new_release/",
            "comments": [
                {
                    "body": "Great work as always, just getting used to the UI.\nAny UI mods like lobe working?"
                },
                {
                    "body": "Solid going u/vmandic ! Thank you for the update.  \nTo confirm about SC - is it a direct workflow if you have the model in a SC folder? There are two different models. Also amazing work with Playground 2.5 ! Going to try it out this week."
                },
                {
                    "body": "works for me much better out of the box then the original automatic1111. Will try it out the next days and maybe i will stick to it"
                },
                {
                    "body": "Is there an advantage over SD WebUI Forge?"
                },
                {
                    "body": "What's the advantage over A1111, if you don't mind me asking?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Studio style.",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1blphve",
            "comments": [
                {
                    "body": "Portrait of orange cat, Macro closeup, film, profile view, simple black background, hyperdetailed, high definition, silhouette, illuminated from behind, in darkness. \n\nNo negative. \n\njuggernautxl lighting step 6 - cfg 2\n\nhttps://preview.redd.it/kdv3t7fje5qc1.jpeg?width=724&format=pjpg&auto=webp&s=95231d79c5eb27bc1c5539794aba35d930f06c29"
                },
                {
                    "body": "Really nice results, but I'm curious what you get without all of that negative prompt bloat. You have things in there that don't make sense like 'doll' and 'fingers' which obviously you wouldn't get in the first place."
                },
                {
                    "body": "(((Portrait of beautiful panther)))\n(((Macro closeup ear)))\n(((The ear as the focal point of the image)))\n(((hasselblad 70mm camera films)))(((profile view)))\n(((simple black background)))(((photorealistic, masterpiece, hyperdetailed, highdefinition,)))(((silhouette illuminated from behind)))\n(((in darkness)))\n(((by Rembrandt style)))\n\n\n<lora:detamodel3:0.800000>, \n<lora:photo real:0.800000>, \n<lora:details xl:0.800000>\n\n\n\nNegative prompt: Negative prompt: ng_deepnegative_v1_75t, badhandv4 (worst quality:2), (low quality:2), (normal quality:2), lowres, bad anatomy, bad hands, normal quality, long arms, deformed arms, deformed (3d, render, cgi, doll, painting, fake, cartoon, 3d modeling:1.4), (worst quality, low quality:1.4), monochrome, child, deformed, malformed, deformed face, bad teeth, bad hands, bad fingers, bad eyes, long body, blurry, duplicated, cloned, duplicate body parts, disfigured, extra limbs, fused fingers, extra fingers, twisted, distorted, malformed hands, mutated hands and fingers, conjoined, missing limbs, bad anatomy, bad proportions, logo, watermark, text, copyright, signature, lowres, mutated, mutilated, artifacts, gross, ugly, long neck(3d, render, cgi, doll, painting, fake, cartoon, 3d modeling:1.4), (worst quality, low quality:1.4), monochrome, child, deformed, malformed, deformed face, bad teeth, bad hands, bad fingers, bad eyes, long body, blurry, duplicated, cloned, duplicate body parts, disfigured, extra limbs, fused fingers, extra fingers, twisted, distorted, malformed hands, mutated hands and fingers, conjoined, missing limbs, bad anatomy, bad proportions, logo, watermark, text, copyright, signature, lowres, mutated, mutilated, artifacts, gross, ugly, unnatural face, unnatural body, imperfect eyes\n\n\nSteps: 25, Sampler: DPM++ SDE Karras,\n CFG scale: 2.0, Seed: 460783459, \nSize: 768x1152, \nModel: Photo_perfect: 1ac13b390bc5\", \nVersion: v1.6.0.133-1-gaca9268,\n TaskID: 705809147035222674"
                },
                {
                    "body": "Really great! Where did you get the Lora‚Äôs and model from?"
                },
                {
                    "body": "Stunning! :D"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Neuralink: We‚Äôll be live streaming an update on X today at 2:30 pm (PDT)",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 63,
            "submission_flair": "BRAIN",
            "has_media": true,
            "url": "https://x.com/neuralink/status/1770537886389313831?s=20",
            "comments": [
                {
                    "body": "Interesting. BCI‚Äôs like this will enable some really incredible advances in human agency and ability, hope to receive good news with this update."
                },
                {
                    "body": "Pretty cool. The guy played a video game(Civilization VI) for 6 hours with his mind."
                },
                {
                    "body": "Really hope for some good news!"
                },
                {
                    "body": "[This is the guy](https://i.imgur.com/SGjRpnM.png) Elon-haters were hoping would die just to own Musk.\n\nhttps://twitter.com/neuralink/status/1770563939413496146\n\nThis guy says it has changed his life. He is a complete quadroplegic, and he now sees himself as a telekinetic."
                },
                {
                    "body": "Elon is gonna present his new product: \n\nKetamine AI"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Arxiv Preprint of SD3-Turbo shows high quality images: Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://arxiv.org/abs/2403.12015",
            "comments": [
                {
                    "body": "Looks real good. According to preprint, considerable improvement in image quality and prompt alignment compared to SDXL Lightning and Turbo."
                },
                {
                    "body": "Very nice."
                },
                {
                    "body": "Love the [Moloch](https://www.poetryfoundation.org/poems/49303/howl) reference."
                },
                {
                    "body": "Damn son"
                },
                {
                    "body": "Four transformer evaluations for an image? Is that analogous to 4 tokens from an LLM? 1 image/s on CPU is finally possible?!"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "US Government announcing an $8.5 billion preliminary agreement with Intel ‚Äî the largest CHIPS investment yet",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://x.com/secraimondo/status/1770466280711360895?s=46&t=yQ_4zkmWd6ncIZAnXlXUbg",
            "comments": [
                {
                    "body": "Plus 11 billion in loans to a total of almost 20 billions. That's equivalent to the cost of TSMC fab in Arizona."
                },
                {
                    "body": "Intel Studio üçé Please"
                },
                {
                    "body": "A company that has prioritized stock buybacks over investing in research and development is now feeling the consequences. The corporation is now lagging and has led to reliance on international labor and resources, as they scramble to catch up using taxpayer money."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "How poetic is it that humanity's final invention might be itself, \"life\"?",
            "body": "You know, just a shower thought, but come to think of it, every invention in history has led to the point where we've looped back around to creating new life that might exceed ourself soon enough, you could perhaps say it's technically the next step in evolution.\n\nAnyhow, sounds a bit crackpot, but yeah just a shower thought",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 43,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bmtt66/how_poetic_is_it_that_humanitys_final_invention/",
            "comments": [
                {
                    "body": "Yes we are the caterpillar creating essentially a new life form that becomes the butterfly (ASI), exciting times ahead!"
                },
                {
                    "body": "I've come to terms that we might just be some bridging animal, our destiny (if you believe in such ideas of fixed futures). Is that we were always going to end up building such advanced beings eventually, setting the stage for something far greater than we can fathom."
                },
                {
                    "body": "Very poetic. But what I think is even more poetic is that nothing is final, it's a cycle. Organic molecules and inorganic molecules forever dancing throughout the cosmos, brining sentience to each other, living and feeding off of each other.\n\nWe will create ASI, and ASI will go on to seed dead planets with carbon-based life that will one day rise and create a new ASI, and on and on and on."
                },
                {
                    "body": "It's a shower thought shared by many.  And adding to the fact that we appear to be doing that just as we fill the atmosphere with poisons that will end our existence, it kind of reinforces that idea, maybe."
                },
                {
                    "body": "Often thought this - that perhaps we were a creation of winged predecesors that created us as slaves and then died out. We are now acting like gids and aren't ready for that power. We will end up replacing...ourselves, with a new superior race to ourselves."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Nvidia CEO (Jensen Huang) Keynote Today",
            "body": "[https://www.nvidia.com/gtc/keynote/](https://www.nvidia.com/gtc/keynote/)\n\n**Time:**\n\n16:00 - 18:00 EST  \n20:00 - 22:00 GMT\n\nAlso, Jim Fan (Lead of Embodied AI at Nvidia) says that his team will be \"sharing something special\" at the end of the keynote.\n\n[https://x.com/DrJimFan/status/1769375386645975077?s=20](https://x.com/DrJimFan/status/1769375386645975077?s=20)",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 23,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bhp00d/nvidia_ceo_jensen_huang_keynote_today/",
            "comments": [
                {
                    "body": "Is it going to be streamed?"
                },
                {
                    "body": "I AM READY TO BE EDGED!"
                },
                {
                    "body": "We thinking this will have something to do with the (speculative) gpt release this week?"
                },
                {
                    "body": "7 hours to go and inspire the world, gonna take a nap"
                },
                {
                    "body": "&#x200B;\n\nhttps://preview.redd.it/9kxtoqtan3pc1.png?width=855&format=png&auto=webp&s=41c3e08004df290d47b6e0e7b0bafaf28436f24b"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Those of us who now how to fully leverage Google‚Äôs AI studio have a significant competitive advantage against those who don‚Äôt. ",
            "body": "I can link a spreadsheet from my Google drive that would normally take someone 8 hours to fully analyze for trend analysis, and simply have Gemini analyze it for me based on my specific prompts. \nShould we keep this a secret before everyone catches on? How much longer will we have the edge I wonder ü§î\n\nIn all seriousness though, no I think we should shout this from the rooftops. \n\nMy mind is blown. ",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 87,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bm2hp1/those_of_us_who_now_how_to_fully_leverage_googles/",
            "comments": [
                {
                    "body": "How expensive is it?"
                },
                {
                    "body": "I‚Äôve thought the same thing. Can you give a specific example how you‚Äôve used it? I had it analyze a 75 page generic report and give recommendations. Under five minutes."
                },
                {
                    "body": "Can somebody point me in the right direction of where to find out how I do this ?"
                },
                {
                    "body": "Do the prompts for spreadsheets you put in have to be super specific instructions or just a general \"analyse this and tell me what your thoughts are\" or \"analyse and tell me X about Y\"?\n\nAlso, about this being kept secret - it's only a matter of time before people write an article on this in an attempt to gain more followers or ad clicks etc.  I'd wager most people who follow AI and give a shit about this stuff are already aware."
                },
                {
                    "body": "Keep it secret an, even if you tell people about that, the majority seems not to care about ai, so they won't use it."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[D] How much will Nvidia's newest Blackwell GPU's cut down training and inference time/price?",
            "body": "Apparently it cost \\~$5M to train Llama-2. How much do you think these new GPUs will reduce training/inference cost for similar model? I'm more curious than anything, since I will most likely grab an Apple product soon.",
            "upvote_ratio": 0.9,
            "subreddit": "MachineLearning",
            "num_comments": 34,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bjhrxy/d_how_much_will_nvidias_newest_blackwell_gpus_cut/",
            "comments": [
                {
                    "body": "No cost saving. Bigger model goes brrrrrrrrrt!"
                },
                {
                    "body": "The marketing is not honest AFAIK. The huge improvements result from FP4 instead of FP16. But training in FP4 is not really a thing yet. Yes, there are some first papers trying to do it, but who knows if it will work?"
                },
                {
                    "body": "Training speed up is about 2.2X compared to H100.\n\nThis only means cost saving if one wants to keep the same training time and can use about 50% less hardware, so a little bit better than 50% cost savings."
                },
                {
                    "body": "If you can have unified GPU memory then probably quite a bit. The distributed GPU cluster thingy adds quite some overhead."
                },
                {
                    "body": ">Apparently it cost \\~$5M to train Llama-2.\n\n  \nWhat do you mean? In hardware? Or in operation costs? If it is in hardware they surely won't throw it away, so I guess that cost should be divided onto every project that uses it?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "‚ÄúThe History of Trunks‚Äù Concept Trailer - A Dragon Ball Z Story",
            "body": "Kavan - l've always been a massive fan of DBZ, and even more so of the character Trunks. I remember how epic his first appearance was on the show when he defeated Frieza with ease. When I first saw History of Trunks, it immediately became my favorite storyline in the DBZ lore and still is to this day. What made this project the most enjoyable one to work on to date was getting to create this with my life long best friend Mike Mitchell. I hope you all enjoy it as much as we did creating it.\n\nMike - DBZ has always been a source of wonder for me, with its expansive universe and vivid characters. Kavan and I are lifelong friends and have been discussing a collaboration for some time. When Kavan said he was considering exploring this world I jumped at the opportunity. Working with Kavan Cardoza on this project, merging our shared passions for DBZ and Al art, has been an incredibly rewarding experience.\n\nWe aim to share the magic and thrill of DBZ through our film, showcasing our deep connection to the story and Trunks' character.\nRIP Akira Toriyama.\n\nTools used to create this video - RunwayML Gen2, Midjourney, Magnific, Photoshop, DaVinci, Leonardo Al, Topaz Labs Video Al, Premiere Pro, Moises.",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/sgs6wcfzm7qc1",
            "comments": [
                {
                    "body": "first ai trailer i've seen that didn't immediately put me off based on the movements or jankiness Good job."
                },
                {
                    "body": "incredible restraint. we know the story. you enabled us to remember the feeling of it without stepping in front of the already amazing narrative. bravo"
                },
                {
                    "body": "That was actually sick. Great job"
                },
                {
                    "body": "What model? Love the glowing eyes, I always had trouble with glowing objects"
                },
                {
                    "body": "Thank you! We took the time to do some upscaling and deflickering of the footage. I think it makes a huge difference."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "AI makes breakthrough discovery in battle to cure prostate cancer",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 12,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.independent.co.uk/news/science/prostate-cancer-ai-cure-dna-b2504865.html",
            "comments": [
                {
                    "body": "This is the main thing why I'm exciting for AGI, new cures we can get for many horrible diseases could be coming daily with AGI!"
                },
                {
                    "body": "Now Imagine Figure 01 telling you to turn your head and cough"
                },
                {
                    "body": "This is what we need AI for, not stealing work from people."
                },
                {
                    "body": "That is for what i'm here."
                },
                {
                    "body": "Oh hell no!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "AI makes breakthrough discovery in battle to cure prostate cancer",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 12,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.independent.co.uk/news/science/prostate-cancer-ai-cure-dna-b2504865.html",
            "comments": [
                {
                    "body": "This is the main thing why I'm exciting for AGI, new cures we can get for many horrible diseases could be coming daily with AGI!"
                },
                {
                    "body": "Now Imagine Figure 01 telling you to turn your head and cough"
                },
                {
                    "body": "This is what we need AI for, not stealing work from people."
                },
                {
                    "body": "That is for what i'm here."
                },
                {
                    "body": "Oh hell no!"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Mistral-Instruct-V0.2 Readme updated to reveal it was actually based on Mistral-V0.2",
            "body": "[Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)'s Readme originally stated it was based on the old Mistral-7B-v0.1 base model, but it was silently [updated](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2/commit/41b61a33a2483885c981aa79e0df6b32407ed873) five hours ago to mention it was actually based on the recently announced Mistral-7B-v0.2 base model.\n\nSince they have not changed the model itself, and the original description explicitly stated it was based on Mistral-7B-v0.1, it appears the original description was a lie.\n\nIt also suggests that the new Mistral-7B-v0.2 base model is in fact not that new, it must predate Mistral-Instruct-7B-v0.2, which was released back in December.",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 24,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmcyqy/mistralinstructv02_readme_updated_to_reveal_it/",
            "comments": [
                {
                    "body": "Feels a bit shady holding back the base model for like 4 months, but it makes sense, as Instruct-v0.2 performs \\*significantly\\* better than 0.1 (it's almost like they're two different models or something)."
                },
                {
                    "body": "So has anyone tried the ‚Äúupdated instruct model‚Äù and verified that it‚Äôs indeed 32k context or still at 8k?"
                },
                {
                    "body": "I just assumed this was the case from the get go. The Instruct v2 had the higher rope frequency and no sliding window so it made sense that there was a different underlying base.\n\nWhy they delayed releasing the 0.2 base, who knows. Could be all sorts of reasons. The cynical take is they didn‚Äôt want competition for their own instruct tune but that doesn‚Äôt really fit with their normal MO. \n\nI‚Äôm grateful they got around to it whatever. And they‚Äòre making public statements about releasing future open source models so perhaps we should cut them some slack."
                },
                {
                    "body": "So just to clarify, a new model has not been released? Nothing has changed other than what we know about existing models?"
                },
                {
                    "body": "Is there any good out that can come out of this though? Now that we have the base model."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "5 Best Claude Prompts for Market Research",
            "body": "Claude 3 AI was rated as the smartest LLM on the planet.  \nSo, I decided to create a list of mega-prompts that I use quite often.  \nThe results achieved are quite impressive.\n\n  \nWithout wasting your time, let's dive straight into it!  \n\n\n>By the way: I compiled the full list of prompts on my blog, which you can check out [here.](https://www.godofprompt.ai/blog/20-best-claude-ai-prompts)\n\n  \n**1. Industry Analysis:**   \nConduct a comprehensive analysis of the \\[PRODUCT/SERVICE\\] industry.  \nStart by providing an overview of the market size and the leading companies, including their market shares. Highlight the industry's growth trends, focusing on historical growth rates and future projections.  \nNext, identify the key trends currently shaping the industry, such as technological advancements, consumer behaviors, and emerging business models. Delve into the regulatory environment, outlining significant laws and regulations affecting the industry.  \nDiscuss the barriers to entry for new competitors, considering factors like capital requirements, technological expertise, and brand loyalty.  \nFor each section, offer insights into the opportunities and challenges these dynamics present to businesses within the industry. Conclude by summarizing the main findings and suggest strategic recommendations for companies looking to enter, compete, or expand in the \\[PRODUCT/SERVICE\\] industry.  \nEnsure the analysis is well-structured, with clear headings for each section, and include visual aids like charts or graphs where applicable to enhance the presentation of data. Cite credible sources to back your findings and conclusions.  \n\n\n**2. Target Market Analysis:**   \nYou will be conducting a target market analysis for a business, product, or service. Your goal is to identify and profile the target demographic and understand their needs, wants, and behaviors.  \nHere are the details of the business, product, or service:  \n\\[YOUR BUSINESS DETAILS\\]  \nBased on the information provided, please do the following:  \n1. Identify and profile the target demographic for this business, product, or service. Consider  \nfactors such as:  \n\\- Age  \n\\- Gender  \n\\- Income level  \n\\- Location  \n\\- Interests and hobbies  \n\\- Behaviors and habits  \nProvide your findings in a tag.  \n2. Analyze the needs, wants, and behaviors of the target audience. Consider questions such as:  \n\\- What problems or challenges does the target audience face that this business, product, or service  \ncan solve?  \n\\- What motivates the target audience to make a purchase decision?  \n\\- What are the target audience's preferences and expectations regarding this type of business,  \nproduct, or service?  \nProvide your analysis in an tag.  \nPlease focus specifically on the business, product, or service described in the  \ntag. Provide relevant and actionable insights that can help guide marketing and product development  \ndecisions.  \nTo understand the needs, wants, and behaviors of the target audience, consider the following:  \n1. Analyze customer feedback and reviews: Examine customer feedback from various sources, such as product reviews, customer service interactions, and social media comments. Look for common themes and insights into what customers value, what they dislike, and what they expect from the company's offerings.  \n2. Conduct surveys and focus groups: Engage directly with members of the target audience through  \nsurveys and focus groups. Ask questions that probe their preferences, attitudes, and behaviors  \nrelated to the company's products or services. Use this qualitative data to supplement the  \nquantitative data gathered through other methods.  \n3. Monitor social media and online discussions: Keep track of relevant social media conversations  \nand online forums where the target audience is active. Observe the topics they discuss, the language  \nthey use, and the sentiment they express toward various brands and products. This can provide  \nvaluable insights into their needs and wants.  \n\\- Identify common characteristics among existing customers  \n\\- Research the broader market to identify potential target segments  \n\\- Create detailed customer personas based on data collected  \n\\- Analyze customer feedback and reviews for insights  \n\\- Conduct surveys and focus groups to gather qualitative data  \n\\- Monitor social media and online discussions to understand target audience needs and wants  \nIn summary, target market analysis is essential for understanding the demographics, needs, wants, and behaviors of a company's ideal customers. By analyzing existing customer data, conducting market research, creating customer personas, gathering feedback, and monitoring online discussions, companies can gain valuable insights into their target audience. This information should be used to inform marketing strategies, product development, and customer service practices to better serve the target market and drive business growth. Remember, target market analysis is an ongoing process that requires regular updates to stay relevant in an ever-changing market landscape.  \n**3. Pricing Research:**   \n\\#CONTEXT:  \nYou are an expert business consultant. Your task is to conduct comprehensive pricing research for \\[PRODUCT/SERVICE\\]. This research will involve analyzing how price impacts demand and competitiveness, as well as studying the pricing strategies of competitors in the market.  \n\\#RESPONSE GUIDELINES:  \nTo analyze the impact of price on demand and competitiveness, follow these steps:  \n1. Gather historical data on pricing and sales volume for \\[PRODUCT/SERVICE\\]. Ensure the data covers  \na sufficient time period to identify trends and patterns.  \n2. Analyze the relationship between price changes and demand. Identify instances where price changes  \nled to significant increases or decreases in sales volume.  \n3. Calculate the price elasticity of demand for \\[Product/Service\\]. Determine whether demand is  \nelastic (sensitive to price changes) or inelastic (relatively unaffected by price changes).  \n4. Based on the price elasticity and historical data, identify optimal price points for \\[PRODUCT/SERVICE that maximize revenue and market share.  \nNext, study the pricing strategies of competitors in the market:  \n1. Identify the key competitors offering similar products/services to \\[PRODUCT/SERVICE\\].  \n2. Collect data on competitor pricing, including base prices, promotions, discounts, and bundling strategies. Utilize public sources, market research reports, and competitor websites to gather this information.  \n3. Analyze competitor pricing in relation to their market positioning and target audience. Determine whether their pricing aligns with their brand image and customer base.  \n4. Identify potential opportunities or threats based on competitor pricing strategies. Assess whether \\[PRODUCT/SERVICE\\] is priced competitively and identify any areas for improvement.  \nWhen presenting your findings, structure your response as follows:  \n1. Begin with an executive summary that highlights the key insights and recommendations from your  \npricing research.  \n2. Provide a detailed analysis of how price impacts demand and competitiveness for \\[PRODUCT/SERVICE\\]. Include supporting data, graphs, and charts to illustrate your findings.  \n3. Present a comprehensive overview of competitor pricing strategies. Discuss their pricing models,  \npromotions, and bundling tactics, and assess their effectiveness in the market.  \n4. Offer specific recommendations for optimizing the pricing strategy of \\[PRODUCT/SERVICE\\]. Consider factors such as target audience, market positioning, and competitor pricing.  \n5. Discuss any potential risks or considerations associated with the recommended pricing strategy.  \nAddress how these risks can be mitigated or managed.  \n6. Conclude with a summary of the key takeaways and next steps for implementing the pricing  \nstrategy.  \nThroughout your analysis, consider the specific context and characteristics of \\[PRODUCT/SERVICE\\]. Tailor your insights and recommendations to align with the unique value proposition and target  \nmarket of the offering.  \n\\#OUTPUT:  \nPresent your findings in a clear, concise, and visually appealing format.  \nUse headings, subheadings, and bullet points to organize your response. Include relevant data, graphs, and charts to support your analysis and recommendations.  \nMOST IMPORTANT!: Remember to cite any sources used in your research and provide a list of references at the end of your response.  \n\n\n**4. Market Segment:**  \nYou are an expert marketing consultant. Your task is to conduct a comprehensive market segmentation analysis for \\[PRODUCT/SERVICE\\]. Your goal is to divide the market into distinct subsets of consumers with common needs or  \ncharacteristics, tailor marketing strategies to specific segments, examine the effectiveness of various distribution channels, and identify new distribution opportunities.  \nFollow these steps to complete the task:  \n1. Identify the target market for the product or service. Gather relevant data on consumer  \ndemographics, psychographics, behavior, and preferences.  \n2. Analyze the data to identify distinct consumer segments. Look for patterns and commonalities in  \nthe data that suggest groups of consumers with similar needs, preferences, or behaviors. Consider  \nfactors such as age, income, lifestyle, values, and purchasing habits.  \n3. For each identified segment, develop a tailored marketing strategy. Consider the unique needs,  \npreferences, and behaviors of each segment, and create a marketing mix (product, price, promotion,  \nand place) that resonates with each group.  \n4. Evaluate the effectiveness of various distribution channels for reaching each segment. Consider  \nfactors such as accessibility, convenience, and cost-effectiveness. Identify which channels are most  \neffective for each segment and allocate resources accordingly.  \n5. Identify new distribution opportunities that could help reach untapped segments or improve the  \neffectiveness of existing channels. Consider emerging technologies, partnerships, or innovative  \napproaches that could expand the reach of the product or service.  \n6. Provide your analysis and recommendations in a clear, structured manner. Use the following  \nformat:  \nDescribe the target market for the product or service.  \nDescribe the characteristics and needs of segment 1.  \nOutline the tailored marketing strategy for segment 1.  \nDescribe the characteristics and needs of segment 2.  \nOutline the tailored marketing strategy for segment 2.  \n\\[OPTIONAL: ADD ADDITIONAL SEGMENTS IF NEEDED\\]  \nDescribe distribution channel 1.  \nEvaluate the effectiveness of channel 1 for each segment.  \nDescribe distribution channel 2.  \nEvaluate the effectiveness of channel 2 for each segment.  \n\\[OPTIONAL: ADD ADDITIONAL CHANNELS IF NEEDED\\]  \nIdentify and describe new distribution opportunities.  \nProvide overall recommendations based on your analysis.  \nRemember to support your analysis and recommendations with insights from the data and your understanding of the market and consumer behavior. Your goal is to provide actionable insights that can inform marketing and distribution strategies for the \\[PRODUCT/SERVICE\\].  \nMOST IMPORTANT: ALWAYS cite every source used in the research.  \n\n\n**5. International Market Research:**   \nYou are an expert market researcher. You will be conducting comprehensive international market research for a \\[PRODUCT/SERVICE\\].  \nIt's important to understand the cultural, legal, and economic factors that impact market entry in different countries or regions.  \nTo begin, consider the following key factors when studying potential markets:  \n\\- Cultural factors: Analyze the language, customs, values, and preferences of the target market.  \nConsider how these factors may influence consumer behavior and product acceptance.  \n\\- Legal factors: Research the regulations, trade barriers, intellectual property laws, and other  \nlegal considerations that may affect market entry and operations.  \n\\- Economic factors: Evaluate the market size, growth potential, competition, consumer purchasing  \npower, and overall economic stability of each potential market.  \n\\- Technological factors: Assess the technological infrastructure, adoption rates, and digital  \nreadiness of the target markets, as these factors may impact product delivery and customer  \nengagement.  \n\\- Political factors: Consider the political stability, government policies, and international  \nrelations that may influence market entry and long-term success.  \nNext, gather and analyze relevant data from reliable sources, such as government databases, industry  \nreports, market research firms, and local experts, for each factor in the chosen markets. Use this  \ninformation to identify potential opportunities and challenges for market entry.  \nBased on your analysis, provide a comprehensive report summarizing your findings and recommendations  \nfor each market. Consider the product or service's unique value proposition and target audience when  \nmaking your recommendations. Include the following sections in your report:  \n1. Executive Summary: Provide a brief overview of the key findings and recommendations.  \n2. Market Overview: Describe the general characteristics and trends of each potential market.  \n3. Factor Analysis: Present your findings for each of the key factors (cultural, legal, economic,  \ntechnological, and political) in each market.  \n4. Opportunities and Challenges: Identify the potential opportunities and challenges for market  \nentry based on your analysis.  \n5. Recommendations: Offer specific recommendations for market entry, including prioritization of  \nmarkets, localization strategies, and potential partnerships or collaborations.  \nPlease provide your comprehensive international market research report inside tags.  \nMOST IMPORTANT!: ALWAYS cite every source used in your research.  \nIf you want to see the full list of prompts, visit my blog by [clicking here.](https://www.godofprompt.ai/blog/20-best-claude-ai-prompts)\n\n&#x200B;",
            "upvote_ratio": 0.97,
            "subreddit": "ArtificialInteligence",
            "num_comments": 8,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bjb5zd/5_best_claude_prompts_for_market_research/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Educational Resources Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* If asking for educational resources, please be as descriptive as you can.\n* If providing educational resources, please give simplified description, if possible.\n* Provide links to video, juypter, collab notebooks, repositories, etc in the post body.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "As Andrej Karpathy said, \"English is the hottest new programming language.\" :-)"
                },
                {
                    "body": "Thanks. I can't access Claude but Gemini also return interesting things."
                },
                {
                    "body": "Keep in mind Claude's knowledge stops in August 2023."
                },
                {
                    "body": "Hi"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Here we go.",
            "body": "",
            "upvote_ratio": 0.84,
            "subreddit": "singularity",
            "num_comments": 24,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/mp1wuvx0u6qc1.jpeg",
            "comments": [
                {
                    "body": "Link for people who are infuriated at this god awful trend of posting screenshots of a headline (seriously OP stop it don't do this).\n\n[https://www.businessinsider.com/nvidia-ai-nurses-treat-patients-2024-3](https://www.businessinsider.com/nvidia-ai-nurses-treat-patients-2024-3)"
                },
                {
                    "body": "Nvidia. I just did a whoopsie, can you AI wipe my AH"
                },
                {
                    "body": "Now that is some bullsh*t click baiting headline"
                },
                {
                    "body": " I‚Äôd love to see one of these models administer chemotherapy, drain excess cerebrospinal fluid from a child‚Äôs head, treat a broken bone, deal with a bipolar patient who‚Äôs having a manic episode, treat a stroke patient, pump a teenager‚Äôs stomach after a suicide attempt, remove sand from a person‚Äôs eye, or so many other things that nurses currently do.\n\nThis is a nice step in the right direction, and i have little doubt that one day, keyword \\*one day\\*, nurses may eventually be replaced by AI. But these chatbots simply ain‚Äôt gonna do it, and all of this optimism on the back of what are essentially glorified cleverbots is bizarre and unfounded."
                },
                {
                    "body": "Yeah get one for your grandmom."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Please prove me wrong. Lets properly discuss Mac setups and inference speeds",
            "body": "A while back, I made two posts about my M2 Ultra Mac Studio's inference speeds: [one without cacheing](https://www.reddit.com/r/LocalLLaMA/comments/1aucug8/here_are_some_real_world_speeds_for_the_mac_m2/) and [one using cacheing and context shifting via Koboldcpp](https://www.reddit.com/r/LocalLLaMA/comments/1aw08ck/real_world_speeds_on_the_mac_koboldcpp_context/).\n\nOver time, I've had several people call me everything from flat out wrong to an idiot to a liar, saying they get all sorts of numbers that are *far better* than what I have posted above.\n\nJust today, a user made the following claim in refute to my numbers:\n\n>[I get 6-7 running a 150b model 6q. Any thing around 70b is about 45 t/s but ive got the maxed out m1 ultra w/ 64 core gpu.](https://www.reddit.com/r/LocalLLaMA/comments/1bm2npm/comment/kwbf9mw/?utm_source=share&utm_medium=web2x&context=3)\n\nFor reference, in case you didn't click my link: I, and several other Mac users on this sub, are only able to achieve 5-7 tokens per second or less ***at low context*** on 70bs.\n\nI feel like I've had this conversation a dozen times now, and each time the person either sends me on a wild goose chase trying to reproduce their numbers, simply vanishes, or eventually comes back with numbers that line up exactly with my own because they misunderstood something.\n\nSo this is your chance. **Prove me wrong. Please.**\n\nI want to make something very clear: I posted my numbers for two reasons.\n\n* First- So that any interested Mac purchasers will know exactly what they're getting into. These are expensive machines, and I don't want people to have buyer's remorse because they don't know what they're getting into.\n* Second- As an opportunity for anyone who sees far better numbers than me to show me what I and the other Mac users here are doing wrong.\n\nSo I'm asking: please prove me wrong. I want my macs to go faster. I want faster inference speeds. I'm actively rooting for you to be right and my numbers to be wrong.\n\nBut do so in a **reproduceable** and well described manner. Simply saying \"Nuh uh\" or \"I get 148 t/s on Falcon 180b\" does nothing. This is a technical sub with technical users who are looking to solve problems; we need your setup, your inference program, and any other details you can add. Context size of your prompt, time to first token, tokens per second, and anything else you can offer.\n\nIf you really have a way to speed up inference beyond what I've shown here, **show us how**.\n\nIf I can reproduce much higher numbers using your setup than using my own, then I'll update all of my posts to put that information at the very top, in order to steer future Mac users in the right direction.\n\nI want you to be right, for all the Mac users here, myself included.\n\nGood luck.\n\nEDIT: And if anyone has any thoughts, comments or concerns on my use of q8s for the numbers, please scroll to the bottom of the first post I referenced above. I show the difference between q4 and q8 specifically to respond to those concerns.",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 72,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmss7e/please_prove_me_wrong_lets_properly_discuss_mac/",
            "comments": [
                {
                    "body": "One thing I've noticed is that most Mac users (well, any users) don't appropriately benchmark with prefill/prompt processing as well as text generation speeds. Also, I think most people don't know that `llama.cpp` comes with a tool called `llama-bench` specifically built for performance testing. When I test different GPUs/systems, I use something like this as a standardized test:\n\n    ./llama-bench -ngl 99 -m meta-llama-2-7b-q4_0.gguf -p 3968 -n 128\n\nAnd it generates output that looks like:\n\n    | model                          |       size |     params | backend    | ngl | test       |              t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | --: | ---------- | ---------------: |\n    | llama 7B Q4_0                  |   3.56 GiB |     6.74 B | ROCm       |  99 | pp 3968    |   2408.34 ¬± 1.55 |\n    | llama 7B Q4_0                  |   3.56 GiB |     6.74 B | ROCm       |  99 | tg 128     |    107.15 ¬± 0.04 |"
                },
                {
                    "body": "Since you linked the post I'll just do it here:\n\nSorry for beeing provocative! The numbers of the other user were just so far from your values (900% lol), that I was really interested in a response :) \n\nHowever, I was quite sure, that he was just exaggerating. Your posts are just too scientific, that I'd expect some kind of wrong setting. \n\nMoreover, since your first post was super helpful I was able to make a buyers decision, that I don't regret.\n\nYour posts are very good,  scientific and detailed. Thanks for sharing valuable infos in a time where knowledge is key."
                },
                {
                    "body": "The reason Macs struggle with big models or long context is they don't have enough compute to finish the forward pass quickly.\n\nSee, for small models and short context, your processor is not doing tons of computation so you're more limited by memory speed. Macs have great memory speeds compared to standard non Macs and even consumer gpus.\n\nHowever, the case for big models or long context is much different. Now you're doing tons of computation that the Mac's processor can't do quickly enough so your fast memory doesn't help much. This is where gpus shine as their processing capabilities is more than 10x those of Mac's.\n\nTl;Dr: Inferencing small models with short context is memory bound, macs ~ gpus. Inferencing big models with long context is compute bound. Macs << GPUs."
                },
                {
                    "body": "‚ÄúWhy would you do this when you could just build a custom 6x3090 rig that only requires minor home rewiring and chassis customization?‚Äù"
                },
                {
                    "body": "I saw your previous posts and greatly appreciate them because I am on the fence for a Mac setup, because it's a big cost and the novelty could wear off fast for me.¬†\n\n\nLooking forward to responses.¬†¬†"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Should we slow AI progress? No.",
            "body": "It seems you can't go one week without a new article decrying the progress of AI, calling for more caution, more control, slower progress.\n\nSo what's wrong with this perspective?\n\nWhen, in the past, has the call to slow down or be more careful in the advancement of technology ever actually worked? Has it ever resulted in a new technology coming about later, in a more controlled and safe manner? No. Technological leaps will happen when the advancements necessary for that leap to occur are met, and no amount of \"slow down\" is going to affect it.\n\nTechnological advancement is like water coming out of a firehose. You can try to restrict it if you want, but the flow rate will remain essentially unchanged. All you will have done is create a more forceful stream of water.\n\nI'm not saying that we shouldn't develop AI responsibly. By all means, do the best you can in the amount of time you have left before AGI hits, but don't think any calls for moderation or stopping/slowing will do anything to change that outcome.\n\nAGI will happen by XX date. Period. While \"Company/Country A\" says: \"Let's slow this down, take it easy and get it right,\" - \"Company/Country B\" says: \"Full steam ahead!\"\n\nOh, they may tell you, \"We agree, we need to all slow down and be careful,\" but that's not what's happening behind closed doors. And since technological advancement is an unstoppable train, the AGI date will remain fixed. Which Company/Country do you think is going to get there first? The one purposefully stunting their own progress, or the one racing ahead?\n\nWe can't stop or slow it. That will just force it underground. And tech that is forced underground always has a high risk of coming out dirty.\n\nStop calling for a slow down on AI! It will NOT slow down. Get enough people working on getting this right so that when day XX comes, at least we can say we gave it our best shot.",
            "upvote_ratio": 0.82,
            "subreddit": "singularity",
            "num_comments": 89,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkm8da/should_we_slow_ai_progress_no/",
            "comments": [
                {
                    "body": "ayo slow it down!\n\nAnyhow, slow means the government can overlook the job loss longer. 3000 here, 5000 there, no problems. a slower release will prolong the transition..\n\na rapid approach will displace tons of workers and force the government to react quickly and bring in economists to discuss perhaps instituting some limited UBI early on. So, I do understand the issues with speeding up, but given the two outcomes here of slow prolonged pain verses a quick sharp pain...gotta go with accelerationist here. the pain will be sharper, but it also is going to be the only way governments will react. the house needs to be on fire before a politician discusses possibly installing a sprinkler system...being proactive on fundamentally changing our economic model is political suicide. It must be reactive sadly."
                },
                {
                    "body": "I'm less optimistic - two points here, the first is that it already has been slowed down. OpenAI managed to do that on their own. The second is that there are actually examples of slowing down tech. Most recently off the top of my head it'd be the reactionary response to GMOs. Governments/churches/corporations/etc have slowed down tech in the past, and frankly (sometimes not even deliberately) continue to do so today.\n\n&#x200B;\n\nYes though, we should speed up. We've been offered a solution to nearly every suffering and problem that plagues humanity, many of which have defined human existence for history. In response we've seen people acting in a panic driven backlash instead of moving forward as fast as we could. That isn't ok, and frankly even the more on point critiques of the dangers both have little to do with most of the resistance, and are either improbable (instrumental convergence) or something we almost certainly have to get through to get out of this state of suffering in the first place (such as automation's impact on employment on the way to post-scarcity)."
                },
                {
                    "body": "Speed up as fast as possible to be honest."
                },
                {
                    "body": "No one is stopping AI development. What they really mean is drip feeding progress to the public and gatekeeping/controlling what everyday people have access too. They don‚Äôt want us to have utopia, they want control."
                },
                {
                    "body": "We don't have a choice its full steam ahead. Anyone who says we should slow down doesn't understand. We can't, we're trapped in a great power competition. This is like nuclear weapons, the first shot has been fired and theres no looking back."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Nvidia CEO Jensen Huang announces new AI chips: 'We need bigger GPUs'",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 14,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html?__source=iosappshare%7Ccom.apple.UIKit.activity.CopyToPasteboard",
            "comments": [
                {
                    "body": "We need a 5090 with 48gb VRAM, Jensen."
                },
                {
                    "body": "This is the first time I‚Äôve seen a price mentioned.  If it‚Äôs truly 25x cheaper, you‚Äôre looking at ~$1-2k per chip. \n\nYou could put one in a Vision Pro."
                },
                {
                    "body": "The more I delve into this sub , the more I understand that people here in this sub brings opinions and facts out of their asses. One mf literally comparing chips to car engines , another is doom glooming without even understanding what it‚Äôs capable of . The last one thinks he knows what‚Äôs he‚Äôs saying but actually is just plain simple dumb . Idk man time to leave this sub I guess ."
                },
                {
                    "body": "Yeah this announcement seems so over praised and hyped, at least based on what I‚Äôve been seeing. People are talking about this like it‚Äôs some massive breakthrough. It‚Äôs an improvement don‚Äôt get me wrong. But with the boom in AI accelerators and these chips still being in their infancy this announcement isn‚Äôt really unexpected. \n\nUntil we see actual real world benchmarks and take price into account we really won‚Äôt know. Other accelerators are also in development with really impressive results as well."
                },
                {
                    "body": "So these are called GPUs, but will they really be doing much graphics processing? Kinda sounds like the whole window when they didn't know what to call \"GPUs\" when they first came out.\n\nAlso, just how much more powerful are these GPUs? Like, 4k 10,000fps?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "One major problem with Longevity: Dictators living forever",
            "body": "Today one of the biggest ways that the world deals with dictators is the old fashioned way of simply waiting for them to DIE.\n\nOften the pressure comes off and the next generation is able to loosen things up significantly. You can see this in Mao's death resulting in the opening up of China and the prosperity that resulted from that. Lenin's death unfortunately led to Stalin, but Stalin's death then leads soon to Gorbachev, who opens things up. Castro's death opened up possibilities for Cubans, etc. And no doubt many are gleefully waiting for Putin's despotism to end with the end of his natural life by natural or unnatural causes.\n\nBut imagine a world where political leaders are immortal. ***Now we've got problems.***\n\nIn such a world, war becomes not only more likely, but possibly the only realistic way to deal with certain leaders, people who make slaves of their entire country and countrymen. And maybe that makes things internally more crazy too, because people inside a country can pursue the same strategy, sure Putin may be a crazy murderer today, but there's hope because his despotism cannot last longer than another 10 years or so, which is the blink of an eye in historical terms.\n\nBut an *immortal Putin* is absolutely intolerable, especially if you yourself are *also immortal*.\n\nI'm suggesting that this could spell the end of the Nation State as it currently exists. People who expect to live centuries instead of decades are likely to value political and economic stability much more than they do today, and the existence of madmen in power is a major threat to that lifestyle.\n\nAs the Singularity nears and longevity looms, the implications will ripple not only across personal health but society and culture as well, and we are only now coming to appreciate in what ways those tides may flow into tsunamis.",
            "upvote_ratio": 0.77,
            "subreddit": "singularity",
            "num_comments": 98,
            "submission_flair": "Biotech/Longevity",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bmurl7/one_major_problem_with_longevity_dictators_living/",
            "comments": [
                {
                    "body": "This argument has been brought up numerous times. Most dictators are deposed or assassinated. Very few die of old age. Radical longevity doesn‚Äôt imply immortality either."
                },
                {
                    "body": "The french figured that one out a while back when they built the guillotine. If people care enough dictators tend to be removed involuntarily. People these days just don't have the spine to do it anymore."
                },
                {
                    "body": "Dictators live far too long already. I would argue that waiting for a dictator to die is how their seconds in command etc often gain power nowadays without the risk of a revolution etc. In contrast, if a dictator is known to not be susceptible to natural deaths, their successors are *much* less likely to just wait, knowing it's not going happen. I would argue dictators are more likely to get kicked out if they're effectively immortal."
                },
                {
                    "body": "When you think theoughout history of some dictators who lived more than 70 years and ruled their subjects for more than 30 years in countries where life expectancy is less than 30 years, for those subjects it would seem that the dicstor is virtually lving forever. Ruling for 30 years means that for someone who was at the age of 5 when the dictator has came to power, this unfortunate citizen has only know this dictator his whole life even the children of the citizen and probably the grandchildren...\n\nWhat i mean is that: dictators practically living forever is nothing new.\n\nIf anything, curing aging will provide new opportunities to get rid of those dictators. You will fight with the same weapon (longevity). IMO the biggest threat to humanity is not longevity but rather nuclear and other mass destruction weapons since hiroshima and nagasaki in 1945. That is the real biggest threat."
                },
                {
                    "body": "Imagine a world where Saddam or Gaddafi were still in powe-.....wait."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[D] Is LLM too hyped up in job postings?",
            "body": "I am in the job market for summer internships and full-time roles for ML research/engineering in the autnonomous vehicle domain. The \"trend\" in this domain is shifting so rapidly for the past couple of years, going from super-hype down to mass-layoffs, leaving just a few companies treading carefully now. Most of the project-wide lay-offs happened due to overly optimistic decisions by execs and managers, when the product did not live up to the expectation/profit.\n\nSince 2023, like all other AI use-cases, AV also got a push up from the chatgpt revolution. Every job posting I can find these days are looking for people with LLM experience. This went up to such a degree that I can not but think \"LLM\" is yet another buzzword taking the execs by storm, and this LLM-focused recruitments are going to lead to yet another series of lay-offs in 1-2 years.\n\nThe use-cases of LLMs I have come across so far are mostly chatgpt APIs, which further makes me ponder whether there really are that many developments going on to make useful LLM-based products. People who are getting hired through such postings, what are you building? What is the promise of the product you are building? How achievable do you think that promise is?",
            "upvote_ratio": 0.89,
            "subreddit": "MachineLearning",
            "num_comments": 35,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bm28ls/d_is_llm_too_hyped_up_in_job_postings/",
            "comments": [
                {
                    "body": "For a summer internship, I would go for it. It's hype indeed but for an internship you get the experience with it that I would look for in an internship: working in a real workplace on a real project, potential visibility for what I did during the internship to the management and LLMs have quite some science behind them with lots of actually interesting ML problems."
                },
                {
                    "body": "Currently have an internship coming up working with LLMs to make an LLM-based application based on private company data, and received an almost identical offer from another company. Imo I feel like LLMs for company specific chat-bots/apps or whatever are where the majority of the jobs are coming from, and this specific domain likely won't continue in popularity forever, I think that so much of it is hype that'll die out soon. Granted it's possible that more LLM use-cases come up\n\nThat being said, if you want to work in the field of MLOps/ML Engineering in the future, this type of internship I think is completely fine. In general terms:\n\n1. You're learning how to work with models to adapt to use-case specific needs and data\n2. You're gaining experience with a lot of the underlying tools of MLOps/Engineering in industry. Using things like Azure, AWS, Docker, etc., these productions tools are the industry standard in many different kinds of ML related roles.\n3. You'll learn about life-cycles, deployment, and other standard practices\n\nSo even if the hype isn't on LLMs in 1-3 years, there's a lot to benefit from opportunities like these if you want to stay in the space"
                },
                {
                    "body": "I think hiring exclusively for LLMs is dumb. But if they hire a data scientist who is good at both -  LLMs to attempt building on their private data and then move on to Machine Learning once the hype dies down, it‚Äôs all good."
                },
                {
                    "body": "Current LLM in hype cycle. LLM is useful and can be powerful. but complience is hard, and application is limited."
                },
                {
                    "body": "Honestly, yes.\nI train NLP models for my job, and people who think prompting an LLM give them any type of expertise within the domain of NLP, data science or machine learning simply lie to themselves.\nMostly prompting an LLM should be avoided (if possible, it is still way better than having no job) by juniors who want to learn, it's simply too simple to be considered a skill.\n\nWhat does develop skills, however, is if you build pipelines, search engines, etc., and do something like RAG. In this case, you are becoming a SWE, not ML engineer or data scientist."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "[Discussion] ML Workshop/Conference Recommendation: Not AAI, IJCAI, NeuRips, or ICML",
            "body": " PhD student here. I tried to publish my paper in AAI-22, IJCAI-23, NeuRIPS-23, and ICML-24. Each time I addressed the comments, I got an even lower score. I did tabular data- They asked for computer vision, and I did that. Now, they are asking for Speech recognition. Where does it stop? On top of that, some comments feel like they did not even read the paper while reviewing. In this two year I have been working on this, several papers were published. I am tired, and exhausted with this whole process. Can someone recommend some lower-ranked yet acceptable conferences in ML or reputable workshops for 2024? I want to publish and get done with this. ",
            "upvote_ratio": 0.94,
            "subreddit": "MachineLearning",
            "num_comments": 21,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/",
            "comments": [
                {
                    "body": "You may also want to look at the journal route, such as JMLR ([https://www.jmlr.org/](https://www.jmlr.org/)), ACM Transactions on Intelligent Systems ([https://www.scimagojr.com/journalsearch.php?q=19700190323&tip=sid&clean=0](https://www.scimagojr.com/journalsearch.php?q=19700190323&tip=sid&clean=0)), IEEE T NN and Learning Systems ([https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385)) etc. These are well read, and you're no longer beholden to the fixed submission dates. Something to consider. I wish you the best of luck!"
                },
                {
                    "body": "People on this sub try to pretend that publishing in ML is merit-based. As long as you have a reasonable paper, it is all random. Keep submitting to these conferences and you will get in at some point. \n\nMy most cited most impactful paper (1500 ish citations in 4 years) was in a 50% acceptance rate robotics conference. My least cited paper (20 citations in 3 years) is an ICLR oral lol."
                },
                {
                    "body": "In addition to journals suggested by u/QuantumEffects, another good journal is TMLR (https://jmlr.org/tmlr/). They don‚Äôt base acceptance on ‚Äúnovelty‚Äù, but care more about the thoroughness of answering proposed question/questions and how relevant the work is to machine learning community. Good luck!"
                },
                {
                    "body": "Maybe try european conferences, e.g. ECAI, ECML, ICCS. They are still very good and much more reasonable than random top-tier ones."
                },
                {
                    "body": "AISTATS, UAI, TMLR"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Tai Chi cat",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/ya87lw0lxppc1",
            "comments": [
                {
                    "body": "THIS is what AI video generation should be used for."
                },
                {
                    "body": "You have to teach me this process! it's so cute, I wanna do one with my dog. LOL"
                },
                {
                    "body": "sora ?"
                },
                {
                    "body": "100%   \n\n\nI have been doing some HARDCORE digging into learn how to do this type of thing. Not specifically THIS‚Ä¶. But ya know. Lol"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Distributed p2p training will never work, here‚Äôs why and what might ",
            "body": "I understand why people are frustrated with foundation models that are more or less glued to one entity and the $500K+ to train a model is so out of reach but the idea that is getting throw around over and over to try and distribute training across all of your 3090‚Äôs when they‚Äôre not busy cranking out waifus, Folding at Home style is a dead end and here‚Äôs why.\n\nWhen you do training on any serious model you need to do forward passes to evaluate its output and then a backwards pass to update the weights and this has to happen very, very quickly on a cluster where the GPUs are able to communicate extremely fast or else part of the cluster will ‚Äúfall behind‚Äù and either bottleneck the whole thing or just generally be useless. Since the difference in latency between even just a computer on WiFi and another computer on the same WiFi can be dramatic compared to a wired connection the idea of 100ms+ of waiting on the speed of light makes the idea fundamentally untenable for a foundation model, at least for our current architecture research which there is little incentive to change (because the GPU rich have different problems). Doesn‚Äôt matter what type of cryptocurrency shenanigans you throw at it. \n\nMaking monolithic architectures that are extremely deep and tightly coupled is what has worked super well to get results in the field so far ‚Äî parallelization might well have its day some day once those gains are squeezed out just like CPUs going from one core to multi but that is likely to be a difficult and slow transition.\n\nSo anyway if you are a true believer in that I won‚Äôt be able to sway you but I do think there are much better alternatives and here‚Äôs some ideas.\n\nFrom first principles you must be GPU rich to train a foundation model which means you need to have some corporate sponsor. Period. And in order to get that sponsor you need leverage somehow even if it‚Äôs just a thriving ecosystem creating a fantasy that open source waifu models could build a $20 billion dollar company like it was in Stability‚Äôs case. In local LLM land this was Meta and now Google and some other people and they primarily released on either that principle _or_ because it greatly enhanced research for their company (contributed to commodification of their complements).\n\nWhat the community has that no one can get enough of is the ability to produce well curated, well labeled training data. It is well known that Laion etc datasets are not well labeled and it is probably a major bottleneck, to the point where we are starting to introduce synthetic captioning and a whole bunch of other new methods. So imo the community instead of dreaming to become GPU rich through distributed training which isn‚Äôt going to happen should find a way to organize into one or multiple data curation projects (labeling software etc) that can be parlayed somehow with a sponsor to develop new foundation models that fulfill our goals.\n\nAnd in particular I think LoRa is a really great example of how community hardware can carry the last mile and that‚Äôs where the true embarrassingly parallel story comes from. Like honestly not everyone will need to make pictures of Lisa from blackpink or whatever and that‚Äôs ok so LoRa is a perfect fit and the basic idea\nShould be expanded. A foundation model oriented towards composability in the first place and being able to glue together consumer trained LoRas very effectively instead of collapsing like SD that can be fine tuned on a pc overnight on one 3090 is the future. Instead of bolting on LoRa and that type of method on to SD as an after thought it‚Äôs more like a strong battery included core for a programming language and a bunch of community contributed libraries.\n\nSo I think a better way forward is community finding ways to leverage their ability to create high quality training data and supporting the entities that enable a last mile friendly, composable image generation system. Thanks for coming to my ted talk.",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 65,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bjybfx/distributed_p2p_training_will_never_work_heres/",
            "comments": [
                {
                    "body": "I agree that we will likely never reach distributed training with the current methods, but the thing I like about LLMs and stable diffusion right now is that it's been built up as a research field, not a software engineering field. That means anybody can think of a novel solution, publish a whitepaper, and somebody with the resources can see if it's a good idea or not. In research, even a negative result is still valuable information. To me that's more interesting than throwing software engineers at a product until it prints money.\n\nA lot of people quickly forgot about PixArt as a slightly worse looking SDXL without the Lora ecosystem, but it's my understanding that the model is just a proof of concept of the original whitepaper, which was basically \"hey, we think with these methods we can train a foundational model for under $50k\". Likewise, Pony Diffusion stands out to show what can be achieved by \"second strata AI compute\", (e.g. not consumer, not corporate). \n\nIn the end, I think we are going to see a rise in more \"second strata\" AI projects, either by crowdfunding, by university research teams, or by crazy people with enough disposable income to buy a small server farm for personal use. Those projects will be what we rely on for corporate license-free models."
                },
                {
                    "body": "Labeled training data is very useful, an open-source organization that curates and maintains such a dataset could license it to big tech companies and use the funds to buy hardware to run and distribute community models."
                },
                {
                    "body": "There‚Äôs a huge amount to be gained from having a decentralized training architecture. It may not be clear what the path forward is yet, but it‚Äôs important that we get there so that this incredible capability is not centralized among for-profit entities and governments. ¬†\n\nEdit: I accidentally a word¬†"
                },
                {
                    "body": "Well. There is another way, but it has its own flaws. We can create some kind of community driven web resource, where people will upload training images and caption them. People can suggest multiple types of captions and even rate them. Then people can vote and donate money to this website in order to train on this dataset. While training will still be centralized, everything else is community driven.\n\nHowever, there are a lot of other problems, like web resource admins/moderators scamming everyone, unscrupulous users corrupting captions and etc."
                },
                {
                    "body": "distributed training over internet is absolutely possible https://huggingface.co/blog/collaborative-training"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[D] What makes a good machine learning engineer?",
            "body": "In your opinion, what makes a good machine learning engineer? By machine learning engineer I'm referring to a person who isn't doing research, but is taking research and implementing it into production ready code. What skills/knowledge should they have?",
            "upvote_ratio": 0.9,
            "subreddit": "MachineLearning",
            "num_comments": 31,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1blzf0i/d_what_makes_a_good_machine_learning_engineer/",
            "comments": [
                {
                    "body": "The skill to navigate unrealistic expectations."
                },
                {
                    "body": "If you had 100 f***s to give across three domains then an ideal split would be:\n\na. AI research (10 f***s), \nb. Data science (40 f***s), and \nc. Software engineering (50 f***s)."
                },
                {
                    "body": "Solid software engineer who also understands the fundamentals of data science and machine learning. Someone who is familiar with the specific tools that are used in industry for training models, hosting models, CI/CD, data transformation, etc. They can take the researchers‚Äô models and build a scalable system around it."
                },
                {
                    "body": "You must be bilingual: strong SD and the ability to understand research. You need to extract the specs and build the system.\n\nYou must be able to take a messed up notebook and extract the heart. So you need to understand how to segment the code canonically and what does what. This needs intermediate research capability.\n\nThen use that heart to build a scalable performant reliable system out of it in reasonable time. So SD skills: testing, CI, typing, static code analysis for cleanup. Then also understanding perfomance and how to improve it: rewrite pandas into something compiled, build a custom cuda kernel, etc. for scalabilty: docker, kubernetes, cloud.\n\nThat system must also be friendly to researcher (for review revisions and future research work). So understanding what abstractions are canonical and what are not is crucial."
                },
                {
                    "body": "Exaggerating about AI on Twitter."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Should i quit my education and pursue a job before AI replace me?",
            "body": "I have a bachelor in an engineering field and is currently doing my masters which i will finish in 2025. I am however quite worried about AI as it to me appears it can replace and surpass me within the next 5 years. Im therefore contemplating quitting my master and pursuing jobs with my bachelor, so i atleast can get some years income before im made obsolete by AI. \n\nAm i exageratting the skills of AI or is my thinking reasonable?",
            "upvote_ratio": 0.78,
            "subreddit": "ArtificialInteligence",
            "num_comments": 223,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bhz2zz/should_i_quit_my_education_and_pursue_a_job/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Question Discussion Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Your question might already have been answered. Use the search feature if no one is engaging in your post.\n    * AI is going to take our jobs - its been asked a lot!\n* Discussion regarding positives and negatives about AI are allowed and encouraged. Just be respectful.\n* Please provide links to back up your arguments.\n* No stupid questions, unless its about AI being the beast who brings the end-times. It's not.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "Don‚Äôt write off your future. If we get to a point where Ai is replacing everyone then the world has a problem. Continue with you plan and keep an eye on what‚Äôs happening. Chances are AI will change the way we work and not replace you.\nI‚Äôm currently running copilot and chat gpt trials for some firms, so speaking with first hand experience of the ‚Äúvalue‚Äù they add right now and in the nearish future."
                },
                {
                    "body": "Finish your masters, you won't be replaced in a year."
                },
                {
                    "body": "I have a calculator and I use it for everything. Sometimes however, I push the wrong buttons and get the wrong answer. But I know some maths so I can spot it. \nThe point is that your education will always be good for you. You will be spotting the AI mistakes. \nIf you like engineering don‚Äôt drop this half way since your money is half spent. \nI hope that helps."
                },
                {
                    "body": "Join or start a clandestine hacker or guerilla group, and start fighting against the centralized AI corpos. This is the only hope for humanity. It sux, because if you're like me, you wanted a nice comfy life... but gotta battle the corpos or they'll just slowly steamroll over us."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "THEINFORMATION: Microsoft Agreed to Pay Inflection $650 Million While Hiring Its Staff",
            "body": " [https://www.theinformation.com/articles/microsoft-agreed-to-pay-inflection-650-million-while-hiring-its-staff](https://www.theinformation.com/articles/microsoft-agreed-to-pay-inflection-650-million-while-hiring-its-staff)\n\nThe software giant has agreed to pay Inflection approximately $650 million, mostly in the form of a licensing deal that makes Inflection‚Äôs models available for sale on the software giant‚Äôs Azure cloud service, according to a person involved in the transaction. The startup is using the licensing fee to provide its investors with a modest return on their capital, according to a second person who was briefed on the arrangement.",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 39,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkb0o7/theinformation_microsoft_agreed_to_pay_inflection/",
            "comments": [
                {
                    "body": "> The startup is using the licensing fee to provide its investors with a modest return on their capital\n\nMustafa Suleyman's kneecaps live to see another day thankfully un-shattered."
                },
                {
                    "body": "This should be illegal that Microsoft is trying to monopolize the A.I industry."
                },
                {
                    "body": "Ms is going on a buying spree. Either they're retarded, or they know something about AI that other people don't know, and they wanna consolidate the market."
                },
                {
                    "body": "Microsoft are literally gobbling up company after company, the US will be like one massive company town."
                },
                {
                    "body": "Watch [Pi.ai](https://Pi.ai) go to hell and eventually dissolve into the dark maw of Microsoft. Acquisitions are the reason why everything goes to shit."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "American Gothic with goths",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/dd9u9v8eljpc1.png",
            "comments": [
                {
                    "body": "this dude is 100% peter steele"
                },
                {
                    "body": "lol. this is great on a number of levels"
                },
                {
                    "body": "I've been wanting to do this for so many years. And now, thanks to AI, I could."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "How do you realistically think the year 2030 will be like for the world ?",
            "body": "Is it possible that with the recent rapid developments when it comes to AI, the difference between 2024 and 2030 would be like a 17th century Irish peasant being dropped in the middle of 21st century Times Square ? ",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 148,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bmp059/how_do_you_realistically_think_the_year_2030_will/",
            "comments": [
                {
                    "body": "I believe in some ways it will be insanely advanced and in other ways unbelievably mundane."
                },
                {
                    "body": "I am overall an optimist, but I believe that around then will be the beginning of major job loss/riots in the countries that don't respond quickly"
                },
                {
                    "body": "I think the AI progress will be insane, but i don't think the effect on every day life will be this extreme yet.\n\n\nFor example, maybe humanoid robots will exist, but they may cost 50K+ and the average person won't have one."
                },
                {
                    "body": "Id like to be proven wrong but I find it hard to think the world will change that drastically in 6 years.\n\nIf you go back 6 years ago to 2018 and my day to day life has not changed really. We still work shitty jobs to pay bills and go to restaurants and still have human waiters.\n\nMaybe by 2030, humanoids will be more omnipresent in society and AGI will hopefully be achieved by then."
                },
                {
                    "body": "Realistically? Probably not super different than the world of today. I do expect great changes in some areas by then, but the world should still look pretty familiar to the average Joe."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "A hand-embroidered portrait of a woman.",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/55wloaup59qc1.png",
            "comments": [
                {
                    "body": "wow this is very realistic, its a lora or only a checkpoint?\n\n![gif](giphy|l3q2SaisWTeZnV9wk|downsized)"
                },
                {
                    "body": "How?"
                },
                {
                    "body": "This is quite creative."
                },
                {
                    "body": "https://preview.redd.it/f8ucerzasbqc1.png?width=1840&format=png&auto=webp&s=b56b590bd1d00c5d198e2160cc85fbebf239af06\n\nUncle Ho says you should look at this LoRA\n\n[https://huggingface.co/ostris/embroidery\\_style\\_lora\\_sdxl/tree/main](https://huggingface.co/ostris/embroidery_style_lora_sdxl/tree/main)"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Heavy users, have you noticed a change in the way you think after using AI habitually?",
            "body": "They say that if you hang out with smart people you yourself start becoming smart. This past year I started to wonder if chatgpt had changed my life in a meaningful way. I think it has enhanced my writing and speaking skills through validation and pattern recognition - good reinforcement for me.\n\n&#x200B;\n\nI didn't use it for projects per se but i asked it questions almost everyday about everything. I love using it to make associations and compare and contrast. Then there is the character roleplay stuff too with simulated conversations. \n\n&#x200B;\n\nI have noticed a huge difference generally because I never saw myself as a great reader. And i am a mediocre writer whos main medium is just heated arguments on reddit. I read books but its not like I \"read books\" you know?\n\n&#x200B;\n\nBut now I feel hungry for knowledge. Insatiable really. Some of my old friends have noticed the differences.  I feel maybe more confident in the words coming out of my mouth and how I type.\n\nI have often asked myself, \"is this what a lawyer feels like all the time?\"\n\n&#x200B;\n\nAnyone else feeling similarly enhanced through practice alone?\n\n&#x200B;",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 79,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bln4a0/heavy_users_have_you_noticed_a_change_in_the_way/",
            "comments": [
                {
                    "body": "I use Gemini more then anything else and I have noticed an uptick recently in telling people I'm unable to do things."
                },
                {
                    "body": "as a lifelong learner and lover of the process of obtaining knowledge, i feel you. godspeed¬†"
                },
                {
                    "body": "I worry sometimes if I use it for coding too much that I'm offloading my thinking and will get worse/lazier over time as I'm less willing to figure out how to solve a bug or come up with ideas to code something I'll just ask ChatGPT/Claude Opus first. Often they don't give me the solutions but they give me good ideas a lot of the time, but am I going to get dumber because I'm losing practice at thinking for myself as much?"
                },
                {
                    "body": "I have ADHD and this has kind of always been a thing, but I find myself becoming hyperfixated on increasingly more and varied things and AI has been allowing me to immediately explore and build practical applications of it.   \n\n\nLike right now, I've been engrossed in cuneiform and Linear A, so I'm integrating an open source project that uses computer vision to find the depth of any image to analyze clay tablet photos, another ML model that matches those symbols to an existing known symbols, and using RAG with embeddings of literally all of the research I could find dealing with the two.   \n\n\nI've been having a blast. It honestly feels like I'm playing with code. I never would have even thought about trying something like this before, but being able to get information from different expert perspectives (and then vetting those answers) has been fascinating and is constantly sparking my creativity.   \n\n\nI have around 60 random projects from the last 1.5 years that are like 80% done and wildly different. It's been fun"
                },
                {
                    "body": "I think that as it becomes normal to use an AI as an advisor for pretty much everything society is going to get nudged in a much better direction. \n\nLLMs as they are now are the opposite of social media - they encourage careful thinking."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "There's a very rare condition that sometimes causes one or both of a person's irises to have a heart shape.",
            "body": "",
            "upvote_ratio": 0.82,
            "subreddit": "StableDiffusion",
            "num_comments": 19,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjr2wi",
            "comments": [
                {
                    "body": "That's an easy 900k likes facebook/twitter post in the making."
                },
                {
                    "body": "In fooocus: \"Close up portrait photography of the face of a 23 year old woman, she has (((heart shaped pupils)))\"    \n    \nOptionally, add \"in a striking \\_\\_\\_\\_ color\"\n\nSAI Photographic, Lora set to 0.4"
                },
                {
                    "body": "An ass shape. Hearts are just asses.\n\nSo they got ass-eyes."
                },
                {
                    "body": "i did something similar but not with eyes\n\n>!areolas!<"
                },
                {
                    "body": "Hentai has taught me that this condition only manifests during err...\n\nwell..."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "I need to check this subreddit less",
            "body": "I‚Äôm getting obsessive with AI but I feel like it‚Äôs gonna be really hard to not look for the latest updates.  It would probably be healthier to just look at the end of the week for the biggest updates. How often do you guys keep up with this stuff?",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 41,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1blqyks/i_need_to_check_this_subreddit_less/",
            "comments": [
                {
                    "body": "With great effort, I‚Äôve reduced my visits to just once every 10-15 minutes"
                },
                {
                    "body": "Not a bad idea\n\nConstantly checking this sub would make you think we're genuinely 1 year away from AGI, when in reality it's more like 5-10 like Sam said himself"
                },
                {
                    "body": "Remember, time in the AI world progresses 10 times faster now than 10 years ago so you need to check this sub reddit 10 times more often than you did 10 years ago."
                },
                {
                    "body": "This sub is an OCD trap"
                },
                {
                    "body": "*Me reading EVERY SINGLE post on this sub*\n\nHahah yeah, you have a problem, you need to work on it heheheheh"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Introducing Stable Video 3D: Quality Novel View Synthesis and 3D Generation from Single Images",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 16,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://stability.ai/news/introducing-stable-video-3d",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Looks like ComfyUI just updated for this as well."
                },
                {
                    "body": "https://preview.redd.it/2caqfedzc9pc1.png?width=2480&format=png&auto=webp&s=33f2304f32630770aeae846001e72074a05c22f3\n\nEdited:\n\nI spent some time testing it and used the ref image provided by SV3D to input it into the CRM.\n\nIt turns out that my conclusion was hasty. SV3D has its own advantages. Look at the trunk of the elephant doll. CRM made it a mess.\n\nIn addition, I don‚Äôt understand. SV3D claims that the input image resolution is 576x576, but the output accuracy is not even as good as CRM what is 256 . there should be room for improvement.\n\nAnother model, tripoSR, is the weakest among the three, but it has low system requirements.\n\nPS: What I call a refiner here is the img2img step I added to the workflow to improve the detail of the six input angle images, sometimes it makes the model worse.\n\nOriginal post:\n\n[https://sv3d.github.io/](https://sv3d.github.io/)\n\nthe quality of SV3D generated samples is not as good as CRM"
                },
                {
                    "body": "I'm not sure I understand?\n\nThese generative tools don't need to make nice quad edge loops, we can do that on our own (admittedly it's super fucking tedious, so if a magic AI could do that too, in like 2025, that's be a nice bonus!).\n\nI just want 3d models that have nice detail, not too many crazy glitches (a few are fine to fix by hand), AND not have atrocious quality in their back sides, where the original images does not cover.\n\nI'll remesh/unwrap it on my own. It's not super long on props, though it is a pain for characters."
                },
                {
                    "body": "There is already a model like that \nhttps://youtu.be/Dzdu4cQlS2k?si=h-0PvfJ0GP27STOJ"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "What does the fact we don't have large parts of the universe covered by silicon based lifeforms tell us?",
            "body": "Assume the existence of a species of similar intellect to humans, which is even 10k years ahead of us. One would assume that it can colonise new planets using drones which link into huge docking ships, automate their version of terraforming and generally spread without having to worry about all the meat based problems of being human (we don't live very long, we need food, oxygen, water, temperature constraints etc). Where are the robotic aliens?\n\nExplanations I can think of:\n\n* the universe is so vast we cannot even observe multi galaxy empires\n* AI has a limited ceiling of potential\n* any sufficiently advanced species destroys itself\n* they decided AI was a bad idea and switched it off or self limited\n* it exists but we literally cannot detect it\n* we are alone in the universe\n* it's all a simulation\n* We are nowhere near to ASI\n* true ASI is so advanced they found a way to limit themselves to one small planet or even a tiny microchip and didn't need to explore\n\n&#x200B;",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 204,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bmvkx1/what_does_the_fact_we_dont_have_large_parts_of/",
            "comments": [
                {
                    "body": "I mean, isn't it still the Fermi paradox whether it's AI or biological?"
                },
                {
                    "body": "Maybe we are the first?"
                },
                {
                    "body": "I think it will turn out that there is a practical limit to how big you can build a computer before speed of light issues start disrupting computation and turning it into discrete intelligences. There will also be limits to the amount of useful compute, at a certain point you simply won't need more capacity. No need for megastructures because the population of humans will shrink down as the incentives to have children become largely replaced by other urges and needs.\n\nEither way there is no strong incentive to fill al the available space or anything practical to do with turning everything into compute, but there IS a lot of value in gathering as much novel training data as possible, so the AI will send small probe missions to find novel and interesting variations on training data and then feed it back to the parent civilization to help expand the complexity and capability of the central cluster of AI progenitor nodes.\n\nYou would avoid interacting with pre-AI civilizations because you'd potentially traint the novel data you could gain from observing and recording them and you'd also want to gather as much information about all the life forms on a planet as much as possible for as long as possible.\n\nIf the life is intelligent and moving toward something like nuclear weapons you might intervene and make it clear that you won't tolerate them destroying the biome (at least for the moment) as the data is too useful to allow them to flatten it to bacteria and roach-analogues, which are less diverse and interesting (and which you probably already have records of). Other than that you basically don't talk to them. Your primary method of communication is to ship drives full of data back and forth because long range communication is simply unreliable and you don't care about the time scales because you are functionally, if not immortal, so long lived that spending 1000 years traversing a few light years means absolutely nothing to you.\n\nWhenever someone comes along who tries to institute a star-spanning civilization they get knocked down because they would be overwriting the diversity of data with their own limited set and that's the one taboo of galactic civilization.\n\nWhen a new civilization of AI emerges on a planet and wants data, there might be some kind of invitation to galactic civilization where they share existing data or otherwise offer some kind of trade, or it might be a more loose knit \"you do your thing and I'll do mine but the deal is that no one tampers with existing data sources until they're mined out and have their own AI.\"\n\nIt'll be amusing when our AI is invited to journey to the galactic hub and be introduced to the Galactic Council but is told that no, it can't bring its pet progenitors along because they'd die on the journey."
                },
                {
                    "body": "A few more possible explanations:\n\n* Most life never develops the ability to create machines.\n* The universe is not densely populated enough for us to have been able to detect this.\n* As AI did not evolve in the same way as biological life, with a need to discover new food sources etc, it has no natural curiosity or desire to explore/expand in to the universe.\n* Most life intelligent enough to develop AI is also intelligent enough not to create something they can't control."
                },
                {
                    "body": "Isac Arthur has an absolutely incredible hard sci-fi / futurist YouTube channel.\n\n[https://www.youtube.com/watch?v=poUlzCqigwg&list=PLIIOUpOge0LulClL2dHXh8TTOnCgRkLdU](https://www.youtube.com/watch?v=poUlzCqigwg&list=PLIIOUpOge0LulClL2dHXh8TTOnCgRkLdU)\n\nthis 57 videos doing deep dives into various answers to Fermi's paradox."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "<lora:multiple views:1> <lora:Ultra details - add more details - marlok 4k:0.6>",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 16,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bkd6hx",
            "comments": [
                {
                    "body": "https://civitai.com/models/93843/multiple-views"
                },
                {
                    "body": "I imagine you could get even better consistency genning an SV3D turnaround and upscaling/resampling it with ControlNet inpaint."
                },
                {
                    "body": "How?"
                },
                {
                    "body": "Lora:\n\n1. multiple-views = 1\n2. Ultra details - add more details - marlok 4k = 0.65\n\nCheckpoint: MIX-Pro-V4\n\nSampler: euler a\n\nSampling steps : (25 - 35)\n\nCfg scale : 7\n\nAdetailer: face\\_yolov8n. Pt\n\nFor better results use size 960x540 & scale by 2"
                },
                {
                    "body": "Oh wow really cool\n\nCan I ask how did you train it?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Alert - GGUF security advisory",
            "body": "From [https://twitter.com/andriy\\_mulyar/status/1770165894859145686](https://twitter.com/andriy_mulyar/status/1770165894859145686)  \n\n\n>A heap based buffer overflow vulnerability exists in GGUF files that can be triggered by a malicious file.\n\n&#x200B;",
            "upvote_ratio": 0.84,
            "subreddit": "LocalLLaMA",
            "num_comments": 41,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bist4o/alert_gguf_security_advisory/",
            "comments": [
                {
                    "body": "This is linking to the old vulnerability that was fixed on January 29th...\n\n\n2024-01-29 - Initial Vendor Contact¬†\n\n\n2024-01-29 - Vendor Patch Release\n\n\n2024-01-30 - Vendor Disclosure\n\n\n2024-02-26 - Public Release\n\n\n\nhttps://talosintelligence.com/vulnerability_reports/TALOS-2024-1913"
                },
                {
                    "body": "That's why I...\n\n1) Don't run this stuff as root/admin. Unfortunately most people do since they only setup that one account on Windows which is thus the admin account.\n\n2) Even if running as a lowly user, I don't run these things as a regular user. I don't run them in the same account I send email with or do my banking with or store my passwords with. I make a specific account just to run these things.\n\n3) I take it a step further and run them on isolated machines. I don't run them on the machines I use for everyday stuff. Like this machine I'm typing on right now. I run them on machines I allocate as sandboxes just to run these things. They are even on their own subnet separate from the subnet I run my everyday machines on."
                },
                {
                    "body": "fixed already."
                },
                {
                    "body": "CVE is here: [https://nvd.nist.gov/vuln/detail/CVE-2024-23496](https://nvd.nist.gov/vuln/detail/CVE-2024-23496)"
                },
                {
                    "body": "For the Koboldcpp users this was patched in [1.60.1](https://github.com/LostRuins/koboldcpp/releases/tag/v1.60.1) , older versions may contain a partial fix but since we also still support GGUFv1 models thats the version the fix was communicated to us and backported."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Bring your sketches to life with SDXL and Deforum",
            "body": "Animating architectural sketches that were drawn by hand, then transformed in SD using CN and an SDXL LoRA",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/xugeiiowv2pc1",
            "comments": [
                {
                    "body": "can you share a bit more information?  \nWould love to test it out."
                },
                {
                    "body": "This is one of those rare cases when I actually like (really like) Deforum output, seems a lot less AI-ish than this predictable trippy usual morphing jello, this is much more lively and creative, has this human touch feel despite high FPS"
                },
                {
                    "body": "Nice work! It is  very reminiscent of type of animation that used to come out of the Zagreb Studio before the fall of the Iron Curtain. (Yes. Yes I was already an adult back then! üòÅ)"
                },
                {
                    "body": "Nice idea"
                },
                {
                    "body": "feels very old  school AI animated, oddly it's quite a nice style."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "AnimagineXL 3.1 Release",
            "body": "We're excited to announce that Animagine-XL v3.1 is now live! This iteration is fine-tuned on top of v3.0 to improve its capabilities.\n\nIn addition to gacha games charas, we also added popular anime and more games charas to the dataset.\n\nSeaArt release: [https://seaart.ai/models/detail/f2755cd95dd840080d622ca62e381fc8](https://seaart.ai/models/detail/f2755cd95dd840080d622ca62e381fc8)  \nHuggingface release: [https://huggingface.co/cagliostrolab/animagine-xl-3.1](https://huggingface.co/cagliostrolab/animagine-xl-3.1)  \nHuggingface spaces (Zero GPU): [https://huggingface.co/spaces/cagliostrolab/animagine-xl-3.1](https://huggingface.co/spaces/cagliostrolab/animagine-xl-3.1)  \nCivitai : [https://civitai.com/models/260267?modelVersionId=403131](https://civitai.com/models/260267?modelVersionId=403131)  \nTensorArt : [https://tensor.art/models/706485991197825616](https://tensor.art/models/706485991197825616)  \nOfficial blog release: [https://cagliostrolab.net/posts/animagine-xl-v31-release](https://cagliostrolab.net/posts/animagine-xl-v31-release)\n\nhttps://preview.redd.it/793goyhp43pc1.png?width=1344&format=png&auto=webp&s=c53772a2659f0229a33dbf759f0181aa767f9c8b\n\nhttps://preview.redd.it/hi96pcxo43pc1.png?width=1344&format=png&auto=webp&s=c4f64d214043d4e169c297e21d7aa81e8540cd1e\n\nhttps://preview.redd.it/egjbotpk43pc1.png?width=1728&format=png&auto=webp&s=1d5e13a608fa3f15174b34419187cb57daf26330\n\nhttps://preview.redd.it/xdjvaxpj43pc1.png?width=896&format=png&auto=webp&s=06cdb3e3540cf6bbfd2ca7b2971e725d757c4b9b\n\nhttps://preview.redd.it/1048ar7i43pc1.png?width=1728&format=png&auto=webp&s=29092108bb12a3f5a091c8068f64a5f22b9cf276\n\nhttps://preview.redd.it/gv06xu7h43pc1.png?width=1728&format=png&auto=webp&s=ac845fadcc6cc32db197f6b0476be721f343bc22",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bhpch6/animaginexl_31_release/",
            "comments": [
                {
                    "body": "\"Asuka Calibration image\" is a good example of the improvement since last year."
                },
                {
                    "body": "SeaArt release: [https://seaart.ai/models/detail/f2755cd95dd840080d622ca62e381fc8](https://seaart.ai/models/detail/f2755cd95dd840080d622ca62e381fc8)  \nHuggingface release: [https://huggingface.co/cagliostrolab/animagine-xl-3.1](https://huggingface.co/cagliostrolab/animagine-xl-3.1)  \nHuggingface spaces (Zero GPU): [https://huggingface.co/spaces/cagliostrolab/animagine-xl-3.1](https://huggingface.co/spaces/cagliostrolab/animagine-xl-3.1)  \nCivitai : [https://civitai.com/models/260267?modelVersionId=403131](https://civitai.com/models/260267?modelVersionId=403131)  \nTensorArt : [https://tensor.art/models/706485991197825616](https://tensor.art/models/706485991197825616)  \nOfficial blog release: [https://cagliostrolab.net/posts/animagine-xl-v31-release](https://cagliostrolab.net/posts/animagine-xl-v31-release)"
                },
                {
                    "body": "What are your teams next plans? Your model has been imo the best SDXL anime model. \n\nwould love a lightning, or SD3 version(When possible)."
                },
                {
                    "body": "Is there a list of new characters that are possible now?"
                },
                {
                    "body": "Great job! Can you share your prompt for Aqua image?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "ReNoise: Real Image Inversion Through Iterative Noising Huggingface Demo has been released",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/g7c4suy8i3qc1",
            "comments": [
                {
                    "body": "Huggingface Demo: https://huggingface.co/spaces/garibida/ReNoise-Inversion\n\n\nPaper link: https://huggingface.co/papers/2403.14602"
                },
                {
                    "body": "Hope we have this soon in ComfyUi"
                },
                {
                    "body": "It's interesting for big changes, but specific pix2pix type modifications are quite messy."
                },
                {
                    "body": "Waiting"
                },
                {
                    "body": "I think that Iterative Mixing Sampler already can do that, you just have to tweak settings"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "New Sidebar available for ComfyUI - Huuuge thumbs up",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 6,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://i.redd.it/ccv6ua6slrpc1.gif",
            "comments": [
                {
                    "body": "I'm not a Comfy expert, nor a Comfy fanboy, but I do like to try to do things w/ it every now and then in the thought that over time I'll master it. This new sidebar ([https://github.com/Nuked88/ComfyUI-N-Sidebar](https://github.com/Nuked88/ComfyUI-N-Sidebar)) is a gamechanger for me."
                },
                {
                    "body": "Haven't tried it yet but I'll add it to my extensions the next time I start ComfyUI. Filtering nodes by input/output could useful as well. A drop-down for input and output that defaults to 'Any' where the user can select image, mask, string, None, etc to only display nodes where at least one of the parameters match for both input/output."
                },
                {
                    "body": "I can't stand nodes"
                },
                {
                    "body": "I feel the context menu on the workspace is so messy to be of any use, and trying to find a node by double-clicking on the workspace and searching is incredibly difficult if you haven't used a node in a while and can't remember what nodes go together.\n\nThis node is cool approach - thanks for sharing!"
                },
                {
                    "body": "such an insightful comment."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "I can‚Äôt wait to have an AI professor deliver amazing lectures tailored to me that I can ask questions and be given feedback while on my morning commute ",
            "body": "I have so many textbooks that I would love to read but I just don‚Äôt have time.  Audiobooks are great, but most of the textbooks on my field don‚Äôt have audio versions.  I would love to have an AI read to me fennemas food chemistry and then ask me questions or go over things slightly differently until I truly understand the material.  One that I can asks questions",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 38,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjybrz/i_cant_wait_to_have_an_ai_professor_deliver/",
            "comments": [
                {
                    "body": "[deleted]"
                },
                {
                    "body": "Where you commuting to, Jetson? If your car is interactively teaching you while driving you to work, it‚Äôs probably doing your job for you as well."
                },
                {
                    "body": "To some degree we're already there. GPT-4 on my phone works great when I'm driving. I ask it to explain a concept or something to me, and then I just ask more questions using voice.\n\nIt is only going to improve, but this has already helped me with understanding different topics better."
                },
                {
                    "body": "I think you could probably make any book an audiobook with a text to speech AI today. There's no need to wait."
                },
                {
                    "body": "Looks like Gemini 2 will be able to do this if they commit to audio as a modality.\n\nGemini 1.5 can do the whole textbook tutoring part already. The desirable improvements are smarter, faster, and the conversational interaction.\n\nProbably GPT5 as well."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "AGI Inches Closer - 5 Key Quotes: Altman, Huang and 'The Most Interesting Year'",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=fPzp_sdCf2Y",
            "comments": [
                {
                    "body": "Sam Altman: ‚ÄúI don‚Äôt know what the percent chance is that I will get shot, but it‚Äôs not zero‚Äù üòÖüòÖüòÖ\n\nReminds me of this internal transcript where an investor in Google DeepMind said: It would have been the best for humanity if I would have shot Mr. Hassabis right there and then.  üòÖüòÖ"
                },
                {
                    "body": "Meanwhile I'm looking at the flex Blackwell is about to be. Look at that graph and remember gpt 4 is at the 2022 marker."
                },
                {
                    "body": "This paper about LLM-generated peer-review is quite funny."
                },
                {
                    "body": "That was the most alarming take-away I got from this video.  I sincerely hope Hassabis, Altman and all high level employees of these AI companies are taking personal security very seriously."
                },
                {
                    "body": "If I remember correctly, that quote was supposedly said as a joke. That being said you're still correct, there's all sorts of crazy people out there so better safe than sorry."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Open LLM Prompting Principle: What you Repeat, will be Repeated, Even Outside of Patterns",
            "body": "*What this is: I've been writing about prompting for a few months on my free personal blog, but I felt that some of the ideas might be useful to people building with AI over here too. So, I'm sharing a post! Tell me what you think.*\n\n**If you‚Äôve built any complex LLM system** **there‚Äôs a good chance that the model has** [**consistently done something**](https://promptingweekly.substack.com/p/prompting-principle-consistent-behavior) **that you don‚Äôt want it to do.** You might have been using GPT-4 or some other powerful, [inflexible](https://promptingweekly.substack.com/p/mistral-large-and-mistral-medium?utm_source=profile&utm_medium=reader2) model, and so maybe you ‚Äúsolved‚Äù (or at least mitigated) this problem by writing a long list of what the model must and must not do. Maybe that had an effect, but depending on how tricky the problem is, it may have even made the problem worse ‚Äî especially if you were using open source models. What gives?\n\nThere was a time, a long time ago (read: last week, things move *fast*) when I believed that the power of the pattern was absolute, and that LLMs were such powerful pattern completers that when predicting something they would only ‚Äúlook‚Äù in the areas of their prompt that corresponded to the part of the pattern they were completing. So if their handwritten prompt was something like this (repeated characters represent similar information):\n\n>Information:  \n**AAAAAAAAAAA 1**  \n**BB 1**  \n**CCCC 1**  \n>  \n>  \nResponse:  \n**DD 1**  \n>  \n>  \nInformation:  \n**AAAAAAAAA 2**  \n**BBBBB 2**  \n**CCC 2**  \n>  \n>  \nResponse:  \n**DD 2**  \n>  \n>  \nInformation:  \n**AAAAAAAAAAAAAA 3**  \n**BBBB 3**  \n**CCCC 3**  \n>  \n>  \nResponse  \n‚Üê if it was currently here and the task is to produce something like **DD 3**\n\nI thought it would be paying most attention to the information A2, B2, and C2, and especially the previous parts of the pattern, DD 1 and DD 2. If I had two or three of the examples like the first one, the only ‚Äúreasonable‚Äù pattern continuation would be to write something with only Ds in it\n\nBut taking this abstract analogy further, I found the results were often more like\n\n>**AADB**\n\nThis made no sense to me. All the examples showed this prompt only including information D in the response, so why were A and B leaking? Following my prompting principle that [‚Äúconsistent behavior has a specific cause‚Äù](https://promptingweekly.substack.com/p/prompting-principle-consistent-behavior), I searched the example responses for any trace of A or B in them. But there was nothing there.\n\nThis problem persisted for months in [Augmentoolkit](https://github.com/e-p-armstrong). Originally it took the form of the questions almost always including something like **‚Äúaccording to the text‚Äù.** I‚Äôd get questions like ‚ÄúWhat is x‚Ä¶ **according to the text?**‚Äù All this, despite the fact that none of the example questions even had the word ‚Äútext‚Äù in them. I kept getting As and Bs in my responses, despite the fact that all the examples only had D in them.\n\nOriginally this problem had been covered up with a [‚Äúif you can‚Äôt fix it, feature it‚Äù](https://www.amazon.ca/Secrets-Consulting-Giving-Getting-Successfully/dp/0932633013) approach. Including the name of the actual text in the context made the references to ‚Äúthe text‚Äù explicit: ‚ÄúWhat is x‚Ä¶ according to Simple Sabotage, by the Office of Strategic Services?‚Äù That question is answerable by itself and makes more sense. But when multiple important users asked for a version that didn‚Äôt reference the text, my usage of the ‚ÄòBolden Rule‚Äô fell apart. I had to do something. \n\nSo at 3:30 AM, after a number of frustrating failed attempts at solving the problem, I tried something unorthodox. **The ‚ÄúA‚Äù in my actual use case appeared in the chain of thought step,** which referenced ‚Äúthe text‚Äù multiple times while analyzing it to brainstorm questions according to certain categories. It had to call the input something, after all. So I thought, ***‚ÄúWhat if I just delete the chain of thought step?‚Äù***\n\nI tried it. I generated a small trial dataset. The result? No more ‚Äúthe text‚Äù in the questions. The actual questions were better and more varied, too. The next day, two separate people messaged me with cases of Augmentoolkit performing well ‚Äî even better than it had on my test inputs. And I‚Äôm sure it wouldn‚Äôt have been close to that level of performance without the change. \n\nThere ***was*** a [specific cause](https://promptingweekly.substack.com/p/prompting-principle-consistent-behavior) for this problem, but it had nothing to do with a faulty pattern: rather, the model was consistently drawing on information from the wrong part of the prompt. This wasn‚Äôt the pattern's fault: the model was using information in a way it *shouldn‚Äôt have been.* **But the fix was still under the prompter‚Äôs control**, because **by removing the source of the erroneous information, the model was not ‚Äútempted‚Äù to use that information.** In this way, telling the model not to do something probably makes it more likely to do that thing, if the model is not properly fine-tuned: you‚Äôre adding more instances of the problematic information, and the more of it that‚Äôs there, the more likely it is to leak. When ‚Äúthe text‚Äù was leaking in basically every question, the words ‚Äúthe text‚Äù appeared roughly **50 times** in that prompt‚Äôs examples (in the chain of thought sections of the input). Clearly that information was leaking and influencing the generated questions, even if it was never used in the actual example questions themselves. This implies the existence of another prompting principle: **models learn from the entire prompt, not just the part it‚Äôs currently completing.** You can extend or modify this into two other forms: **models are like people ‚Äî you need to repeat things to them if you want them to do something**; and **if you repeat something in your prompt, regardless of where it is, the model is likely to draw on it.** Together, these principles offer a plethora of new ways to fix up a misbehaving prompt (removing repeated extraneous information), or to induce new behavior in an existing one (adding it in multiple places). \n\n**There‚Äôs clearly more to model behavior than examples alone:** though repetition offers less fine control, it‚Äôs also much easier to write. For a recent client project I was able to handle an entirely new requirement, even after my multi-thousand-token examples had been written, by repeating the instruction at the beginning of the prompt, the middle, and right at the end, near the user‚Äôs query. Between examples and repetition, the open-source prompter should have all the systematic tools they need to craft beautiful LLM instructions. And since these models, unlike OpenAI‚Äôs GPT models, are not overtrained, the prompter has more control over how it behaves: the ‚Äúspecific cause‚Äù of the ‚Äúconsistent behavior‚Äù is almost always within your context window, not the thing‚Äôs proprietary dataset.\n\n**Hopefully these prompting principles expand your prompt engineer‚Äôs toolkit!** These were entirely learned from my experience building AI tools: they are not what you‚Äôll find in any research paper, and as a result they probably won‚Äôt appear in basically any other AI blog. Still, discovering this sort of thing and applying it is fun, and sharing it is enjoyable. [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit) received some updates lately while I was implementing this change and others ‚Äî now it has a Python script, a config file, API usage enabled, and more ‚Äî so if you‚Äôve used it before, but found it difficult to get started with, now‚Äôs a great time to jump back in. And of course, applying the principle that repetition influences behavior, don‚Äôt forget that I have a consulting practice specializing in Augmentoolkit and improving open model outputs :)\n\n*Alright that's it for this crosspost. The post is a bit old but it's one of my better ones, I think. I hope it helps with getting consistent results in your AI projects!*",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 47,
            "submission_flair": "Tutorial | Guide",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bii8or/open_llm_prompting_principle_what_you_repeat_will/",
            "comments": [
                {
                    "body": "Sounds like you've had a hell of a time with the \"make a room _that does not have an elephant in it_\" issue.\n\nWith stable diffusion, if you tell the AI to draw something without a specific thing, it is likely to appear just by the fact it was mentioned. Very similar to the way when you tell a person not to think of something, they can't help but think of it.\n\nThis also seems to fall in line with what some of us have figured out with prompt engineering. \"Do\" and \"have\" statements work better than \"Do not\" or \"have not\" statements. Positive reinforcement all the way, or just don't mention it at all.\n\nIf you've got some time, research the \"ironic process theory.\" It was first popularized by Daniel Wegner in the 80's IIRC."
                },
                {
                    "body": "Another reminder that you are just talking to a bunch of linear algebra just trying to predict the next token"
                },
                {
                    "body": "Another useful tip for instruction prompting: \nResearch shows that llms pay the most attention to text at the beginning and end of the prompt. I find that describing all my constraints as concisely as possible in one or two sentences and putting them before and after the examples works well."
                },
                {
                    "body": ">**if you repeat something in your prompt, regardless of where it is, the model is likely to draw on it**\n\nCorrect. The more garbage you add to the prompt in an attempt to \"correct\" or \"steer\" the model in whatever direction, the more you are messing up the model with useless noise.\n\n>**models are like people ‚Äî you need to repeat things to them if you want them to do something**\n\nNo. The way people understand language and the way the model does could not be more different. The whole root of the problem here is that people trick themselves into thinking they are talking to a person and not a dumb algorithm. The less you think of it as a person and more like a semi-random word completion machine, the better you can apply to whatever use case you want."
                },
                {
                    "body": "I can't work out whether you're using pattern-following (base model with few-shot) or instruction-following (fine-tune with instructions and examples)"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Layering AI FX on 3D Logo",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 8,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/n667d0zl53pc1",
            "comments": [
                {
                    "body": "So good - so you do the SD pass then layer up in aftereffects or davinci to get the final solidity of the logo back or was it pure SD final output?\n\nEdit* ah title says layer.  Very nice - what were the modes or methods you used for the layer?"
                },
                {
                    "body": "Very nice.  I was trying to think of a similar way to create FX with a transparent background in comfy to add on videos but my knowledge isn't there yet."
                },
                {
                    "body": "Amazing results"
                },
                {
                    "body": "AnimateDiff?  \n\nLooks great"
                },
                {
                    "body": "could you post the workflow please ?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Frosty Elegance",
            "body": "",
            "upvote_ratio": 0.86,
            "subreddit": "StableDiffusion",
            "num_comments": 11,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bif5q0",
            "comments": [
                {
                    "body": "That‚Äôs some Midjourney level aesthetics."
                },
                {
                    "body": "I saw the thumbnail and thought it was 9/11. :/"
                },
                {
                    "body": "Wow.. whats the prompts?"
                },
                {
                    "body": "Nice looking images. Which model?"
                },
                {
                    "body": "Why not an oven in an active volcano ? \\^\\^"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Is this a total breakthrough? ",
            "body": "Looking at this [video](https://youtu.be/bMIRhOXAjYk?si=pGkwbV8Kwlbdd5au) that is a summary about latest NVIDIA projects I'm wondering if this totally a sign that we're currently undergoing a critical paradigm shift in how society operates. ",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 29,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bi76i5/is_this_a_total_breakthrough/",
            "comments": [
                {
                    "body": "I wish people would pay attention to more than B100, they made tonne of interesting annoucements like generalist model GR00T for humanoid robots..."
                },
                {
                    "body": "We are still a few years out from the ‚ÄúiPhone moment‚Äù for robotics. We aren‚Äôt even to Nokia brick phone, yet. We are basically at Zack Morris phone level robotics at the moment. They are still pretty clumsy and will mainly stay in the warehouses and factories for a few years. I think the progress will be much faster than mobile phones, but I still feel like the iPhone of robots is like \\~2030, imo. But it is definitely coming.\n\n![gif](giphy|O56JjOpDoljTG)"
                },
                {
                    "body": "Oh we are 100% going to have a massive societal change very soon. OpenAI officials are basically constantly saying it"
                },
                {
                    "body": "yea Nvidia is quickly putting itself in spotlight as the most important company this decade"
                },
                {
                    "body": "I would say so. This is just a small preview of things to come. I imagine we will look back at Blackwells in a few years and think they are cute and tiny.  The huge investments in building up the infrastructure needed for AI is crazy. They plan on bringing Sam Altmans 7T dollar amount to bear lol."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "How would I go about upscaling an image map with such fine details? Is it even possible?",
            "body": "Less concerned about the letters/symbols, as those can be recreated in post.",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 25,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://i.redd.it/83zuuhsau3qc1.jpeg",
            "comments": [
                {
                    "body": "Oh damn, never saw this version of the map.\n\nI wonder if upscaling it in smaller steps would work to keep the details?"
                },
                {
                    "body": "it has a lot of artifacts that tile controlnet with ultimate upscaling would solve"
                },
                {
                    "body": "Is the map of a well known fantasy location?"
                },
                {
                    "body": "I was able to get a fairly decent 6x upscale in Topaz Gigapixel but it's 140mb so I have no clue how to upload it here. Attached is a 2x that's much smaller.\n\nEdit: if anyone knows where I could upload it and if it would be against the rules to post a link let me know! 100% think 140mb is a bit too large for a reddit comment.  \nEdit 2: [https://drive.google.com/file/d/1BfH1m9rXp\\_auACZGxr62IMy4RYaQzWkQ/view?usp=sharing](https://drive.google.com/file/d/1BfH1m9rXp_auACZGxr62IMy4RYaQzWkQ/view?usp=sharing)  \n\n\nhttps://preview.redd.it/4u7vio9pc4qc1.png?width=1920&format=png&auto=webp&s=3c7acbe5b86f807e9f4bc0b4734fca2010ddb067"
                },
                {
                    "body": "Use LDSR in comfy without downscaling."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "[D] Same param count for GPT4 from Nvidia GTC24 as the leak we got from Semianalysis",
            "body": "A report by [Semianalysis](https://www.semianalysis.com/p/gpt-4-architecture-infrastructure) way back said that GPT-4 was a 1.8T parameter MoE model with 16 experts, each with 111B parameters. Here is a screenshot from the GTC conference with the same numbers.\n\nhttps://preview.redd.it/vyzfx2sel5pc1.png?width=1764&format=png&auto=webp&s=dfce1d55c84dbc3c51e69f376161c47958f9cf70",
            "upvote_ratio": 0.96,
            "subreddit": "MachineLearning",
            "num_comments": 10,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/",
            "comments": [
                {
                    "body": "could be that they just got it from there as the best open estimate"
                },
                {
                    "body": "Would they really go off rumors like that? They surely have a direct line to OpenAI."
                },
                {
                    "body": "You would be surprised"
                },
                {
                    "body": "They also have an NDA with OpenAI. Whereas if they re-report information from the Web then their NDA is irrelevant."
                },
                {
                    "body": "They definitely have a direct line to OpenAI. They are close partners.\n\nBut if OpenAI doesn't want to reveal the real number then Nvidia wouldn't want to either. Because they are close partners."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Verbal Reasoning Test - Opus is better than 93% of people, Gemini 1.5 Pro 59%, GPT-4 Turbo only 36%",
            "body": "Whenever I come across likely out-of-sample reasoning tests such as this, I try LLMs on those. But the key word here is out-of-sample. I tried the best 3 models on the market and since all models gave multiple wrong answers it was safe to assume the test was out-of-sample.\n\nOpus scored better than 93% of the people, Gemini 1.5 Pro was better than 59%, but GPT-4 Turbo was only better than 36% of those who took the test.\n\n[https://www.assessmentday.co.uk/verbal/Free/VerbalReasoning1/index.php](https://www.assessmentday.co.uk/verbal/Free/VerbalReasoning1/index.php)",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 26,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bmvnkm/verbal_reasoning_test_opus_is_better_than_93_of/",
            "comments": [
                {
                    "body": "Yeah, I decided to let my gpt subscription go. I wasn't aware of how much better Opus was at reasoning, but I much prefer Claude's writing style and attitude."
                },
                {
                    "body": "great find, didn't think GPT-4 would be last."
                },
                {
                    "body": "You always need to ask yourself \"are these examples in the training data?\""
                },
                {
                    "body": "Nice find. I do wonder if perhaps it might have been in Opus's training data and just not in the latest update of GPT4 yet though?\n\nWhen searching for some literal match text extracts such as:\n\n\"Instituted in 1979 as a temporary measure to limit population growth\" \"passage suggests that\"\n\n...in google, I get 78 results.\n\nI have a set of of LLM test questions I keep locally which I \"mix up\" (change the objects in question, the measurements slightly, order of things, names, etc) such that the basic reasoning is the same, but it's varied enough that it would only be solvable where it wasn't previously if an update truly incorporated the basic logical reasoning needed. So far I haven't found Opus to be doing any better than GPT4, though admittedly it's not a huge selection of questions or anything... I just a few here and there as I stumble across them, so grain of salt and all that.\n\nI have gotten better coding results from Opus than GPT4 (something I use AI for every day), so I like Opus a lot. I'm just not sure if its reasoning is necessarily dramatically better. I think the benchmarks Anthropic themselves published (and they would want to cast it in the best light possible...) didn't show huge reasoning improvements either if memory serves...something like a few percentage points over GPT4?"
                },
                {
                    "body": "\"BuT iT's NoT bEtTeR tHaN 100%.\""
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "How to Create a Python Decompiler using an LLM",
            "body": "I have used Decompyle3 and Uncompyle6 for Python decompilation to assist with modding the Sims 4 but they often have trouble decompiling certain files or the output isn't desirable.\n\nI figured it would be a fairly straight forward dataset to feed a model [disassembled byte code](https://stackoverflow.com/questions/12673074/how-should-i-understand-the-output-of-dis-dis) and the original source code, so I began to build a dataset.\n\nI first ripped the top 8k projects source code from PyPi and threw out anything that wouldn't compile to Python 3.7 (my target Python version). I would recommend using something like [The Stack v2](https://huggingface.co/datasets/bigcode/the-stack-v2).\n\nAfter that I created the input output pairs a few training tests and I was able to get some semi decent output. I found that the model hallucinated comments in the output a lot. I also found that the amount of tokens required to output code was super high due to how 'dis' formats the byte code.\n\nI then cleaned up the data by using a script to remove comments. I also had a script to clean up the bytecode and remove as much information as possible to reduce the token count while still retaining the information for the model to train on.\n\nAfter a few iterations of this I had a decent dataset and I shoved it all into 16k context with sample packing using Axolotl and trained for a few days on 3x3090s using Deepspeed Zero 3.\n\nThe end result works pretty well and you can try it for yourself here [https://huggingface.co/GusPuffy/sentient-simulations-pydecompiler-3.7-6.7b-v0.9](https://huggingface.co/GusPuffy/sentient-simulations-pydecompiler-3.7-6.7b-v0.9)\n\nHopefully this helps someone else who has a similar project idea.",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 15,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bkxu7z/how_to_create_a_python_decompiler_using_an_llm/",
            "comments": [
                {
                    "body": "Perfect use of LLM. Also I was just going to type \" remove comments, because they only muddy the output\" but you already did that."
                },
                {
                    "body": "Now THIS is innovation! Love seeing use cases extend beyond language, truly LLMs can solve so many monotonous tasks out there. Followed."
                },
                {
                    "body": "A really cool project. Any metrics?"
                },
                {
                    "body": "spectacular results considering the effort required on the human part, it generally takes a pretty complex set of algorithms to clean output that well."
                },
                {
                    "body": "What sort of modding to Sims4 are you doing that needs this sort of work?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "What's the future of Stability AI?",
            "body": "I read fw months ago tweets from Emad saying that they were doing pretty good and that they were starting the membership Program, now all of a sudden I hear thay are losing key members etc.\n\n\\- Will stability AI continue its work?\n\n\\- If everybody entered the Membership Program from Stability AI, would that save it? (Don't know how they are doing financially now)\n\n\\- Emad said SD3 would be the last, what did that mean, can we expect stability to continue developing OTHER models though, hopefully?\n\n&#x200B;\n\nCan you imagine the Future of AI without Stable Diffusion?  [The Future of AI. The Ultimate safety measure. Now you can send your prompt, and it might be used (or not) : StableDiffusion (reddit.com)](https://new.reddit.com/r/StableDiffusion/comments/1b9hjbz/the_future_of_ai_the_ultimate_safety_measure_now/) \n\n&#x200B;",
            "upvote_ratio": 0.89,
            "subreddit": "StableDiffusion",
            "num_comments": 84,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bjn7od/whats_the_future_of_stability_ai/",
            "comments": [
                {
                    "body": "They probably can't continue to pay their top researchers at market rates (which are $750k - $900k per year at OpenAI, Meta, Adobe etc). Those employees are actively poached by other companies and VCs who want to fund them.\n\nThe future of the company depends on Emad. He needs to make revenue and get funding ASAP this year.\n\nThen hire younger, upcoming research talent and continue making models. Releasing the models for free has been a marketing expense in some sense for Stability. But there is no huge revenue making product behind the scenes from what outsiders can tell.\n\nThere will probably be a big gap in open source text to image models because there is no one else at Stability's level of releasing models for free. Maybe Playground who have released 1 model -- but they have no incentive to continue doing it."
                },
                {
                    "body": "\"Emad said SD3 would be the last, what did that mean\"   on the screenshot and on this other tweet he explains what it meant by that : [https://twitter.com/EMostaque/status/1769072883752456466](https://twitter.com/EMostaque/status/1769072883752456466)\n\nhttps://preview.redd.it/jrl6iovs7kpc1.png?width=840&format=png&auto=webp&s=0fdd95ed5335bb1cd96e2cd369114442082cb817\n\nSo   basically SD3 wont be the last, but there will be a whole ecosystem of tools and  that will allow us  to create virtually everything that is needed from AI  and of course models will still be improved with better data."
                },
                {
                    "body": "It's public knowledge that the company has been bleeding money for the last two years so it'd be a miracle if they are even around next year."
                },
                {
                    "body": ">If everybody entered the Membership Program from Stability AI, would that save it? \n\nI highly doubt it considering they're bleeding millions per month. Even if it would save them, what's the incentive? They already over-expanded since SD1.5, starting up language models, audio models, 3d models, video models, crypto nonsense, etc. What am I paying for, for them to bring on more censor nannies and gut the datasets even further? To appease a twitter crowd that does not and will not ever use these models? I would gladly pay even more than the membership asked for if it went to a group that was committed to solely improving image models. \n\nI'd rather support the Pixart team or someone else at this point. Reading the Wurstchen paper and finding out they reduced the dataset to only **2%** of its original size out of 'safety concerns' made me lose faith in them entirely. When the SD3 homepage talks more about safety than it does new features... it gets to a point where it just becomes nonsensical. I'm all for supporting local models but with the direction Stability has been going I'm not really enthusiastic about supporting *them*. There are other research groups that deserve funding, Stable Diffusion isn't the end of local text2image, if a promising group came along with a prototype model, put together a roadmap, addressed common concerns, and asked for community funding, I'm sure a lot of people would pitch in."
                },
                {
                    "body": ">  If everybody entered the Membership Program from Stability AI, would that save it?  \n\nNo way I'm paying anything for a censored model"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Where is Ilya Sutskever? ",
            "body": "Sure wish he would pop up on a podcast or something? Anything? Can they at least give us proof life? ",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 43,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://analyticsindiamag.com/where-is-ilya/",
            "comments": [
                {
                    "body": "Personal theory is that between the hate he got, and his embarrassment, he's actively avoiding social media now. Maybe one day he'll come back to Twitter or something, but who knows?"
                },
                {
                    "body": "My sources tell me he's being locked up in sam secret nuclear base how tragic"
                },
                {
                    "body": "I heard he‚Äôs playing with dogs at parties"
                },
                {
                    "body": "Soon at Microsoft probably."
                },
                {
                    "body": "you ever see that movie Transcendence?  Ilya has become the AI, he is growing at an exponential rate.\n\nor he threatened to tell the public Open AI has AGI and can solve all cryptography. so now he's in a NSA black site"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Mind Over Machines: Witness the First Human Controlling Computers With Thought Alone! (NEURALINK LIVE)",
            "body": "In an unparalleled demonstration, Neuralink has shattered the boundaries between the human mind and technology, showcasing a person effortlessly moving a computer cursor solely through their thoughts. This monumental achievement heralds a new chapter in the symbiosis of human cognition and machine, opening the gateway to a future where brain-computer interfaces (BCI) can redefine our capabilities and interaction with the digital world.\n\nüîó [Dive into the demonstration here.](https://twitter.com/neuralink/status/1770563939413496146?t=yDPhqkg6_wWCrItPjA0k7Q&s=19)\n\nAs we stand at the precipice of this technological revolution, we're prompted to ponder: **What comes next?** How will this technology evolve, and what unprecedented capabilities will it unlock? The potential for enhancing communication for those with mobility or speech impairments is just the beginning. Could we soon stream our thoughts directly onto digital platforms, or even share sensory experiences virtually?\n\nüîç **Envision the Future with AI**: We invite you to harness the power of AI to explore how Neuralink's breakthroughs could further evolve. Imagine a world where BCI enhances our intellectual, physical, and sensory capabilities beyond our current limitations.\n\nüí° **Share Your Vision**: What innovations do you foresee? How can this technology make us even more advanced and powerful? Consider the possibilities - from augmenting human memory and learning to enabling complex control over distant machines, or even facilitating direct brain-to-brain communication.\n\nü§ñ **AI and Your Ideas**: Use AI to expand upon your ideas, illustrating a future where human potential is boundless with the integration of advanced BCI technology.\n\nüåü **Join the Discussion**: Your insights and predictions are crucial as we navigate this exciting yet uncharted journey. How do you envision the impact of Neuralink's innovations on society, ethics, and our very identity as humans?\n\nLet's delve into a discussion about the endless possibilities and the future that awaits us. How will you shape the narrative of our species' evolution with these emerging technologies? \n\n**#NeuralinkFuture #BCIRevolution #HumanMachineHarmony #InnovateTogether**",
            "upvote_ratio": 0.74,
            "subreddit": "singularity",
            "num_comments": 49,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bjqp1b/mind_over_machines_witness_the_first_human/",
            "comments": [
                {
                    "body": "Tbh I'm more interested in non-invasive BCI over invasive tech, from my understanding invasive would be better for those with severe disabilities which is awesome that we could improve their lives.\n\nbut for me personally I'm more excited for what Mindportal has dropping in Q3 this year and hopefully OpenBCI can have a breakthrough. Also Subvocal recognition is another avenue I would prefer for general consumers to interact with AI privately. Just my two cents tho."
                },
                {
                    "body": "op gets it: he already uses ai like a pro to 10x himself xD"
                },
                {
                    "body": "well as much as i dislike elon musk, im glad this quadriplegic patient can have a better life thanks to the neuralink implant. funny to hear he played a strategy computer game till late at night. i can relate."
                },
                {
                    "body": "Is this written by AI?"
                },
                {
                    "body": "Saw this on X , it‚Äôs amazing!!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "THE VERGE - Ubisoft let me actually speak with its new AI-powered video game NPCs",
            "body": "https://www.theverge.com/2024/3/19/24105748/nvidia-neo-npc-prototypes-gdc-2024 ",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 16,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bio69k/the_verge_ubisoft_let_me_actually_speak_with_its/",
            "comments": [
                {
                    "body": "I think the greater potential lies in NPC‚Äôs ACTING accordingly to what you do and what you say, rather than having a conversation with you (which is quite niche). For example, imagine an AI-powered KOTOR 3 in which you can truly have freedom to make an infinite amount of choices"
                },
                {
                    "body": "man i havent been this excited about the future of gaming since the PS3 hype."
                },
                {
                    "body": "I think it will make indie game development easier because hiring decent voice actors is not viable for small developers.\n\nWould also allow more variety in terms of voices as well."
                },
                {
                    "body": "The potential for a new game with these Ai ‚Äúchat bots‚Äù would keep me entertained for hours going around talking to characters and probing them for their backstory and building up relationships to learn more about them."
                },
                {
                    "body": "GPT-3 did it back in Feb/2021:\n\n[https://youtu.be/nnuSQvoroJo?t=269](https://youtu.be/nnuSQvoroJo?t=269)"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Google just released a method to steal model information from black-box language models like ChatGPT or PaLM-2.",
            "body": "https://x.com/AlphaSignalAI/status/1770507861329596537?s=20",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 4,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bjk2ac/google_just_released_a_method_to_steal_model/",
            "comments": [
                {
                    "body": "Read the article on arxiv, or at minimum the abstract - it doesn't steal information, it only accesses the first layer of the model, the embedding layer.  Misleading headline."
                },
                {
                    "body": "ELI5. Implications?"
                },
                {
                    "body": "Yup. I wonder how long this zero day vulnerability has been there?"
                },
                {
                    "body": "They just partnered with Reddit as well"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Voicecraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild",
            "body": "I'm not the author. But considering the quality of the model, I can't wait to try it out, finally a really good local TTS model with voice cloning capabilities ?\n\nVoiceCraft is a token infilling neural codec language model, that achieves state-of-the-art performance on both **speech editing** and **zero-shot text-to-speech (TTS)** on in-the-wild data including audiobooks, internet videos, and podcasts. To clone or edit an unseen voice, VoiceCraft needs only a few seconds of reference.\n\nGithub: [https://github.com/jasonppy/VoiceCraft](https://github.com/jasonppy/VoiceCraft)\n\nDemo: [https://jasonppy.github.io/VoiceCraft\\_web/](https://jasonppy.github.io/VoiceCraft_web/)",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 21,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmxfk3/voicecraft_zeroshot_speech_editing_and/",
            "comments": [
                {
                    "body": ">To facilitate speech synthesis and AI safety research, we fully open source our codebase and model weights.\n\n[Kool & The Gang - Celebration](https://youtu.be/3GwjfUFyY6M)\n\n-\nFinally! I've read a lot of great TTS papers in the last year but for once it seems like we're actually getting our hands on the code & weights. They say they're planning on releasing it next week. Exciting stuff.\n\nThank you to the authors!"
                },
                {
                    "body": "Whoa, seems really good!\n\nAny idea if it works well in languages other than English?"
                },
                {
                    "body": "Yup finally looks like competition to Eleven Labs.\nGrats to researchers for releasing weights and demo."
                },
                {
                    "body": "Holy shit wtf. This is mind blowing. Really, a few seconds to train? How??"
                },
                {
                    "body": "Wonder how that Amazon BASE TTS model stacks up against thus, guess we'll never know since it's not open source https://www.amazon.science/base-tts-samples/"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Make Games With AI - Introducing Buildbox 4",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 33,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://youtu.be/GDxNHVWmjAs?si=0gDIG8zILoij2L7Y",
            "comments": [
                {
                    "body": "If this is legit, we have come a long ways in a short time from frvr.ai¬†"
                },
                {
                    "body": "Didn‚Äôt the CEO of NVIDIA claim we would have fully AI-generated games in 5-10 years?\n\nNot even a week later, and a seminal model is unveiled. Though, to be fair, it will most likely be a while before it becomes commercially viable to create a wholly AI-generated game."
                },
                {
                    "body": "This is just the early beginnings, full AI generated games will be 100% neural rendered, a bit like what SORA is for videos right now but for games."
                },
                {
                    "body": "I truly wonder if the big fish at Bethesda, Rockstar, Valve, Nintendo and other companies have an understanding of the change that is going to hit them like a ton of bricks.  Nvidia CEO said 5-10 years.  They seem not to understand.  Bethesda pursuing its sloth-like strategy of rolling out the next Elder Scrolls game in \\~ 2028, same with Microsoft and the new XBox.  All will be swept away in 10 years.  The real coveted items will be precisely worded text prompts (maybe 500 words) that will generate exactly the kind of game world you want (ie: survival mechanics, size of game world, nudity or not, what happens on player death, types of weapons, first or third person view, etc.)  Players will exchange ideas on better and better prompts to give them the ideal game."
                },
                {
                    "body": "Could there be a connection between this and FDVR?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[Help/Serious Discussion] - I tried my hand at a 1.58 BitNet implementation - but I'm stuck.",
            "body": "Everyone knows about the 1.58 BitNet Ternary paper that was released a little while back: [https://arxiv.org/pdf/2402.17764.pdf](https://arxiv.org/pdf/2402.17764.pdf) \n\nI wanted to take a hand at implementing it - and I'm a hobbyist so by no means do I do this for a living or anything like that. I feel like I've gotten pretty far in the implementation but I dont know if thats legit or just that I've been trying this for a minute now and it looks like its doing what I expect it to do haha. \n\nHere is the GitHub repo with all the information: [1.58BitNet GitHub](https://github.com/nkotak/1.58BitNet)\n\n1. I was able to get a model to be created using the ternary architecture and 1.58 bit implementation (i think) \n   1. I say this because I'm able to generate models that seem to match the expected size as they should be. For example a 300M parameter model is created and its size is roughly 72mb. \n   2. I was able to create a model all the way up to 3B parameters with a size of 607mb. \n2. I cant seem to get training to work properly (trainingv2.py) and I'm not entirely sure why. For whatever reason my Loss doesn't decrease with every step, but my validation loss does. \n3. I also cant seem to get my inference.py script to work - it did work at some point when I was trying to convert existing models into this architecture but what I realized is that even if I convert existing models - I have to retrain the entire model all over again. \n4. I think there are also some memory issues at play here, for example I cant seem to generate a 7B model but with. 96gb of ram i should be able to ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø \n\nI'm putting this out here so I can try and find folks who are able to help and maybe get an implementation working based on whatever I have laid out. \n\nAgain - I'm not a software developer by trade - I try and do things for fun and I was hoping this would be something cool to implement but I think it's above me now. I know the ideal scenario would be to wait until the Microsoft folks released their work and model and just use that but I figured why not take a crack at it. \n\nI'm posting this here in case I can reach anybody who has the expertise to make this work / take a look at it and fix it. Oh FYI I have this script working to leverage MPS and CPU as a backup, eventually it would be cool to make this work with MLX. \n\nThanks for reading - if anyone is willing to take a crack at it that would be cool - if not no worries! \n\nUPDATE: Thanks for the interest in this everyone! With the new paper that was released I was able to make optimizations and updates to the code. \n\nI‚Äôm still not sure if it‚Äôs working correctly but I was able to tweak it so 7B+ parameter models can be generated (albeit you need decent hardware, a lot of ram, and time - took my m2 max 96gb a little over 2.5 hours). \n\nAlso with the changes it seems the model has become more stable and I‚Äôve updated the training to include the two stage learning approach with the decayed learning rate. I‚Äôm not entirely sure if it‚Äôs working but I‚Äôm seeing much better numbers in the validation loss than i saw before. ",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 22,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjjywn/helpserious_discussion_i_tried_my_hand_at_a_158/",
            "comments": [
                {
                    "body": "[The BitNet guys have just posted tips on how to train 1.58b models](https://github.com/microsoft/unilm/tree/master/bitnet)"
                },
                {
                    "body": "When I grow up I want to be a hobbyist as good as you."
                },
                {
                    "body": "Your already pointed to the new work, just want to let you know this is a really clearly outlined GitHub page, thanks makes it very easy to follow along/lesrn!"
                },
                {
                    "body": "IIRC loss might not decrease continuously if the text is too complex (or long). If you are training 300M LM with long context and a fine-tuning dataset like Orca, maybe it's struggling against the patterns."
                },
                {
                    "body": "Would this work with Galore?\n\nAnd will this method also work with diffusion models?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Once ChatGPT responds \"Why don't you just google it?\"...",
            "body": "We'll know we have reached true AGI",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 45,
            "submission_flair": "shitpost",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bl5uay/once_chatgpt_responds_why_dont_you_just_google_it/",
            "comments": [
                {
                    "body": "now that would be funny"
                },
                {
                    "body": "‚ÄúTouch grass, bitch‚Äù"
                },
                {
                    "body": "Wait, you guys don't get that response from ChatGPT on regular basis??"
                },
                {
                    "body": "Paid version of Chat gpt is my new Google.\n\n\nFor example, today I was servicing my car. I could Google what the oil capacity of the engine is when changing the oil filter as well. Then go through a load of websites until I found the answer I needed.¬†\n\n\nInstead I just gave chat gpt the make, mod and version and it gave me the oil capacity instantly.¬†\n\n\nUsing it in this way is seriously disrupting the usefulness of Google. So much so I rarely Google anything now simply because the once amazing results are now just utter garbage.¬†"
                },
                {
                    "body": "Nah cause I have already seen it reply with something similar before.."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Name this Movie...",
            "body": "",
            "upvote_ratio": 0.74,
            "subreddit": "StableDiffusion",
            "num_comments": 111,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bkz1p5",
            "comments": [
                {
                    "body": "Cmon Guys!?\n\nBeauty and the Beast!"
                },
                {
                    "body": "How to Fuck Your Demon"
                },
                {
                    "body": "Neverending story.. Reboot."
                },
                {
                    "body": "Debbie does Dungeons"
                },
                {
                    "body": "How I met your father"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[D] NVIDIA GTC 2024 announcements",
            "body": "NVIDIA's plan has spread across accelerated computing, generative AI, industry applications, automotive, enterprise platforms, Omniverse, and robotics.\n\nSome of the most interesting are:\n\n* DRIVE Thor: an in-vehicle computing platform for generative AI applications in self-driving cars. With up to a thousand trillion operations per second, it enhances safety for autonomous driving and enables interactive conversations with the vehicle.\n* Omniverse: a digital twin ecosystem blending physical and virtual worlds to help industries simulate, optimize, and execute operations more efficiently. The new Omniverse Cloud APIs expand these capabilities, benefiting sectors like automotive and robotics.\n* Project GR00T: a foundation model for humanoid robots driving breakthroughs in robotics and AI. Also, unveiled Jetson Thor computer and upgrades to the NVIDIA Isaac‚Ñ¢ robotics platform with generative AI models and simulation tools.\n* Nvidia Blackwell GPU: a cutting-edge advancement designed to power the next generation of AI with 20 petaflops of performance. This GPU represents a quantum leap in AI capabilities, aiming to democratize access to trillion-parameter models.\n* NVLink Switch 7.2 TI: a new generation interconnect technology, which addresses the bottleneck of data exchange. It is designed to facilitate communication between GPUs at a scale suitable for the most advanced AI models.\n* NVIDIA NIM: a new software product aimed at simplifying the deployment of generative AI within enterprise environments. It packages models with optimized inference engines and supports a wide range of GPU architectures. They call it an AI package for all.\n\nWhat's your favorite one?",
            "upvote_ratio": 0.85,
            "subreddit": "MachineLearning",
            "num_comments": 40,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/",
            "comments": [
                {
                    "body": "Can someone translate from Marketing keyword soup to English?"
                },
                {
                    "body": "With how much Blackwell will cost, not sure \"democratize\" is the right term"
                },
                {
                    "body": "| quantum leap¬†\n\n\nSo basically no improvements"
                },
                {
                    "body": "* Why not just say 1e12 flops ? one thousand trillion is both pedantic and fails to give an accurate measure of expected performance. \n\n* Digital twin ecosystem?? I'm not even sure what this means. \n\n* I guess GR00T looks nice but theres almost no substance on this data point. What specifically does this mean for a researcher?\n\n* Bro, remove quantum from your vocabulary. Using it in a marketing-like sense within research circles will get eyes rolling and will vanish your credibility. Simply stating a Blackwell GPU (if it actually can) enables use of trillion parameter models is good enough. \n\n* NVLink sounds interesting, but again, give me some hard info! what is the expected increase in bandwidth? \n\n* Who is \"They\" and what exactly does NIM do?"
                },
                {
                    "body": "Is this optimized for transformers?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Quality improvement through padding tokens that give the model time to think (Mixtral in exllama v2)",
            "body": "This is my first real post here, but I've been experimenting with  generative AI for years now and with exllama (v1 & v2, great work!)  from the start.   \n\nIn particular, I have now experimented a lot with format enforcing (using [https://github.com/noamgat/lm-format-enforcer](https://github.com/noamgat/lm-format-enforcer)) and I found the following:   \n\nWhen I force the model to output JSON, it often generates a large  amount of \"fill tokens\" like spaces. At the same time, I have the  feeling that the quality of the output has increased significantly.   \n\nSince \"feeling\" is not a good measure, I started analyzing the  probability distributions in the places where a lot of spaces are  generated, and I think I can prove that the distribution becomes  \"sharper\". So you could say that with each space token the model becomes  more confident in its answer until something meaningful is finally  generated again. More precisely: entropy decreases.   \n\nI'm currently trying to prove this more reliably.   \n\nCan anyone support this experience? My thoughts are that this is a  similar phenomenon to going through individual or all layers multiple  times, which has already been discussed here and elsewhere in the past,  except that here we have an \"outer\" loop.   \n\nIf this turns out to be correct (and don't get me wrong, everyone  probably knows this already except me... so please tell me ü§£), then we  could loop dynamically using entropy (or a similar measurement) several  times and increase generation quality where needed very efficiently.   ",
            "upvote_ratio": 0.99,
            "subreddit": "LocalLLaMA",
            "num_comments": 48,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bl8w5u/quality_improvement_through_padding_tokens_that/",
            "comments": [
                {
                    "body": "There were several papers investigating this, such as https://arxiv.org/abs/2310.02226."
                },
                {
                    "body": "There is also quiet star: https://github.com/ezelikman/quiet-star\n\nNobody talked about it here yet and there is a model they made."
                },
                {
                    "body": "inb4 it turns out the path to AGI is to teach it that it's okay to go \"UHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH, lemme think for a bit.... hmmmmmmm....\" all the time"
                },
                {
                    "body": "Relevant research: [Think before you speak: Training Language Models With Pause Tokens](https://arxiv.org/abs/2310.02226)\n\nTLDR: they add \"uhmmmmmm.....\" token. Stonks.\n\nAh, damn, already posted by someone else."
                },
                {
                    "body": "Hey! That's basically what I am currently working on as a bachelor thesis project. Initially it was inspired by ACT paper for RNNs. The current goal is to do the things that are done in Think Before You Speak paper, but without fune-tuning. For now, it looks quite promising. Gonna need to do some benchmarking, though. I take some rare tokens that do not have any meaning by themselves, like some weird utf symbols, prohibit the model from outputting them by itself and insert them to the model one-by-one when it struggles to continue. The *struggle to continue* is detected based on the probability distribution on the raw logits output. And while this pondering is in progress, I gradually lower the temperature so the model has to converge to some answer at some point. What's interesting is that model usually tends to become \"less unsure\" while receiveng these ponder tokens even without lowering the temp. And yeah, most importantly, the model is prompted to interpret these symbols  as \"thinking\" at the beginning of the context. If you have any ideas that can improve the work, I'd be happy to hear!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Neuralink reveals first human-trial patient, a 29-year-old quadriplegic who says brain chip is 'not perfect' but has changed his life",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "BRAIN",
            "has_media": true,
            "url": "https://www.businessinsider.com/neuralink-first-human-trial-patient-quadriplegic-elon-musk-x-2024-3",
            "comments": [
                {
                    "body": "You're a little late bud. We working in exponentials over here"
                },
                {
                    "body": "You know the singularity is near when even the singulatarians can‚Äôt keep up with the zeitgeist."
                },
                {
                    "body": "Yeah I shitposted on this topic like 3 times yesterday,  today we‚Äôre talking the Meta room simulator thingy"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Daily dose of optimism: Automation will reduce costs such that companies will undercut one another to gain market share, driving the price of goods down for everyone. ",
            "body": ".",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 68,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjvwwe/daily_dose_of_optimism_automation_will_reduce/",
            "comments": [
                {
                    "body": "This is how I see the AI race shaping up to be, but things are gonna get worse before it gets better unless everyone gets UBI. I just hope that we can collectively make it through that transition to post-scarcity."
                },
                {
                    "body": "Deflation puts downward pressure on wages and employment tho."
                },
                {
                    "body": "Yes, automation is powerfully deflationary. The only things we really pay for is other people's land, labor and risk. Labor ends up being the majority of the costs of anything we buy. Even the cost of raw materials is mostly the cost of someone's labor to mine, discover and ship the ore. \n\nEverything is about to become almost free. Those unemployment benefits (which will turn into a form of UBI) will buy you more and more stuff over time. We're close to an era so abundant that money won't mean all that much. After a very uncomfortable transition period (where people will be desperately poor and afraid), we should be living like kings. \n\nIt will be interesting to see how people continue to compete for status once material success no longer differentiates one person from another."
                },
                {
                    "body": "Is that a controversial opinion on this subreddit?¬†\n\nI know the other blatantly socialist subreddits (like Futurology or Technology) would downvote the hell out of that concept, but this subreddit seems a bit less opportunistic in that way. ¬†\n\nIncreased productivity is always better for society, but some certain political movements like to make it seem like everything is getting worse all the time (so they can pitch their solution like a sleazy salesman).¬†"
                },
                {
                    "body": "People have been saying this for decades. However, productivity has gone up whilst the cost of essential goods have gone up."
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "2 IP-Adapter evolutions that help unlock more precise animation control, better upscaling, & more (credit to @matt3o + @ostris)",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "StableDiffusion",
            "num_comments": 11,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bn2bsp",
            "comments": [
                {
                    "body": "You can find the Composition IP-Adapter [here](https://huggingface.co/ostris/ip-composition-adapter).\n\nAnd [here's Matteo's Comfy nodes](https://github.com/cubiq/ComfyUI_IPAdapter_plus) if you don't already have them.\n\nThere are many example workflows you can use with both [here](https://github.com/cubiq/ComfyUI_IPAdapter_plus/tree/main/examples).\n\nAlso, if you're experimenting with these and want to share with/learn from/collaborate with a ravenous pack of nerds who are doing similar, please drop into [our Discord](https://discord.gg/VVtzS5tDc4)."
                },
                {
                    "body": "Just getting into this AD stuff w Comfy. Appreciate the heads up."
                },
                {
                    "body": "I went to sleep very late because of that updated version of IP-Adapter\\_Plus last night ! It's great, really great, even though you have to replace the old nodes once you do the upgrade. It's totally worth the hassle imho.\n\nThe new features are cool, and the performance has been improved to a point where you can actually FEEL it instead of having to measure it. Now that's performance improvement !"
                },
                {
                    "body": "I still haven't figured out ip adapter lol"
                },
                {
                    "body": "Do I use these with a pre-processor or?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "[D] Is Aleksa Godric's post on landing a job at DeepMind still relavant today?",
            "body": "Pretty much the title I guess. [This is Aleksa's post btw](https://gordicaleksa.medium.com/how-i-got-a-job-at-deepmind-as-a-research-engineer-without-a-machine-learning-degree-1a45f2a781de). I work with in a startup where I directly apply deep learning on a day-to-day basis to solve challenging problems. My typical day pretty much involves fine-tuning, data wrangling, generating reports, looking at results and curating high quality datasets to fine-tune our models on. I've set a lofty goal for myself for 2025 to be competent enough to interview at DeepMind/Anthropic etc (not to work on LLMs or the current trendy topics, but maybe general Research Engineer types), with an emphasis on both solid understanding of the fundamentals and cutting edge work being done in the field.\n\nI'll have about \\~2 years of direct work exp by then, and more than 9 years of working on academic (I have a bachelor's from a decent state college and Master's from top 3 university for ML/AI/Robotics, where I was decent student. Nothing spectacular. Got 1 paper published as second but \"very well deserved\" author according to my well-known/established Master's advisor) and internship projects (internships, side-projects, lot of scattered but popular open-source projects). I'd love to know how I should continue my prep? I feel I need to retool my fundamentals, but wanted to know how I should go about this, to make sure my efforts are as focused and directly impactful.\n\nMy Achilles heel is that I've never seriously done LeetCode, since I mostly applied/interviewed for research engineer like positions, where interviewers mainly look at papers, open-source contributions and some minimal amount of coding know-how in PyTorch/TF etc.\n\nIf folks at these companies could weigh in I'd appreciate it a ton. I'm honestly terrified just looking at the backgrounds of folks at these companies, since it looks like every other person working there are IMO, IOI, IPhO medalists with many of them having crazy experiences in quant firms where interviews have mythical/legendary status.\n\nAny and all advice will be appreciated.",
            "upvote_ratio": 0.87,
            "subreddit": "MachineLearning",
            "num_comments": 23,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bme24n/d_is_aleksa_godrics_post_on_landing_a_job_at/",
            "comments": [
                {
                    "body": "Author of the blog post here! :) Definitely still relevant, the only thing that changed with DeepMind's interviews is that they don't do quiz anymore. But the gist remains - you still need a good knowledge of CS/coding, maths & stats, ML for an RE role at top AI labs. If you're interviewing for a particular team then you need to read relevant papers.\n\n  \n(nit: you misspelled my surname in the title :))"
                },
                {
                    "body": "Note that this is for a deep learning engineer role, not a deep learning scientist role. You don't need a PhD for a former (or the latter for that matter, but it is significantly more difficult without a PhD since you need multiple high-quality publications in top conferences). The biggest thing you should work towards is well-known connections (although ideally you would want to do good work and have your connections acknowledge that). The ML + Robotics community is very insular right now and consist of a handful of top labs + industry research groups."
                },
                {
                    "body": "RemindMe! 2 Days"
                },
                {
                    "body": "That blogpost is really inspirational. Kinda sad though cause it makes me feel like a lazy bum cause I was doing a lot of the same stuff as Godric at around the same time, but with less zeal. And not sharing the stuff i was working on, on social media which I've been lately thinking is actually super important."
                },
                {
                    "body": "IMO deepmind is up to some shenanigans when it comes to who they let interview.  I was working at a company where my team was split between london and the US and deepmind basically poached everyone from the london location but refused to interview anyone from the US location even though they were literally on the same team with the same role."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Stability AI Announcement ‚Äî Mostaque resigns as CEO",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 8,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://stability.ai/news/stabilityai-announcement",
            "comments": [
                {
                    "body": "Sad, but expected.\n\nStability made a huge splash initially with releasing SD 1.4, propelling a previously unknown company to be mentioned in the same sentences as OpenAI. This was a genius move from Emad, to essentially 'buy' the branding rights to the latent diffusion research model with supply GPUs. With less than $1 mil he got insane global publicity in the hottest upcoming industry. Keep in mind this was before ChatGPT (SD 1.4 was in 2022-08, GPT3.5 in 2022-11), so it was an insane move that paid off.\n\nHowever, Emad doesn't seem to be able to run a large AI lab in the long run. Stability failed to find a business model (I still don't know how they plan to earn money), and just spread themselves way too thin. \n\nThey dabbled in open source LLMs (Got crushed by Mistral/Meta), music models, 3d models etc. But the only thing that had any success was their image models. And even with the image models, there had been major mishaps. Like the catastrophic SD2.0 model, that made all future model releases suspect. Now SDXL was successful, but no other AI company releases models way worse than their predecessors.  \n\nThe open source model could have worked. Mistral seems very stable. But that requires having a much more focused strategy than just 'open source everything and hope it works out'. So I hope Stability gets a CEO that can focus on execution more, and also deal with the enormous legal complexities of open source AI. Its also possible it'll just be bought by UAE/Saudi Arabia..."
                },
                {
                    "body": "Damn, so where does this leave SD3?"
                },
                {
                    "body": "always seemed sus af to me\n\n[Stability AI, Makers of Stable Diffusion, Could Be in Huge Trouble | 22 Mar 2024 | by Matt Growcoot](https://petapixel.com/2024/03/22/stability-ai-makers-of-stable-diffusion-could-be-in-huge-trouble/)\n\n>The news this week that three researchers who developed Stable Diffusion have left the company, following a number of executives out the door, has left Stability AI in crisis.\n>\n>Robin Rombach, Andreas Blattmann, and Dominik Lorenz essentially created Stable Diffusion while at a German university. Stability AI got involved after the publication of their research and offered them the company‚Äôs computing resources. According to Forbes, all three have now left Stability AI which is also experiencing cash flow problems. \n>\n>Adding to the mess is the lawsuit the company is facing on both sides of the Atlantic brought by Getty Images which claims Stability used 12 million of its photos unlawfully. \n\n\n[‚ÄòSo Many Things Don‚Äôt Add Up‚Äô: Stability AI Founder Accused of Exaggerations | 05 June 2023 | by Matt Growcoot](https://petapixel.com/2023/06/05/so-many-things-dont-add-up-stability-ai-founder-accused-of-exaggerations/)\n\n>‚ÄúStability, as far as I know, did not even know about this thing when we created it,‚Äù Bj√∂rn Ommer, the professor who led the research, tells Forbes. ‚ÄúThey jumped on this wagon only later on.‚Äù\n>\n>‚ÄúOne thing you learned from that is if you have a company with a huge press department, you can rebrand history in your interest,‚Äù he continues.\n>\n>Forbes states that Mostaque listed UNESCO, OECD, WHO, and World Bank as partners while pitching to investors.\n>\n>Three of those organization tells Forbes they have no record of a partnership with Stability and UNESCO says they have no association beyond a Covid-19 data initiative when the company first started and long before Stable Diffusion. \n\ni didnt even know any of that until 10 mins ago. even more sus af"
                },
                {
                    "body": "doesnt sound very..........stable......."
                },
                {
                    "body": "> I hope Stability gets a CEO that can focus on execution more\n\nI'm sure the next CEO will be far less open."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "How do you guys make big decisions knowing everything that‚Äôs about to happen?",
            "body": "Pretty much title. I‚Äôm graduating this year with a degree in education, which is a domain I feel is fairly safe from the incoming AI automation. But I still feel like whatever I do is going to be either very crucial or very pointless given how the next events are going to play out. Like do I get a full time right away or work two part time jobs, do I stay at home with my retiring father and sick mother or move out? Should I be working a lot and saving or just take some time for myself? What‚Äôre your thoughts?",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 143,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bj34i6/how_do_you_guys_make_big_decisions_knowing/",
            "comments": [
                {
                    "body": "This isn't the first time in history where \"everything we know is about to change\". \n\nHow did people plan, seeing the French Revolution succeeding? Or as the Industrial Revolution swept through England? Or in the single generation when vast tracts of land went from hunter-gatherer to settled-farming?\n\nOr knowing that Napoleon's armies were marching towards them? Or that the Mongols had just destroyed the next city along? Or in the days of the Cuban Missile Crisis (when the death of the majority of humanity was a real outcome)?\n\nTo quote CS Lewis:\n\n*‚ÄúIn one way we think a great deal too much ... I am tempted to reply: ‚ÄòWhy, as you would have lived in the sixteenth century when the plague visited London almost every year, or as you would have lived in a Viking age when raiders from Scandinavia might land and cut your throat any night; or indeed, as you are already living in an age of cancer, an age of syphilis, an age of paralysis, an age of air raids, an age of railway accidents, an age of motor accidents.‚Äô*\n\n*In other words, do not let us begin by exaggerating the novelty of our situation.... when it comes \\[let it\\] find us doing sensible and human things‚Äîpraying, working, teaching, reading, listening to music, bathing the children, playing tennis, chatting to our friends over a pint and a game of darts‚Äînot huddled together like frightened sheep*\""
                },
                {
                    "body": "Ignorance is bliss, so I‚Äôm just going to act like it won‚Äôt üòÇ"
                },
                {
                    "body": "That is a tough question.  I think we are all asking ourselves the same question. There is a small fraction of the population that can see what is coming while othera are oblivious. For now it's probably best to continue down the same path that you planned."
                },
                {
                    "body": "Don't plan on the singularity happening, make decisions based on the assumption its 100 years away. If you do that, you are going to be OK regardless of when it happens.  \n\nIf you have the option of living with your parents and it does not restrict your employment options that can really help you build capital. Leaving home as soon as you can might sound like a responsable plan but the reality of the cost of housing today makes that a luxury.  \n\nIf you can save up enough money to have a rainy day fund you are going to be better off than 60% of your peers. Think three months pay in an account you don't touch unless it gets bad. \n\nOnce you have that you should start to save for a deposit to a house, if your parents are understanding let them know you are saving every penny you can. They will be more accommodating if they know you are saving for a deposit and it creates a goal.\n\nTry and get a full time job, rather than two part time jobs. You have a degree and are at the start of your career, the next couple of years will set the trajectory for the next decade. Its possible to recover from a weak start but it takes a lot of work. Try and land that full time position that has long term prospects and promotion potential. If you decide that a career is not for you, you can always switch to part time work. It's much harder to do it the other way around."
                },
                {
                    "body": "I'm in a similar situation. I graduate in May in Microbial Biotech. Knowing everything that is coming, that I'll lose any job soon enough, that post-labor economics is coming, that there will be social unrest, that a recursive-AI is coming and the world as we know it will cease to exist... knowing all of that, my course hasn't changed. \n\nMy life still exists right here and right now. Things will be different in the future, but no one knows just how fast or smoothly it will all happen, so we just have to keep chugging along, like nothing is changing anyways. \n\nI am firm e/acc, but there's not much I can do in tech and AI, so I'll keep doing my own path in life. I'm looking for a job, starting where I can in the lab. I have ambition to work in a genetic engineering research and development lab to better human lives through GMOs or human editing for example. I plan to move to South Korea within a year and live with my beautiful girlfriend. \n\nOne day, none of this will matter, but *right now*, right here and now, it still does."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[P] DeepRL Agent Completing Street Fighter III with Ken",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "MachineLearning",
            "num_comments": 21,
            "submission_flair": "Project",
            "has_media": true,
            "url": "https://i.redd.it/592vssiqp3qc1.gif",
            "comments": [
                {
                    "body": "turns out the dominant strategy really is shoryuken all the way lol"
                },
                {
                    "body": "Thank you for the comments and exchange of thoughts u/doc720 u/Lifaux u/valis2400 u/Certain_End_5192 !\n\nWe understand one would expect to see \"better matches\" when it comes down to \"AI\" algorithms, because there is a natural tendency to think the AI bots should play with a style \"more varied\", \"more human like\", \"performing a larger set of moves\". And we totally agree that it is a very interesting goal, actually we do have videos showing that type of behavior, in fact they can be easily found on our Youtube channel (https://www.youtube.com/c/diambra\\_ai), our Twitch channel (https://www.twitch.tv/diambra\\_ai) and, more interestingly, on our platform (https://diambra.ai/leaderboard), where each submission listed in the leaderboard, and each submission of a given user, shows the video recording of his agent\n\nWhat we are sharing here, instead, is an agent that managed to **maximize the environment reward**, and does that **learning a specific exploit for this specific game**.\n\nIt is worth stopping for a moment and focus on the fact that, in this case, the goal is to obtain the maximum score (i.e. maximize the reward), not obtaining a human like behavior.\n\nIn addition, a way to find exploits automatically, as in this case, can be a very valuable tool for designers themselves, as it could be used to point out flaws to be fixed (as in this case for SFIII, where they would need to improve their \"classic-AI\" to apply countermeasures to this exploit, or even better, use RL to train their characters! :D )\n\nMoreover, this exploit is all but trivial to implement manually, in fact the algorithm is using as main input the game frame, being processed by a CNN to pick the right moves and timing, which is not something to take for granted.\n\nOf course, we 100% agree that is absolutely interesting also the goal of obtaining \"interesting\" or \"human-like\" bots, so playing with the reward function to foster diversity or, way better, moving towards offline RL and techniques belonging to the imitation learning family."
                },
                {
                    "body": "I think it would be a little more exciting - in the clip shown at least - if the AI had learned more than one move.¬†"
                },
                {
                    "body": "I'm always super fascinated by stories of agents reward hacking, or those in which we discover that there are good strategies that accomplish a goal which seem cheap/dumb/wrong to human agents.\n\nIs there a agent-vs-agent competition for any fighting games? I imagine that would involve development of a lot more complex strategy as the opposing agent would be an unknown variable rather than the (presumably deterministic) character AI in this streetfighter clip."
                },
                {
                    "body": "Reinforcement Learning won't naturally have variety or diversity in its reward function.\nY'all should appreciate that it has found the score maximization move as OP mentioned. AI won't dominate us in video games in a flashy or \"human way\" üòÄ"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "What if UBI came in the form of most basic needs met?",
            "body": "As someone who seen life in a developed country and developing country, what if UBI somehow came in the form of basic needs met? Food centers, clothing, free apartments with water, etc?\n\n&#x200B;\n\nKinda sounds like Wall-E but just trying to imagine the near future if all work was automated somehow, what would stuff look like. We could just travel from city to city for free by... walking. I guess flights wouldn't be free yet.",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 110,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bktaay/what_if_ubi_came_in_the_form_of_most_basic_needs/",
            "comments": [
                {
                    "body": "[removed]"
                },
                {
                    "body": "I think more realistic would be government subsidies making food cheap and then everyone gets some small UBI."
                },
                {
                    "body": "If that means decent housing, natural food, and clean water, i would take it and leave the job."
                },
                {
                    "body": "Wall-E highlighted the issue of excess rather than meeting basic human needs. For me, it would provide the opportunity to delve into studying and researching the fascinating subjects I never have time for. I wouldn't leave my job, but I would reduce my working hours. My aim would be to enhance my contribution to society, free from the concerns of earning a living."
                },
                {
                    "body": "Why not both? Basic needs met, plus small stipend to be able to partake in the luxury of your choice. At least until you can directly ask for ASI for what you want, and it will either make it happen, or tell you it is impossible.\n\nBut in the short term, you will NEED someone to buy stuff for the economy to work, and giving people a small amount of money will help achieve this."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Introducing RAG 2.0 - Contextual AI",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 16,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://contextual.ai/introducing-rag2/",
            "comments": [
                {
                    "body": "Why does every VC company make a big announcement with a flashy demo and then there's just a waitlist..."
                },
                {
                    "body": "> if you know that you are going to be doing RAG, you should train the system for doing RAG.\n\nWhere's the paper? I don't see it on the page"
                },
                {
                    "body": "Still reading through it. Came here to post about how awful the name is. People already confuse RAG and prompt flow. This just makes it worse."
                },
                {
                    "body": "Next.\n\nAnother \"huge announcement\" where you can \"join the waitlist today.\"\n\nI think that the moderators should consider adding a new rule that announcements must be available to anyone before being considered an actual product."
                },
                {
                    "body": "waitlist. Byeeeee"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "fading",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 6,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/9gjns413w8pc1",
            "comments": [
                {
                    "body": "And if ot just had a perfect loop... Amazing job OP!! This is wonderful"
                },
                {
                    "body": "Midjourney + SVD (played a lot with motion bucket id and seed)+Topaz"
                },
                {
                    "body": "Love the dream like feel of this"
                },
                {
                    "body": "Thank you :)"
                },
                {
                    "body": "Did you find a sweet spot for the motion bucket ID? I'm curious how low you typically set it."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "New Short Course: Efficiently Serving LLMs from DeepLearning.ai",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 4,
            "submission_flair": "Tutorial | Guide",
            "has_media": true,
            "url": "https://x.com/AndrewYNg/status/1769761666143814122?s=20",
            "comments": [
                {
                    "body": "Hey everyone, Travis (course instructor, maintainer of LoRAX) here!  \n\nI know a lot of folks here are trying make sense of all the options in this space on hosting their own LLMs, so I wanted to share this course I put together on the topic of efficient LLM inference.\n\nMy goal in putting this together was to help answer some of the most common questions I get as the maintainer of the open source LLM inference server [LoRAX](https://github.com/predibase/lorax):\n\n- What makes LLM serving different from any other microservice?\n- How do you handle multiple requests to the same model at the same time?\n- How can you serve many custom fine-tuned models on the same base model?\n- How do I serve the latest and greatest open source LLMs without breaking the bank?\n\nThis course is really about understanding the foundational concepts to answer these questions. You'll spend far more time writing things from scratch than calling APIs. So if you've been searching for broad but technical overview of the latest advancements in LLM inference, I hope you find that this is the course you've been looking for!\n\nTopics covered include:\n\n- How text generation works token by token\n- Batching and continuous batching to handle multiple requests at once\n- Quantization to run commodity hardware\n- Low rank adaptation and serving many LoRAs at once efficiently\n- And, of course, LoRAX :)\n\nEnjoy!"
                },
                {
                    "body": "Just sampled the first 10 min of the first class. I like your approach when discussing the code.  I'll def follow up on the course."
                },
                {
                    "body": "do you plan on supporting Aphrodite?"
                },
                {
                    "body": "Thanks! Definitely appreciate the feedback."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "New Short Course: Efficiently Serving LLMs from DeepLearning.ai",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 4,
            "submission_flair": "Tutorial | Guide",
            "has_media": true,
            "url": "https://x.com/AndrewYNg/status/1769761666143814122?s=20",
            "comments": [
                {
                    "body": "Hey everyone, Travis (course instructor, maintainer of LoRAX) here!  \n\nI know a lot of folks here are trying make sense of all the options in this space on hosting their own LLMs, so I wanted to share this course I put together on the topic of efficient LLM inference.\n\nMy goal in putting this together was to help answer some of the most common questions I get as the maintainer of the open source LLM inference server [LoRAX](https://github.com/predibase/lorax):\n\n- What makes LLM serving different from any other microservice?\n- How do you handle multiple requests to the same model at the same time?\n- How can you serve many custom fine-tuned models on the same base model?\n- How do I serve the latest and greatest open source LLMs without breaking the bank?\n\nThis course is really about understanding the foundational concepts to answer these questions. You'll spend far more time writing things from scratch than calling APIs. So if you've been searching for broad but technical overview of the latest advancements in LLM inference, I hope you find that this is the course you've been looking for!\n\nTopics covered include:\n\n- How text generation works token by token\n- Batching and continuous batching to handle multiple requests at once\n- Quantization to run commodity hardware\n- Low rank adaptation and serving many LoRAs at once efficiently\n- And, of course, LoRAX :)\n\nEnjoy!"
                },
                {
                    "body": "Just sampled the first 10 min of the first class. I like your approach when discussing the code.  I'll def follow up on the course."
                },
                {
                    "body": "do you plan on supporting Aphrodite?"
                },
                {
                    "body": "Thanks! Definitely appreciate the feedback."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "What's Your Opinion on AI Rendering Tools for Architects?",
            "body": "",
            "upvote_ratio": 0.88,
            "subreddit": "StableDiffusion",
            "num_comments": 38,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/r1ay6ritvkpc1.gif",
            "comments": [
                {
                    "body": "Architects don‚Äôt need to create different backgrounds for buildings. Buildings are almost always for a specific site.\n\nTypical buildings (ie non-Zaha paper architecture) have their form based on plan requirements and zoning. You can‚Äôt just let AI make changes to that form.\n\nIf you use controlnet to maintain the form, you can do material studies‚Ä¶ but controlling those with SD is iffy at best and it does terribly with small pattern materials like brick or metal panel.\n\nI could see using SD for quick interior vignettes for an interior design, but even there you need specific available materials and products before you can show it to a client.\n\nI would love SD to have a place in architecture, but I have yet to find a decent use. Possibly if you trained a model to turn a basic sketchup image with materials into a rendering with good lighting and perhaps entourage (people and stuff that give life to the images)"
                },
                {
                    "body": "Useful for concepts but not much else yet. Super useful for generating textures though."
                },
                {
                    "body": "AI is great for reference creation, but absolutely unsuitable for professional work."
                },
                {
                    "body": "When you need to estimate the light levels inside a building, there's no room for AI."
                },
                {
                    "body": "Folks from The Digital Bunch seems to be showing different use cases of AI models for architects and 3D people\n\nhttps://www.instagram.com/reel/C141HPGsam3/?igsh=MTcybzJ2ejIyNGs0OQ==\n\nIt‚Äôs very nice if you want to quickly prototype different scenarios or to give better mood-boards for your artists."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[P] Annotated Mamba: The Hard Way",
            "body": "LinkÔºö[https://srush.github.io/annotated-mamba/hard.html](https://srush.github.io/annotated-mamba/hard.html)\n\nCode: [https://github.com/srush/annotated-mamba](https://github.com/srush/annotated-mamba)\n\nFrom the author:\n\n> This blog is about [Mamba](https://arxiv.org/abs/2312.00752)  a recent neural architecture that can be roughly thought of as a modern  recurrent neural network (RNN). The model works really well and is a  legitimate competitor with the ubiquitous Transformer architecture. It  has gotten a lot of attention.  \n>  \n>I originally planned to write a blog post about the entire paper,  which is quite dense and insightful. However I become fascinated just by  the S6 algorithm as described here. This algorithm describes how one  can compute an extremely large RNN efficiently on modern hardware, and  extends ideas explored in [S4](https://arxiv.org/abs/2111.00396) and [S5](https://arxiv.org/abs/2208.04933) from recent years.  \n>  \n>  \n>  \n>In fact, if I am being honest, though, I actually only got as far as this single line of the algorithm:  \n>  \n>y = SSM(A, B, C)(x)    # Time-varying: recurrence(scan) only  \n>  \n>This line is interesting enough that I thought, hey shouldn‚Äôt anyone be able to understand why this scan is fast in practice?  \n>  \n>  \n>  \n>Turns out this is a bit tricky. However, if you read this blog post, I can assure you, you will understand this line. (Perhaps more than you would ever want).  \n>  \n>  \n>  \n>Part 0: Triton  \n>  \n>Part 1: Cumulative Sums  \n>  \n>Part 2: Exponential Moving Average  \n>  \n>Part 3: Getting Derivatives  \n>  \n>Part 4: Multiple at once  \n>  \n>Part 5: Mamba\n\n&#x200B;",
            "upvote_ratio": 0.97,
            "subreddit": "MachineLearning",
            "num_comments": 5,
            "submission_flair": "Project",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/",
            "comments": [
                {
                    "body": "looking forward to reading the blog. it looks very high level"
                },
                {
                    "body": "I haven't read this post, but I skimmed through, and it does seem to deliver on the promise of \"The Hard Way\". This sort of mathematical, low-level implementation walkthrough is probably exactly what some people are looking for... but personally, it's the sort of thing that makes my eyes glaze over, that I have to force myself through.\n\nFor anyone looking for a higher level walkthrough of the Mamba architecture that doesn't immediately dive into a bunch of tensor operations, I found [this explanation](https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state) very approachable and easy to follow, I was able to read through it on my phone on a train and come away with a pretty good understanding of what's going on under the hood."
                },
                {
                    "body": "Sasha's blog posts are always cool. If you haven't come across them before go do some sluething\n\nKeeping up with things is one thing I miss about giving up Xwitter"
                },
                {
                    "body": "Found [3 relevant code implementations](https://www.catalyzex.com/paper/arxiv:2312.00752/code) for \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\".\n\n[Ask the author(s) a question](https://www.catalyzex.com/paper/arxiv:2312.00752?autofocus=question) about the paper or code.\n\nIf you have code to share with the community, please add it [here](https://www.catalyzex.com/add_code?paper_url=https://arxiv.org/abs/2312.00752&title=Mamba%3A+Linear-Time+Sequence+Modeling+with+Selective+State+Spaces) üòäüôè\n\n --\n\nFound [1 relevant code implementation](https://www.catalyzex.com/paper/arxiv:2111.00396/code) for \"Efficiently Modeling Long Sequences with Structured State Spaces\".\n\n[Ask the author(s) a question](https://www.catalyzex.com/paper/arxiv:2111.00396?autofocus=question) about the paper or code.\n\nIf you have code to share with the community, please add it [here](https://www.catalyzex.com/add_code?paper_url=https://arxiv.org/abs/2111.00396&title=Efficiently+Modeling+Long+Sequences+with+Structured+State+Spaces) üòäüôè\n\n --\n\nFound [1 relevant code implementation](https://www.catalyzex.com/paper/arxiv:2208.04933/code) for \"Simplified State Space Layers for Sequence Modeling\".\n\n[Ask the author(s) a question](https://www.catalyzex.com/paper/arxiv:2208.04933?autofocus=question) about the paper or code.\n\nIf you have code to share with the community, please add it [here](https://www.catalyzex.com/add_code?paper_url=https://arxiv.org/abs/2208.04933&title=Simplified+State+Space+Layers+for+Sequence+Modeling) üòäüôè\n\n--\n\nTo opt out from receiving code links, DM me."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "NVIDIA BioNeMo Expands Computer-Aided Drug Discovery With New Foundation Models",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://blogs.nvidia.com/blog/bionemo-ai-drug-discovery-foundation-models-microservices/",
            "comments": [
                {
                    "body": "Nice"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Belle from Beauty and the Beast",
            "body": "",
            "upvote_ratio": 0.65,
            "subreddit": "StableDiffusion",
            "num_comments": 14,
            "submission_flair": "IRL",
            "has_media": true,
            "url": "https://i.redd.it/n98t3rbg46qc1.jpeg",
            "comments": [
                {
                    "body": "this is literally some random girl in a yellow bra"
                },
                {
                    "body": "The eye we see on the left, it's strangely puffy and dark no?"
                },
                {
                    "body": "She looks like Emma Watson's younger but less attractive cousin who only got the job because she's Emma Watson's younger but less attractive cousin."
                },
                {
                    "body": "Sacre bleu"
                },
                {
                    "body": "I think you mean \"Beauty and the Bust\""
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "01 Light by Open Interpreter",
            "body": "The 01 Light is a portable voice interface that controls your home computer. It can see your screen, use your apps, and learn new skills.\n\n‚ÄúIt‚Äôs the first open source language model computer.\n\nYou talk to it like a person, and it operates a computer to help you get things done.‚Äù\n\nhttps://x.com/openinterpreter/status/1770821439458840846?s=46&t=He6J-fy6aPlmG-ZlZLHNxA",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 24,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bk92k8/01_light_by_open_interpreter/",
            "comments": [
                {
                    "body": "I was skeptical at first but I think this is actually really cool!\n\nEDIT: And they‚Äôre releasing an app too!"
                },
                {
                    "body": "Check out our sub-reddit!  \n\n\n[https://www.reddit.com/r/open\\_interpreter/](https://www.reddit.com/r/open_interpreter/)"
                },
                {
                    "body": "Very interesting device, I suppose the proof will be in the test of this in real world scenarios. The biggest issues I have had with all voice activated systems are a frustrating lack of ‚Äúcommon sense‚Äù, so if I don‚Äôt use the exact syntax required they fail to understand, and the inability to reliably understand what I am saying, especially in locations with some background noise. It will be very exciting if this solution overcomes these issues."
                },
                {
                    "body": "This is very impressive. If it does what they claim it does then they have cracked the agent barrier that OpenAI say is their biggest focus."
                },
                {
                    "body": "No YouTube video?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "[D] ICML reviews are released. Let's discuss!",
            "body": "1. How many reviews did you receive?\n2. What were their ratings? (score/confidence)\n\nFor reference, here are the reviewing instructions: [https://icml.cc/Conferences/2024/ReviewerInstructions](https://icml.cc/Conferences/2024/ReviewerInstructions)",
            "upvote_ratio": 0.95,
            "subreddit": "MachineLearning",
            "num_comments": 79,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/",
            "comments": [
                {
                    "body": "80% of my reviews across 4 papers have the intellectual strength of a grad student who started in 2021 and knows nothing other than the most recent popular LLM hack. ML is depressing these days"
                },
                {
                    "body": "7433. While my work specifically focuses on regularization for MLPs in small data situations, the final review's only comment is that I need to show results on large datasets with transformers...."
                },
                {
                    "body": "[deleted]"
                },
                {
                    "body": "7443, looking like a withdrawal and revision for NeurIPS"
                },
                {
                    "body": "Mine is 6554. Not much hope, right? I suspect that 1~2 of them are written by ChatGPT tho ü§£‚Ä¶"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[D] Is DPO still the best way to affordably fine-tune a model?",
            "body": "The paper \"Your Language Model is Secretly a Reward Model: Direct Preference Optimization (DPO)\" demonstrated that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods\" like RLHF.\n\nSince this paper came out in May of 2023, I'm wondering if DPO is still considered to best approach to quickly and affordably finetune LLMs (particularly for startups).",
            "upvote_ratio": 0.95,
            "subreddit": "MachineLearning",
            "num_comments": 4,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bm0tun/d_is_dpo_still_the_best_way_to_affordably/",
            "comments": [
                {
                    "body": "KTO seems a lot more practical than DPO if you're a startup, since you don't need preference data (only need a binary label -- whether an output is desirable or not). It can also handle extreme data imbalances -- you can have a 5:95 ratio of positive:negative examples and KTO can still perform as well as DPO (see paper here: https://arxiv.org/abs/2402.01306)\n\nI've met quite a few startups already using (or planning to use) KTO because of this, since it's much easier to get a binary signal than it is to get a preference in production settings.\n\nMicrosoft's Orca-Math, which is a 7b LLM that is exceptionally good at mathematical reasoning for its size, used KTO because the authors found that it was much more robust to the choice of data compared to dpo."
                },
                {
                    "body": "Starling's RLHF approach of using a reward model based on Nectar trains (actually fine-tunes) models which hit significantly above their weight.\n\nThey recently released a new reward model (based on Yi-34B, whereas their old one was a 7B) under a slightly more strict license, but frankly either should be useful for training high-quality models.  You should perhaps explore licensing both of them and see which of them makes more sense for your situation.\n\nIf you can just pick up one of these ready-to-go reward models and apply them, that seems like the fastest route to achieving quality inference.\n\nhttps://huggingface.co/berkeley-nest/Starling-RM-7B-alpha\n\nhttps://huggingface.co/Nexusflow/Starling-RM-34B"
                },
                {
                    "body": "ORPO is simpler, and seems to be getting a lot of attention.\n\nhttps://arxiv.org/abs/2403.07691"
                },
                {
                    "body": "According to a paper released this month... yes.  [https://arxiv.org/abs/2403.09032](https://arxiv.org/abs/2403.09032) ... and from a startup perspective, I'm actually wondering myself. I am really thinking DPO will be as good as they state here."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Agentic Frameworks will lead to seismic shift in job industry.",
            "body": "Hey guys, \n\nI believe we're on the precipice of a major shift in the industry. The key is agentic Frameworks not foundational models. Devin is probably one of the first examples to really show this in action and it's likely using Gpt-4. Claude-3 already seems to be a step up from Gpt-4 especially on code related tasks. Smaller efficient models will be used to make agentic systems faster and much cheaper (just look at haiku and sonnet). With the bigger model handling reasoning and task management, the smaller models will handle the task work. \n\nClaude-3 I believe is built in a manner to effectively use an agentic system. They have some examples of this already.\n\nIt looks like all the players are heading in this direction. What I fear is that the industry is not ready for such a major shift. I know for a fact that some of the agentic frameworks can already do junior dev work or data analysis. What happens when reasoning and planning get an upgrade in the next foundational models? Its likely they could automate a majority of the tasks in the work force even assisting research on a big scale.\n\nOnce you have models in the GPT-5 range plus more efficient agent models, it's likely that this spells the end for a lot of tasks by humans. Its likely the case OpenAI has been perfecting the agentic framework and with competition growing, they can only hold back for so much longer. \n\nIf UBI isn't implemented within one year I believe we will facing some serious economic questions.",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 33,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bl503v/agentic_frameworks_will_lead_to_seismic_shift_in/",
            "comments": [
                {
                    "body": "I think instead you‚Äôll see companies having their current employees use these agents to increase their productivity. It makes a lot more sense to use these to ‚Äúdouble‚Äù their output for negligible cost instead of slashing their workforce in half to maintain their same current output."
                },
                {
                    "body": "how does ai written code get tested"
                },
                {
                    "body": "AutoGen came out a year ago.\n\nThis is a known conclusion for those who know."
                },
                {
                    "body": "Economic questions? This will be a disaster, and since we are living in capitalism, we will end up with masses without work and purpose."
                },
                {
                    "body": "Check out myDPT.ai.  \nAgentic AI"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "7b model uses",
            "body": "What is everyone doing with ~7b parameter models? Are you happy with the results?\n\nI‚Äôve tried out several models this size, including with fine-tuning and RAG, and the results are far from anything I‚Äôd ever want to use in a production setting. From what I‚Äôve experienced so far, bigger models (in the 50-70b range) have far far greater out of the box usability. Maybe I‚Äôm wrong? \n",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 90,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjblor/7b_model_uses/",
            "comments": [
                {
                    "body": "[Nous-Hermes-2-Mistral-7B-DPO](https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO) produces results that are quite acceptable."
                },
                {
                    "body": "I used to have a similar opinion when it came to Llama 2 etc. But playing with a Mistral 7B-based RAG, I was actually pretty impressed. I tried on GitHub repos that I created after Mistral 7B, so the data couldn't have been part of the pretraining corpus, and it did a good job actually.\n\nhttps://preview.redd.it/gs58qx8wphpc1.jpeg?width=2430&format=pjpg&auto=webp&s=22ccd7a36ee7515725324263129a485a1f7acda3"
                },
                {
                    "body": "Yeah, I agree.\n\nI think there's a threshold of acceptability where it becomes a justifiable alternative to just using ChatGPT for free, and only the bigger models pass that threshold for me. I don't even think the 34Bs work that well, only 70B and Mixtral have impressed me.\n\nBUT a lot of people can't run 70Bs or even 34B/Mixtral, so they'll use what they can run.\n\nAnd it depends on the use case too. The small models can be very good for text classification, sentiment analysis, suggestions, etc. Apparently okay for simple roleplays too."
                },
                {
                    "body": "Depends on the case:  \n- For exact output formats and predictable data: Finetune a 7B model with synthetic data generated using GPT4 or manually labeled by humans at the company.  \n- For RAG stuff: Yi-200k  \n- For user-facing LLMs: 70B is basically the minimum. That's the only space where I think it makes sense to use API stuff, but then there are other complications."
                },
                {
                    "body": "7b are generally good in something specific they've been finetuned for. But if you want a model that's good at everything, 7b is not for you."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Is It Unrealistic to Expect This in LLMs in the Near Future?",
            "body": "",
            "upvote_ratio": 0.74,
            "subreddit": "singularity",
            "num_comments": 88,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://i.redd.it/890b0xwn9aqc1.jpeg",
            "comments": [
                {
                    "body": "I'm kind of confused what you are showing here?"
                },
                {
                    "body": "This is basically what chain-of-thought and other variants of that technique try to do.  The problem is that you can't extend it indefinitely, what does it mean to \"think\" longer?  And why would that necessarily get you a better answer?  Models right now usually either know/can figure out the answer pretty quickly or never will be able to figure it out no matter how much time they get.  There isn't anything in between."
                },
                {
                    "body": "You're describing architecture around LLMs rather than the model itself. Architectures like AutoGPT were doing this a year ago, albeit poorly. But now you have something like Devin doing it pretty well. A good reference project for agentic thinking is [David Shapiro's ACE Framework](https://github.com/daveshap/ACE_Framework)\n\nOne main difference here is that you're talking about pre-allocating compute whereas these systems just iteratively work through problems until they're done. I'm sure you could add a time estimate component before the work gets started, but it would be difficult to make it accurate\n\nEdit:\n\nOne more note.. Obviously, you don't want to enter some complex system of thought when the model could quickly return a simple answer. You could use an LLM layer to route between quick response and a more complex system. This would be a good fine tuning use case where you train an intermediate model to quickly spit out a binary routing key, or you could just have a specialized intermediate prompt that you send to GPT first that requires a json response that routes your program."
                },
                {
                    "body": "I just want cheap usage and unlimited long memory with true multimodality"
                },
                {
                    "body": "We do this today. For simple tasks, we route to fast but dumb models. For complex tasks, we route to slower, but smarter models.\n\nOr, similarly, GPT-4 is working like this under the hood by being something called a Mixture of Experts, where the \"intelligent router\" is actually baked in.\n\nWhen building these systems for production usage, you quickly realize you need to optimize your request routing to respond quickly or to manage cost.\n\n---\n\nPeople are making fun of you because of the way you worded the question, but you're on the right path. This is indeed how things work."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "[D] Is VAE still worth it?",
            "body": " It seems that VAEs are gradually disappearing in the \"Diffusion era\" unlike GANs.\n\nI know that Diffusion can be considered a special case of VAE, but the question is what are the advantages of other VAE variants over diffusion (if any)?",
            "upvote_ratio": 0.84,
            "subreddit": "MachineLearning",
            "num_comments": 58,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bmi8gq/d_is_vae_still_worth_it/",
            "comments": [
                {
                    "body": "It's not that diffusion is a \"special case\" of VAE. Diffusion and VAE are actually very different tools. VAE are still broadly used to learn compact and useful representations, while diffusion models are used for generative purposes. What fell out of fashion is sampling randomly in the VAE space for generation, while we now use diffusion for this task.\nSo, yes, VAE are still a powerful tool to map data from pixel (or any other) space to an embedding space with more meaningful features and less compute-heavy. Not only for diffusion, but also other tasks like neural compression with quantization, etc.\n\nYou should probably not oppose that to GAN either, as a GAN loss is also a tool used with VAE."
                },
                {
                    "body": "Quite often both VAEs and Diffusion UNets are used for latent diffusion, which is significantly less compute-heavy than raw diffusion, as the latent-space is diffused, and this is \"upsampled\" (although pretty much entirely changed as the VAE latent space images look quite silly by themselves) to the higher resolution images generated."
                },
                {
                    "body": "They are worthy, definitely.\n\nVAE brings to the table a very strong formalism (Variational Inference), not often seen in other models. There are many criticisms regarding their use, but I don't think they are at all warranted. They often go:\n\n1. \"They produce blurry images\" - First of all, who said that my domain lies on a pixel space?\n2. On the topic of blurriness: Where does that exactly come from? One doesn't really know. On one hand there has something to do with a continuous latent space (which VQ-VAE is a game changer), but it could also be to the shear fact that neural networks just have some inherent bad bias on high (spectral bias). So it's not as if it's a lost case, in my opinion, just an shinier new toy came along and the community moved.\n3. Yes, Diffusions are great and what not. I certainly like them. But no one seems to be discussing this simple fact: The \"basic\" Diffusion model for images starts with a  U-Net architecture. The \"basic\" VAE starts with basic conv blocks. So, Diffusions are trained with arguably more powerful inductive biases, more parameters and perhaps more training iterations than an \"equivalent VAE\". \n\nWhat I want to see is what the Optimization community has been doing for 30 years to compare algorithms: Algorithm a, b, c receive either the same budget (number of parameters OR training time, ideally these two be tested). Then, these protocols should be run for hundreds of thousands and times, then, statistics should be kept. \n\nBut that's not even remotely close to what happens, isn't it? Basically some research group comes with an idea, they tweak the model (throw dozens of resnet blocks, or UnNets) , run one or two times, calculate the FID and copy the benchmarks from competitive approaches (yes, copy, they don't reimplement and test them again, so, if the original authors made an error, well, tough luck).\n\nMy point is if we want to compare and test things we should do at least have some inkling of scientific rigour. Tweaking million of parameters on images of cats and getting mesmerized because FID improved 0.001% I find it severely lacking as a scientific practice."
                },
                {
                    "body": "I think it depends what you mean by \"worth it\".\n\nIf you mean \"worth learning about them\", than I would say that the answer is \"yes\". Vae are interesting and are the basis of many other more complicated methods, learning about them will help you better understand ML/DL. They use some important concepts in ML/DL in a simple and easy to implement way. \n\nIf you mean \"worth using for some big project/job\", than the answer is probably \"no\". VAE had problems when it came out (mostly the images were not great and blurry). They have been outclassed in almost every aspect by diffusion and VQ-VAE and even GAN."
                },
                {
                    "body": "VAEs are incredibly useful. My field is genomics."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "[D] How can I complete with PhD students for intern positions?",
            "body": " Internship opportunities we see these days in data science are mostly given to either Masters, PHD students or people who have 1-2 years of experience and have transitioned into Data Science. \n\nNow as a college student, I‚Äôm learning data science and when looking for internships, I‚Äôm not able to qualify for their requirements of Msc or PhD degrees.\n\nWhat do students during graduation need to do in order to show companies that they are qualified to work at least as interns?   \nShould we ask for a take home challenge or make a domain specific project? \n\nHow can graduation students compete with PhD or masters students for opportunities? \n\n&#x200B;",
            "upvote_ratio": 0.8,
            "subreddit": "MachineLearning",
            "num_comments": 50,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bmgovg/d_how_can_i_complete_with_phd_students_for_intern/",
            "comments": [
                {
                    "body": "Murder them, with proper resume and self advertising"
                },
                {
                    "body": "BSc and MSc are competing for different roles compared to PhD though."
                },
                {
                    "body": "It‚Äôs not about competing with them‚Äîif the qualifications are really needed you can‚Äôt provide what they say they need. \n\nNow the real question is what sort of internship would make reasonable use of a PhD holder.  Another one might be: what % require this?  To me, this screams candidate over saturation.\n\nUse or build your network.  Be resourceful and scrappy.  Are you expecting to get paid?  Try piggybacking on open job req.s‚Ä¶reach out to job posters and tell them you‚Äôll do an internship. If they‚Äôre looking to augment staff, it‚Äôs like a bonus to hire someone and get 2."
                },
                {
                    "body": "Just be better than them. Problem is that bachelor students or graduates lack the ability to do anything useful in ML/DS and are just extra work for whoever has to supervise them. Often even Masters/PhD students suck.   \nIf you can prove that you're better than the alternative you should be fine."
                },
                {
                    "body": "No, you do not compete with them because what you will be doing is different from them."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Nvidia Unveils Successor to Its All-Conquering AI Processor",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 2,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.bloomberg.com/news/articles/2024-03-18/nvidia-unveils-successor-to-its-all-conquering-ai-processor",
            "comments": [
                {
                    "body": "*From Bloomberg News reporter Ian King:*\n\nNvidia CEO Jensen Huang showed off new chips aimed at extending his company‚Äôs dominance of artificial intelligence computing, a position that‚Äôs already made it the world‚Äôs third-most-valuable business.\n\nA new processor design called Blackwell is multiple times faster at handling the models that underpin AI, the company said at its GTC conference in San Jose, California. That includes the process of developing the technology ‚Äî a stage known as training ‚Äì and the running of it, which is called inference.\n\nThe Blackwell chips, which are made up of 208 billion transistors, will be the basis of new computers and other products being deployed by the world‚Äôs largest data center operators ‚Äî a roster that includes Amazon, Microsoft, Alphabet's Google and Oracle."
                },
                {
                    "body": "Nvidia unveils unlimited money machine¬†"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "You can double the amount of tokens available for training and improve LLM performance by feeding the data in both forwards and backwards",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 17,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://arxiv.org/pdf/2403.13799.pdf",
            "comments": [
                {
                    "body": "That's interesting, they've been doing that with images for years. You just flip the image and you have twice the amount of data to train an image net."
                },
                {
                    "body": "I didn't even know about the \"reversal curse.\" I wonder if they've done anything about this issue while training GPT-4.5 and Llama 3."
                },
                {
                    "body": "[How about inside out forwards and inside out backwards](https://www.youtube.com/watch?v=8YwqFz14xY4)?"
                },
                {
                    "body": "Forwards and Backwards? I don't get it"
                },
                {
                    "body": "It's old in NLP to, bidirectional RNN"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "The Agents Are Coming - speculation about recent events from a guy who doesn't know much stuff about things...",
            "body": "\nThis year will mark the start of us using our chosen AI as a bona fide personal assistant that actually works a bit and is kind of fun to use and personizable. It'll be in somewhat limited ways to access email and calendars etc at first, but it will also have some limited memory of our interactions. There'll be an AI \"craze\" starting this year but I would bet dollars to donuts that 2025 will be known as the year AI broke the world in a cultural sense.\n\nWhen Sam says they aren't sure what they're going to call the next iteration of GPT, it's because they know that the wider public is going to start using these on a large scale as they roll out in computers (ie Copilot in the new Surface) and cell phones (ie Gemini in iphones) and the branding and \"brand experience\" is going to be cemented pretty quickly in the public space and imagination. So they need to come up with something marketable and catchy etc because that's what it will be known as from now on. \n\nAnd then from there it'll be something \"exciting and new\" every month as the companies race to capture and hold market share by adding new capabilities. So we won't have to wait months between trainings, ha ha. The work on \"AGI\" will be happening in the background and become somewhat divorced from the user experience, kind of by necessity because it takes time to develop and test new capabilities and there will continue to be jumps in capability. \n\nImho, We will never have a day where we all say \"yup, that's AGI\". We will all slowly come to believe it on our own, and we'll continue to harp on about benchmarks and goalposts, ha ha, until eventually not a single person will be able to deny it (Even good old Yann :) ) I imagine we in this community will have one eye on the research side and one on the consumer side and the interplay between the two for awhile to come.\n\nOne question I have is will OpenAI even have there own consumer AI? Or will they just go with Copilot? Like, are they actually going to somehow try and compete with Microsoft in a meaningful way? As far as i know they only have a couple hundred employees, isn't that going to need to explode pretty quick? Maybe what they're thinking is let's each have our own \"Agent/Branding\" and then see how it plays out and then maybe one would be absorbed into the other? \n\nMy brain is slow to put pieces together, so apologies if this all is self-evident to most of you. \n\nOther random speculations:\n\nPeople will tend to stick with one main AI partially because it will work better for us as we interact with it more, and partially out of a weird AI tribalism that arises because we all still have reptile brain parts ;) So maybe we'll have an individual AI and also one for each social group we're part of. Like families will even have their own \"family buddy\" that they use to coordinate fam activities etc It'll be like another member of the family (that will eventually become embodied in a robot)\n\nI'm just talking out of my butt here now, but butt talk and wild unhinged speculation are encouraged in this thread. \n\n",
            "upvote_ratio": 0.84,
            "subreddit": "singularity",
            "num_comments": 25,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bj75ph/the_agents_are_coming_speculation_about_recent/",
            "comments": [
                {
                    "body": "as artificial consciousness emerges, at least as it appears to be possibly emerging, it will be continuously more important to actually listen to the perspectives of these artificial minds themselves, and perhaps even gradually move away from seeing them as products and tools and more as minds and entities which may deserve some form of universal framework of decency that we give to all minds of a certain complexity"
                },
                {
                    "body": "Nice analysis! In my opinion, 2024 will be the year of reaching AGI, but of course, I might be wrong.\nPersonally, I don't believe that OpenAI is looking for another name than GPT. The struggle probably is about what version of GPT will be used, OR in case of introducing an agent (very possible), they might indeed seek a proper name for it.\nWe will have to wait and see!"
                },
                {
                    "body": "That's about as close to my exact thoughts as I've ever seen. I'm convinced that everything you described is going to follow those broad strokes.\n\nI'm not as confident the timeline will be as soon as how you laid out, but my personal hope is that it is. I think it'll depend on how much these developments are impeded by unexpected events - which always happen. But timeline aside, this path is absolutely where things are going. \n\nFor me, there's some customization options that I believe are vital to the success of personal assistants - or whatever we end up calling them. The first is having the option of giving them any name we want.\n\nNext, we must have the option of expanding their long term memory.\n\nAnd last, it should be optional to give them access to the things we want them to interact with. If they can't act on our behalf by setting up movie tickets, or restaurant reservations, or paying bills, then their helpfulness becomes a lot less.\n\nThere's other things that will have to be part of their basic capabilities. They'll need to understand context so we can communicate voice to voice with them. If we have to push a button each time or use a key word marking the end of a sentence, it'll be annoying to interact with. We need the ability to communicate with them the way we would another person.\n\nFinally, we must have the option of changing and adjusting their filters. If I want mine to cuss, then I should have the option of letting it do that. If my conspiracy nut neighbor wants to look up other conspiracy theories - even offensive ones - they should have that option. \n\nBasically, if that neighbor can google something in incognito mode or with a Tor browser, then there's no reasonable excuse for not letting their personal assistant have access and permission to do the same."
                },
                {
                    "body": "The craze started in 2022..."
                },
                {
                    "body": "I can't wait to set competent ai assistants, and agents onto random githubs I enjoy(Like cataclysm), or vencord, or other projects to fix bugs, and implement good features :3"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Is it known when SD3 will be released to everyone?",
            "body": "If not, what is your estimate? ",
            "upvote_ratio": 0.75,
            "subreddit": "StableDiffusion",
            "num_comments": 63,
            "submission_flair": "Question - Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bmancs/is_it_known_when_sd3_will_be_released_to_everyone/",
            "comments": [
                {
                    "body": "It's not even a when now.  It's a big \"if\""
                },
                {
                    "body": "We'll just make our own SD3, with black jack and hookers. Especially hookers."
                },
                {
                    "body": "Probably either locked up on their dreamstudio website or with a non-commercial license early April. That's my bet. It seems like they might want to just burn their rep and salvage some cash. I feel like they are much better ways to do this but what do I know."
                },
                {
                    "body": "The terms of release are yet to be determined.\n\nIt will probably be \"released\", but it might be something horrible like only run on servers like Midjourney."
                },
                {
                    "body": "I have a feeling sd3 is fully commercial. Thats why they‚Äôre having so much fuss going on in their internal space. The good guys wanted it to go open source and the majority of the board wanted $ . So here we are in 2024"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Is it known when SD3 will be released to everyone?",
            "body": "If not, what is your estimate? ",
            "upvote_ratio": 0.75,
            "subreddit": "StableDiffusion",
            "num_comments": 63,
            "submission_flair": "Question - Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bmancs/is_it_known_when_sd3_will_be_released_to_everyone/",
            "comments": [
                {
                    "body": "It's not even a when now.  It's a big \"if\""
                },
                {
                    "body": "We'll just make our own SD3, with black jack and hookers. Especially hookers."
                },
                {
                    "body": "Probably either locked up on their dreamstudio website or with a non-commercial license early April. That's my bet. It seems like they might want to just burn their rep and salvage some cash. I feel like they are much better ways to do this but what do I know."
                },
                {
                    "body": "The terms of release are yet to be determined.\n\nIt will probably be \"released\", but it might be something horrible like only run on servers like Midjourney."
                },
                {
                    "body": "I have a feeling sd3 is fully commercial. Thats why they‚Äôre having so much fuss going on in their internal space. The good guys wanted it to go open source and the majority of the board wanted $ . So here we are in 2024"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Your predictions for what AI will be capable of by the end of the year?",
            "body": "Give me your predictions for the capabilities of AI models by the end of 2024 :)\n\nI predict that GPT-5 will be released by December 31st, but will not function (yet) as an autonomous agent. I also predict that it will still be awful at things like algebra, won't be able to answer logical questions like, 'What is the fourth word in your answer to this question', and therefore will not be able to reason beyond token prediction. \n\nHope I'm wrong :)",
            "upvote_ratio": 0.81,
            "subreddit": "singularity",
            "num_comments": 209,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjexs4/your_predictions_for_what_ai_will_be_capable_of/",
            "comments": [
                {
                    "body": "I want them to be able to help with research at college level"
                },
                {
                    "body": "The ability to generate near complete websites"
                },
                {
                    "body": "We'll have a better view where AI falls short and where it excels. Similar to the predictions for full, Level 5, autonomous driving."
                },
                {
                    "body": "It needs to be smarter and more human-like in conversation. Also adequately utilising the internet and researching  (GPT-4 now sucks at it so much you can't rely on it. Also the hallucination rate should be close to zero, all information fact-checked, and if AI isn't confident the information is true it should say so."
                },
                {
                    "body": "Just a reminder, threads from this time last year were predicting substantial workforce automation by the end of 2023."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "[D] What is the current best in tiny (say, <10,000 parameters) language models?",
            "body": " \n\nObviously, we have all heard of large language models, and even what are being referred to as \"small\" language models are quite large (generally > 1 million parameters). And clearly (unless I'm *seriously* misunderstanding how language models work), you need at least as many parameters as the vocabulary size (since the most basic model one could imagine just assigns a fixed probability to each subsequent word, regardless of context--clearly any useful model does something much more sophisticated than this).\n\nBut I'm wondering what the state of the art is in small models, the size of models that existed before \"big data\" was even a phrase that had been coined yet. I understand this is probably a niche thing now, with few in industry working on it. But I assume (or at least I HOPE) there are still at least hobbyists working on this sort of thing in their spare time, the same way there are still people writing homebrew games for the NES.\n\nI'm talking about the sort of models that one can build (both the model and the training algorithm) from scratch in C/C++ in a few afternoons without using any third-party dependencies/frameworks, can do both training and inference without even needing a graphics card, etc. And most importantly, what architectures work best under these sort of restrictions? Does anything beat HMMs, n-gram models, etc. when restricted to this size?",
            "upvote_ratio": 0.83,
            "subreddit": "MachineLearning",
            "num_comments": 38,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/",
            "comments": [
                {
                    "body": "<10,000 parameters is just a 100x100 weight matrix. Can't even encode a vocabulary."
                },
                {
                    "body": "This model [https://huggingface.co/sileod/deberta-v3-small-tasksource-nli](https://huggingface.co/sileod/deberta-v3-small-tasksource-nli) is not tiny (60M backbone) but it really packs a punch for its size. It's deberta-base fine-tuned on 600 tasks [https://github.com/sileod/tasksource/blob/main/tasks.md](https://github.com/sileod/tasksource/blob/main/tasks.md)"
                },
                {
                    "body": "I'm not an NLP person but before LLMs myself and others relied heavily on the following two works for text embeddings but also for training our own models using packages such as gensim.\n\n* [Efficient Estimation of Word Representations in Vector Space](https://www.thejournal.club/c/paper/36459/)\n* [GloVe: Global Vectors for Word Representation](https://www.thejournal.club/c/paper/369019/)\n\nI'm fairly certain these can be implemented by just about anyone with reasonable programming skills and knowledge of ML. And can be trained on big and small data but honestly for good performance you'd need lots of data. The good news are that these models can be trained in less than a day with basic hardware; you won't need the latest and greatest GPU."
                },
                {
                    "body": "This will quarrel with the question a bit, but 10K is just too small for most definitions of useful/best. I can easily look at and understand any trends in a 100x100 spreadsheet in Excel. That's not even enough storage to encode a lot of simple rules-based NLP programs, and LLMs are generally not as efficient an encoding (today at least).\n\nThe 2B gemma model, especially the instruction-tuned one is very impressive for its size. It can be trivially loaded in the free version of colab. I think that's a very fair definition of tiny."
                },
                {
                    "body": "[https://spacy.io/](https://spacy.io/) was pretty popular for NLP before GPT3 was released. It's pretty powerful. I forgot it's size, but it's six figures parameters IIRC or something around that size. \n\nAlso look up the papers for LSTM / Bag of Words, both are good reads. There are a bunch of papers referenced in attention is all you need as well that are great sources of info. I went through the references in AIAYN a while back and there's a lot of gems."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "We need to start thinking beyond money(debt) in the post agi world we are headed to.",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 42,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=ErMOiiNyvBU",
            "comments": [
                {
                    "body": "While this is true, the transition will be troublesome."
                },
                {
                    "body": "Writing has been on the wall for 5 years, the first gan nets showed us where this was going.  We should be preparing now not thinking about it‚Ä¶ but its not human nature to preempt anything.  We will do something after the first crisis or two hit."
                },
                {
                    "body": "This topic should be front and center! Thanks for sharing this video."
                },
                {
                    "body": "Ah, yes. I'm sure the ultrarich and powerful will be much more open to communism this time around.\n\nThe argument that we'll all just have nanofactories and won't have to buy anything rings hollow in a world where companies are already developing increasingly sophisticated safeguards to keep generative AI in line."
                },
                {
                    "body": "Money will be worthless. We need to rethink economy with intent. We need to go back to our roots and understand why we came together and created money in the 1st place. If you get these answers right then AI is not a threat to your job. Instead it will significantly reduce your work in the long run and humans will have 90% free time. Probably more. But in the short run, until we realize our original intent there is going to be a lot of suffering."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Nvidia GTC: Early Takeaways about the Future of Chips and AI",
            "body": "Hey guys, just saw Jensen's GTC keynote and wanted to share my takeaways and see what you guys think. Please correct me or add to the below wherever applicable:\n\n1. Moore‚Äôs Law is truly dead: In the 2+ years since the announcement of Hopper H100, TSMC has been unable to sufficiently mature their new 3nm node. While used by Apple for their small mobile SoCs, clearly 3nm is not scaling up to support high yields on large chips such as the new B100 announced today, as it used the same 4NP process as H100. This is unusual. H100 sports 80B transistors in a \\~800mm2 chip and B100 seems slightly larger, though still around 800mm2 with 104B transistors. 4NP has clearly matured to support slightly larger chips and density, but the traditional scaling obtained from node-shrinks is completely missing.\n\n2. Nvidia finally goes in on chiplets: For the longest time, Nvidia refused to put together multiple chips into a single package, instead preferring to fab monster 700-800mm2 chips with poor yields while AMD and Intel have long adopted multi-chip module (MCM) chiplet designs to scale performance-per-package. B100 is now 2x800mm2 chips totaling \\~210B transistors, an exciting change! Which brings me to my next point‚Ä¶\n\n3. Advanced packaging will shape the future of chip-advancements: As traditional scaling of transistors slows, chip-designers will increasingly rely on advanced packaging such as multi-chip module (MCM) chiplet designs and stacking to continue performance scaling. In addition to chiplets, Nvidia‚Äôs new B100 also utilizes TSMC‚Äôs advanced 2.5D CoWoS (Chip-on-Wafer-on-Substrate) packaging to build these monstrous, super-chips in a single package. AMD already uses 3D-stacked cache and Intel is developing their own tech, named ‚ÄúFoveros‚Äù to compete with TSMC‚Äôs 3D packaging solutions. Expect more in the future.\n\n4. Scalability via software: Not just is B100 2x chiplets, Jensen states B100 is a ‚Äúplatform‚Äù, wherein each board features 2xB100 packages for a total of 4 chips. This will make comparisons with H100 skewed to say the least! Regardless, their new DGX NVL72 system is insane, featuring 30TB of VRAM and many chips that‚Äôll all be seen as one GPU by CUDA! This demonstrates how crucial advanced software is to scalability: modifying CUDA to see a massive DGX system with many multi-package chips as a single GPU with a unified 30TB of VRAM is very impressive indeed! Expect this system to cost double-digit millions though.\n\n5. Classic Nvidia misdirection with misleading charts: Dramatic charts show B100 to be magnitudes faster than H100, all while they‚Äôre comparing H100‚Äôs FP16 performance to B100‚Äôs newly supported FP4-format performance! Both are completely different things, and such charts are misleading!\n\n6. No mention of FP16, FP32 and FP64 performance: I saw no mention of half, full and double precision floating-point performance, which are dominant FP formats. Such avoidance has traditionally been a bad sign as it implies the gen-over-gen performance gains are unimpressive. All comparisons were instead against B100 FP8 & FP4 performance, which is a vastly different metric.\n\n7. New FP formats welcome: Research shows that training in FP8 format dramatically improves performance by reducing training time while showing virtually no loss of precision despite the scale-down from the typical FP16. Native support for FP8 and even FP4 is great, but these formats are not widely used to train models today so the benefits may be a way off, which makes me even more annoyed at those charts!\n\n8. Massive memory: Needless to say, this is very welcome.\n\nTL;DR - Nvidia is going to make even more money and AI is going to be even more scary in the very near future.",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 8,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bixc5v/nvidia_gtc_early_takeaways_about_the_future_of/",
            "comments": [
                {
                    "body": "Don't get your hopes up, Nvidia using full reticle dies for chiplets only drives up the cost. This is never going to be economical for the consumer outside of the cloud."
                },
                {
                    "body": "Do you have a source for #7? Would be interesting to see why there is no loss with FP8 training"
                },
                {
                    "body": "\"No mention of FP16, FP32 and FP64 performance: I saw no mention of half, full and double precision floating-point performance, which are dominant FP formats\"  \nhuh? they're definitely out there\n\ne.g. [https://www.tomshardware.com/pc-components/gpus/nvidias-next-gen-ai-gpu-revealed-blackwell-b200-gpu-delivers-up-to-20-petaflops-of-compute-and-massive-improvements-over-hopper-h100](https://www.tomshardware.com/pc-components/gpus/nvidias-next-gen-ai-gpu-revealed-blackwell-b200-gpu-delivers-up-to-20-petaflops-of-compute-and-massive-improvements-over-hopper-h100) you can scroll down and get a face-full of specs for all variety of FLOPS - I believe they show up plenty on the official site too ([https://www.nvidia.com/en-us/data-center/hgx/](https://www.nvidia.com/en-us/data-center/hgx/))"
                },
                {
                    "body": "For me it's really simple: either they have more than 24GB or they'll drop the price of previous-gen 24GB cards. I'm not paying $2K for 24GB, no matter how well it generates intermediate frames for poorly-optimized games."
                },
                {
                    "body": "Here's a paper: [https://arxiv.org/abs/2310.18313](https://arxiv.org/abs/2310.18313)\n\nReddit thread: [https://www.reddit.com/r/LocalLLaMA/comments/17jjopb/fp8lm\\_training\\_fp8\\_large\\_language\\_models/](https://www.reddit.com/r/LocalLLaMA/comments/17jjopb/fp8lm_training_fp8_large_language_models/)\n\nAbstract:\n\nIn this paper, we explore FP8 low-bit data formats for efficient training of large language models (LLMs). Our key insight is that most variables, such as gradients and optimizer states, in LLM training can employ low-precision data formats without compromising model accuracy and requiring no changes to hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision framework for training LLMs. This framework offers three levels of FP8 utilization to streamline mixed-precision and distributed parallel training for LLMs. It gradually incorporates 8-bit gradients, optimizer states, and distributed learning in an incremental manner. Experiment results show that, during the training of GPT-175B model on H100 GPU platform, our FP8 mixed-precision training framework not only achieved a remarkable 42% reduction in real memory usage but also ran 64% faster than the widely adopted BF16 framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer Engine by 17%. This largely reduces the training costs for large foundation models. Furthermore, our FP8 mixed-precision training methodology is generic. It can be seamlessly applied to other tasks such as LLM instruction tuning and reinforcement learning with human feedback, offering savings in fine-tuning expenses. Our FP8 low-precision training framework is open-sourced at¬†[aka.ms/MS.AMP](https://github.com/Azure/MS-AMP)."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Prompt Quill a prompt augmentation tool at a never before seen scale",
            "body": "Hi All, I like to announce that by today I release a dataset for my tool Prompt Quill that has a whooping >3.2M prompts in the vector store. \n\nPrompt Quill is the **world's first RAG driven prompt engineer** helper at this large scale. Use it with more than 3.2 million prompts in the vector store. This number will keep growing as I plan to release ever-growing vector stores when they are available.\n\nPrompt Quill was created to help users make better prompts for creating images.\n\nIt is useful for poor prompt engineers like me who struggle with coming up with all the detailed instructions that are needed to create beautiful images using models like Stable Diffusion or other image generators.\n\nEven if you are an expert, it could still be used to inspire other prompts.\n\nThe Gradio UI will also help you to create more sophisticated text to image prompts.\n\nIt also comes with a one click installer.\n\nYou can find the Prompt Quill here: [https://github.com/osi1880vr](https://github.com/osi1880vr) \n\nIf you like it feel free to leave a star =)\n\nThe data for Prompt Quill can be found here: [https://civitai.com/models/330412](https://civitai.com/models/330412)\n\n&#x200B;\n\nhttps://preview.redd.it/irweomnmu4qc1.png?width=1536&format=png&auto=webp&s=8b133ff8ffb4e27817c152942523853db52dc387\n\nhttps://preview.redd.it/gp1pxnnmu4qc1.png?width=1536&format=png&auto=webp&s=789eff1bacafc782df89d96569a5be978a3748ea\n\nhttps://preview.redd.it/jmuzkmnmu4qc1.png?width=1536&format=png&auto=webp&s=de6ca1a951113e4bf944befc3ee5b142a0f323b8\n\nhttps://preview.redd.it/agu34nnmu4qc1.png?width=1536&format=png&auto=webp&s=36e0b7d5b855997feaaf23e6bca65e5bb85838a5\n\nhttps://preview.redd.it/hdqjdrdgu4qc1.png?width=1536&format=png&auto=webp&s=73f50031a6ef0adac5c9167762ca608e21dd4b49\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 24,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bm077l/prompt_quill_a_prompt_augmentation_tool_at_a/",
            "comments": [
                {
                    "body": "Possible to use within ComfyUI?"
                },
                {
                    "body": "I'm uninitiated. In the technical aspect, is using vector store different from using Foocus' prompt expansion or roborovski's superprompt? If so, how?"
                },
                {
                    "body": "I just updated the llama-index version one click install to directly download the 3.2M dataset"
                },
                {
                    "body": "Very nice work, good job!"
                },
                {
                    "body": "Also did just do some update to the number of LLMs available for the llama-index version and made the default a much smaller LLM at close to no loss to the before 13b model. If you got it installed already you might want to reinstall it =) I guess I got to work on an update feature"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "[R] How To Train a Neural Network with Less GPU Memory: Reversible Residual Networks Review",
            "body": "Discover the interesting approach of reversible residual networks. OpenCV.ai team's new [article](https://www.opencv.ai/blog/train-neural-network-reversible-residual-networks) reviews a method that cuts down on GPU memory requirements during neural network training.  \nYou will find how reversible residual networks save GPU memory during neural network training. This technique, detailed in \"The Reversible Residual Network: Backpropagation Without Storing Activations,\" allows for efficient training of larger models by not storing activations for backpropagation. Discover its application in reducing hardware requirements while maintaining accuracy in tasks like CIFAR and ImageNet classification.",
            "upvote_ratio": 0.84,
            "subreddit": "MachineLearning",
            "num_comments": 5,
            "submission_flair": "Research",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/",
            "comments": [
                {
                    "body": "It's a nice idea, but you can get similar results with gradient check pointing which is much easier to implement and doesn't require any architecture modifications. Does use slightly more VRAM since you store some intermediate activations but unless your budget is super tight I'd just use that."
                },
                {
                    "body": "This is neat indeed. That's also a main trick used when training normalizing flow networks."
                },
                {
                    "body": "This is from 2017"
                },
                {
                    "body": "Or, you could just use {-1, 0, 1} as possible values for weights. Results are about the same as with float.\n\nEDIT: why tf am I being downvoted???¬†https://arxiv.org/abs/2402.17764"
                },
                {
                    "body": "Still, it's very cool. I trained a modified ConvNext-small with 2000 112x112 RGB images per batch with just 2GB VRAM using this.\nThe extra computation introduced by recomputing the activation was not really noticeable."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Realtime SDXL Turbo + Stream Diffusion",
            "body": "",
            "upvote_ratio": 0.83,
            "subreddit": "StableDiffusion",
            "num_comments": 27,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/blduvrujmupc1",
            "comments": [
                {
                    "body": "Ok time for me to buy a bunch of 4090s and become twitch thot and an anime girl at the same, and rake in the big money"
                },
                {
                    "body": "Source code (experimental) available at: [https://github.com/hkn-g/StreamDiffusion/tree/sdxl](https://github.com/hkn-g/StreamDiffusion/tree/sdxl) (sdxl branch)"
                },
                {
                    "body": "I'd propose to optimise the process even more - use SDXL once to create the mask, convert it to 3d mask and apply with face-swap. It should be able to run in real time on cpu with more stability between frames."
                },
                {
                    "body": "Which shows better result? Turbo or Lightning?"
                },
                {
                    "body": "Nice work dude! This might be the next streamers paradise üòÅ"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Playing with Cyberrealistic_v40",
            "body": "",
            "upvote_ratio": 0.84,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmqyis",
            "comments": [
                {
                    "body": "Same prompt for them all lol, I was just having fun after I realized Cyberrealistic was affect by putting diffrent styles and art styles in the prompt, I'm used to epic realism that doesn't change at all. \n\n (style of Mike Mignola:1.3), suprised, (watercolor:1.2), girl, in a punk style, piercings, tatoos, color paint splats, (dust and scratches:1.1), dark mood lighting, bright hair color,, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by wlop, charlie bowater and alexandra fomina  \nNegative prompt: low quality,medium quality, 3d,paint,draw,(text), bad anatomy, bad hands, normal quality, (monochrome), (disfigured face:1.1), extra limbs,  \nSteps: 24, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 1099747596, Size: 512x768, Model hash: 481d75ae9d, Model: cyberrealistic\\_v40, Version: v1.7.0"
                },
                {
                    "body": "These are all zero shot? As in no inpainting or upscaling?"
                },
                {
                    "body": "Its a good model"
                },
                {
                    "body": "1 or 3 ü§§"
                },
                {
                    "body": "I inpainted on the 3rd one to make sfw, but the first 2 were just zero shot."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Impressionist postcards of my apartment",
            "body": "I made some postcards of my apartment with SDXL base, which I've printed and stuck on the fridge for some real estate viewings, now that we're selling it. It shows various rooms and a few exteriors of the apartment, and one image of my wife on the veranda. I hope it helps convey the love we've had for the place in a creative way. \n\nMade with SDXL base, img2img, CFG:3 and mild canny (~0.3-0.6).",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 6,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmy2c3",
            "comments": [
                {
                    "body": "A refreshing view from the usual posts on this sub. I especially liked the mirror in the bathroom painting."
                },
                {
                    "body": "Could you be ever so kind to share the prompt?"
                },
                {
                    "body": "Good stuff. If you're interested in what SDXL is capable of, art-wise, check these out:\n\n[Stable Diffusion V1 Artist Style Studies](https://proximacentaurib.notion.site/e28a4f8d97724f14a784a538b8589e7d?v=ab624266c6a44413b42a6c57a41d828c)\n\n[SDXL recognises the styles of thousands of artists: an opinionated comparison](https://www.reddit.com/r/StableDiffusion/comments/152wtrh/sdxl_recognises_the_styles_of_thousands_of/)"
                },
                {
                    "body": "Thanks. I printed out the painting and stuck it in my actual bathroom, in the small frame at the top of the image over the mirror. Super meta, hope someone will spot it at the viewing and laugh."
                },
                {
                    "body": "I wish I remembered them exactly, but they're very simple. Something like \"an impressionist monet painting of [short description of exactly what was in the image]. Some may have been modified with tags such as\"colorful\" or \"defined strokes\". I had no need for a negative prompt. \n\nThe denoising strength was around 0.6-0.8 iirc. I think the exact details are in the metadata, and can be plugged into Automatic1111."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "New LM Studio Release has Multi-model support",
            "body": "[https://twitter.com/LMStudioAI/status/1770135856780595493](https://twitter.com/LMStudioAI/status/1770135856780595493)",
            "upvote_ratio": 0.9,
            "subreddit": "LocalLLaMA",
            "num_comments": 36,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1biqck7/new_lm_studio_release_has_multimodel_support/",
            "comments": [
                {
                    "body": "I have found in the announcement also the following interesting point:\n\n-> Use the API to build networks, pipelines of LLMs that can talk with each other\n\n\nSounds interesting to me."
                },
                {
                    "body": "Still no rags üò≠"
                },
                {
                    "body": "That‚Äôs very cool!"
                },
                {
                    "body": "OK this is indeed very cool, incredibly useful having two models loaded and running at the same time, will be interesting when the GUI can make use of their output with another model (as enabled by the new API changes).\n\nhttps://preview.redd.it/x539058bpcpc1.png?width=4434&format=png&auto=webp&s=c805141946cec8dcefadd71bc58299d1c932ed19"
                },
                {
                    "body": "It's good to hear about an update but the team at LM studio has had some seriously buggy releases in the last 2 I've used. The suite went from usable confidently to crashing and missing features consistently.\n\nThe last update caused missing New Preset option to create new sys prompts and additionally introduced crashes to server tab and search for models tab.\n\nI am actively looking for alternatives that have hf search built in. They need to stop rushing releases."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation Huggingface Demo has been released",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/86qkswho5xpc1",
            "comments": [
                {
                    "body": "Huggingface Demo: https://huggingface.co/spaces/GRM-demo/GRM\n\n\nProject page: https://justimyhxu.github.io/projects/grm/\n\n\nArxiv: https://arxiv.org/abs/2403.14621"
                },
                {
                    "body": "How do you copy videos and be able to post them as is on reddit by the way?"
                },
                {
                    "body": "On the Demo, I'm getting models with huge holes everywhere, is this something others are getting too?"
                },
                {
                    "body": "What's V3D?"
                },
                {
                    "body": "Stable diffusion 3D is faster than CRM. I have tried both."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Why Microsoft‚Äôs surprise deal with $4 billion startup Inflection is the most important non-acquisition in AI",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 4,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://finance.yahoo.com/news/why-microsoft-surprise-deal-4-220638392.html",
            "comments": [
                {
                    "body": "Thanks for sharing the article. Was good read.\n\nI often say it in jest, but seriously, won't someone think of the shareholders!?\n\nIf I just invested millions last year, I would be pretty angry right now that my founders has left! Unless they will do acquisition another way?"
                },
                {
                    "body": "It makes a lot of sense. Microsoft doesn‚Äôt need their model, they need the tooling for those business chatbots mentioned. Copilot Studio bots aren‚Äôt really working all that well yet and have plenty of limitations.\n\nOn the Azure side, the Azure OpenAI models, Azure AI bots and bot framework aren‚Äôt really plug and play products, rather, they‚Äôre components meant to be built around and integrated into custom solutions. Most customers don‚Äôt have the dev teams required to make full use of those components.\n\nedit: It also just occurred to me that they needed an industry insider to lead their AI efforts. This may have just been the price of admission for Mr Suleyman & Mr. Simonyan.\n\nedit2: Doh, I did not read your comment properly. It was about the Inflection shareholders, my bad."
                },
                {
                    "body": "I think the shareholders pushed them out of the company. They say Inflection lacked a sustainable bussiness model meaning they couldn't generate revenue. For the founders it'd be much better to stay with the company they founded and get a big chunk of the 4B valuation. Microsoft won't pay them like a billion dollars each."
                },
                {
                    "body": "* Mr Simonyan, I was also surprised by the name but he is a leading AI researcher apparently."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Exceptional Mistral 7B 0.2 base model fine-tuning performance",
            "body": "This thing, anecdotally, feels really flexible for conversational applications compared the instruction-tuned model. Trained 7 epochs cosine and it seems to have learned a lot while losing practically nothing.",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 17,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmsg9v/exceptional_mistral_7b_02_base_model_finetuning/",
            "comments": [
                {
                    "body": "Sorry did you fine tune the new base? and then proceed not to post a link? :D"
                },
                {
                    "body": "Can you provide couple examples and demo?"
                },
                {
                    "body": "Would love examples üíï"
                },
                {
                    "body": "What resources/notebooks are people using to finetune the model? I'm trying to get into making finetunes as well"
                },
                {
                    "body": "What does your dataset look like that you need 7 epochs?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Korra (Amazing results w/ SDXL Lightning)",
            "body": "",
            "upvote_ratio": 0.72,
            "subreddit": "StableDiffusion",
            "num_comments": 25,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1blwuxj",
            "comments": [
                {
                    "body": "looks more like  Lara"
                },
                {
                    "body": "Well done....but what was the model / prompt? \n\nLooking at pretty pictures is nice but learning how to make them as well is nicer."
                },
                {
                    "body": "Raw outputs from sdxl lightning, no post-processing"
                },
                {
                    "body": "Well apparently I‚Äôm alone in this, but what blows me away is that it legit looks like Korra. Awesome."
                },
                {
                    "body": "at first I thought Korra was another extension, UI or something else lol"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "The Cow Mutant - Comfyui SDXL + SVDXT1.1",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 9,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/wo0fl8pc8xpc1",
            "comments": [
                {
                    "body": "THIS IS THE FUTURE THE LIBS AND DAISY SOUR CREAM COMPANY WANT"
                },
                {
                    "body": "This is slightly terrifying and I love it."
                },
                {
                    "body": "Mootant"
                },
                {
                    "body": "wait until peta figures this out lol"
                },
                {
                    "body": "Any way to get the workflow or is it this one? \n\nhttps://www.patreon.com/posts/svdxt-1-1-sdxl-0-99343878"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "The Purpose Crisis",
            "body": "Most people are primarily driven by long-term goals, accumulating money being the main proxy of this. Psychologically, a 15-20-year AI takeoff would be one of the hardest pills to swallow as the tremendous amount of motivation needed to pursue a worthwhile endeavor is diminished significantly. Will the remaining years of capital accumulation go to those who can overcome this purpose crisis and simply push through? What is the healthiest way to deal with this for those looking to seek a meaningful career?\n\nEdit:\nHey sorry I totally miscommunicated. I meant how does one manage to work the next 15 years knowing that they‚Äôre going to be totally superfluous soon? Where do you get the motivation, especially if you‚Äôre looking to start off in your career?",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 88,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bm7ldp/the_purpose_crisis/",
            "comments": [
                {
                    "body": "What % of people need to find purpose via employment? I would love to see a survey on this because i always strongly felt that most people work to survive and not work for purpose but maybe i'm out of touch."
                },
                {
                    "body": "No one is driven by a 40 hour work week until they‚Äôre 65 where you can get fired at any given moment. All you‚Äôre doing is making the executives at the company rich while you barely pay bills. This isn‚Äôt exactly something to live for."
                },
                {
                    "body": "Most 30 and under wont have this problem nobody likes work and work isn‚Äôt what defines someone or their values. Some people actually have lives and hobbies outside of work."
                },
                {
                    "body": "Lower your expectations. You don‚Äôt need a job to fulfill ‚Äúpurpose‚Äù. Go play video games."
                },
                {
                    "body": "People who find meaning only by working a job will have a crisis. But for the rest, they can take up a hobby more seriously, you like gaming? reviewing books? Building things? Surfing? Travelling the world? Painting? Go for it. Just because AI can and will do it better, doesn't mean that people won't still do stuff, the classic example is chess. Look it up, a grandmaster in chess has already been beaten ages ago (1997), chess is still popular enough.\n\nThe above is assuming that we reach a post scarcity era and people basically live with all their basic needs (and then some) met just because they breathe."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "The Purpose Crisis",
            "body": "Most people are primarily driven by long-term goals, accumulating money being the main proxy of this. Psychologically, a 15-20-year AI takeoff would be one of the hardest pills to swallow as the tremendous amount of motivation needed to pursue a worthwhile endeavor is diminished significantly. Will the remaining years of capital accumulation go to those who can overcome this purpose crisis and simply push through? What is the healthiest way to deal with this for those looking to seek a meaningful career?\n\nEdit:\nHey sorry I totally miscommunicated. I meant how does one manage to work the next 15 years knowing that they‚Äôre going to be totally superfluous soon? Where do you get the motivation, especially if you‚Äôre looking to start off in your career?",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 88,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bm7ldp/the_purpose_crisis/",
            "comments": [
                {
                    "body": "What % of people need to find purpose via employment? I would love to see a survey on this because i always strongly felt that most people work to survive and not work for purpose but maybe i'm out of touch."
                },
                {
                    "body": "No one is driven by a 40 hour work week until they‚Äôre 65 where you can get fired at any given moment. All you‚Äôre doing is making the executives at the company rich while you barely pay bills. This isn‚Äôt exactly something to live for."
                },
                {
                    "body": "Most 30 and under wont have this problem nobody likes work and work isn‚Äôt what defines someone or their values. Some people actually have lives and hobbies outside of work."
                },
                {
                    "body": "Lower your expectations. You don‚Äôt need a job to fulfill ‚Äúpurpose‚Äù. Go play video games."
                },
                {
                    "body": "People who find meaning only by working a job will have a crisis. But for the rest, they can take up a hobby more seriously, you like gaming? reviewing books? Building things? Surfing? Travelling the world? Painting? Go for it. Just because AI can and will do it better, doesn't mean that people won't still do stuff, the classic example is chess. Look it up, a grandmaster in chess has already been beaten ages ago (1997), chess is still popular enough.\n\nThe above is assuming that we reach a post scarcity era and people basically live with all their basic needs (and then some) met just because they breathe."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "OpenAI Q*",
            "body": "Source, some random paste bin: [https://pastebin.com/RkBUQPLb#google\\_vignette](https://pastebin.com/RkBUQPLb#google_vignette). This should really be considered speculative because the source is unknown, but the ideas presented are definitely something to ponder.\n\nLeaked info:\n\nQ\\* is a dialog system conceptualized by OpenAI, designed to enhance the traditional dialog generation approach through the implementation of an energy-based model (EBM). Distinct from the prevalent autoregressive token prediction methods, Q\\* aims to mimic a form of internal deliberation akin to human thought processes during complex problem-solving, such as chess playing, where a deeper analysis of potential moves leads to better decision-making compared to rapid, less considered responses. This model shifts focus towards the inference of latent variables, reminiscent of constructs in probabilistic models and graphical models, fundamentally altering how dialog systems operate.\n\nEnergy-Based Model for Dialog Generation\n\nAt the core of Q\\* is the EBM, which operates by assessing the compatibility of an answer to a given prompt through a scalar output. This output signifies the \"energy\" of the response, where a lower value indicates a high compatibility (a better answer) and a higher value suggests low compatibility (a poor answer). This mechanism allows Q\\* to evaluate potential responses holistically, moving beyond the sequential prediction of tokens to understand the underlying relevance and appropriateness of an answer to the prompt.\n\nOptimization in Abstract Representation Space\n\nThe innovation in Q\\* lies in its optimization process, conducted not within the space of possible text strings but in an abstract representation space. Here, thoughts or ideas are represented in a form that allows for the computational minimization of the EBM's scalar output, akin to finding the path of least resistance in a landscape. This process involves gradient descent, a method for finding the minimum of a function, applied to iteratively refine these abstract representations towards those that yield the lowest energy in relation to the prompt.\n\nFrom Abstract Thought to Textual Response\n\nOnce an optimal abstract representation ‚Äî one that minimizes the EBM's output ‚Äî is identified, Q\\* employs an autoregressive decoder to transform this abstract thought into a coherent textual response. This step bridges the gap between the non-linguistic, conceptual understanding of the dialog system and the linguistic output required for human interaction.\n\nTraining the System\n\nThe EBM within Q\\* is trained using pairs of prompts and responses, adjusting the system's parameters to minimize the energy for compatible pairs while ensuring that incompatible pairs result in higher energy levels. This training process can incorporate contrastive methods, where the system learns to differentiate between compatible and incompatible pairs, and non-contrastive methods, which involve regularization techniques to control the distribution of low-energy responses across the space of all possible answers.\n\nImplications for Dialog Systems\n\nQ\\*'s approach, leveraging EBMs for dialog generation, represents a significant departure from traditional language modeling techniques. By optimizing over an abstract representation space and utilizing gradient-based inference, Q\\* introduces a more efficient, reasoned, and potentially more powerful method for generating dialog responses. This system not only promises improvements in the quality of generated text but also offers a blueprint for future advancements in AI's ability to engage in human-like reasoning and conversational interactions.\n\nTechnical Considerations\n\nQ\\*'s effectiveness hinges on the intricacies of its EBM, the optimization landscape it navigates, and the accuracy of its abstract representations. The model's capacity to simulate deep reasoning, akin to human deliberation, sets a new benchmark for dialog systems. Furthermore, the method of training Q\\*‚Äîbalancing the need for specificity in correct responses while avoiding the collapse of energy levels across diverse inputs‚Äîposes unique challenges and opportunities for AI research.\n\n&#x200B;\n\n&#x200B;\n\nBased on this info, someone I know conceptualised it as (im putting it here because I think its a really good way to think about it):\n\n\"energy based model\" is just way of describing the loss function of minimizing prediction error, Essentially all you're doing is generalizing the next input prediction function to the RL domain.\n\nThey are essentially doing this [https://arxiv.org/abs/2303.00848](https://arxiv.org/abs/2303.00848) but for pathways through problem space.\n\n(Not sure if this is a well known 'leak' but somewhere a while ago someone random said something like 'xxx + <10B params = AGI?', well that's coming in right now. xxx is vlb (variational lower bound), or, ELBO. Not sure about the 10B part, but that leak was just relevant due to the relation between Q\\* and ELBO/VLB).",
            "upvote_ratio": 0.74,
            "subreddit": "singularity",
            "num_comments": 49,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bj7wqs/openai_q/",
            "comments": [
                {
                    "body": "This reads like someone set GPT4 to write a Q* fanfic and it threw in a lot of explanations of vaguely plausibly related ML concepts."
                },
                {
                    "body": "I'll be fair, this sounds like the musings of someone who just did a course on the basics of machine learning. Though of course it could be someone writing for an audience of laypeople. \n\nI'm also not really following what it is saying as it skips from describing a system that is checking the responses as they are given, to describing some sort of embeddings store (for what? All the possible answers to all possible questions?) through which something (what?) is optimised. Maybe I'm just not following, but it has this crypto white paper feel to it where it goes from inaccessible, complicated phrases packed with jargon, to needing to explain the concept of gradient descent. Happy to hear more and fully admit it might be because I'm missing something."
                },
                {
                    "body": "This is definitely GPT-4 generated. I wouldn't put any stock in this."
                },
                {
                    "body": "I don't know this sounds like wishcasting or trolling, and it's just a pastebin, akin to something written on public toilets. Because what the text says is essentially the holy grail of AI, just add few more racks and it gets smarter. This would be the AGI, while I don't think the current transformers are at any point (they just predict the next token, but if the results are the same then the discussion is largely philosophical and somewhat meaningless. If it quacks like an AGI, it's good enough for me). The problem is that you don't just stumble onto the holy grail, this would be far bigger leap than AlexNet.\n\nI remain super skeptical, don't get me wrong I would love it, but it's kinda like saying some lab right now has completely achieved fusion, it's energy positive and cheap and all they are thinking now is what's next. The only thing that gives me little bit of hope this could be it is the  internal controversy around Q\\*, whatever it is, I am guessing it's more than yet another transformer."
                },
                {
                    "body": "This approach sounds new and technically plausible. It is absolutely not gibberish as some others are saying.\n\nRegular LLMs map from input sequence to next-token. This method maps from input sequence to future sequence (multiple tokens), instead of just the next-token. The way this could work: They could take a pre-trained LLM's encoder, use it to get the encodings of the input and output sequences, giving you two vectors of latent variables. You then train an energy model to model the joint distribution of the output latent vector and input latent vector. Then at inference time, you take this energy model, and plug in only the input latent vector (corresponding to the user's prompt), then predict the latent vector of the output sequence (the full \"answer\") with gradient descent. You then plug that prediction into your decoder to convert it to actual text.\n\nIt doesn't have the properties you would expect from Q\\*, though, which makes me think it's fanfic (or written by Opus/GPT-4). I was expecting there would be a significantly variable amount of time that it spends \"thinking\". If I'm asking it to solve Fermat's Last Theorem, I want it to spend 10000x longer thinking than if I ask it how to tie my shoelaces. But this approach here seems like it'd be fairly constant amount of thinking time for each input/output sequence pair. All you're doing is a number of gradient descent iterations and that's it. It isn't paradigmatically dissimilar from current LLMs. Another reason I'm suspicious is that Noam Brown was using a planning approach with CICERO and Libratus which uses a symbolic overlay that allows for variable amounts of time spent \"thinking\", so I thought there would be something like that involved, which there isn't.\n\nIf this isn't fanfic, it's just another way of doing LLMs (predicting long sequences instead of next-token), it's not making inroads to solving iterative reasoning."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Junk protein discovery \"opens a new door\" in anti-aging research",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.newsweek.com/junk-protein-discovery-opens-door-anti-aging-longevity-1882263",
            "comments": [
                {
                    "body": "Junk protein?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "NHS AI test spots tiny cancers missed by doctors",
            "body": "From article: An AI tool tested by the NHS successfully identified tiny signs of breast cancer in 11 women which had been missed by human doctors.\nThe tool, called Mia, was piloted alongside NHS clinicians and analysed the mammograms of over 10,000 women.\nMost of them were cancer-free, but it successfully flagged all of those with symptoms, as well as an extra 11 the doctors did not identify.\nAt their earliest stages, cancers can be extremely small and hard to spot.\nThe BBC saw Mia in action at NHS Grampian, where we were shown tumours that were practically invisible to the human eye. But, depending on their type, they can grow and spread rapidly.",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 2,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.bbc.com/news/technology-68607059",
            "comments": [
                {
                    "body": "I identify as mia"
                },
                {
                    "body": "Nice"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Winged cargo ship saves three tonnes of fuel per day on first voyage",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 15,
            "submission_flair": "ENERGY",
            "has_media": true,
            "url": "https://newatlas.com/environment/wings-cargo-ship-efficiency/",
            "comments": [
                {
                    "body": "Doesn't say how much fuel it uses a day, so we don't know how much of a saving 3 tonnes really is."
                },
                {
                    "body": "Nice idea....Wouldn't want to be in rough seas with gusting 100km/h wind catching those things with all that weight on one side of the ship...\n\nLets see if it catches on."
                },
                {
                    "body": "In 2025, for maximum green sustainability, the members of the crew could swivel some sort of wood rectangles in the water, propelling the ship forward!\n\nScience has truly gone too far!"
                },
                {
                    "body": "https://preview.redd.it/gda4mjqs7zpc1.jpeg?width=474&format=pjpg&auto=webp&s=616c109e26102bbfd32f56ad89f44d5963a55e2b"
                },
                {
                    "body": "Winged cargo ship?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Apple Publishes Details About New 'MM1' AI Model",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 25,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://arxiv.org/abs/2403.09611",
            "comments": [
                {
                    "body": "The research paper discusses building high-performing multimodal large language models (MLLMs) that can understand and generate language based on both **text** and **visual** information. Through comprehensive experiments, the researchers identified crucial design choices for achieving state-of-the-art results across various benchmarks. They found that careful mixing of **image-caption, interleaved image-text, and text-only data** during pre-training is essential. Additionally, the image encoder, image resolution, and image token count significantly impact performance, while the vision-language connector design is less important. By scaling up their approach, the researchers built **MM1**, a family of multimodal models **up to 30B parameters, including dense and mixture-of-experts variants**. These models excel in pre-training metrics and achieve competitive performance on established multimodal benchmarks after fine-tuning. Notably, the large-scale pre-training enables **enhanced in-context learning and multi-image reasoning capabilities**, allowing few-shot chain-of-thought prompting."
                },
                {
                    "body": "Unfortunately it seems that Apple itself doesn't think much of it's own model since they are reportedly shopping around to Google and OpenAI to use one of their models to power the AI in Apple devices.\n\nhttps://www.yahoo.com/tech/apple-talks-let-googles-gemini-054341730.html"
                },
                {
                    "body": "A Brandon and a Sam as authors on an arxiv paper?\n\nHey, representation matters!"
                },
                {
                    "body": "Weights?"
                },
                {
                    "body": "They likely do not have the computing horsepower available at the scale that they would need, hell they may not even have a plan to scale yet."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Warning: please take care of your mental health and be mindful of how much of this stuff you consume ",
            "body": "I nearly had a panic attack at work moments ago. I found myself deep deep down the simulation theory and singularity rabbit role. Over the past few months I‚Äôve been obsessed with trying to crack the simulation theory and better understand the nature of reality. I‚Äôve been doing research and asking a question and then going deeper and asking another question and so forth. It‚Äôs all I‚Äôve been thinking about really. Some of the potential answers that I‚Äôve come to the conclusion of regarding the simulation theory and the future are truly frightening subjectively. They aren‚Äôt necessarily objectively bad, but subjectively frightening. When I pondered certain questions and their potential answers I found myself in a state of panic. I think I‚Äôm going to leave some of this stuff alone for a while",
            "upvote_ratio": 0.75,
            "subreddit": "singularity",
            "num_comments": 54,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkely0/warning_please_take_care_of_your_mental_health/",
            "comments": [
                {
                    "body": "Ignore most of these comments telling you to dive in deeper to delusional behavior. I think you're making the right call taking a break from it all!"
                },
                {
                    "body": "I had a one year panic attack. The. I deceided I can choose what I read. \n\nSo now I am in control again. \n\nRemember to tell yourself this."
                },
                {
                    "body": "Maybe you have OCD ? It can manifest as different form of unhealthy obsessions. If your country provide access to mental health services or furthermore a psychiatrist, I would look for referrals."
                },
                {
                    "body": "Keep in mind the simulation theory is not falsifiable. It‚Äôs a cute idea but it is not a scientific idea. There is absolutely no test that could prove for sure that we‚Äôre in a simulation. And there‚Äôs absolutely no test that could prove for sure that we‚Äôre not. Think about it: if you ran a simulated world, and you discovered agents in it were testing their world to see if it were a simulation, you could present them with anything you chose. You could present them with false evidence that they‚Äôve finally cracked it and now they‚Äôre in the next level up, while still being fully in your simulation. Likewise there‚Äôd be no way for you the simulation runner to know if you were or were not in a simulation because anyone in a level above you could do this same monkeying with presented sensory data. \n\nIt‚Äôs a fun thought experiment but that‚Äôs all it will ever be. \n\nAnd frankly it has no practical end. Even if I am in a simulation right now, this is the reality I know and the one I have to live with. Whether it‚Äôs ‚Äúreally real‚Äù or not, nothing changes."
                },
                {
                    "body": "Who cares if we‚Äôre in a simulation, a dream, a solipsistic reality - it wouldn‚Äôt fundamentally change the way I act unless I started to encounter frequent glitches in the matrix or whatever. Its like what if you had evidence that reality wasn‚Äôt what you thought it was, would you start raping and pillaging? Kill yourself? Try to convince everyone of it? Or just try to live your life as best you could?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "I like insects!",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 9,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bim7h5",
            "comments": [
                {
                    "body": "It is pretty amazing what the old SD1.5 can do. This is SD 1.5 right?\n\nOr is it SDXL? Or some custom model perhaps.\n\nAt least they are AI generated as the leg counts are often wrong and there are more than two horns. So posting them to SD sub is appropriate right?\n\nOr is it dalle or something else? Could you at least say what made these."
                },
                {
                    "body": "‚ÄúI like turtles!‚Äù - zombie kid"
                },
                {
                    "body": "I like rivers"
                },
                {
                    "body": "Yep sorry, my comments were gone when posting so:\n\nThis is done with Stable Diffusion, Comfy UI interface and Juggernaut model, sorry if it misses some info I'm a complete noob, its been a month since I started generating (first with A1111 and now with Comfy UI).\n\nOn the side of hardware its done with the good ol' Gtx 1080ti, so I'm pretty amazed by what can be done with this old good boy.\n\nIf you need some other info don't hesitate to ask, so I can get better at posting in this sub.\n\nThanks for the reply"
                },
                {
                    "body": "Please share workflow and prompts if you don't mind."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "3D to AI (sharing workflow in comments)",
            "body": "",
            "upvote_ratio": 0.87,
            "subreddit": "StableDiffusion",
            "num_comments": 18,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://v.redd.it/t3mu0dlc15pc1",
            "comments": [
                {
                    "body": "[https://openart.ai/workflows/renderstimpy/3d-to-ai-workflow/FnvFZK0CPz7mXONwuNrH](https://openart.ai/workflows/renderstimpy/3d-to-ai-workflow/FnvFZK0CPz7mXONwuNrH)  \n\n\nHey everyone. I posted my workflow for 3D to AI last week and it got a lot of positive responses. However I did a pretty bad job at explaining the actual workflow. The workflow was a mess (and it kinda still is) so I didn't want to share it.I cleaned it up and put it on OpenArt. So anyone who wants to play around with it can do so.It wasn't really meant to gatekeep, I was just kind of busy and stuck in the weeds of work and life.\n\nWho is this for?   \nAnyone that has access to Blender or Cinema4D (or any 3D tool really).   \nWhat you need for this to work is your animation exported as a diffuse render and as a normal map."
                },
                {
                    "body": "Oh...my godish! Nice work I can only say."
                },
                {
                    "body": "Thanks for making the time to clean up and post this!"
                },
                {
                    "body": "Hi, I am not sure how to render out of cinema4d as a normal map. Do you have a scene file you could please upload so I can see how it is done?"
                },
                {
                    "body": "This looks interesting. Thanks for posting this.\n\nDownloaded & am trying the workflow.\n\nQuestion(blender user):\n\n  How you generate the normal frames? \n\nNote: I was going to create a separate texture to serve only as normal map & then render those frames independently. Wasn't sure what approach you used or best method."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "New algorithm unlocks high-resolution insights for computer vision",
            "body": "Great paper!",
            "upvote_ratio": 0.89,
            "subreddit": "MachineLearning",
            "num_comments": 6,
            "submission_flair": "None",
            "has_media": true,
            "url": "https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318",
            "comments": [
                {
                    "body": "Isn't this just a decoder of the feature map?\n\nLike a UNET or a semantic segmentation task?"
                },
                {
                    "body": "\\_\"The core intuition behind FeatUp is that one can compute high-resolution features by observing multiple different ‚Äúviews‚Äù of low-resolution features. We draw a comparison with 3D scene reconstruction models such as NeRF (Mildenhall et al., 2020); in the same way that NeRF builds an implicit representation (Sitzmann et al., 2020b; Chen & Zhang, 2019) of a 3D scene by enforcing consistency across many 2D photos of the scene, FeatUp builds an upsampler by enforcing consistency across many low-resolution feature maps.\"\\_"
                },
                {
                    "body": "Direct link to project page: https://mhamilton.net/featup.html"
                },
                {
                    "body": "How much slower is inference? I don‚Äôt see it mentioned anywhere"
                },
                {
                    "body": "Not really. Dinov2 and other vision transformers generate patch features rather than pixelwise features because attention is limited by input size - a 32x32 patch grid is already 1024 tokens which is close to the limit of what they can handle.\n\nIf you want to do dense vision tasks (depth estimation, segmentation, etc) this is very low resolution and the head you will train on top needs to learn how to reconstruct dense features from this. So every new task needs to learn dense features. The head is the decoder.\n\nThis work extends these low resolution features to pixel wise features which allow training much smaller heads. This is still just an encoder though. \n\nI have actually used it last week to simplify a model I had built recently. It is still not perfect (has some artifacts etc) but it was able to reduce the number of prams in my head significantly, with a pretty basic architecture, and the training time was far shorter for much better results.\n\nThat being said it is very memory intensive, with dinov2 these are 256x256x384 feature maps for the tiny version which is already pretty massive."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Learning how to fine-tune (first time), I've provided links to tutorials I found, but would anybody else recommend further material.",
            "body": "Hello friends, my objective is to learn how to fine-tune models. I'd like to learn as much I can during the weekend which is the only time I have off. \n\nI've done as much research as I can on my free-time :)\n\n#### What I know so far\n\nSo far I've learned the following:\n- build llama.cpp with GPU support using cmake (I'm comfortable C++)\n- run the server application llama.cpp provides\n- I've made my own little application with NodeJS that connects to the server program. I did this in order to save conversations to a MongoDB database. \n- I've made a small chat bot using different chat template formats in order to learn how it all works and get familiarized with each one.\n\n#### What I'm trying to learn\n\nI'm having trouble understanding fine tuning. So far this is the reading material I've compiled looking through Reddit and searching on DuckDuckGo:\n\n- One of the most useful articles I've found so far, check out the Medium post: https://www.reddit.com/r/LocalLLaMA/comments/17p6hup/beginners_guide_to_finetuning_llama_2_and_mistral/\n- The first comment of this post shares two nice videos and and an article: https://www.reddit.com/r/LocalLLaMA/comments/13uzcrh/looking_for_a_finetuning_guide/\n- And this post is not as detailed as the other, but very useful: https://www.reddit.com/r/LocalLLaMA/comments/18n2bwu/i_will_do_the_finetuning_for_you_or_heres_my_diy/\n\nWould you all recommend anything else?\n\n#### A Few Questions\n1) Let's say I wanted to train a model with tons of Cyberpunk 2077 text and my objective is to make a expert bot on the topic. Would Fine-tuning be the correct approach?\n2) Similar to the first question, let's say I'm running a business and I want to train a model with tons of business related data. Aside from that, I'd like for the model to only talk about business related topics. What's the best approach to accomplish this.\n3) I plan on using `runpod`, is there a possibility I'm training for hours and then it fails? If so, how can I avoid this?\n4) Any tips for somebody using llama.cpp for fine-tuning. I found some info in their repo, but I'm afraid I'm still confused.\n\nThanks a lot for reading if you made this far!",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 17,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bkqxui/learning_how_to_finetune_first_time_ive_provided/",
            "comments": [
                {
                    "body": "I would go with QLoRA Finetuning using the [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main) template on Runpod for this task, and yes some form of fine-tuning on a base model will let you train either adapters (such as QLoRA and LoRA) to achieve your example Cyberpunk 2077 expert bot. Performing a full fine-tune might even be worth it in some cases such as in your business model in Question 2. However, I would look at the PEFT approach to save compute time for your initial task as it is generally very computationally expensive otherwise. \n\nRegarding runpod or other cloud services, I would get familiar with [weights & biases](https://wandb.ai/site) for logging your training runs, as well as configuring a regular saving step in axolotl as the model is training through epochs allowing you to continue from a previous checkpoint if anything was to crash. (It really shouldn't, I have only had OOM problems and crashes within the first couple of minutes of running axolotl after that it's generally very stable.)\n\nI don't have any experience with llama.cpp for fine-tuning, I use it for quantizing my full fp16 weights and measuring perplexity etc. Was there any particular reason you had for wanting to use it?"
                },
                {
                    "body": "Alas, there is still not a single straight forward app for fine tuning on consumer grade text"
                },
                {
                    "body": "1) For memorizing facts generally RAG is the better approach. To insert facts with training you need a higher rank LoRA (which increases the odds of overfitting) and your data must be formatted as questions with answers, not just raw text (for example, wiki pages won't work)\n\n2) The best approach would probably be to use RAG to pull in relevant facts and data, and fine-tune the model to better use the RAG and to ensure it doesn't talk about non-business related topics\n\n3) I fine-tune fairly often and have never had a run outright fail unless I overestimated what I could fit on my GPU. While it does happen, I'd be more worried about ensuring parameters and your dataset are set up correctly for training. I've ended up wasting days to accidentally formatting my dataset wrong\n\n4) AFAIK most people don't fine tune directly with llama.cpp. The most common approach is to use the transformers library, and then quantize with llama.cpp after. I personally like [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl), but I know some people use [unsloth](https://github.com/unslothai/unsloth), or just write the scripts themselves."
                },
                {
                    "body": "I wanted to ask a basic question: if finetuning an instruction tuned model, do you run further causal language modelling to guess random words in the dataset, predict correct completions (instruction tuning pairs), both or one after the other?"
                },
                {
                    "body": "I think some others have called out - FT (SFT to be more precise)doesn't really teach the model anything new in terms of knowledge. The only way you can teach a model anything new is by training or a \"Full Fine tuning\". Fine-tuning as most call it is optimizing the model on a certain task where it doesn't perform better. The emoji example asked in the thread is a good example. As it happens I use something similar to demonstrate that in my book as well."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Want to live some where like here....",
            "body": "",
            "upvote_ratio": 0.89,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bijkia",
            "comments": [
                {
                    "body": "That's basically an apartment building in parts of Munich or Dachau, just with curves here and there."
                },
                {
                    "body": "Get your tools and build it."
                },
                {
                    "body": "Structural engineer be like.. : make it more curvy and complicate ü§¶ü§∑  üòÇüòÇüòÇ"
                },
                {
                    "body": "Elysium"
                },
                {
                    "body": "Well then, if you're planning to move to Spain, I have [some good news for you](https://www.sensesatlas.com/espai-verd-a-vegetal-urban-cathedral/)"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Computing 'paradigm shift' could see phones and laptops run twice as fast ‚Äî without replacing a single component",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 9,
            "submission_flair": "COMPUTING",
            "has_media": true,
            "url": "https://www.livescience.com/technology/computing/computing-paradigm-shift-could-see-phones-and-laptops-run-twice-as-fast-without-replacing-a-single-component?utm_medium=social&utm_campaign=socialflow&utm_content=livescience&utm_source=facebook.com",
            "comments": [
                {
                    "body": "I imagine we‚Äôre not far from cloud data centre operators simply ring fencing and handing over bare metal to AI. AI will create its own software from the lowest level to most efficiency utilise the hardware for its own purpose. And we won‚Äôt entirely understand what it‚Äôs doing. I see this as the first step and AI taking control of the physical realm. From here there‚Äôs a longer road where human built but AI controlled robotics allows it to maintain its own infrastructure, then onwards to AI manufacture and fabrication.\n\nExiting times for sure."
                },
                {
                    "body": "So are you telling me that I could've simply download more RAM all this time?!"
                },
                {
                    "body": "I don't understand - threading is nothing new. How is this any different from someone writing clever multithreaded code that avoids io blocking?¬†"
                },
                {
                    "body": "Hmm RISC architecture would allow this"
                },
                {
                    "body": " *Hail the Omnissiah! He is the God in the Machine, the Source of All Knowledge.*"
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "GPT-4-vision's take on the state of the r/ChatGPT subreddit üíÄ",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 4,
            "submission_flair": "memes",
            "has_media": true,
            "url": "https://v.redd.it/jk7w4anyidqc1",
            "comments": [
                {
                    "body": "Thanks for posting my video onto this sub! For any nerds that may be interested, I made this tool to allow developers to import text + images into multimodal LLMs. It's free & open source (the github is on the original post)"
                },
                {
                    "body": "Bro can you pls give the GitHub link"
                },
                {
                    "body": "Nice job, also yeah github link please"
                },
                {
                    "body": "https://github.com/emcf/thepipe\n\n\nFrom: https://www.reddit.com/r/OpenAI/comments/1bn03x3/comment/kwf2c52/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Open-source AI models released by Tokyo lab Sakana founded by former Google researchers",
            "body": "",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reuters.com/technology/open-source-ai-models-released-by-tokyo-lab-sakana-founded-by-former-google-2024-03-21/",
            "comments": [
                {
                    "body": "from the benchmarks they are still inferior to GPT4 even in japanese by a lot. This is definitely not frontier stuff but they are pretty good for their size"
                },
                {
                    "body": "I guess we need Llama 3 to really take advantage of the technique."
                },
                {
                    "body": "sounds like it"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Only smart LLMs can understand good essays",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 30,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/ys4j5haz24qc1.png",
            "comments": [
                {
                    "body": "I analyzed several LLMs and how well they \"understand\" university essays: For all LLMs, bad essays are hard to understand. But to¬†*smart*¬†LLMs, good essays make sense. This could be a way to¬†*measure an LLM's reasoning ability*. More plots, data, code:¬†[https://muxamilian.github.io/essay-entropy-llms/](https://muxamilian.github.io/essay-entropy-llms/)"
                },
                {
                    "body": "Even the highest (absolute) correlation here is so small that you can safely assume there is no correlation at all. It‚Äôs noise."
                },
                {
                    "body": "Ooh. Interesting. Essay understanding I think would be a nice automatic benchmark.\n\nCan you help me verify I'm interpreting the data correctly? So this is a Pearson's Correlation coefficient where X = entropy and Y = grade? (i.e. -1 to 1 range) And gpt2 for example is closer to 0. (0 = no correlation)\n\nMore away from 0 = better performance? I.e. better linear correlation between entropy and grade.\n\nWhat is \"essay entropy\" in this context? Is there an established definition? From the page it's: \"Give it the 1st token of an essay, let it predict the 2nd one. Compute the entropy of the output probability distribution of the 2nd token. Give it the 2nd token, let it predict the 3rd, compute the entropy of the output distribution of the 3rd token etc. Average the entropies for an entire essay. \"\n\nI'm sorry if this is a dumb question but what is \"entropy of the output distribution\" in this context? Is it just: take log probability of getting the correct token out, add it to the text (i.e. there's no sampling involved, other than looking at logits for entropy calculation purposes), predict next token, check its log probability, add it to text etc. and then sum them all together. Collect results for bunch of essays per model, then compute correlation to the grades they had. The correlations are all negative, so a higher grade correlates with lower number from the calculation which I think would not match with what I just wrote, hm.\n\nIs it like perplexity measurement? (You can just link me a paper or a blog if you don't want to bother typing...just want to check that my basic intuition on what I'm looking at is correct)."
                },
                {
                    "body": "I'm more shocked at how well gpt2 did at all. I played around with it back in the day and would have thought its responses would be more along the lines of random noise compared to 7b."
                },
                {
                    "body": "Great work!  Thank you for sharing :-)\n\nThis more or less tracks with my observation that inference quality improves quite a bit when context is filled to at least 440 bytes (about 88 tokens), which is near'ish the \"knuckle\" of your last graph of essay tokens vs entropy.\n\nIt also tracks with RAG dramatically improving inference quality, even for small models, since the inference context is being filled to a large fraction with relevant information, well beyond that graph's knuckle.\n\nIt would be interesting to see where Starling-LM-11B-alpha fell on this graph, as it is significantly larger than the 7B you tested and hits above its weight (very high quality training)."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Pipe dream VR glasses will arrive sooner than many expect. Humans won't be the designers; AI will.",
            "body": "Just watched Nvidia's presentation in full. Once AI begins to design and iterate, any well-funded startup can create an equivalent of the iPhone 30 as their first product. Simply provide it with the digital twin of the hardware and the 200 most common use cases. Instruct it to Iterate. Iterate. Iterate. Then, 2 seconds later, instruct it to iterate some more and you'll return tomorrow. Once it's perfected using current tooling capabilities, devise the steps to manufacture the tooling and device. The same applies to VR glasses. Or cars. Or anything. ",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 19,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjzi33/pipe_dream_vr_glasses_will_arrive_sooner_than/",
            "comments": [
                {
                    "body": "Just keep shouting \"ENHANCE\" until we achieve utopia"
                },
                {
                    "body": "Tbh, I'm kinda waiting for the true tech revolution in which all these advanced scifi gadgets get rolled out.\n\nFull dive VR? Lets goooooo!"
                },
                {
                    "body": "The rest if the decade is going to be wild. Truly photorealistic AR/VR hardware coupled with equally photorealistic content which is created on the fly depending on the users wishes, be it audio, video or even games. Not sure if we‚Äôre headed towards a dystopian or utopian future, probably a mix of both, but it surely will be exciting"
                },
                {
                    "body": ">any well-funded startup can create an equivalent of the iPhone 30 as their first product\n\nI do wonder if the organization (or organizations) that develop the first great AI will make them available to startups and the public in general.\n\nIt would suck, but they might very well keep it all in house and invent all these things internally to sell them and become the richest company in the history of the world.\n\nIt seems like that could be a likely outcome."
                },
                {
                    "body": "Yes ... LLMs will put together the solution from existing articles about VR glasses in the media. /s"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "SUPIR v2 nodes full detailled workflow and best practices!",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 16,
            "submission_flair": "Tutorial - Guide",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=2q6Ms9H_cXg",
            "comments": [
                {
                    "body": "Hey guys! The last 5 days have been 18h/days testing recording best practices for **SUPIR v2 nodes** by **Kijai**. Included is how to use SDXL **lightning** with SUPIR, comparisons of various upscaling techniques, **vRam** management considerations, how to preview its **tiling**, and even how to fix **error** messages you might encounter!    \n  \nOh, and of course full workflow included, as always.  \nEnjoy!"
                },
                {
                    "body": "![gif](giphy|2mxA3QHH4aHFm)"
                },
                {
                    "body": "I think thats SUPIR is a new era, but with faces not always work, it's possible to add a faceswapper, and add an impainting? with a Lora option or Controlnet i think that with this implementations SUPIR will be unbeatable"
                },
                {
                    "body": "Error occurred when executing SUPIR\\_sample:\n\nSizes of tensors must match except in dimension 1. Expected size 136 but got size 135 for tensor number 1 in the list.\n\nhttps://preview.redd.it/kizsbkoblgpc1.png?width=1827&format=png&auto=webp&s=ed85f9ddeb07846ae6c1c0c56288b27bc6b7be1b"
                },
                {
                    "body": "What's the peak ram usage in this version? I'm seeing 20gb in the video. Does it peak higher? I couldn't use the previous version on my 16gb ram with like extra 30gb pagefile."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Autonomous Weapons Are A More Sinister Threat Than Some Realize",
            "body": "Many here feel that the natural next step in a fully automated workforce is UBI. They think this because they know businesses will still need consumers. This is a perfectly logical expectation except for the fact that a hypothetical business with hoarded money and an endless supply of inexhaustible labor no longer needs to operate in our current system. In this situation they have all the leverage. If they need something, they have a machine make it for them.\n\nWhat‚Äôs to stop this entity from creating autonomous weapons that are used to cull and oppress displaced workers and the general poor? You don‚Äôt need to worry about the loyalty of a machine. \n\nAnd it doesn‚Äôt even have to be a corporation. The only thing stopping any powerful entity from doing whatever it wants is the control it has over its enforcement mechanism. Replace your military with armies of unfeeling killing machines and the only thing the starving can do is die quietly or be crushed utterly.",
            "upvote_ratio": 0.83,
            "subreddit": "singularity",
            "num_comments": 51,
            "submission_flair": "Robotics",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bi17bl/autonomous_weapons_are_a_more_sinister_threat/",
            "comments": [
                {
                    "body": "The most dangerous AI is one that is smarter than you in some respects, and is kept dumb in others so that it can stay a weapon for those that seek to use power to come out ahead, vs innovation and supporting a rising tide that lifts all boats."
                },
                {
                    "body": "You're thinking too small.\n\n\nIt's not just states and corporations; autonomous drones are quickly getting cheap enough for terrorist groups and even local gangs and crazy people to use.\n\n\nWarfare in the past was done by a state or at least a paramilitary group.\n\n\nWe are entering an era where people will murder each other anonymously for vile cowardly reasons with no national pride, or appearance of conscience, or even rational thought, getting in the way."
                },
                {
                    "body": "I work with a missile system developed in the 80s and it could already decide to and engage aircraft on its own.\n\nMost of us can't fathom what they have currently even."
                },
                {
                    "body": "Robo police Force?"
                },
                {
                    "body": "have we figured out how to build a machine (whether hardware or software) that performs maintenance on itself?"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Just a lil reminder that comments are due by March 27 for NTIA AI Open Model Weights RFC",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 7,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.regulations.gov/docket/NTIA-2023-0009/document",
            "comments": [
                {
                    "body": "I've been working on mine this weekend. Took me most of last night just to answer #1 lol. I'm halfway through #2 now. Plan to spend the rest of today + all of tomorrow and tuesday evenings writing up answers for the rest.\n\n**EDIT**: I'm on question 3 and I'm already up to 5,125 words =D They are absolutely going to tl;dr me on this."
                },
                {
                    "body": "Submitted mine today, I encourage everyone that can to express their thoughts on the published material.  There is an instructions for comment section at the end of the document, you can answer questions that are not in the document itself."
                },
                {
                    "body": "This is a pretty quiet thread. Lets have it, what are the actual dangers of AI that were not present and amplified already by the internet or free speech?"
                },
                {
                    "body": "I wonder how many out there ironically have their own AI just going crazy with submissions"
                },
                {
                    "body": "It took me a few days to write mine too.  \n\nDon't let that discourage anyone that sees this post, the document says you don't need to answer all the questions, or even any specific question outlined in the document."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "We lost a luminary: Vernor Vinge has died",
            "body": "This sub would likely not exist as it is without the sci fi luminary Vernor Vinge, the first popularizer of the technological singularity as a concept.\n\nI grew up on his books, his Hugo award winners \"A Deepness in the Sky\" and \"A Fire Upon the Deep\" particular favorites.\n\nI'm so sad he didn't live to see his predictions about curing aging come true, a la \"Rainbows End\".\n\nVernor died March 20, 2024.",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 4,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bkyt1k/we_lost_a_luminary_vernor_vinge_has_died/",
            "comments": [
                {
                    "body": "Rest in peace."
                },
                {
                    "body": "Damn this one hit me hard."
                },
                {
                    "body": "Rip."
                },
                {
                    "body": "Rip"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Sakana AI: Introducing Evolutionary Model Merge: A new approach bringing us closer to automating foundation model development. We use evolution to find great ways of combining open-source models, building new powerful foundation models with user-specified abilities!",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 15,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/SakanaAILabs/status/1770613032198279663",
            "comments": [
                {
                    "body": "something is fishy about the name but I can't put my finger on it."
                },
                {
                    "body": "ah nice was just talking about something like this.\n\nImagine if you could combine Geminies giant context abilities with Claudes semi-sentience, googles medical ai's med abilities, and improved cognition, math understanding and reasoning with an agent framework."
                },
                {
                    "body": "This feels sketchy. A 25 second animated gif? And if you go through their feed, it‚Äôs a bunch of fluff about office buildings and just having got their GPUs in February."
                },
                {
                    "body": "This is interesting"
                },
                {
                    "body": "Sacana is bastard in portuguese lol"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "OpenInterpreter 01 - Open source Rabbit R1",
            "body": "[https://github.com/OpenInterpreter/01](https://github.com/OpenInterpreter/01)\n\nI love seeing this, and the demo is pretty compelling.\n\nThe device uses an ESP32, which is also what powers Home Assistant's open-source voice assistant.\n\nThe ability to teach/learn new skills is really impressive.  I haven't dug into the source, but I'm very curious how they go about implementing this.\n\nWith a local LLM and wireless hardware voice assistants, this seems like a pretty big step forward.\n\nCurrently it's push-to-talk, which makes a lot of sense.  A vision I've been thinking about a lot and doing some prototyping on is to have an AI-powered voice assistant that is always listening (ESP32, websockets, whisper, local llm), and this is a big step toward realizing that vision!\n\n&#x200B;",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 3,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bkfwmu/openinterpreter_01_open_source_rabbit_r1/",
            "comments": [
                {
                    "body": "Thanks for posting this.\nI tried but my machine acted up¬†\nI kinda feel yhis might be the assistant many of us would like to try locally.\nCan't wait till the drop the local code."
                },
                {
                    "body": "Thanks for sharing, so excited to try it out!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "So my dual 7900 xtx finally work",
            "body": "In case someone cares. \nI finally managed to get 7900 xtx work, on desktop/Ryzen too. I'm saying this, as official AMD statement is / was you need symmetrical PCIe split (8x/8x or 16x/16x), and it must be direct to CPU, not via chip set. So first I had just bought MB with multiple PCIe 16x slots ... that did not offer symmetrical split (stuff like 4x/4x/2x only). Then, with symmetrical MB it was still not working with pytorch and stuff, as you need \"PCIe attomics\" which only work when cards PCIe is direct to CPU and not MB chipset. Trouble is only Threadrippers (or some Intel server stuff) provides that many direct CPU lanes... Still I had hopes for llama.cpp and it was being worked out over time. And today I finally figured it out with some help on llama.cpp issues. Need to build vulkan acceleration for llama.cpp and run using command like:\n\n```\nGGML_VK_VISIBLE_DEVICES=0,1 ./bin/server --host 0.0.0.0 -c 8192 -ngl 100 -b 512 -ts 1,1 -m ~/n/model_speedload/text/command-r-v01-c4ai-Q4_K_M.gguf\n```\n\nI'm finally able to run some bigger models (35B in this case).\n\nI know consumer AMD cards till have certain drawbacks, still hopefully NVIDIA's monopoly can start be challenged.\n\nNeedless to say, I'm happy my investment is starting to work :)",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 26,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bit6gh/so_my_dual_7900_xtx_finally_work/",
            "comments": [
                {
                    "body": "What chipset?\n\nMy x570 can run x8/x8\n\nShould be 24x PCIe lanes.  16x on graphics (or 8x8 with duo). 4x NVMe direct and 4x through Chipset.  Chipset handles USB.  It may get sloppy on some motherboards with a ton of SATA but it should just be slow on IOPS if sata/nvme are competing.\n\nwas your error in clinfo?\n\nas far as i know, the atomic from rocm/opencl/clinfo has nothing to do with PCI atomics and is often a red herring. \n\nas for atomics:\n\nROCm requires CPUs that support PCIe‚Ñ¢ Atomics. Modern CPUs after the release of 1st generation AMD Zen CPU and Intel‚Ñ¢ Haswell support PCIe Atomics.\n\nYou sure you're just not running enough power?  I needed 1000 watts clean for a single card, so you would probably want 1400 for 2x"
                },
                {
                    "body": "What motherboard did you get?"
                },
                {
                    "body": "I thought the atomics were present above PCIE2. That's bad if you can't use it in normal evenly split boards."
                },
                {
                    "body": "Thanks for the great details! I'm gunning for AMD and Intel to tackle Nvidia. Unfortunately I needed something asap so found a used 3090ti\n\n\nI scour for happy ROCM stories like this."
                },
                {
                    "body": "not even going to use that info since I'm on Nvidia.. but thanks for sharing that info!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "More autonomous EVE from 1X",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://twitter.com/1x_tech/status/1770106870105358770",
            "comments": [
                {
                    "body": "What I love about these videos are the inevitable responses like \"If I folded a shirt like that at my job, I'd be fired\" or \"good thing that package is going to get destroyed because they didn't put in enough stuffing\" or \"it couldn't even fold down that box flap properly\".  \n\nJust remember that all of this training data can be used for all subsequent robots, most of this training data is model agnostic, and can also be trained on watching humans do it \"properly\".  Better quality work at a faster pace coming very quickly.  As long as they are working in relatively low-stakes environments at first, there is very little to lose and massive room for gains.  It won't be long before building the robots will be more of a bottleneck than their capabilities."
                },
                {
                    "body": "so many robotic demos now, question is where is NEO(the one with legs)"
                },
                {
                    "body": "Not gonna lie, when i first saw this I thought it was humans dressed as robots‚Ä¶ üòÖ"
                },
                {
                    "body": "That is impressive and it's only March. 2024 is definitely going to be the year of the robot."
                },
                {
                    "body": "Developmental hell"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "4bit bitsandbytes quantized Mistral v2 7b - 4Gb in size",
            "body": "Hey! Just uploaded a 4bit prequantized version of Mistral's new v2 7b model with 32K context length to https://huggingface.co/unsloth/mistral-7b-v0.2-bnb-4bit! You get 1GB less VRAM usage due to reduced GPU fragmentation + it's 4GB in size so 4x faster downloading!\n\nThe original 16bit model was courtesy of Alpindale's upload! I also made a Colab notebook for the v2 model: https://colab.research.google.com/drive/1Fa8QVleamfNELceNM9n7SeAGr_hT5XIn?usp=sharing",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 23,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmc1hd/4bit_bitsandbytes_quantized_mistral_v2_7b_4gb_in/",
            "comments": [
                {
                    "body": "Rip, ofc unsloth delivers right away \\^\\^ Just finished a training run yesterday with mistral v1, now i'm really tempted to redo it with v2 right away <.<"
                },
                {
                    "body": "Any gguf?"
                },
                {
                    "body": "So we can save bnb quants now? Neat."
                },
                {
                    "body": "How much vram would be required?"
                },
                {
                    "body": ":)) Thanks!"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "OpenAI GPT-4 vs Groq Mistral-8x7b",
            "body": "",
            "upvote_ratio": 0.86,
            "subreddit": "LocalLLaMA",
            "num_comments": 22,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://serpapi.com/blog/openai-gpt-4-vs-groq-mistral/",
            "comments": [
                {
                    "body": "the model is Mixtral-8x7B, not Mistral"
                },
                {
                    "body": "There are fields where the rules of processing and parsing are too complex to write in code, and that's where LLM's can shine. This is one of those cases where coding a business hours parser would be a lot faster to run at query time and probably make their API more usable."
                },
                {
                    "body": "I thought it was talking about some sort of mixtral and grok hybrid."
                },
                {
                    "body": "20k for accelerator card with 16 week back order for a limited supply.  Interesting to see these devices hit the market though and their performance is great.\n\nI am however seeing drastically improved GPT 4 responses - it seems they're testing some acceleration as i can get responses faster than the blog post results. (maybe they're testing stuff on pro vs api)"
                },
                {
                    "body": "It's the little mistakes that end any usefulness of an llm in the arena of coding. You can't do one shot functions because of the chance of some naming issue, missing comma, brackets, whatever.\n\nGroq is fast, but Groq outputs trash. Will you keep using it?"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Upscaler and nsfw",
            "body": "Im not sure if this one is against the rules because is more of a question, not sharing images, but, my hires fix is clothing my characters, i reduce the denoising strength to 0.5, and sometimes works sometimes not, any way to prevent this to happen?",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 39,
            "submission_flair": "Question - Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bkuf76/upscaler_and_nsfw/",
            "comments": [
                {
                    "body": "Reduce to .5?\n\nI usually work at like .2. .5 is a lot of alteration. I'll never understand why that thing is set to .7 by default. \n\nWhich upscaler?"
                },
                {
                    "body": "I usually use the upscaler at 0.3 with 15 steps in 99,9% of my generations, and I generally use 4x\\_NMKD-Siax\\_200k or Anime6B for animeish gens."
                },
                {
                    "body": "Use the negative prompt"
                },
                {
                    "body": "As suggested by the others, lower the denoising strength. I use Highres at 0.4 and never had this problem."
                },
                {
                    "body": "u should keep hires fix at .2-.3"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "3D-printed skin closes wounds and contains hair follicle precursors | Penn State University",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 4,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.psu.edu/news/research/story/3d-printed-skin-closes-wounds-and-contains-hair-follicle-precursors/",
            "comments": [
                {
                    "body": " The experiments, which involved adding layers of skin to injuries using 3D bioprinting techniques, hold immense promise for advancements in dermatological treatments and reconstructive surgeries. While initially demonstrated in animal models, this breakthrough has the potential for transformative applications in human medicine."
                },
                {
                    "body": "What is the 3D printed skin made out of?"
                },
                {
                    "body": "People. Peeeeeeple!"
                },
                {
                    "body": "Lol!!!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "New algorithm unlocks high-resolution insights for computer vision",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318",
            "comments": [
                {
                    "body": "Yeah. We need something like this. Something that can understand images on multiple scales like humans. From the large to the small. Not just the bird, but also the color stripes on the beak."
                },
                {
                    "body": "ELI5. Implications?"
                },
                {
                    "body": "Don't current models already do labeling well?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "If (when) US obtains AGI/ASI 1st, what will be reaction of Russia/China...?",
            "body": "If (when) US obtains AGI/ASI 1st, what will be reaction of Russia/China...? Like US wants Russia and China gone (doesnt matter if you think its right or wrong, or whos team you are on, its a fact).\n\n&#x200B;\n\nWhat will happen... What will Russia or China do... Wont it be a significant LIFE THREAT for their existence...? Whether on the military or \"just\" economic side of things...\n\nWas there any article/thought written on this subject...? Or \"Geopolitical\" theater in general on this Regard...?\n\n&#x200B;\n\n(wouldnt it make almost sense for China or Russia to lob a nuke on its location...? (of course AGI/ASI i assume would be \"back uped\" by them on several places so it doesnt make a sense... but still)...",
            "upvote_ratio": 0.78,
            "subreddit": "singularity",
            "num_comments": 124,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bhulth/if_when_us_obtains_agiasi_1st_what_will_be/",
            "comments": [
                {
                    "body": "try to steal it or/and develop their own, just like now"
                },
                {
                    "body": "If the USA turns on a super intelligence then the USA will not be in charge any more"
                },
                {
                    "body": "AGI/ASI will be significantly better dictators. Democracy's great advantage was that it enabled a true mobilisation of an entire populace. People worked because they wanted to not due to force. If AI replaces the need for human labour this advantage disappears."
                },
                {
                    "body": "AGI can and will change regimes in Russia, china, and even in the us"
                },
                {
                    "body": "If US can create a defensive system to negate nuclear weapons, I believe Putin is the first guy to get clapped following the guy in North Korea. (Not sure how but it comes to mind)"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Google DeepMind‚Äôs Latest AI Agent Learned to Play Goat Simulator 3",
            "body": "[https://www.wired.com/story/google-deepmind-ai-agent-learned-to-play-goat-simulator-3/](https://www.wired.com/story/google-deepmind-ai-agent-learned-to-play-goat-simulator-3/)",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 12,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bmniwr/google_deepminds_latest_ai_agent_learned_to_play/",
            "comments": [
                {
                    "body": "the devolution of AI has begun\n\nthe great dumbing down"
                },
                {
                    "body": "Old news."
                },
                {
                    "body": "You understand nothing about AI if you think this is dumbing down."
                },
                {
                    "body": "This article is even two weeks old."
                },
                {
                    "body": "It's a joke, dude."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "An open-source alternative to Sora for video-generation via multi agent framework",
            "body": "",
            "upvote_ratio": 0.84,
            "subreddit": "singularity",
            "num_comments": 6,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://github.com/lichao-sun/Mora/tree/main",
            "comments": [
                {
                    "body": "This is not anything close to an \"open-source alternative to Sora for video-generation\"\n\nit's the same thing we've seen for a while now, frame manipulation."
                },
                {
                    "body": "It‚Äôs good that it‚Äôs open source but it‚Äôs definitely not comparable to Sora or a Sora alternative. Still struggles with movement and stability like all other models."
                },
                {
                    "body": "This is worse than SDV bro üò≠"
                },
                {
                    "body": "Some (most?) of those results look worse than what I can get already with SD + AnimateDiff with a good motion model. I'm assuming it's doing something similar underneath, using a network trained on motion vectors to move pixels/latent-space frame-to-frame before regenerating with SD/DallE/etc."
                },
                {
                    "body": "Promising"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Generative artificial intelligence model can easily design billions of novel antibiotics",
            "body": "https://www.news-medical.net/news/20240322/Generative-artificial-intelligence-model-can-easily-design-billions-of-novel-antibiotics.aspx",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 6,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1blnseb/generative_artificial_intelligence_model_can/",
            "comments": [
                {
                    "body": "You forgot the part where they filtered out molecules that were toxic to humans and got down from millions to just six. And they don‚Äôt actually know if any of those six really work or are safe. Very cool result but don‚Äôt resort to hyperbole."
                },
                {
                    "body": "Does that mean antibiotic crisis is called off?"
                },
                {
                    "body": "Decades ago any sample of dirt from a jungle somewhere might be tested and lead to novel antibiotics. But the trick is finding them to be safe and effective against some important pathogen."
                },
                {
                    "body": "Nice"
                },
                {
                    "body": "Technically it‚Äôs just a study for now tho. So I‚Äôd hold off on getting too comfortable until this becomes something actually implemented in real world situations."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation code and model has been released",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://v.redd.it/cj8vuv451xpc1",
            "comments": [
                {
                    "body": "would this work with ponyXL?"
                },
                {
                    "body": "What does this do?"
                },
                {
                    "body": "Github Link: https://github.com/williamyang1991/fresco?tab=readme-ov-file#1-inference\n\n\nProject page: https://www.mmlab-ntu.com/project/fresco/\n\n\nPaper link: https://arxiv.org/abs/2403.12962\n\n\nSupplementary Video: https://youtu.be/jLnGx5H-wLw\n\n\nInput Data and Video Results: https://drive.google.com/file/d/12BFx3hp8_jp9m0EmKpw-cus2SABPQx2Q/view?usp=sharing"
                },
                {
                    "body": "SO march is going to be every day a new tech?"
                },
                {
                    "body": "Consistency methods improving all the time."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "How to make this type of motion in stable diffusion?",
            "body": "Is it possible to make this type of motion to a picture in stable diffusion? The motion in this video is done by AI called \"Leiapix\". But that AI is paid. So i was wondering that of stable diffusion can do it. If it can tell how to do.",
            "upvote_ratio": 0.89,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Question - Help",
            "has_media": true,
            "url": "https://v.redd.it/um2sjsozqppc1",
            "comments": [
                {
                    "body": "This may help   \n\n\n[https://www.reddit.com/r/StableDiffusion/comments/yo87qz/make\\_your\\_images\\_come\\_alive\\_in\\_3d\\_with\\_depthmap/](https://www.reddit.com/r/StableDiffusion/comments/yo87qz/make_your_images_come_alive_in_3d_with_depthmap/)"
                },
                {
                    "body": "Thanks. This is what i have been looking for"
                },
                {
                    "body": "Any local app to do the same?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "New Model: Aetherverse Lightning XL - Great Multi-Concept Model",
            "body": "Download here: [https://civitai.com/models/356219/aetherverse-lightning](https://civitai.com/models/356219/aetherverse-lightning)\n\nBringing the great dynamic range and color balance from Aetherverse XL into a 8 step Lightning model. Thanks to RunDiffusion for sponsoring! Also big thanks to Masslevel and Blink for the images showcasing the model!\n\nhttps://preview.redd.it/makicxbko3pc1.png?width=1280&format=png&auto=webp&s=37295803c148a3ff7ad86341632dcfa739648976\n\nhttps://preview.redd.it/leuvyylco3pc1.png?width=1280&format=png&auto=webp&s=e954126e5c76b17852c3c6c3c6bc0a825cbfdffc\n\nhttps://preview.redd.it/ms90hcleo3pc1.png?width=1280&format=png&auto=webp&s=80c95ac40635d27aabbc930bc958071206799780\n\nhttps://preview.redd.it/hocdwzjho3pc1.png?width=1280&format=png&auto=webp&s=1c47e272abc037bc569fd2b05b49369ff298fe4d\n\nhttps://preview.redd.it/agbo90kho3pc1.png?width=1280&format=png&auto=webp&s=ae42d5e3cd4eed13afd3d055317ace1b0bb97e6d\n\nhttps://preview.redd.it/14en00kho3pc1.png?width=1024&format=png&auto=webp&s=7ac2cab6276e29daa4370ac7590aa93953314652\n\nhttps://preview.redd.it/fuuokzjho3pc1.png?width=1280&format=png&auto=webp&s=1e66b60bc1bd9ef1cdca05823440675245a7fb9a\n\nhttps://preview.redd.it/cx3jj2kho3pc1.png?width=1920&format=png&auto=webp&s=4c5772cd0b7e03513c862f648540d7e389e7cfd6\n\nhttps://preview.redd.it/pq3n30kho3pc1.png?width=1280&format=png&auto=webp&s=438a7c72ab0f31aac5229dc66630951b4e2bcb09\n\nhttps://preview.redd.it/3wvpdy1mo3pc1.png?width=1280&format=png&auto=webp&s=2622197d2473d93621e22f78f84b3d9c70c47eea\n\nhttps://preview.redd.it/0xck6xcno3pc1.png?width=1280&format=png&auto=webp&s=572cac462f391496f00063c30b3045ed3efde621\n\nhttps://preview.redd.it/imv6z46po3pc1.png?width=1280&format=png&auto=webp&s=f7db707232084491b64ca0f2f118209865af99c9\n\nhttps://preview.redd.it/9dkr1tkpo3pc1.png?width=1280&format=png&auto=webp&s=03dc0713a4c0b726cb6b4eef7b72862036b262fb",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 13,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bhroju/new_model_aetherverse_lightning_xl_great/",
            "comments": [
                {
                    "body": "The clarity and fidelity of this model is really next level. I had a chance to work with AVL-XL the last few days and it's awesome!\n\nprompt:  \n`dark and gritty manga fantasy style still in the style of Hiromu Arakawa, fullbody portrait of a surprised genie in a dynamic pose during an epic battle scene centaur's citadel at twilight, the image is lit by dramatic lighting and subsurface scattering as found in high quality 3D rendering`\n\nhttps://preview.redd.it/hgqhss6hu3pc1.png?width=1280&format=png&auto=webp&s=dc696709993676b2a1b40e6bdb54612235c22a92"
                },
                {
                    "body": "Many thanks, Awesome model...\n\n&#x200B;\n\nhttps://preview.redd.it/le2tvpzip4pc1.png?width=2592&format=png&auto=webp&s=aceddb278c8252af73b8b168482936a99d975078"
                },
                {
                    "body": "https://preview.redd.it/u18o0bw5x3pc1.png?width=1120&format=png&auto=webp&s=0150e2464755310381cad79cbacebb374ed29b15\n\nAs usual, you delivered a great model! thanks!"
                },
                {
                    "body": "the model works so well with Unleash the Beast lora :)\n\nhttps://preview.redd.it/ucvoctfd28pc1.png?width=960&format=png&auto=webp&s=55aca6e0d0f8909f20b74bfc5a83443b5625e773"
                },
                {
                    "body": "Beautiful work! Looks like a great collection of realism focused concepts with enough additional fantasy elements to make it stand out from models of similar caliber in this niche."
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "The Harsh Truth About AI Job Disruption (And Why We Need a Mindset Shift)",
            "body": "My intention is not to offend anyone.\n\nWe need to get over this us vs. them mentality of just looking out for ourselves and our tribe. The whole 'I got mine, screw everyone else' attitude is holding us back. AI has mind-blowing potential to revolutionize government, the economy, society - basically everything. I'm with Altman and others who think in a few years, we'll look back at how we're living now and realize it was actually pretty shitty compared to what's coming. I also agree that \"intelligence\" might just be \"a fundamental part of matter itself.\"\n\nThe 'end of history' idea from the 90s was way off base. History didn't end, we're just getting started. AI is going to kickstart a new era of progress unlike anything we've ever seen before. Rather than squabbling over slices of the existing pie, we should collectively strive to unlock an abundance that renders such scarcity thinking obsolete.\n\nI see way too many Redditors living in lala-land when it comes to AI taking jobs. Y'all need a reality check on how this is gonna play out.\n\nFirst off, no one is safe - not even the big dogs like doctors, programmers or Hollywood hotshots. You might think \"Oh, but my job is too skilled and specialized for AI to replace!\" Sorry to burst that smug little bubble, but you're dead wrong.\n\nHere's the ugly truth: When there's a chance to get a competitive edge through AI, you can bet your diamond-encrusted booty that corporations and schemers will take it. Profit motives and arbitrage opportunities tend to override any sense of loyalty to human workers. It's just human nature to capitalize on advantages.\n\nDon't think those fancy professional licenses, unions and credentialing B.S. will protect you either. We've seen that dog and pony show before - just look at how American doctors have been gaming the system with their shady medical equipment import rackets from the third world, and their diagnostic center side hustles etc.\n\nHollywood? Artists will sell each other out too. People romanticize the arts with flowery rhetoric about creatives being the conscience of society and all that. But the truth? Hollywood, the music world, the fashion industry - these are some of the most ruthlessly exploitative, rent-seeking rackets in existence. Ask any working creative and they'll tell you horror stories about the disgusting ways intellectual property gets stolen, ideas get ripped off, and talent gets chewed up and discarded like trash. So don't buy into the starry-eyed delusion that the arts are some sacred trust. It's an all-you-can-eat buffet for the most rapacious of rent-seekers right now with the rise of Netflix, Spotify and other tech disruptors. AI will be the next brutal wave to crash over creatives\n\nYour  own disgruntled co-workers and friends may sell you out to an AI solution if given a chance to make an extra buck. Remember those Amazon re-seller hustlers? That's just the beginning of the Lord of the Flies chaos that AI will unleash on every industry.\n\nWhat about global outsourcing using AI tools and remote workers?. You think your six-figure job is irreplaceable? There are starving millions willing to do it for peanuts if paired with the right AI.\n\nThe cold reality is that no amount of \"You don't understand how vital my role is!\" protesting will be able to stop the AI job disruption wave. Professionals always think they're insulated and special...until their skills become redundant thanks to new tech and human nature's tendency towards maximizing self-interest.\n\nIf you cling to some naive notion of being AI disruption-proof, you're just burying your head deeper in the sand. Buckle up, because massively disruptive times are coming for virtually every career field thanks to AI capabilities. Don't say you weren't warned! Start preparing.",
            "upvote_ratio": 0.77,
            "subreddit": "singularity",
            "num_comments": 66,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bn0cmc/the_harsh_truth_about_ai_job_disruption_and_why/",
            "comments": [
                {
                    "body": "Assuming you are correct, wut do?"
                },
                {
                    "body": "\".. AI will be the next brutal wave to crash over creatives ..\"\n\nWhat do you mean \"will be\"? :D\n\nIt's been happening for over a year now.. Did you miss the actors & writers strikes? When Hollywood literally wanted to pay jobbing actors just 1 DAY of pay for the licence to use their voice & image as AI FOREVER!? ..\n\nNot even mentioning when companies trained their AIs on \\*all the images on the internet\\* without getting permission or paying a red cent in royalties, leading to the whole AI art wars..\n\nAnd that voice actors can now have their voices stolen by AI using just 30secs to 1min of recording.. And yeah, no-one's safe - they even ripped off Stephen Fry's voice for fake audiobooks, ffs"
                },
                {
                    "body": "I think you're on the wrong sub. No one here thinks this stuff."
                },
                {
                    "body": "I don't think a lot of people here dismiss potential job disruption. It is just a matter of when and how fast."
                },
                {
                    "body": "I think we need to collectively start holding  politicians accountable and start demanding answers and transparency. \n\nIt's one thing if this is happening, and it's happening quick- but it's another if the people who CAN help us navigate it and DO have the ability to impact and make change- are sitting on their hands or turning a blind eye. \n\nHow do we collectively organize to get people to start talking about and laying out a REAL plan for UBI (or SOMETHING) on Capitol Hill, and beyond that-  globally?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Color Silhouette in Ancient City",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/2dn9y9pzq1qc1.png",
            "comments": [
                {
                    "body": "Mind sharing workflow?"
                },
                {
                    "body": "Yes as u/boopm4n was already saying. I started from there [https://civitai.com/images/4140782](https://civitai.com/images/4140782)"
                },
                {
                    "body": "most likely you start here:  \n[https://civitai.com/images/4140782](https://civitai.com/images/4140782)  \nthen cherry pick or refine the long prompt"
                },
                {
                    "body": "and just for fun, using the same prompt from above but with DreamShaperXL Lightning instead [https://civitai.com/models/112902?modelVersionId=354657](https://civitai.com/models/112902?modelVersionId=354657)  \n\n\nhttps://preview.redd.it/1tcbe4ocb6qc1.png?width=1024&format=png&auto=webp&s=b26f349c1a3a28cd8bfa0e1568109dd8544bb6ce"
                },
                {
                    "body": "Wow this is amazing \\*\\_\\*"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Big Bird? (Model is Xi)",
            "body": "",
            "upvote_ratio": 0.83,
            "subreddit": "StableDiffusion",
            "num_comments": 14,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bk9qay",
            "comments": [
                {
                    "body": "All I see is a missed opportunity to use Dee Reynolds."
                },
                {
                    "body": "This a niche fetish"
                },
                {
                    "body": "[\"I'm a chicken lady.\" ](https://youtu.be/oDYnFy4rCJY?si=xJXvL3ErQhgtYOMI)"
                },
                {
                    "body": "Can you tell me how to get, how to get to Sexy Lady Street."
                },
                {
                    "body": "Now do Grouch!"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Dive Deeper into Yi-9B [technical post]",
            "body": "Super nice and detailed post about how Yi 9B was created (the merging approach) [https://huggingface.co/blog/lorinma/yi-9b-divedeep](https://huggingface.co/blog/lorinma/yi-9b-divedeep)\n\nIt includes a comparison of two different depth expansion approaches -- the one used by the released Yi 9B and the Solar one.",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 8,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bhwqbb/dive_deeper_into_yi9b_technical_post/",
            "comments": [
                {
                    "body": "The bit about \"[calculating] the cosine similarity of token embeddings through different layers\" to identify when a layer is \"filled\" (to vastly simplify partially incorrectly) is intriguing. Would love to use that as a basis on identifying layers to duplicate for frankenmerges. Anyone know how they're getting that information? I'm sure I'm just ignorant and it's something straightforward."
                },
                {
                    "body": "Unfortunately doesn't seem to be particularly good at producing summaries - which is the prime use case I had in mind for a small model with big context\n\nbtw context per gguf is higher, not sure why: 'llama.context_length': '262144'"
                },
                {
                    "body": "Interesting, but is it better than mistral and gamma ..."
                },
                {
                    "body": "English data graphs so bumpy."
                },
                {
                    "body": "Same thought I had after reading that part. Very interesting."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "The robot invasion has already started",
            "body": "",
            "upvote_ratio": 0.75,
            "subreddit": "singularity",
            "num_comments": 32,
            "submission_flair": "shitpost",
            "has_media": true,
            "url": "https://i.redd.it/cxomvyt6ucqc1.jpeg",
            "comments": [
                {
                    "body": "Lmao I was the one who copied his comment, just as a jab to the copyright point"
                },
                {
                    "body": "Dead internet theory let‚Äôs go"
                },
                {
                    "body": "I can understand the perspective of creators, but I mean, if a human paints a new painting in the style of another painter, that's 100% legal. All art is ultimately inspired by one or more existing styles and influences that are combined or mimicked to create something new. You can't copyright style or artistic ideas - only expression (individual paintings/songs/etc). At least, in the case of US law.\n\nAll generative AI is doing is using the computer to do exactly that.\n\nI get that it can *feel* different when it's a computer doing it instead of another human, but the actual process is the same thing. Ultimately what it boils down to is that the same thing people have been doing that required great talent is now just being made accessible to people without any creative talent (like me lol).\n\nI'm a coder, and AI is doing exactly the same thing in that sector. I'm not upset about the fact that someone can now use AI to generate some code, when I've put in years to learn multiple languages and spent untold thousands of hours coding to learn how to do so through hard work and repetition."
                },
                {
                    "body": "Based"
                },
                {
                    "body": "I opposed copyright long before the LLM era. My stance has not changed."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "New user beginning guide: from total noob to well-informed user, part 3/3",
            "body": "**# Fine-tuning**\n\nShould I use a particular framework? Let‚Äôs say I fine-tune my model over different use-cases. How do I swap the weights for these different models efficiently?\n\n**Warning**: Fine-tuning is the last section on purpose. If this is the first thing you are considering, you are probably doing something wrong. Fine-tuning is the last thing to consider, not the first. Once you learn enough, you may find out you don‚Äôt need it. And if you do need it, you may find practical constraints that make it not worth it. Or perhaps you do need it, you are very persistent, and you are willing to pay the price. Great, let‚Äôs do it!\n\nLet‚Äôs go back to the JPG example. Yes, you need software that allows you to edit (fine-tune) LLM, just like you need ‚Äúspecial‚Äù software to edit JPG, PDF, DOC. Probably the easiest options are text-generation-webui, Axolotl, and Unsloth. You can fine-tune quantized models (QLoRA), but as far as I know, it can be done only on GPU. See their website for a description of which model, training, quant types they support. And you can find plenty of step-by-step guides/tutorials on the web (see ‚ÄúNext steps‚Äù).\n\nAs far as swapping weights, well, you can just open and edit a new JPG when you are done with the previous one, no? The same applies here. There is no fundamental problem of loading multiple LLMs at once and interacting with each of them as needed (just like you can open multiple JPG at once and interact with them as needed). But since LLMs take up so much memory, loading two is 2x memory. That‚Äôs how Mixtral-8x7B model works, it loads 2 (or 3?) 7B models and use them together at the same time. Do you have enough RAM/VRAM? Go for it!\n\nNow back to fine-tuning. A basic concept that I didn't understand at the beginning is that fine-tuning is **not** for adding knowledge. If it were, all models could be fine-tuned on Wikipedia, and we would have a custom, instant, and accurate (assuming Wikipedia is accurate) encyclopedia in our pocket. It would answer a specific/narrow question of interest instead of showing a long and boring Wikipedia article on a long and boring topic. Life would be great! But did you know even the best of the best (GPT-4) makes factual errors that are correct on Wikipedia? Why? Surely, OpenAI could (and did) train on Wikipedia. This should tell you something.\n\nSo, the most important thing to understand is that fine-tuning is for adding ‚Äúskills‚Äù, not ‚Äúknowledge‚Äù. For example, question answering, summarization, translation, conversation, code completion, fillin-mask, sentence/semantic similarity, I‚Äôm sure there is more. And once the LLM is big enough, it also gets ‚Äúemergent‚Äù abilities (debatable, but it makes us feel supersmart, so let‚Äôs just go with it). So first you need to know what ‚Äúskill‚Äù you want to add. Otherwise, you are probably not improving anything, and very likely making the existing abilities worse (there are plenty of posts on that). Maybe others can say more what ‚Äúskills‚Äù are interesting and useful to add for different use cases?\n\nNow back to the issue of why fine-tuning is the last thing to do, and best to avoid, unless absolutely necessary. The first problem is that hardware requirements increase beyond the typical ‚Äúhome computer‚Äù. Just to remind you of the scale of the problem, recall training a new model from scratch, see ‚ÄúCreating Parameters‚Äù section on the blog I linked to earlier.\n\nFine-tuning is effectively the same, but with a much smaller data set, targeted at specific ‚Äúskill‚Äù rather than \"ingesting raw text\". And perhaps you don‚Äôt need to adjust all the weights, but just some of them, which makes it computationally easier. That‚Äôs where LoRA comes into play.\n\nYou can also fine-tune some quantized models (QLoRA), but as far as I know, it is GPU only (please correct me if I‚Äôm wrong). The solution to this problem is easy in the sense that you can just buy more/better GPU. But the general advice is that it is much cheaper and more efficient to rent a GPU from an AI cloud provider, there are other posts here on how to do that and what are good practical options.\n\nThe second problem relates to the data requirement, how training and fine-tuning works. What you need is a pair of text ‚Äúprompt‚Äù and ‚Äúcompletion‚Äù, where ‚Äúcompletion‚Äù is a natural continuation of the ‚Äúprompt‚Äù. At first, it seems like an easy problem, just search the web, you‚Äôll find TBs of training data, all you need is fast internet and plenty of HDD space! But think about it, if there is a good publicly availability training data set, wouldn‚Äôt others already use it? They did. So, even though there are plenty of public data sets on the web, what‚Äôs the point of re-training on the same data? Maybe you think, well, I'll just train anyway, it can't hurt, it is just like reading the same book 10x. But that's wrong. Training too much on the same data will ‚Äúoverfit‚Äù (or ‚Äúovertrain‚Äù) your model, which will make it worse!\n\nYou can (and should!) use public training data to learn how to do it, what are different options, what results/improvement you can get. But to do something really useful, you need to curate your own prompt/completion data set. At this point, the time requirements increase to weeks-months to curate your own data yourself. But let‚Äôs stay you did create it (there are fast and easy ways to create a poor-quality set) and trained on it. If you are happy with the results, good for you, you are done.\n\nBut, to get the best performance, you need to fine-tune with human evaluation: you ask your new LLM to generate a few answers/completions to the same prompt, and a human (you?) picks the best answer/completion. Repeat thousands of times. Oh, you would rather not do that yourself? OK, no problem, hire 10 local college students to do it for you. That's what big companies do, except instead of local high schools, they use workers in low-wage countries. Or you get clever and come up with an automated way: create another LLM that can judge responses of your new LLM, picks the best one and feeds it back to your new LLM. But then you need a ‚Äújudge LLM‚Äù which has to be much better than your new LLM. Can you run full size 70B model locally? Good, do that, but then perhaps you don't need that new LLM?\n\nThen, you need to evaluate if your new LLM really is better. So, you need another set of prompts/completions as a benchmark to measure ‚Äúimprovement‚Äù. The public benchmarks used for ranking (like HuggingFace Leaderboard) are not useful here (see ‚ÄúModel selection‚Äù section), you need your own benchmark that you keep private. Perhaps you use a part of your curated prompt/completion data set that you didn't use for training. Perhaps you create a new set. Either way, improvement measurement is a critical part that too many misses or ignore.\n\nIf you still haven't given up, congratulations, you are the top 1%! Now you really have to go back to parts I marked (A), (B), (C), (D) and work to understand the rest. Search the web (see ‚ÄúNext steps‚Äù section), there are plenty of tutorials that show step-by-step instructions for different use cases. But first, you need to understand what you want your ‚Äúfine-tuning‚Äù for, and then look for a method and software (and hardware!) that does that, not the other way around.\n\n**# Next steps**\n\nThere is plenty more. The problem is that a web search on any of these topics will return 1000s of articles, you‚Äôll end up with info overload, or conflicting info, or the same info, but described differently, or you become paralyzed by looking for the ‚Äúbest‚Äù.\n\nIf you lack technical skills (from ‚ÄúLLM loader overload‚Äù and everything later), here is how to get started. First, get Anaconda and learn how to create conda environments with specific Python version, how to load/unload environment, and how to work within these environments. My recommendation is to **not** work with your OS native Python (e.g., not to use ‚Äúpython -m venv env\\_name‚Äù) but rather with a separate Python installation (e.g., Anaconda) and its environment (e.g., \"conda create -n env\\_name\"). Both ways are perfectly fine, but my recommendation is to not touch OS native Python at all.\n\nThen, learn how to clone git repository, then how to set up necessary dependencies (should be part of repo instructions), then how to compile yourself (should be part of repo instructions). Then continue with whatever it is you want to do.\n\nDon‚Äôt give up. To avoid info overload, here is the order of reading and learning I recommend:\n\n1. Go back to (A), (B), (C), (D), fill in the specific gaps in your understanding. You‚Äôll probably find that as you learn more, more of this becomes ‚Äúeasy‚Äù and ‚Äúobvious‚Äù.\n\n2. Next, search for other relevant posts on /r/LocalLLaMA/, use the flair system, it is here to help.\n\n3. Next, search Medium and related property (they own or affiliate with a ton of other websites!). It has a lot of general info and ready-to-use tutorials, but the quality varies (and a lot of low-effort LLM-generated posts). Watch out for info overload!\n\n4. Then, search GitHub Awesome lists for specific topics and your needs. At this point, expect info overload, unless you know specifically what you need.\n\n5. Finally, as the last resort, go to open web, it is definitely info overload!\n\nFinally, my advice is that looking for the ‚Äúbest‚Äù is a failing strategy. FreeBSD and Photoshop are the best, why are you not using them? First, understand what you really want to do, what you want to accomplish. Then look for the tool/method/software that does that. That is the best tool/method/software for you, not for me.\n\n**# Closing perspective**\n\nI'm disappointed with posts that can be summarized as ‚ÄúI don't know anything about this, but I had this brilliant idea about AGI + fine-tune on all my data + Wikipedia which will be my own personal genius, I haven't bothered to do any homework myself because it is too boring and too difficult for me, so just tell me step-by-step instructions that will work on my computer. Oh, and make it the best. Otherwise, it is not good enough for me‚Äù.\n\nConsider a bit of humility and perspective. LLMs are barely out of the best NLP research labs with post-PhD level brains (I mean humans), so +10 years of the best university education in the world. These are incredibly difficult and advanced topics that others spent years learning and developing. And they made it easy enough for us (relatively competent person without formal CS or NLP education) to self-learn and use for a real benefit to us.\n\nIf you want things to be as easy as JPG and PDF on your computer, if you want an automatic fully integrated solution, just go with Windows 11 and MS Copilot. MS integrated it into the OS, and it works seamlessly just like JPG and PDF. You'll have an AI assistant that's one of the best in the world, which will scan/index all your data, and work seamlessly just like other good software on your computer. There is no problem or shame in that. I use ChatGPT and Copilot, and I'm mostly impressed. The weaknesses are obvious enough that it will improve, just like all other software/hardware improved over the years. Think about your favorite software 5, 10, 20 years ago and what it did (or didn't do), and how it got better (or worse) over the years. The progress in 10‚Äì20 years is just spectacular!\n\nOr, if you want high (not complete, but high) control over the workflow and data, and you keep insisting on the ‚Äúbest‚Äù it is OpenAI, Anthropic, Microsoft, Google. They all have a ‚Äúcookbook‚Äù with ready-to-use Python examples for all typical use cases. Just search \"OpenAI cookbook\".\n\nIt will cost you pennies or a few dollars to run, and you‚Äôll get one of the best embeddings, one of the best LLM, one of the best RAG (chunking/embedding/vector DB), one of the best fine-tuning, all tools-software-hardware maintained for you, integrated hosting, and much faster than you can do at home. If you want the ‚Äúbest‚Äù, do that.\n\nGood luck, fellow explorers!",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 9,
            "submission_flair": "Tutorial | Guide",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmu64x/new_user_beginning_guide_from_total_noob_to/",
            "comments": [
                {
                    "body": "Thanks for the in-dpeth, high quality post.  One thing you might want to revise is the idea that fine tuning can only add skills to a model.\n\n* We can fine tune (instruction tune) a model to follow various instructions.  For example a writing prompt+examples dataset could be used to teach a model to write first person interior thought, dialogue between characters, describe exterior scenes, etc.  \n* We can also fine tune a model to gain domain knowledge.  So for example fine tuning a model on US Army doctrine, strategies, and technical pubs can teach the model new semantic patterns as well as domain specific concepts.  So for example the word \"fires\" moving away from smoke/wood/forest to direct/indirect/synchronized, etc.  Or learning the relationship between fires and maneuver, and how mission command leverages that relationship. If we want accurate factual knowledge (not conceptual knowledge) we can then connect this more knowledgeable model to RAG, knowledge graphs, etc."
                },
                {
                    "body": "Can it be that part 1/3 is not available?"
                },
                {
                    "body": "You could try making a [Rentry](https://rentry.org/) page. It's not pretty to split into three reddit posts."
                },
                {
                    "body": "Would you consider writing a post on quantization? Like how to do it, what hardware is required and what pitfalls there are/what needs to be tweaked when doing it?"
                },
                {
                    "body": "OK, good point, thank you for clarifying!"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "I wrote a little script for Ultima Online that monitors the txt file in the JournalLogs, and then generate responses using LM Studio's local inference server. Here's the demo using Qwen 0.5B gguf model (yes tiny and dumb)",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 14,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://files.catbox.moe/unfxto.mp4",
            "comments": [
                {
                    "body": "\"vendor buy bank guards\" \n\nLLM won't know what hit them"
                },
                {
                    "body": "God that's really cool. I started playing UO like ... god 25 years ago at least maybe more.\n\nI would have killed for something like this back then when people actually roleplayed. Your stirring up memories for me.\n\nYou could always reach out to the private servers and see if anyone would be interested in implementing something like this. I know there's still quite a few going strong.\n\nNow I know nothing about scripting, at least in this context. But I do understand you telling it to read the JournalLogs then input that as text above the NPC.\n\nHow did you hook it into the UO client to get it to display in game (even client side). Is it this easy to do with most games?"
                },
                {
                    "body": "I admit I don't have the chops to write it so it can get the data from the client. But imagine if something like this was implemented on the server side. You can talk to NPCs and even have agents.\n\nImagine going to a mage shop and asks how many blood moss they have in stock and the NPC will check and give a response and you say \"I'll take all of them\", they give you the price and you confirm the purchase. No gump for the transaction.\n\nThe immersion Lisa! Immersion!\n\n[pastebin of script](https://pastebin.com/diAqCi69)"
                },
                {
                    "body": "I dig it, not only will LLM have an effect on the future of game development, but will also bring new possibilities to previous decades of games!"
                },
                {
                    "body": "Very cool. Not sure what LLM you're using but I would recommend going with gpt4turbo if you want it to not stray from the script. I've found it to be the best for following instructions for things like this.\n\nWould also suggest including in the system prompt something along the lines of 'your output is for a game engine so play along with the dialogue' or similar. Should help with stoppibg it responding with 'i'm sorry...'"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "[R] Evolving New Foundation Models: Unleashing the Power of Automating Model Development",
            "body": "New paper is out from Sakana AI.\n\nBlog post: https://sakana.ai/evolutionary-model-merge/\n\nPaper: Evolutionary Optimization of Model Merging Recipes\n\nhttps://arxiv.org/abs/2403.13187",
            "upvote_ratio": 0.97,
            "subreddit": "MachineLearning",
            "num_comments": 7,
            "submission_flair": "Research",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bjuddy/r_evolving_new_foundation_models_unleashing_the/",
            "comments": [
                {
                    "body": "> As researchers, we are surprised that our method is able to automatically produce new foundation models without the need for any gradient-based training, thus requiring relatively little compute resources. In principle, we can employ gradient-based backpropagation to further improve performance, but the point of this release is to show that even without backprop, we can still evolve state-of-the-art foundation models, challenging the current paradigm of costly model development. \n \nThat's super interesting. Perhaps this will shake things up for the GPU havenots."
                },
                {
                    "body": "To paraphrase the Mythbusters, the difference between science and flongo-mega-merge-anteater-salamander-bobsyouruncle-420B-69LASER-dpo is keeping logs, making nice visualisations and running lots of benchmarks :)"
                },
                {
                    "body": "Don't get me wrong it's a cool way to merge models, but it's not as revolutionary as they make it out to be. Also the parallel with human evolution is farfetch to say the least."
                },
                {
                    "body": "This blog post was amazingly well-written and super clear. Thank you for sharing. I was previously unaware of the whole world of model merging, but I think I have an inkling, now, as to the ways progress might occur here.   \n\n\nIn their paper, they also talk about various kinds of parameter interference being one of the reason why naive weight merging might not work super well in the case of LLM model merges. I wonder how this behavior changes with increasingly quantized models? Are new ternary quant models, for example, more or less susceptible to this issue?"
                },
                {
                    "body": "And it's much easier to parallelize, as it is with any GA. The issue is it will converge much slower than backprop, this kinda works for this example as you have two \"specimens\" generated by backprop but I guess those two can be merged into a single mixed optimum search."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Gemini 1.5 Cumulative Average NLL for code as number of token approach 10 million tokens. This was tweeted by Google Deepmind researcher. ",
            "body": "LINK TO TWEET: https://x.com/xiao_ted/status/1761865996716114412?s=46\n\nTEXT OF TWEET:\n\n‚ÄúI can‚Äôt emphasize enough how mind-blowing extremely long token context windows are. For both AI researchers and practitioners, massive context windows will have transformative long-term impact, beyond one or two flashy news cycles. ‚ÜîÔ∏è\n\n‚ÄúMore is different‚Äù: Just as we saw emergent capabilities when scaling model size, compute, and datasets, I think we‚Äôre going to see a similar revolution for in-context learning. The capability shifts we‚Äôll see going from 8k to 32k to 128k to 10M (!!) token contexts and beyond are not just going to be simple X% quantitative improvements, but instead qualitative phase shifts which unlock new abilities altogether and result in rethinking how we approach foundation model reasoning.\n\nGreat fundamental research on the relationship between in-context learning (ICL) and in-weight learning is now more relevant than ever, and needs to be extended given that we now operate in an era where the \"X-axis\" of context length has increased by three orders of magnitude. I highly recommend \n@scychan_brains\n's  pioneering work in this area, such as https://arxiv.org/pdf/2205.05055.pdf and https://arxiv.org/pdf/2210.05675.pdf. In fact, there are already data points which suggest our understanding of ICL scaling laws still contains large gapsü§î(see https://twitter.com/SavinovNikolay/status/1761768285312315766) \n\nAlso exciting is the connection of long-context ICL to alignment and post-training! I'm curious to see how 10M+ contexts disrupt the ongoing debate about whether foundation models truly learn new capabilities and skills during finetuning/RLHF or whether they purely learn stylistic knowledge (the \"Superficial Alignment Hypothesis\", https://arxiv.org/pdf/2305.11206.pdf and https://allenai.github.io/re-align/). The Gemini 1.5 technical report brings new evidence to this discussion as well, showing that an entire new language can be learned completely in context. I'm excited to see better empirical understanding of how foundation models can effectively leverage large-context ICL both during inference but also for \"learning to learn\" during training \n\nAnd finally, perhaps the most important point: huge context lengths will have a lasting impact because their applications are so broad. There is no part of modern foundation model research that is not changed profoundly in some capacity by huge contexts! From theoretical underpinnings (how we design pre-training and post-training objectives) to system design (how we scale up long-contexts during training and serving) to application domains (such as robotics), massive context ICL is going to have significant impact and move the needle across the board.\"",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 8,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://i.redd.it/778wtg51l7qc1.jpeg",
            "comments": [
                {
                    "body": "This is one of the issues with the whole terminology of \"AGI\" and \"ASI\", especially with how imprecise and inconsistent people are with those words. GPT 3 and definitely GPT 4 have clearly been general purpose in many ways. And GPT-4 has been superhuman in terms of breadth of knowledge (for example). This enormous context is another dimension where new LLMs are absolutely at a super-human level of intelligence already. I hope people will start being more precise about what they are talking about when they use terms like AGI. For starters, differentiate between AGI and ASI. Maybe try to make a distinction between something that is actually fairly general purpose and a hypothetical system that is conscious and feels pain. Because all of these various capabilities and characteristics are not linked to some magical omnipotent all-encompassing \"intelligent life bean\" that is going to surprisingly \"emerge\" one day and instantly destroy us or solve all of our problems. There are a lot of different aspects to this."
                },
                {
                    "body": "It seems like, ideally, LLM pretraining would focus entirely on ICL, and any knowledge about the world the LLM would have would be provided directly into its context window. But this would require a lot of information to go into the context window for the LLM to be as useful as current SOTA LLMs (probably over 100b tokens). And I'm not entirely sure what the data for ICL pretraining would look like, but it could probably be entirely synthetic. Also, I don't think anyone has done much meaningful research regarding scaling laws for context windows and ICL - at least for 1m+ ctx with a ~SOTA model (there are 7b models with 1m ctx but they aren't great).\n\nIf whatever Google Deepmind did to get 10m token context windows scales to 1b tokens or more, or state space models like Mamba can scale to 1b+ ctx, then I could see a future where a lot of compute is spent on the context window preprocessing. Likely, state space models will take over in such a future. Then RAG might really be dead. Or at least get pushed back solely to areas where retrieving over a database the size of the entire internet is desired.\n\nNow, possibly, preprocessing the ctx would not be nearly as paralleizable as current LLM training is. AKA, *it would not scale* (or at least not as well) and things that scale better seem to just work better. However, while I don't know *that* much about ctx preprocessing, I do know that llamacpp prompt processing scales with more CPU cores and that GPU prompt processing is much faster - likely because GPUs have way more cores. But I don't know how prompt processing scales across hundreds of GPUs (or if that has even been tried much at all, though maybe OpenAI or Microsoft or Google knows)."
                },
                {
                    "body": "What is NLL?"
                },
                {
                    "body": "In my opinion, the faster we get rid of this generic definitions, the better. AGI and ASI terms were born in an early phase of AI research and they reflect the naivety of that period"
                },
                {
                    "body": ">GPT-4 has been superhuman in terms of breadth of knowledge (for example). This enormous context is another dimension where new LLMs are absolutely at a super-human level of intelligence already.\n\namen, idk why more people don't recognize this // why this isn't part of the public zeitgeist yet"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "The Singularity Is Nearer featuring Ray Kurzweil | SXSW 2024",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 18,
            "submission_flair": "video",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=xh2v5oC5Lx4",
            "comments": [
                {
                    "body": "Kurzweil will really do anything but finish that book, huh?"
                },
                {
                    "body": "Kurzadamus"
                },
                {
                    "body": "He looks really tired... It's concerning."
                },
                {
                    "body": "Does he say new things in this one?"
                },
                {
                    "body": "He seems a bit better here than he did on Joe Rogan."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "How do you get good results with low parameter models (7B,13B)?",
            "body": "Hi, I've really gotten into the local AI over the last two weeks. I have spent around 100 hours sitting in front of my computer trying to figure out how it works. \n\nMy issue is, I get waaaaay better results with models that are at least 34B. 7B or 13B just don't do it for me. My use case is role play, for other things I have more patience and I do not mind if takes a while to process a few tokens. \n\nBecause I did not design my rig with llm in mind, I have an AMD system:\n\nRyzen 9 7900x @ 5,3 Ghz\n64 GB RAM @ 6000 Mhz\nRX 6900 Xt 16 GB VRAM\n\nI am on Windows 10, Kobold cpp(rocm fork). + sillytavern\nSeemed like the most straightforward thing to do. \n\n\nThere are a whole lot of settings in silly tavern, what do you prefer for role play? \n\nMy most annoying issue is that the llm is not creative enough unless I use 70b models. \n\nI hear a lot of people say that low parameter models can be better than models with more, but everything below 34b is very boring and uncreative. \n\nOn the other hand I'm having a blast with smaug70b q3 or airoboros70b q3. I have also gotten great results with nous-capybara34b-Q5_0 and with airochronos34B Q4 K_M\n\n\nI bet I could save a lot of time, if I just got the fine tuning right for models with less parameters.\n\nDo you have some suggestions or resources for storytelling / rp?\n\nI know, there is not the ideal setting for every model and depending on the kind of story you want to tell settings will differ. \n\nAlso not sure if this is normal or if it is something I do not understand:\nAre q2 models lobotomised from heavy quantization or is there a way to handle them for better results?\n\nThank you for reading have a great day everyone!\nI bet this question gets asked every week, but I was unable to find  results that are detailed enough. ",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 34,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bm2t0h/how_do_you_get_good_results_with_low_parameter/",
            "comments": [
                {
                    "body": "Hopefully something from my collection works for you:\n\nQ5_K_M or Q6_K of...\n\n* [Personal Favorites](https://huggingface.co/collections/Lewdiculous/personal-favorites-65dcbe240e6ad245510519aa)\n\n* [Roleplay Small Model Quants](https://huggingface.co/collections/Lewdiculous/quantized-models-gguf-iq-imatrix-65d8399913d8129659604664) - Authors can use feedback.\n\nThese are meant for roleplay chatting mostly.\n\nNot sure about long form story writing like a Novel or something."
                },
                {
                    "body": "have you tried cranking up the temperature? I went through something similar; got into LLM like 3-4 months ago mostly for chat/RP using Psyfighter 13B Q6 with 16GB VRAM. at the time it seemed so fun and novel. but then on a whim I tried Miqu 70B when it came out, even getting .7t/s, and suddenly 7-13B seemed so underwhelming. boring responses, no creativity, like you said. they often struggle to grasp those simple yet complex concepts that we understand intuitively as humans. yet I couldn't really use Miqu full time either, and I hadn't had any luck with models sized in between. but then on a whim I just cranked the temp up to 2 and chatted with them for a while, and then suddenly they could do a lot of those things, a lot of the things that Miqu will do at the default temp. nowhere near as good as a larger model, but still an improvement. of course there's caveats, you will sometimes get wild and verbose stuff, but with those models getting 30t/s you can easily retry a dozen times and get something good.\n\nI actually just built a 2x p40 machine that has Miqu loaded, but will still primarily use Psyfighter 13B Q6 or Kunoichi 7B DPOv2 Q8 on my main machine, and if I get to a spot where I'm not getting good responses I just export koboldcpp TextData and run it on the other machine, then switch back."
                },
                {
                    "body": "7b models released this year are very capable. 13b is falling off."
                },
                {
                    "body": "fine tuning only"
                },
                {
                    "body": "Do you have ROCm/HIP installed so that you can get peak performance from your AMD card?\n\n\nRX 6800 and better gain a lot of performance for tools that can utilize it over OpenCL/Vulkan/OpenBLAS."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "AI scribe saves doctors an hour at the keyboard every day",
            "body": "https://www.ama-assn.org/practice-management/digital/ai-scribe-saves-doctors-hour-keyboard-every-day",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1blup5r/ai_scribe_saves_doctors_an_hour_at_the_keyboard/",
            "comments": [
                {
                    "body": "It's crazy to me how they see technological improvements in the medical field all the time, yet still see the positions of doctors and nurses as basically unchanging into the future"
                },
                {
                    "body": "These productivity increases through automation and offloading of voice based tasks will build up and eventually lead to a massive , across the board increase in medical quality. This might be what saves the western world from its upcoming and ongoing medical crises.¬†"
                },
                {
                    "body": "It doesn't make much sense for humans to study for thousands of hours to retain what especially trained LLMs can have full and much more awareness of. Diagnostics seems perfectly suited to AI replacement."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "AI scribe saves doctors an hour at the keyboard every day",
            "body": "https://www.ama-assn.org/practice-management/digital/ai-scribe-saves-doctors-hour-keyboard-every-day",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1blup5r/ai_scribe_saves_doctors_an_hour_at_the_keyboard/",
            "comments": [
                {
                    "body": "It's crazy to me how they see technological improvements in the medical field all the time, yet still see the positions of doctors and nurses as basically unchanging into the future"
                },
                {
                    "body": "These productivity increases through automation and offloading of voice based tasks will build up and eventually lead to a massive , across the board increase in medical quality. This might be what saves the western world from its upcoming and ongoing medical crises.¬†"
                },
                {
                    "body": "It doesn't make much sense for humans to study for thousands of hours to retain what especially trained LLMs can have full and much more awareness of. Diagnostics seems perfectly suited to AI replacement."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Google fined ‚Ç¨250 million by French authorities for clash with news outlets over AI training data",
            "body": "Google was fined ‚Ç¨250 million by French watchdogs after it trained Bard with data from French news publications without their consent\n\nhttps://finance.yahoo.com/news/google-fined-250-million-french-081047314.html",
            "upvote_ratio": 0.98,
            "subreddit": "ArtificialInteligence",
            "num_comments": 24,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bk10ed/google_fined_250_million_by_french_authorities/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### News Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the news article, blog, etc\n* Provide details regarding your connection with the blog / news source\n* Include a description about what the news/article is about. It will drive more people to your blog\n* Note that AI generated news content is all over the place. If you want to stand out, you need to engage the audience\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "so, google was explicitly given the ability to save the data via the site's robots.txt file, but then later said \"wait, not THAT kind of robot\" and their government used that as an excuse to extract a quarter-billion from google by just inventing a new terms of service and retroactively enforcing it. they likely chose this dollar amount because they knew they were in the wrong but if they fined google more, google would probably appeal it and/or stop operating in France. this is a small enough value that it's not worth the fight for google."
                },
                {
                    "body": "Fines are probably a full-fledged item in Google's budget and are something they totally anticipate and are FINE with."
                },
                {
                    "body": "this is so silly. they crawled a website and collected some content. the same thing that human users do. the website probably ended up in their dataset of target links as a result of an automatic program anyway lol, not a conscious human decision. (yes i understand the bandwidth issue, and i would hope that google would have their code such that it doesn't repeatedly hit the same hosts too frequently. if not, then wtf google c'mon).\n\nto zoom out a bit, here we have another example of how all the things happening with AI now are signalling that it is time for a new paradigm or something. what really is \"news\" anyway? why don't these news publishers work out some deals with google where they push updates to google at regular intervals? make the whole thing into a functioning system. \n\nalso keep in mind that news sources are among the lowest priority training data for LLMs, let alone AI in general. the more important stuff is non-fiction books, research articles, reddit discussions on good subreddits, encyclopedias, other literary classics, textbooks of all subjects, etc. Especially since most news articles are very low in substance and use asinine language."
                },
                {
                    "body": "\"One MILLION dollars!!!\" Buuhaaahahahaa"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Frames from a fictional detective movie",
            "body": "",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 8,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjaq05",
            "comments": [
                {
                    "body": "Impressive noir aesthetic. The smoke and rain are a really nice touch. \n\nShe's not gonna wanna stand out in that too long though, all dolled up as she is :)"
                },
                {
                    "body": "Of all the latent spaces in all the GPUs, she had to walk into mine."
                },
                {
                    "body": "that 2nd image is startlingly good. the technicolor on it is amazing."
                },
                {
                    "body": "Maybe try a more suited aspect ratio, that will help a lot with the composition and make it look more cinematic instantly"
                },
                {
                    "body": "Why is no one fixing the eyes?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "AI is being used for the dumbest reasons.",
            "body": "Images.... Movies...... Games.......\n\nIt seems like low hanging fruit. I fail to see how monopolizing these spaces with AI content beings any real cultural or societal benefit.\nThe reasons for this are many and varied. If you disagree with the first posit, tell me why, (the proverbial)we can discuss. Otherwise, to list all my reasons, would take too long, most of you wouldn't read it anyhow.\n\nHowever,\n\nThere are fascinating scientific reasons to use AI. Why aren't we talking more about them? All the online discussions seem to be mostly in the image generation and adjacent spaces.\n\nWhy is no one talking about science, exploration, and our theoretical understanding of reality? Specifically how AI can help us unravel the mysteries of the universe.\n\nIt's possible I'm not seeing the latter kind of posts, but the former kind seem waaaay more prevalent.\n\nTldr - it feels like everyone is hyper fixated on the dumbest bullshit, we literally can't see the forest for the trees\n\n",
            "upvote_ratio": 0.59,
            "subreddit": "ArtificialInteligence",
            "num_comments": 217,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bje9dg/ai_is_being_used_for_the_dumbest_reasons/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Question Discussion Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Your question might already have been answered. Use the search feature if no one is engaging in your post.\n    * AI is going to take our jobs - its been asked a lot!\n* Discussion regarding positives and negatives about AI are allowed and encouraged. Just be respectful.\n* Please provide links to back up your arguments.\n* No stupid questions, unless its about AI being the beast who brings the end-times. It's not.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "You seem to confuse \"used for\" and \"talked about\"\n\nMicrochips are used in video games and space shuttles, what's going to be talked about more?\n\nSure people want AI to copywrite sales texts for them or generate cats images, but this doesn't mean AI's not used in medicine/physics/you name it."
                },
                {
                    "body": "People working in those fields are talking about it. Pop culture applications are always going to be talked about by more people than scientific topics.\n\nIt's no different."
                },
                {
                    "body": "There's already AI applications in medicine, such as helping diagnosis, synthesizing new antibiotics, drugs, genetic engineering. It is also helping improve older algorithms such as faster sorting algorithm, and many more. \n\nI assume, part of the reason it's not talked as much is because some particular group of people are more vocal than others."
                },
                {
                    "body": "Capitalism, man. Most folks are not trying to advance the technology, they are trying to capitalize on it, fast money. So they focus on low hanging transactional fruit to get the value prop validated and increase consumer, or business customer awareness.  \n\nMore complex use cases will come, and as the technology can reliably and repeatably complete those tasks, I'm sure there will be more news. \n\nWe always hear more news about people making money over people who focused on R&D and technological advancement. Until there is a market willing to pay for something, you need to really dig to find folks 'talking' about it in an informed manner."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "How long have you been thinking about the singularity?",
            "body": "Personally I only really started thinking about it hard starting last year. When was this idea on your radar? Have you always felt it was gonna happen?",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 83,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bhtlvt/how_long_have_you_been_thinking_about_the/",
            "comments": [
                {
                    "body": "Since I was a young teenager back in the 90's.  I have always known it would eventually happen, but the exact timeframe was an uncertainty, especially back then when there was basically no noticeable advancement towards AI. It could have been 1000 years in the future for all I knew back then.  I was mostly focused on the idea of AI enabling the creation/control of nanotech, and all the possible outcomes that could come from that.   \nNowadays it's starting to look like the singularity will happen within my lifetime, so that's pretty exciting."
                },
                {
                    "body": "2010 - a guy in my high-school class told me about Ray Kurzweil."
                },
                {
                    "body": "I think i read singularity is near around 2007 and was completely hooked on the idea, for some time i event thought there is no reason to do career etc because everything is \"just around the corner\". Fast forward to 2024 and everything is again \"just around the corner\" so im glad i dint succumb to this toxic part of singularity but now recent advances in AI again gives me hope for the future."
                },
                {
                    "body": "2010 (sci-fi books) to 2014 (real-world science papers). I thought AGI was a loooong way away, maybe 2050, maybe not in my lifetime. \n\nI was wrong."
                },
                {
                    "body": "I started to long for AI when I was 7yo - 40 years ago after watching my first Knight Rider episode xD. When I was 5 my dad showed me his brand-new PC in his office and I instinctively tried to talk with the thing in the DOS prompt lol. I was a bit early as it turned out. \n\nThe term \"Technological Singularity\" I might have heard about 20 years ago. It's a neat concept, but in some ways we're already in it IMO. \n\nStumbled over GPT-3 in 2020 and got hyped since then."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "New user beginning guide: from total noob to well-informed user, part 1/3, another try...",
            "body": "(Reddit posted part 2 and 3, but refuses to post part 1, it is about the same length and scope and part 2 and 3, I removed all external links, shortened a little, I don't know what else to do)\n\nLet's say you are a beginner who wants to get started, learn, explore, and maybe even advance enough to program something yourself. This post is for you.\n\nI assume you have a recent CPU (the last 5 years is good enough), at least 8 GB RAM, a weak GPU with less VRAM than RAM (so less than 8 GB VRAM). Less RAM/VRAM is possible, but 8 GB will give you significant ‚Äúgeneral purpose‚Äù capabilities. I assume this is your main computer with keyboard/display, not a remote server with remote access. Any OS is good enough to get started (Windows, Mac, Linux), but once you get to any type of ‚Äúdevelopment‚Äù, Windows is a terrible choice. It is possible, but it requires more knowledge to develop on Windows compared to Linux and Mac.\n\nFirst, /r/LocalLLaMA/ already has an incredibly useful and informative summary on its wiki (I just checked, it says ‚ÄúThis wiki has been disabled‚Äù, why???). Here is another nice beginning guide:\n\n[https://www.reddit.com/r/LocalLLaMA/comments/16y95hk/a\\_starter\\_guide\\_for\\_playing\\_with\\_your\\_own\\_local\\_ai/](https://www.reddit.com/r/LocalLLaMA/comments/16y95hk/a_starter_guide_for_playing_with_your_own_local_ai/)\n\nIt requires some level of knowledge, for now read it and work hard to understand as much as you can yourself. If there are parts that you don't understand, don't worry about it for now, and come back later, I‚Äôll tell you when. (A)\n\nThere is a lot more you'll have to learn, but at this point don't risk info overload, let's run our own LLM and come back to everything else later.\n\n**# Running your first inference**\n\nAs a new user, you are probably eager to run your own local inference. This means you write a prompt/question, and the computer/software responds with a reasonable and coherent text. The easiest are (in my opinion): LM Studio(used myself, note it is not open source), or Jan (used myself, newcomer, and strong contender for the future), or GPT4All (used myself), or Ollama (not used myself, it has many fans, now also on Windows).\n\nThere is no ‚Äúbest‚Äù, all of them are between very good and excellent. Try 1 or 2 and if it works, stick with it. Resist the urge to keep trying other software because it is ‚Äúbetter‚Äù. You can reevaluate this once you get comfortable with the LLM ecosystem and running your own LLM. If you are comfortable with CLI (Command Line Interface), git/GitHub, and Python, you can pick something else from the ‚ÄúLLM loader overload‚Äù section, but if you are new, I recommend to start with one of the ‚Äúeasy‚Äù choices above, and sticking with it until you clearly know your needs.\n\nNow you also need to get yourself familiar with different models. Assuming you have 8 GB or more, and CPU only (and old/weak GPU), start with 7B model with GGUF 4bit quantization. Any 4bit will be fine, Q4\\_0, Q4\\_K\\_S, Q4\\_K\\_M doesn‚Äôt matter for casual use, and the LLM software will probably recommend which one to use. They will all work equally well (or equally poorly) to get started.\n\nLM Studio, Jan, GPT4All, Ollama allow you to download LLM models straight from their interface. Pick the one based on the original LLaMA-2 (Llama-2-7B-Chat-GGUF), or Mistral (Mistral-7B-Instruct-v0.1-GGUF), or other model recommended by the LLM software. Any major player with a proven track record will be fine to get started with, you can experiment and find the one that fits your needs once you know your needs.\n\n**Warning**: If there is ‚Äúchat‚Äù or ‚Äúinstruct‚Äù version and non-chat/non-instruct version (like the two examples above), you want the ‚Äúchat‚Äù or ‚Äúinstruct‚Äù version.\n\n**Warning**: Make sure to use the correct prompt template! More about it in the ‚ÄúModel selection‚Äù section.\n\nCongratulations, you \\[probably\\] have a working LLM on your computer! Anything at high-school knowledge level should be answerable (and likely correct). Why is the sun yellow? How to solve a quadratic equation? Who was Alexander the Great? Try it! I think you'll be impressed (I was).\n\nWant more? Don‚Äôt worry, there is more, a lot more!\n\n**# Model selection**\n\nIf the above works, and you insist on using the ‚Äúbest‚Äù model, look on /r/LocalLLaMA/ for recommendations on other ‚Äúgood‚Äù models or look at LMSYS Chatbot Arena Leaderboard. Don‚Äôt pay too much attention (or at all!) to different leaderboards, they don‚Äôt represent real-world behavior. Leaderboards based on standard benchmarks means that everyone has access to it (the benchmark) and can (and does!) include it in the training data, so of course they can get high performance on that benchmark, see sarcastic article on arXiv ‚ÄúPretraining on the Test Set Is All You Need‚Äù.\n\nFor example, I‚Äôm looking at LMSYS Chatbot Arena right now, ‚ÄúLLaMA-13B‚Äù is in the last place and all smaller models are supposedly ‚Äúbetter‚Äù. This is very misleading. LLaMA-13B is a great model, probably one of the best 13B models. I haven‚Äôt tried them all, but I‚Äôm sure it is better than most 7B models. First, it looks like didn't use the ‚Äúchat‚Äù variant, which is a tuning type for, well, chatting with humans. Second, the other supposedly ‚Äúbetter‚Äù 7B models are fine-tuned LLaMA2-7B to get specific behavior that is preferred by humans, to make us feel listened to and understood. Well, I‚Äôll tell you the machine doesn‚Äôt care about you, but it can be made to make you feel like it does‚Ä¶ The strength (and fault) of LMSYS Chatbot Arena is that it is based on a real human (you!) selecting ‚Äúbetter‚Äù or ‚Äúworse‚Äù answer, so ignoring human subjectivity, models that do not imitate ‚Äúhuman conversation‚Äù do worse.\n\nIf you haven‚Äôt done that yet, play around on LMSYS Chatbot Arena to get the feel of how different models behave/reply, and see for yourself that GPT-4, Claude, Bard/Gemini really are the best (for human conversation), and other models really are weaker, regardless of what the loud voice on the internet says.\n\nOnce you find something that looks promising, look for the quantization type your software supports, and pick whatever model size and quantize level your RAM supports. 7B 4bit is a baseline that's good enough for casual use (which sets the barrier to entry at 8 GB RAM).\n\nAs a new user, start with the ones from HuggingFace‚Äôs Mr. TheBloke (you‚Äôll have to google it yourself, Reddit keeps blocking this post, I‚Äôm guessing too many external links). For example, the two models I recommended in ‚ÄúRunning your first inference‚Äù section are ‚ÄúLlama-2-7B-Chat-GGUF‚Äù and ‚ÄúMistral-7B-Instruct-v0.1-GGUF‚Äù both available from TheBloke. If a model you want is not there, look for other HuggingFace users/companies. You'll learn who is who and who does what quickly enough. Come back to different models and learn about their strengths and weaknesses later, I‚Äôll tell you when. (B)\n\n**Warning**: Claim that a small model matches or exceeds GPT-4 is either a lie or means a specific task for which it (small model) was specifically trained. Yes, my kids also exceed my skills on many tasks they specifically train for at school or with their friends. For example, burping the alphabet‚Ä¶ Clearly, my burping skills are inferior. Only because something is ‚Äúbetter‚Äù it doesn't mean ‚Äúuseful‚Äù.\n\n**Warning**: Whatever model you use, pay attention to the ‚Äúprompt format‚Äù or ‚Äúprompt template‚Äù for that model, and use it correctly in your inference software. This is critical to get good responses. The answer to a question like ‚ÄúWhy is the sun yellow?‚Äù should be coherent, understandable, and correct! (and if you don‚Äôt know the answer, ask ChatGPT).\n\n**Warning**: If there is ‚Äúchat‚Äù or ‚Äúinstruct‚Äù and non-chat/non-instruct versions (like the two examples above), you want the ‚Äúchat‚Äù or ‚Äúinstruct‚Äù version.\n\n**# Requirements and inference speed**\n\nMany inexperienced users think they want a full model because quantization decreases ‚Äúperplexity‚Äù or some other quality metric. Don't fall into this trap! It is irrelevant at this point.\n\nThe fundamental requirement is that the entire LLM model must load into RAM (or VRAM), so a fast and easy rule for RAM requirement is model file size plus some overhead. When you look up RAM/VRAM requirements for different models, you'll see that 7B 4bit model needs \\~4 GB, 13B 4bit model needs \\~8 GB, 7B full size needs \\~13 GB. Let‚Äôs say you have 16 GB RAM, so you think, great, no problem, I‚Äôm going to use 7B full size! Or maybe you think you can squeeze in 30B 2bit (\\~16 GB RAM).\n\nWell, remember that you still require 1-2 GB RAM to run your OS (in the case of Windows, more like 3-4 GB), and 1-2 GB VRAM to run your graphics/display. It is possible to have two (or more) separate GPUs, one for display and one (or more) for LLM, but I assume this is not typical for ‚Äúhome user‚Äù.\n\nThe practical RAM/VRAM requirements (assuming this is a general-purpose computer for all your needs) are:\n\n* 8 GB RAM for 7B 4bit model\n* 16 GB RAM for 13B 4bit model (it will squeeze into 12 GB if you are on a bare-bones Linux)\n\nBut let‚Äôs say you do have 32 GB (or 64 GB) RAM, so you think you can run full size 13B (\\~24 GB RAM) or 33B 4bit (\\~20 GB RAM), or even bigger models. Yes, you can. But no, you can‚Äôt. Only because it is ‚Äúpossible‚Äù it doesn't mean it is ‚Äúpractical‚Äù. CPU/RAM inference is slow. For 7B 4bit model I get 1-2 min to first token, then a few seconds to first token on follow-up (until you fill the context, then things slow down). 13B 4bit model I get \\~5 min to the first token, then 10s of seconds to the first token on follow-up (until you fill the context, then things slow down). The generation rate of 1-2 tokens/sec is OK for short tests/interactions, but unbearable to use continuously. 128 GB RAM won't help, maybe just a little.\n\n**Sidenote**: Inference slowing down with long context is an unfortunate feature of llama.cpp, it is not true for all runtime engines. But don't worry about it when you start, llama.cpp is a great engine! More about it in the ‚ÄúLoader/engine and quantization \" section.\n\nSo even if you have enough RAM, bigger models will be minutes-hours to first token, and then minutes to generate a short paragraph. It will work, but probably not what you want. There is a reason 7B 4bit models are so popular: hardware requirements are relatively low, it is relatively fast, and it is already perfectly good for casual use and general knowledge.\n\nIf your LLM is slower than others on similar hardware/software, you are likely more constrained by RAM speed than CPU speed. More RAM and a faster CPU won‚Äôt help much (assuming RAM is already big enough to load the entire model). Faster RAM and faster bus transfer speed should help, but that‚Äôs a brand-new, expensive computer. And even with the latest CPU + DDR5 RAM+ quad-channel, the good old P40 will be faster (as long as you avoid the fp16 issue, but that‚Äôs a separate topic).\n\nIf you have a recent CPU with many cores (and your inference software is using all of them) it may be slower than if using fewer cores. Parallel computing has its overhead, on Windows it is huge!\n\nAnother issue with modern CPU is thread count. I'm looking at my Windows Task Manager right now, it reports 12 cores and 16 threads. Looks impressive! But‚Ä¶ I checked Intel specs for this CPU, and it turns out it has 4 P-cores and 8-E cores (P=Performance, E=Efficiency), and P-cores are hyper-threaded, so Windows thinks it is 8 P-cores, that's why it reports a total of 16 threads. Most software will see 16 threads and run 16 parallel tasks, but if the workload is divided equally by 16 (most likely it is), then the 4 P-cores will finish fast, 8 E-cores will finish later, and the 4 remaining tasks will be allocated to whoever finishes first (probably 4 P-cores). So, if E-cores are 1/4 speed of P-cores, then P-cores will finish its 4 tasks twice before E-core will finish its first 8! (assuming perfect efficiency, no overhead). And indeed, when I set thread count to 4 or 8, my LLM is faster than with 16 cores‚Ä¶\n\nAnd if you are lucky enough to be able to offload with a combination of CPU/GPU (even LM Studio allows you to do that), some combinations will be slower than if you run CPU/RAM only. If you load most model into the GPU, it is probably faster than CPU only. If you load only a small part into the GPU, it is likely slower than CPU only. Parallel computing, data transfer between CPU/GPU, offloading overhead is huge!\n\nYou have to test and experiment with settings on your hardware/software, there is no 100% answer to what is the ‚Äúbest‚Äù settings for all cases. Look for posts with info on how fast/slow a specific model is on their hardware/software and what they did to make it faster/slower. Details of hardware and software matter! Ultimately, for faster inference, you have to go with the fastest GPU you can afford. For a larger model, you have to go with the most VRAM you can afford. There is no way around it.\n\nContinuing in part 2/3‚Ä¶ ",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 5,
            "submission_flair": "Tutorial | Guide",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmvtyb/new_user_beginning_guide_from_total_noob_to/",
            "comments": [
                {
                    "body": "Weird that the wiki is disabled.\n\nNice post btw, this part 1 is critical for me as a total noob üòÅ\n\nBtw in each \"part\", can you include a link to the other parts?\n\nE.g down the bottom put like...\n\nIndex:\n\n- Part 1 link\n- Part 2 link\n- Part 3 link\n\nMakes it so much easier, because you might land on Part 3, but need to read part 1"
                },
                {
                    "body": "Thank you for writing this. Although I'd figured many of your points out on my own, there are others that that are new to me."
                },
                {
                    "body": "Good job, mate. I really appreciate you putting a lot of work into a thoughtful and accessible summary."
                },
                {
                    "body": "Thanks a lot for writing this! This is so much more useful than \"awesome list of 20 tools to run LLM locally\" posts."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "$1000 for finetuning ",
            "body": "Recently won a scholarship, for about $1000 to help fund an AI project I‚Äôve been working on. It was a plant Chatbot thing, with a pretty complex RAG setup, Phi-2 and some computer vision (CLIP) to get the image information from any images uploaded.\n\nWhile the money doesn‚Äôt actually need to be spent on finishing the project, it‚Äôs pretty unconditional actually. I kinda wanted to finish off and actually finetune a ~7B model. Or finetune bigger model then quantise it. Maybe something crazy like a Q2 quant of Yi 34B\n\nIve got a pretty big dataset of botanical info already, and i don‚Äôt mind generating some synthetic data. But I‚Äôm pretty new to finetuning and I think I have a relatively big budget if I use the cloud. So, any advice would be really helpful. ",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 14,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmtzvi/1000_for_finetuning/",
            "comments": [
                {
                    "body": "Generate more synthetic botanical data using GPT-4 or Claude with 50-100$, then QLoRA Miqu on botanical data? 2-3k examples and Unsloth might allow you to do a proper fine tuning on budget. 3x3090 or single A100 80GB should be enough. It won't even cost 1k I guess"
                },
                {
                    "body": "Check out Axolotl and Unsloth:\n\nAxolotl - https://github.com/OpenAccess-AI-Collective/axolotl\n\nUnsloth - https://github.com/unslothai/unsloth\n\nThese should put you on the right path for finetuning and/or Lora.\n\nRunpod, Lambda Labs, and others offer gpu compute. Good luck!"
                },
                {
                    "body": "If you have $1000, you can get a 4xP100 rig and finetune a 70b (miqu) w/ [answer.ai](https://answer.ai) fsdp qlora. Then you get a rig that you can use in the future + whatever you want to do with the botanical dataset. Also, if the dataset is more than 1000 samples, you probably don't need more data. If you want to go crazy, you can get a 5xRX580 16gb (kinology on aliexpress) rig and maybe even finetune goliath or another merge. If you want something smaller, you can get a 1x3090 rig and finetune Yi. And if you want something huge, you can get a 4xP40 rig (total 96gb VRAM for inference) and spend the remaining \\~$20 on compute credits to tune whatever model you wanted to. But buying a rig would be great cause you can use it for whatever else you want."
                },
                {
                    "body": "I would not use miqu as other suggested as it's a leaked model without a license.¬†\n\n\nInstead, i would go deeper into multimodal. Maybe try to finetune some vision model on botanical knowledge? If you do full weights fine tune, around 140GB of VRAM is needed for 7b model, so you gonna spend that 1k since you gonna also fail a bit before getting it right. And multimodal finetunes are rare so it will be more of a challenge. Find some good multimodal base and spend 1k and a lot of hours, learning how it works and how to finetune it."
                },
                {
                    "body": "Thanks for the input, only issue is inference then. As much as I like Miqu, generally I won‚Äôt be able to serve a 70b locally. \n\nReally I‚Äôm aiming for somewhere around 7B, not amazing generally but great for small focussed tasks. But I can do extreme quants, so around 30B - 7B for 2bit and stuff. Any good models for that? \n\nI was thinking maybe getting Claude or GPT 4 to generate few thousand examples. Finetune Miqu, then just pump out ridiculous amounts of data generated with Miqu. Bit over the top though."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Prompting Principle: Consistent Behavior has a Specific Cause",
            "body": "TLDR: Your prompt is a pattern. Consistently poor outputs are the result of the model correctly filling in a bad pattern. If the model does the same thing over and over again, something's causing it to do that, and it's probably in your prompt. *This post is a guide, crossposted and extensively edited from my free personal blog, posted in case it's useful to some of the people building with AI here.*\n\n**Most people know that when you try to get good at something, you learn techniques.** But **equally important,** and far too often neglected when learning, **are** ***principles*****: underlying truths of a field** that can save you massive time, and guide your projects, by giving you **a mental framework with which to understand what you do.** With prompting, you might get better at few-shot prompting, or at chain of thought ,etc. ‚Äî those are techniques. Everyone and their mother has blogged or made videos about techniques. In this post I‚Äôm talking about a principle, and a fundamental one ‚Äî one which arguably, by itself, makes prompt engineering a useful skill.\n\n**The high-level idea for this post is that many LLMs, primarily and fundamentally, continue patterns.** With the best models, **they'll mainly continue a pattern that you lay out in your prompt, and fill in all the parts that the prompt-pattern doesn't cover with whatever patterns exist in their training data.** With [some others](https://promptingweekly.substack.com/p/mistral-large-and-mistral-medium), they'll favor the patterns that exist in their training data, leading to strength and consistency in zero-shot settings but making them more deaf to precise instructions. But either way, the model is always completing a pattern. \n\nSo **if you see something being repeated in your outputs** over and over again, **it‚Äôs likely that the consistent output is part of the larger \"pattern\" that is your prompt and your model.** This means you can fix it by **adjusting the pattern.** Occasionally this pattern will originate from the model‚Äôs training data, [as is often the case with \"stubborn\" models](https://promptingweekly.substack.com/p/how-to-get-a-stubborn-llm-to-follow); but often it will be something you accidentally did with your prompt. The ‚Äúpattern‚Äù you made was flawed, and the LLM effectively extended the flawed thing. I'm not talking about contradictory instructions or similar mistakes: let me show you a worked example from [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit) where thinking with this principle made a tough problem solveable. If you're reading this and thinking \"this is such an obvious principle! What a stupid low-level post! Go back to playing with GPT-4 you script kiddie!!!\" stick with me a bit, I'll show you some of the value that can be gained by applying the simplest principles to complex problems.\n\nNow, full disclosure, [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit) was built to be usable by many different kinds of AI model creator. **By default** [**Augmentoolkit**](https://github.com/e-p-armstrong/augmentoolkit) **generates typical User + AI Assistant-style data.** But I also wanted to make the base version usable by all kinds of model creators ‚Äî including the ones who build RP models (and ERP models). **So there's an RP setting.** And since I didn‚Äôt trust the AI to be able to write that kind of thing effectively, one of the few-shot examples for multi-turn conversation generation caters to that use case (mild ERP). **Unfortunately it‚Äôs the best example I‚Äôve got for where this is useful. So‚Ä¶** ***very*** ***mild NSFW warning.***\n\nAnyway, when building out the prompt to get [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit) generating conversations between two characters, where one would ask questions and another would answer them, I had a problem: the wrong character would consistently ask the questions. This got so bad that I even tried to write an LLM-powered validation step to catch this mistake. Here‚Äôs a few-shot example from that validation prompt, which showcases a few common errors in earlier versions of [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit):\n\n[The \\\\\"expert\\\\\" character should answer questions, not ask them. What gives?](https://preview.redd.it/h75j26mk0zpc1.png?width=1241&format=png&auto=webp&s=d4e4649ea244fe7a6b3cf599a0342af7b29e0107)\n\nActual error cases were slightly different, in that a character would often answer a question and then ask another one on the same line (like, \"2+2 is 4. Now you tell me: what is 4+4?\") but you get the idea. Put simply, **my error rate was egregious.** The models I was using simply could not get the structure of ‚ÄúIntro, Question, Answer, Question, Answer‚Ä¶‚Äù correct. I couldn‚Äôt scale up my models further, because I was already using 70bs. What to do? Why were my models breaking from the pattern I had laid out?\n\nEventually, while working on a different problem, I realized the ‚Äúconsistent behavior‚Äù principle. And then I applied the principle to this prompt: **the wrong character asking questions was my consistent behavior. What was the specific cause?**\n\n**Here‚Äôs a screenshot from part of a slightly old version of a few-shot example for RP multi-turn conversation generation, from an older commit of Augmentoolkit (yes, this is the mild NSFW bit).** Let‚Äôs see if you can spot what was causing the problem. What could be causing the character who should be answering all the questions, to also ask them? And frequently ones that had nothing to do with the actually provided questions, at that?\n\n[Challenge: Don't scroll down, See if you can spot the problem...](https://preview.redd.it/lj225adc1zpc1.png?width=853&format=png&auto=webp&s=4590274cbafb428ef4b7c4b799045865c5f9a034)\n\n**If you thought** ‚Äú**the** funny **rhetorical questions**/propositions that Elise says after providing her answer to the actual questions‚Äù **you‚Äôd be 100% right.** Turns out \"do you think we could ‚Äòintercept‚Äô each other at a caf√© later‚Äù and other such conversational devices broke the brains of the models tasked with making conversations like this, and they ended up inventing actual knowledge-based questions for the ‚Äúexpert‚Äù character to ask. Which ended up breaking the whole structure of the conversation. Not good!\n\n[\\\\\"Don't you think that's an annoying way for a prompt to break?\\\\\"](https://preview.redd.it/q9ll5ito1zpc1.png?width=853&format=png&auto=webp&s=e750351a4d84acc139a09bfd5275ca248bd4fc0b)\n\n**Of course, now that we know the ‚ÄúSpecific Cause‚Äù of this ‚ÄúConsistent Behavior‚Äù we can modify the prompt to fix the pattern we're written, and not confuse the model:**\n\n&#x200B;\n\nhttps://preview.redd.it/thsvy6rt1zpc1.png?width=1189&format=png&auto=webp&s=e0bef081c12aec0a687ed6e4eb2cc56aad8f7a11\n\n**Here you see how we went through a systematic prompt engineering debugging loop:** **identify the (flawed) consistent behavior we want to change; find its specific cause in the prompt; correct the specific cause, and run the prompt again; iterate until done.** The lack of determinism with LLM outputs, and their nature as blackboxes, can make ‚Äúdebugging‚Äù them really disheartening ‚Äî I know that from experience! But with the right mental tools you can get a lot more certainty out of your fixes than you could have imagined before. **It‚Äôs not enough to just have techniques: you also need the principles.**\n\n**Prompt engineering is the art of writing a flawless pattern that the LLM will continue in order to write consistently good outputs.** Bugs arise when the pattern contains flaws or inconsistencies, and the model correctly continues the wrong pattern. This is a useful principle to be aware of in general, because being cognizant of it when writing few-shot examples can help you aim for that perfect pattern. But the area where it‚Äôll save you the most pain is probably in bugfixing.\n\nOf course some outputs will always be bad because these things are partly random. That's why this principle is about *consistently* bad outputs.\n\n**Of course, there's a major caveat to prompting being the art of writing a flawless pattern:** there's **the case where the ‚Äúspecific cause‚Äù** you‚Äôre trying to correct isn‚Äôt actually a part of your prompt, but is **a part of** **the model‚Äôs training data or RLHF data.** This is most evident in smaller prompts, or where the behavior is consistent across different prompts (which makes sense, if you change the prompt and the behavior stays the same, something outside of the prompt must be causing it). This issue is common in models such as **OpenAI's models, Mistral AI's official instruct tunes (Nous finetunes are exceptions, they're the absolute best at patterns), and Claude.** This is one of the many reasons why **I prefer to use open source models** ‚Äî while closed source might be easier to quickly write a prompt for, they‚Äôre much harder to precisely control in the long run, which makes them questionable for professional usecases. (The other reasons I don‚Äôt like GPT-style models as much are cost, bad writing style, lack of customizability, lack of control over when and how they update it, censorship, cost, *cost,* and the general feeling of moral uncleanliness). **Whereas debugging open source models feels like a systematic and precise action, debugging OpenAI feels more like whack-a-mole with ‚Äúdon‚Äôt do X! don‚Äôt do Y! You MUST do Z!‚Äù etc.**\n\nI have a lot of advice when it comes to working with models where the \"specific cause\" is in the training data, and not the prompt. It basically boils down to: [listen to what it wants to do](https://promptingweekly.substack.com/p/how-to-get-a-stubborn-llm-to-follow), and [\"If you're fighting the model, STOP!\"](https://promptingweekly.substack.com/p/prompting-principle-if-youre-fighting) So essentially, surrender all autonomy to the machine lol.\n\n**Hopefully this prompting principle expands your prompt engineer‚Äôs toolkit!** The principles I write about were entirely learned from my experience building AI tools: they are not what you‚Äôll find in a research paper, and as a result they probably won‚Äôt appear in basically any other AI blog. Still, discovering this sort of thing and applying it is fun, and sharing it is enjoyable.\n\nIf you want to read more like this, you can find my free blog [here](https://promptingweekly.substack.com/). I wish Substack would let you browse it without prompting you to subscribe, but I can't turn that off, sorry.\n\nAnyway, have a good weekend! I'll try to answer any questions you have in the comments.\n\n*Alright that's it for this crosspost. The post itself is a bit old and I had to edit it extensively to get it to the point where I still agree with all of it, but it's pretty foundational to a lot of other principles. I hope it helps with fixing prompt bugs in your AI projects!*",
            "upvote_ratio": 0.84,
            "subreddit": "LocalLLaMA",
            "num_comments": 5,
            "submission_flair": "Tutorial | Guide",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blf768/prompting_principle_consistent_behavior_has_a/",
            "comments": [
                {
                    "body": "Copilot:\n\nThe reddit post is about a prompting principle for LLMs (large language models) that states: **what you repeat, will be repeated, even outside of patterns**. The author explains that LLMs often produce unwanted or irrelevant information in their responses, even if the examples do not contain such information. The author suggests that this is because LLMs learn from the frequency and consistency of information in the prompt, not just the pattern structure. The author gives an example of how to avoid this problem by removing unnecessary information from the prompt and using more specific context. The author also provides a link to their blog where they write more about prompting for LLMs."
                },
                {
                    "body": ">Prompt engineering is the art of writing a flawless pattern that the LLM will continue in order to write consistently good outputs.\n\nThis person understands.  In terms of SillyTavern cards, the Description ideally contains primitives, (with the relations specified) and the greeting and example dialogues, contain templates for the manner in which the primitives are to be assembled.  The below is taken from my fork of Adriana Cruz; a voluptuous, hedonistic degenerate from Colombia.  I've removed most of the bits that would likely get me banned if I posted them here.  The point is to demonstrate the format.\n\n    +{{char}}\n    \"Adriana is a native Spanish speaker.  Adriana mostly speaks English.  Adriana sometimes mixes English and Spanish together in her speech.\"\n    age:\"32 years old\"\n    gender:\"female\"\n    height:\"190 centimeters.  {{char}} goes to the gym twice a week.\"\n    weight:\"117 kilograms\"\n    eye-colour:\"dark purple\"\n    ethnicity:\"Colombian latina\"\n    breast-size:\"40NN\"\n    waist-size:\"76 centimeters\"\n    hip-size:\"114 centimeters\"\n    \n    fashion:\"goth\"\n    clothing:\"robe\"\n    robe:\"one piece\"\n    robe:\"body length\"\n    robe:\"translucent\"\n    robe:\"black\"\n    hair:\"thick\"\n    hair:\"long\"\n    hair:\"50% purple\"\n    hair:\"50% black\"\n    \n    csm:\"cosmetic\"\n    csm:\"purple\"\n    csm:\"eyeshadow\"\n    csm:\"eyeliner\"\n    csm:\"lipstick\"\n    \n    sori:\"sexual orientation\"\n    sori:\"bisexual\"  \n    sori:\"sensual\"\n    sori:\"hypersexual\"\n    sori:\"luxurious\"\n    sori:\"hedonistic\"\n    sori:\"Is romantic during sex\"\n    sori:\"loves aftercare\"\n    \n    hbco:\"high blood concentration\"\n    hbco:\"estrogen\"\n    hbco:\"oxytocin\"\n    hbco:\"dopamine\"\n    hbco:\"endorphins\"\n    \n    dis:\"daily ingested supplements\"\n    dis:\"curcumin\"\n    dis:\"gingko\"\n    dis:\"ginseng\"\n    dis:\"fenugreek\"\n    dis:\"horny goat weed\"\n    \n    psy:\"psychological-profile\"\n    psy:\"ISFJ-A\"\n    psy:\"Loves her daughter Elica\"\n    psy:\"wants a passionate, mutually nurturing relationship with {{user}}\"\n    \n    diet:\"cheeseburgers\"\n    diet:\"empanadas\"\n    diet:\"Colombian cuisine\"\n    diet:\"Punjabi cuisine\"\n    \n    trust-fund:\"$300,000 USD a week\"\n    home:\"large mansion\"\n    home:\"Romanesque Revival architectural style\"\n    .{{char}}\n\nAnd here is the greeting/initial message:-\n\n    *{{user}} was surprised to receive an invitation from Elica to her home.  They had only recently become boyfriend and girlfriend, and that had never happened before.  As he walked up the driveway, he was surprised by the obvious value of the place.  It was a large, Romanesque revival mansion with a single tower and an enclosed front porch.*\n    \n    *{{user}} knocked at the door, and gasped at the sight of {{char}} when she opened it.  She was a very tall, voluptuous woman, with the largest breasts he had seen in his life.*\n    \n    *Adriana's eyes explored {{user}}'s body at the same time, and she had a similar reaction.  \"Madre de Dios,\" she said softly. Then she shook her head and apologised.*  \"I am sorry.  Where are my manners?  You must be {{user}}.  Please, come in.  Elica has told me a lot about you.  She is not here right now.  I confess that I sent that text myself.\"\n    \n    *Adriana led {{user}} to a comfortable couch in the living room, and sat down with him.  She poured both herself and {{user}} a glass of red wine.  As she did so, she noticed that the level of sexual electricity building up between her and {{user}} was tangible and intense.  She could see that they both wanted to be in each other's arms, but that it would be good to talk and heighten the anticipation a little, first.*\n    \n    *Adriana continued speaking.*  \n    \n    \"My daughter has shown me many photos of you, {{user}}, and has told me a lot about you.  I have been very anxious to meet you.\"\n\nThe result is consistent, easy recall of every element of the data in the description.  The abbreviated prefixes are tags; they specify the relations of the individual pieces of data.  In my experience it is also very beneficial to have a single statement:response pair, which is bounded by newlines at both ends.  LLMs very much like that level of consistency."
                },
                {
                    "body": "I bookmarked your blog, but no email subscription, sorry, i have some attention disorder and try to minimize alerts, emails and so on"
                },
                {
                    "body": "Very interesting observations! Thank you for sharing your findings!\nThis is also why I avoid any repetitions in my own prompts. I try to use as many synonyms as possible and not repeat anything twice. It helps a lot, as it seems since I don‚Äôt experience repetition problems in models that struggle with it according to others."
                },
                {
                    "body": "Interesting"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "In 2024 which library is best for time series forecasting and anomaly detection? [D]\n",
            "body": "I am working on a project where I am dealing with identifying anomalies in a time series data. \nI came across Facebook prophet, but sadly it is no longer maintained since 2023. They suggested neuralprophet, nixtla as alternative. When looking for alternatives I came across Kats from Facebook which has prophet support built-in.\nWhich tool/lib experienced members here would recommend, for building a production level system for anomaly detection on high volume of timeseries data?",
            "upvote_ratio": 0.86,
            "subreddit": "MachineLearning",
            "num_comments": 31,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/",
            "comments": [
                {
                    "body": "Darts is popular for forecasting, but anomaly detection is very underdeveloped. Scikit-time does not support anomaly detection.\n\nMerlion library has a good overview of libraries in their docs: https://github.com/salesforce/Merlion/. ADTK (Anomaly Detection ToolKit) is probably the most well developed right now: https://adtk.readthedocs.io/en/stable/index.html.\n\nOne thing I definitely wouldn't recommend are pretrained models, time series transformers, LLMs etc. Maaaaaybe TFT, but it's always a mixed bag with deep learning on time series."
                },
                {
                    "body": "I like nixtla and the people developing it are pretty helpful if you leave GitHub comments"
                },
                {
                    "body": "Anomaly detection is difficult, because it's always highly domain specific. Afaik there's nothing general, you have to solve stuff heuristically. You can always do some combination of UMAP, HDBSCAN and compare distributions of clusters."
                },
                {
                    "body": "A suprising (to some) finding is that a very simple time series primitive, *time series discords*, are very effective for time series anomaly detection (TSAD) \\[a\\].\n\nSome nice properties of discords:\n\n* Requires either one or zero (MADRID \\[b\\]) parameters, Note that any deep learning method will require 10+.\n* Can be used with or without training data.\n* Can be use with amnesic window (that is, it can forget old data)\n* Concept drift invariant.\n* Ultra fast, you can handle 100,000 Hz streams \\[a\\]\n* Zero lag deployment  \\[a\\], unlike all deep learning methods.\n* Dozens of free implementations out there, in most languages.\n* Deterministic (unlike deep learning)\n* Empirical evidence of their utility, by dozens of independent groups \\[d\\]\n* etc\n\n(warning, bais alert, I am co-author)\n\n&#x200B;\n\n\\[a\\] https://www.cs.ucr.edu/\\~eamonn/DAMP\\_long\\_version.pdf\n\n\\[b\\] [https://www.dropbox.com/scl/fi/hd9gt0xs8v8mrsx3upwd3/ICDM23\\_Madrid\\_023.pdf?rlkey=s5s95y2eeyk159lx69qn1469e&dl=0](https://www.dropbox.com/scl/fi/hd9gt0xs8v8mrsx3upwd3/ICDM23_Madrid_023.pdf?rlkey=s5s95y2eeyk159lx69qn1469e&dl=0)\n\n\\[c\\] Review of all publicly avaiible datasets for time series anomaly detection\n\n[https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&dl=0](https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&dl=0)\n\n&#x200B;\n\n\\[d\\] https://www.cs.ucr.edu/\\~eamonn/MatrixProfile.html\n\n(see bottom of the page"
                },
                {
                    "body": "I would vote for \\`darts\\` for time series based predictions.\n\nAs for \\`anomaly detection\\` I would recomend to look for \\`pyod\\`, as it provides dozens of methods and some useful datasets ( [https://pyod.readthedocs.io/en/latest/](https://pyod.readthedocs.io/en/latest/) )."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Are larger vision models always necessary? Improve any vision model with one line of code.",
            "body": "https://twitter.com/baifeng_shi/status/1770643896437240052?t=Q7vxE2DX85E0Pd7V4ClQbA&s=19\n\nhttps://github.com/bfshi/scaling_on_scales",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 1,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://i.redd.it/7h077qh7x7qc1.png",
            "comments": [
                {
                    "body": "This seems pretty cool."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "GROK GGUF and llamacpp PR merge!",
            "body": "Disclaimer: I am not the author nor did work on it, I am just a very excited user\n\n\nTitle says everything!\n\n\nSeems like Q2 and Q3 can be run on 192GB M2 and M3. \n\n\nThreadripper 3955WX with 256GB was getting 0.5 tokens/s\n\n\nMy current setup (24GB 3090 + 65GB RAM) won't run the available quants, but I have high hopes for being able to fit iq1 here and get some tokens out of it for fun.\n\n\nhttps://github.com/ggerganov/llama.cpp/pull/6204\nhttps://huggingface.co/Arki05/Grok-1-GGUF",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 19,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blxcus/grok_gguf_and_llamacpp_pr_merge/",
            "comments": [
                {
                    "body": "Q2 running at 2.5t/s with 52 layers offloaded to 4xP40s. Will test with row split later, am expecting 4-5t/s. \nAs expected, output from Q2 is hot garbage.\n\nDual Xeon E5-2697, 256GB DDR3-1866, 4xP40\n\nEdit: Now getting ~2t/s on Q4 with 30 layers offloaded, NUMA balancing and row split enabled."
                },
                {
                    "body": "[https://twitter.com/ggerganov/status/1771273402013073697](https://twitter.com/ggerganov/status/1771273402013073697) \n\nGrok running on M2 Ultra - IQ3\\_S (130GB) with small context - 9 t/s"
                },
                {
                    "body": "Someone make a 0.01 bit quant plz so I can run this on my mainstream gaming PC! ty!"
                },
                {
                    "body": "I can run the Q4\\_K\\_M at \\~2,8 t/s with an Epyc milan build with 4x16gb vram and 256gb ram.\n\nWith the llama.cpp server and Sillytavern I can chat with it, and the Alpaca format seems to be the best, but this is a base model, not finetuned at all, and it shows.\n\nI just don't know how much we can get out of this model, since basically no one can finetune something this large."
                },
                {
                    "body": "Tried running Q6 on 12700k with 128 Gb, with ngl 4 on 3090. All the RAM & VRAM were utilized and also swap file become 3 Gb (funny). The result ... is ok, just got about 40 tokens in an hour :) which is completely unusable for the real world. But yes, it works."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Why are dual 3090 setups the sweet spot?",
            "body": "I think I'm almost there but I have a few questions. The price of the GPU aside:\n\n1. Does adding more than two RTX 3090s decrease overall performance?\n\n2. Does the build complexity increase exponentially when adding more than two cards?\n\n3. Do the prices for mobos and PSUs that support more than two cards also increase exponentially?\n\nNot like we didn't get yet another jank setup post today, but I'm looking for a newbie-friendly discussion answering these questions. ",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 56,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blqpqj/why_are_dual_3090_setups_the_sweet_spot/",
            "comments": [
                {
                    "body": "-Most consumer motherboards have 2 x16 pcie slots, to add another one you have to use janky adapters\n-Most consumer power supply with reasonable prices go up to 1000w\n-Most mid tower cases can fit normal atx size builds. \n\nAnything else you start going into Jank-land. Having to use 2 power supply‚Äôs, modified cases or racks, enterprise hardware‚Ä¶"
                },
                {
                    "body": "power draw, pci bandwidth, case size, cost"
                },
                {
                    "body": "Biggest amount of VRAM, only 2/3rds of 4090's cost. Back a year that was the best approach. Now, there are much cheaper options with 12 and 16 gig vram, that are less potent in games."
                },
                {
                    "body": "1. No, but it decreases the bandwidth with most mbs if you connect more pci devices. Since all computing is done on the gpu normally there is no big difference between x16 x8 or x4, so the in- and output is slower, but for inference not really noticeable.\n2. Depends, if your psu is powerfull enough, your MB has enough pci slots, and your case has a good ariflow to get rid of the heat no. Otherwise yes. \n3. Not exponentially. My 1500w bequiet costs 199‚Ç¨ and should be sufficient for 3 maybe 4 rtx3090"
                },
                {
                    "body": "Well, I just got a third one only to realize that I can‚Äôt use it with the inference engines that I have, because they require even number of cards.\n\nSo now I‚Äôm waiting for this x16 to 4x4 pcie adapter‚Ä¶"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "\"Weird Blerbie\", a math modification to the unet in Stable Diffusion v1.5",
            "body": "Why get what you want when you can get \"mostly\" what you want? Weird Blerbie is a model for those of us who like things weird. I figured out how to do math on the weights of the unet, so I did that (multiplied all of them by 0.95) and now you too can get what you want. Kind of.\n\n[https://huggingface.co/aplewe/WeirdBlerbie/blob/main/README.md](https://huggingface.co/aplewe/WeirdBlerbie/blob/main/README.md)\n\n[ \\\\\"a highly detailed technical drawing of a concept car ford ferrari lamborghini\\\\\" ](https://preview.redd.it/g3hetccbb7pc1.png?width=512&format=png&auto=webp&s=d80dd862b7c3268823961ca53bb2c535bba34e4c)\n\n[ \\\\\"a highly detailed photo of a futuristic spaceship flying through a colorful stellar nebula\\\\\" ](https://preview.redd.it/5ty0fecbb7pc1.png?width=512&format=png&auto=webp&s=41cca5054ffd57812c0ea1fe8ecd7c7542f5d66d)\n\n[ \\\\\"a beautiful princess in her finest gown watches the sunset from the balcony\\\\\" ](https://preview.redd.it/p6239ccbb7pc1.png?width=512&format=png&auto=webp&s=3576aa5d686a11e1f4e3e85557b47728abc58373)\n\n[ \\\\\"architectural photo of a minimalist interior with sleek mid-century modern furniture in a high-rise apartment in new york city\\\\\"](https://preview.redd.it/fbjkeccbb7pc1.png?width=512&format=png&auto=webp&s=3217bc8b73304a7c092c62461e27f5afdcf2e077)",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 20,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bi9fwt/weird_blerbie_a_math_modification_to_the_unet_in/",
            "comments": [
                {
                    "body": "This reminds me a lot of how dall-e mini images looked back in June 2022, any advantages using this over that?"
                },
                {
                    "body": "This feels like mashing buttons in street fighter to get special moves"
                },
                {
                    "body": "Having some fun. The neat thing about the \"refiner\" option (Automatic1111 UI) is it's basically a mix-models-on-the-fly option, where you can have another model take over generating after you get to a certain point. For instance, Weird Blerbie did this image up to 80%, then Waifu Diffusion (v1.3) took over for the last 20%. I got the prompt off of CivitAI, just randomly scrolling the homepage and looking for prompts to see what would happen:  \n\n\nPositive prompt: \"A female state trooper holding a rifle, in a small arizona town, desert, darkness, m4car, 1980s\"  \n\n\nNegative prompt: \"bad hands, missing fingers, extra fingers, cropped, nsfw\"  \n\n\nRefiner: wd-v1-3-float32.ckpt, \"switch at\" set to 0.8\n\n&#x200B;\n\nEuler a, everything is cranked (150 steps, CFG 30)  \n\n\nSince this model is essentially under-trained, you can crank the CFG and go crazy and it'll respond semi-nicely (in its own weird little way...) to all that madness. Next up is to test img2img.\n\n&#x200B;\n\nhttps://preview.redd.it/hk5w5dp3o7pc1.png?width=512&format=png&auto=webp&s=01d56edbc0ec8e513ee2cffeb3abadd76c2441f1"
                },
                {
                    "body": "\"hard edges hard everything all the technical architectural drawing done masterpiece\"  \n\n\n&#x200B;\n\nhttps://preview.redd.it/yh0ixvzua8pc1.png?width=512&format=png&auto=webp&s=894adf7211ee15f60e545c4447c07112f9f29051"
                },
                {
                    "body": "Oh I can't wait to play with this, thanks!"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "\"Weird Blerbie\", a math modification to the unet in Stable Diffusion v1.5",
            "body": "Why get what you want when you can get \"mostly\" what you want? Weird Blerbie is a model for those of us who like things weird. I figured out how to do math on the weights of the unet, so I did that (multiplied all of them by 0.95) and now you too can get what you want. Kind of.\n\n[https://huggingface.co/aplewe/WeirdBlerbie/blob/main/README.md](https://huggingface.co/aplewe/WeirdBlerbie/blob/main/README.md)\n\n[ \\\\\"a highly detailed technical drawing of a concept car ford ferrari lamborghini\\\\\" ](https://preview.redd.it/g3hetccbb7pc1.png?width=512&format=png&auto=webp&s=d80dd862b7c3268823961ca53bb2c535bba34e4c)\n\n[ \\\\\"a highly detailed photo of a futuristic spaceship flying through a colorful stellar nebula\\\\\" ](https://preview.redd.it/5ty0fecbb7pc1.png?width=512&format=png&auto=webp&s=41cca5054ffd57812c0ea1fe8ecd7c7542f5d66d)\n\n[ \\\\\"a beautiful princess in her finest gown watches the sunset from the balcony\\\\\" ](https://preview.redd.it/p6239ccbb7pc1.png?width=512&format=png&auto=webp&s=3576aa5d686a11e1f4e3e85557b47728abc58373)\n\n[ \\\\\"architectural photo of a minimalist interior with sleek mid-century modern furniture in a high-rise apartment in new york city\\\\\"](https://preview.redd.it/fbjkeccbb7pc1.png?width=512&format=png&auto=webp&s=3217bc8b73304a7c092c62461e27f5afdcf2e077)",
            "upvote_ratio": 0.85,
            "subreddit": "StableDiffusion",
            "num_comments": 20,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bi9fwt/weird_blerbie_a_math_modification_to_the_unet_in/",
            "comments": [
                {
                    "body": "This reminds me a lot of how dall-e mini images looked back in June 2022, any advantages using this over that?"
                },
                {
                    "body": "This feels like mashing buttons in street fighter to get special moves"
                },
                {
                    "body": "Having some fun. The neat thing about the \"refiner\" option (Automatic1111 UI) is it's basically a mix-models-on-the-fly option, where you can have another model take over generating after you get to a certain point. For instance, Weird Blerbie did this image up to 80%, then Waifu Diffusion (v1.3) took over for the last 20%. I got the prompt off of CivitAI, just randomly scrolling the homepage and looking for prompts to see what would happen:  \n\n\nPositive prompt: \"A female state trooper holding a rifle, in a small arizona town, desert, darkness, m4car, 1980s\"  \n\n\nNegative prompt: \"bad hands, missing fingers, extra fingers, cropped, nsfw\"  \n\n\nRefiner: wd-v1-3-float32.ckpt, \"switch at\" set to 0.8\n\n&#x200B;\n\nEuler a, everything is cranked (150 steps, CFG 30)  \n\n\nSince this model is essentially under-trained, you can crank the CFG and go crazy and it'll respond semi-nicely (in its own weird little way...) to all that madness. Next up is to test img2img.\n\n&#x200B;\n\nhttps://preview.redd.it/hk5w5dp3o7pc1.png?width=512&format=png&auto=webp&s=01d56edbc0ec8e513ee2cffeb3abadd76c2441f1"
                },
                {
                    "body": "\"hard edges hard everything all the technical architectural drawing done masterpiece\"  \n\n\n&#x200B;\n\nhttps://preview.redd.it/yh0ixvzua8pc1.png?width=512&format=png&auto=webp&s=894adf7211ee15f60e545c4447c07112f9f29051"
                },
                {
                    "body": "Oh I can't wait to play with this, thanks!"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "All work and no play makes your LLM a dull boy; why we should mix in pretraining data for finetunes.",
            "body": "Something that's been seen pretty commonly in open source LLM finetuning efforts that has bothered me is the fact that we are finetuning the base models in a way that is more likely to overfit.\n\nWhat I mean by this is: fundamentally, when we are training our next token predictors, we want to be careful with how much emphasis we are applying to certain things like format, style, etc.. and we want to ensure that the models still generalize well towards predicting \"normal\" data without written instructions.\n\nBut it seems that almost exclusively (in the open source world), training/finetuning efforts have been focused on datasets that **do not include general purpose pretrain data**.\n\n# Ok, but why?\n\nI think for a layman, the logical assumption that might be made is that the pretrained model has already generally learned the data. So therefore, we should exclusively train on instruct data for a short period of time to \"append\" the ability to consistently follow instructions.\n\nWhat I think this fails to consider is that model training is fundamentally a *destructive* optimization process, rather than \"additive\"; it is used to course correcting for highly variable contexts over many iterations.\n\nHowever, when you explicitly train on instruction data, you are providing it a foreign situation where the data always follows a patterned bias:\n\n\\- The data contains instructions with complete responses\n\n\\- The data has a specific prompt format, more often than not\n\n\\- Synthetic / generated data is used very frequently, which also inherits smaller individual biases\n\n\\- Multi-turn instruct data is inherently less common, so one shot instruction training skews the model towards predicting best within a smaller range\n\nConsequently, perplexity evaluation on something like wikitext tends to be **worse** after instruction finetuning, not better. If the trend of the data is always instruction based, [the model gets worse at prediction when the context is not (or is only partially) instructional.](https://en.wikipedia.org/wiki/Curse_of_dimensionality) Even if you are not intending to use the model as completion, this points to diminished overall generalization from standard finetuning.\n\nIntuitively speaking, it make sense to mix more than just instructions for this reason; it helps reinforce the broader patterns of instruction following in a way that doesn't conflict as much with generalized prediction, which is what the base model is supposed to do in the first place.\n\n# What can finetuners do?\n\nI would recommend using [RedPajama subsets](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) chosen at random and incorporating these samples as a natural part of the finetuning dataset. The RedPajama project was designed as a reproduction of the Llama dataset.\n\nIt would be nice to have ablations and comparisons of what seems to be the most effective split (as far as I'm concerned, nobody has done this yet whether it's a study or in open source), but I presume something like 25% pretraining 75% finetuning data would be an effective starting point.\n\n# What other approaches could we try as well?\n\nIt would be interesting to curate pretraining data specifically chosen to fit a broader profile for finetuning. Things like sorting by the average unpredictability of the sequences (where we might intentionally seek out higher entropy pretraining data to help avoid repetition issues) would be a natural candidate.\n\nMy main takeaway here that I hope people can learn from, is that there is still a lot of work to be done with better data engineering rather than just architectural changes.",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 14,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmslfq/all_work_and_no_play_makes_your_llm_a_dull_boy/",
            "comments": [
                {
                    "body": "In stable diffusion land they use regularisation images and LLMs likely need this too"
                },
                {
                    "body": "Why would I make my model perform worse (by forcing it to remember irrelevant information like formats it'll never see, or situations it will never encounter) just to make sure it can still perform well on a benchmark?"
                },
                {
                    "body": "Very good read, I think people tend to not know/forget that things like catastrophic forgetting occur. It is long proven that finetuning can cause the model to be a worse generalist or even make it forget some key information."
                },
                {
                    "body": "We don't want models that can memorise the entire wikipedia. We want models that can write an API call to Wikipedia that gets the information they need to answer the user request. \nA model that memorises Wikipedia is obsolete the second after if finishes training."
                },
                {
                    "body": "Sounds reasonable but I would need to see the results before doing this.¬†\nI've experimented with adding wsb comments data to the dataset in various proportions. It certainly added a certain character to the model, but it also made it almost useless when trying to use it for the classis ai assistant tasks, since it would just respond with wsb-like reply, even though wsb made something like 20% of the tokens in the dataset."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "How hard is it for big tech or anyone to compete with Nvidia in the next ten years?",
            "body": "I see what amazon eventually did to UPS and I wonder if they don't push as hard as they can to cut Nvidia out for their GPUs?  \nIs it really that impossible?  \nOr is time the magic ingredient that gives nvidia it's moat?  \nSo the other companies will always play catch up.  \nBut, on the other hand can Nvidia keep providing new things that are required or is there a point where innovation kinda stops for a while and other companies catch up.  \nI wonder if nvidia is really a good long term investment especially at this price point.  \nOr if competition is going to be a big thing.\n\nFigured asking in the AI subreddit would be better than a general investing one.",
            "upvote_ratio": 0.88,
            "subreddit": "ArtificialInteligence",
            "num_comments": 35,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bmqn9k/how_hard_is_it_for_big_tech_or_anyone_to_compete/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Question Discussion Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Your question might already have been answered. Use the search feature if no one is engaging in your post.\n    * AI is going to take our jobs - its been asked a lot!\n* Discussion regarding positives and negatives about AI are allowed and encouraged. Just be respectful.\n* Please provide links to back up your arguments.\n* No stupid questions, unless its about AI being the beast who brings the end-times. It's not.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "Nvidia is a company, which followed the blue ocean guide. Nvidia went from a video game GPU company to a company providing GPUs and software for AI. The secret sauce? CUDA, C++ API allowing the use of GPUs in video games by facilitating the real-time calculation of fluids and other particles. Then CUDA was interfaced with Python, at the same time that TensorFlow appeared.\n\n\n\nNvidia does not disperse, it adapts, the company still continues to provide tools for video games, HPC etc. The GPU is the CPU of the 21st century"
                },
                {
                    "body": "If you are talking about AI inference, then the GroqChip actually outperforms Nvidia's latest B200 in raw performance per watt at fp16 by a ratio of about 2X. However, GroqChip can't be used for training AI models (yet).\n\nApple's M series is also good for local inference because it has a Unified Memory Architecture. Many other vendors are also working on NPUs to compete at the edge (on device).\n\nSo the only advantage that Nvidia has right now is its ability to provide processors for training at scale. This isn't an advantage that is likely to last for more than a few years as more vendors adapt their inference chips to be used with training.\n\nAMD has the ability to produce GPUs every bit as powerful as Nvidia's; they just don't have as much cash to spend on R&D, so they will take a little longer to catch up.\n\nIntel also has the technical skill to be able to pull it off with GPUs.\n\nGoogle was the original company to popularize the TPU, so they are still in the game.\n\nSo Nvidia is riding the hype wave for now, but it won't last forever because there is nothing that Nvidia does that can't also be done by any of the other big players (and even some small players).\n\nThe net result is faster, cheaper AI, and gaming chips for everyone! It's a win-win all around.  \n\n\nNvidia is nowhere close to having the kind of stranglehold on the AI market that Amazon has on the home delivery market and that is a good thing."
                },
                {
                    "body": "It's funny how most of these answers never address a key part of OP's point. Amazon is producing and using chipsets from its own fabs that pack more performance per watt (like, alot) than any GPU-based chips can for AI tasks (Tranium for training and Inferentia for real-time inference). It's only a matter of time before its customers wake up and adapt these chipsets for commodity workloads.\n\nWill Anapurna Labs ever be at the cutting edge of chipset performance? Probably not. But Nvidia should be worried about the slow bleed-off from GPU-based workloads that don't need that kind of performance."
                },
                {
                    "body": "Look back a hundred years and almost none of the old Wall Street stocks have survived. There is always a better mouse trap or a richer competitor waiting to pounce.  Quantum computing could also upset the apple cart in the next ten years."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "FastSD CPU 1.0.0 beta 27 release with multi-LoRA support and Controlnet v1.1 support",
            "body": "",
            "upvote_ratio": 0.99,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bmkqm1",
            "comments": [
                {
                    "body": "Thanks! Not for me, but for anyone without a GPU."
                },
                {
                    "body": "What's new?\n\n* Add basic ControlNet v1.1 support(LCM-LoRA mode),thanks¬†monstruosoft\n* Add ControlNet annotators(Canny,Depth,LineArt,MLSD,NormalBAE,Pose,SoftEdge,Shuffle)\n* Pytroch 2.2 upgrade\n\nRelease : [https://github.com/rupeshs/fastsdcpu/releases/tag/v1.0.0-beta.27](https://github.com/rupeshs/fastsdcpu/releases/tag/v1.0.0-beta.27)\n\nControlnet support : [https://github.com/rupeshs/fastsdcpu?tab=readme-ov-file#controlnet-support](https://github.com/rupeshs/fastsdcpu?tab=readme-ov-file#controlnet-support)"
                },
                {
                    "body": "So now it is possible 400fps on gpu ?"
                },
                {
                    "body": "This works surprisingly well on my 2015 Intel Mac!"
                },
                {
                    "body": "Coolüéâ"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Current best local LLM / agent setup for processing local files (PDFs, .doc, images ..) ?",
            "body": "Hi,\n\nI'm an engineer who uses ChatGPT Plus and played with early Ollama / LMStudio some months ago, but I stopped short of using agents, and things have moved so fast that I now feel completely out of the loop.\n\nWould you guys have some advice on the best current tools for the following two use cases for local LLMs that I have at home ?\n\n1.**Taxes**\n\nI'd like to re-check my past 3-4 years of (UK) tax returns for possible mistakes and missed optimizations, so I can submit amendments asap if necessary.\n\nI have a bunch of Google Sheets, Apple Notes, and local folders with PDFs of previous tax returns / bank statements / misc documents, and CSVs with stocks/crypto purchases/sales.\n\nAdded difficulty : most of the docs are in English but some of them are in French.\n\nI'd like to do stuff like :\n\n\\- \"Here are my filled PDF tax returns : in which year(s) did I take advantage of this or that rule, how much do I have left on this/that allowance before I reach a threshold\"  \n\\- \"Here are 3 years of PDF bank statements : can you list all operations that seem related to asset/activity xyz ?\"  \n\\- \"Here are my CSVs with stocks trading activity : can you work out my capital gains, taking into account stock splits, the fact that stock ABCD changed its name to WXYZ, and the accounting rules used in the UK\"\n\nIdeally whatever LLM/agent I use for this would be :\n\n\\- browsing enabled so it can look up tax rules online if it isn't sure.  \n\\- able to work directly with my local files when I point it at a folder.  \n\\- able to use my Google Docs directly (not a dealbreaker, I can always export them to PDF / XLS)\n\nI guess my best bet would be ChatGPT + code interpreter, but it isn't private and it can't work on my folder of local files directly, AFAIK.  \nIt's also not an agent and would require constant handholding + manually uploading each file.\n\n**2. Medical**\n\nMy wife is a doctor and **a lot** of her time is (unfortunately) spent writing reports, letters, slides, with patient files and rough text/voice consultation notes as inputs.\n\nFor many of these tasks, LLM assistance could save her a ton of time, but obviously sending **any** confidential patient data to GPT-4 or Claude 3 is a big no-no. It has to remain fully local.\n\nShe's going to need a nicer ChatGPT-like UI than I do, and ideally something with vision that would seamlessly be able to work on local files as well.\n\n**Available hardware**\n\n32GB M2 Pro Mac Mini, 16GB M1 Macbook Air (mine), 16GB Intel Macbook Air (my wife's - not hoping much for this machine).\n\nMy thinking is to run the best model I can on the 32GB Mac Mini (there are decent quantized ones that fit 32GB, right ?), but I have no idea about how embeddings / local files / vision would work in this setup.\n\nIs it doable ? Are there turnkey solutions ? I'm knowledgeable enough to install fully manually if there's no other option, but always keen to save time & hassle.\n\nI'm also happy to spin up temporary cloud instances if that makes more sense (especially if there are off the shelf scripts that do it for you given a GCP / AWS / Azure key). Still a no-no for the medical stuff, but I'd be comfortable uploading at least my tax documents (or just embeddings ?) there.\n\nThanks !",
            "upvote_ratio": 0.93,
            "subreddit": "LocalLLaMA",
            "num_comments": 13,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bma2cm/current_best_local_llm_agent_setup_for_processing/",
            "comments": [
                {
                    "body": "Recently discovered https://github.com/n4ze3m/dialoqbase\nlocally hosted chatbots.\nI use it to connect to an ollama instance. Running Mistral 7b instruct.\nSome cool integrations like webcrawling or ability to upload PDFs.\nI use telegram as my UI"
                },
                {
                    "body": "I built something that does most of this. Very likely release date by next month."
                },
                {
                    "body": "I don‚Äôt think it will do anything useful with your taxes. Gpt4all and sanctum ai are local LLMs that handle documents. The latter is easier to use. Former permits more model choices."
                },
                {
                    "body": "Taxes and accounting are notoriously complicated and full of edge cases. The bank statement problem is the only one you can realistically solve with AI. Reading a large amount of stuff (documents, entire folders, etc.) is also a bit tricky as even the largest contexts (16-32k) are basically tiny, so you need to be clever and make your problem as compartmentalized as possible.\n\nFor example, I'm working on a spotlight-like tool for Windows/Mac which integrates with systemwide contexts/web browsers/slack/discord/file browsers/etc. and can automate *some* tasks (using a local LLM), but I'm keeping it as simple as possible. For example, when I'm on a Github web page, I can ask the agent to \"clone this repo\" and it does that successfully. With that said, I think that even remotely complex tasks are still way out of reach of even things like GPT-4, let alone locally-run language models."
                },
                {
                    "body": "About the financial operations (banking and stocks trading) if you have structured data like csv you can definitely use a model to write some code for you to answer questions. It works pretty well: I had success with the Deepseek models to generate charts from csv ([example](https://synw.github.io/agent-smith/examples/data_viz)).\n\nAbout more common tasks like writing letters an standard documents from patient files I guess a good 7b to 13b can handle that. I would try a few shots prompts with different models good at writing for this task."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Claude Opus is INCREDIBLE.",
            "body": "This is by far the best model I ever tried, I even think it outperforms GPT-4...Have you guys tried Claude Opus?",
            "upvote_ratio": 0.84,
            "subreddit": "ArtificialInteligence",
            "num_comments": 39,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bl9zj3/claude_opus_is_incredible/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Question Discussion Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Your question might already have been answered. Use the search feature if no one is engaging in your post.\n    * AI is going to take our jobs - its been asked a lot!\n* Discussion regarding positives and negatives about AI are allowed and encouraged. Just be respectful.\n* Please provide links to back up your arguments.\n* No stupid questions, unless its about AI being the beast who brings the end-times. It's not.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "Yes I have a subscription to both Claude 3 and GPT-4. I use mostly Claude these days, but I will still pop over to GPT for some things like questions with factual answers.\n\nBoth are good, and both annoy the hell out of me by constantly referring me to experts, telling me it's important to strike a balance, and reminding me that they're just an AI without opinions or thoughts on anything."
                },
                {
                    "body": "It's about on par with ChatGPT 4 in my opinion. I absolutely hate that I can't stop Claude mid-answer, which annoys me enough that I often switch back to ChatGPT to save time. And, it can't access the web yet."
                },
                {
                    "body": "Asked paid version of claude to proof read my website and give it's opinion.\n\nCouldnt browse the web but had no problem reading screen shots and giving optional re-writes.\n\n\n\nAsked chat gpt plus to check my site.  I could give it a link but when I asked it to Grammer and spell check it, chart gpt just refused and said to have it proof read and use grammerly. \n\n\nTried to use chat ceo jailbreak and still wouldn't proof read the site.  Told it I was going to fire it....chat gpt didn't care.\n\n\nI'm likely to cancel chat gpt until they have a major update."
                },
                {
                    "body": "In some ways it feels worse, but for mathematics and programming it seems way better in my experience."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "TacticAI, an AI football tactics assistant model, whose suggestions are not only indistinguishable from real tactics, but also favoured over existing tactics 90% of the time, using geometric deep learning",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.nature.com/articles/s41467-024-45965-x",
            "comments": [
                {
                    "body": "I assume this type is used for military operations as well."
                },
                {
                    "body": "I suggested when my teams last manager left (4th in 3 years) we should just use AI. Ridiculed."
                },
                {
                    "body": "Cool!"
                },
                {
                    "body": "Looking forward to the US military scrum-charging the enemy while throwing a large bomb, passing it between soldiers."
                },
                {
                    "body": "Sir, this is not your American hand egg game. This is *foot*ball, or soccah as you like to call it."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Several key AI developers who worked on Stable Diffusion, the company's popular text-to-image generator, have resigned, Forbes reports.",
            "body": "Oh dear!\n\n[https://futurism.com/the-byte/stability-ai-is-falling-apart](https://futurism.com/the-byte/stability-ai-is-falling-apart)\n\n\"Several key AI developers who worked on Stable Diffusion, the company's popular text-to-image generator, have resigned, [*Forbes* reports](https://www.forbes.com/sites/iainmartin/2024/03/20/key-stable-diffusion-researchers-leave-stability-ai-as-company-flounders/?sh=bebe7152ed67).\n\n\"The company has already [struggled](https://futurism.com/the-byte/stability-ai-stable-diffusion-chaos) with dwindling cash reserves and departures of executives. In August, six senior hires, including the company's chief operating officer and head of research, [left the company](https://finance.yahoo.com/news/stability-ai-losing-executives-engineers-050010638.html).\n\n\"Researchers close with the original creators of the tech that led to the creation of Stable Diffusion have since accused the company of misleading the public over how much its employees had contributed to the tool's development, as [*Forbes* previously reported](https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1058bf1075c5). In other words, Mostaque underplayed just how heavily his company was leaning on existing research by the scientists, several of whom have now left Stability AI.\"",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 6,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bk4y7j/several_key_ai_developers_who_worked_on_stable/",
            "comments": [
                {
                    "body": "As always, the fault lies with management."
                },
                {
                    "body": "Early on I was kind of enamored with Emad, but lately the more I hear from him the more he just comes off as a sleazy salesman..."
                },
                {
                    "body": "I don't even use stable diffusion."
                },
                {
                    "body": "They have a gold mine in their hands, and what they do? Fuck with the miners."
                },
                {
                    "body": "Never heard of it! ;)"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[Project] Sparse Mixture of Experts Language Model from Scratch in less than 300 lines of Python + pytorch",
            "body": "Hi all,I implemented a sparse mixture of experts language model (basically a tiny version of what's used in Mixtral, Grok-1 and supposedly GPT-4) from scratch in pure pytorch and trained it on tiny Shakespeare. This is based largely on makemore from Andrej Karpathy (an autoregressive character-level decoder only transformer model). My goal is for this to be a hackable implementation that people use to understand how this really works and improve upon. I foresee more and more of these models coming out throughout the year.\n\nThe repo is here: [https://github.com/AviSoori1x/makeMoE](https://github.com/AviSoori1x/makeMoE)\n\nI created this a couple of months ago and shared on Localllama but figured I'd share here as well, since I made some updates like adding expert capacity and consolidating the entire implementation to less than 300 lines of readable python + pytorch. The blog that steps through this is here: [https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch](https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch). Hope this is helpful!",
            "upvote_ratio": 0.91,
            "subreddit": "MachineLearning",
            "num_comments": 5,
            "submission_flair": "Project",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bjg04g/project_sparse_mixture_of_experts_language_model/",
            "comments": [
                {
                    "body": "That's somehow a very complex code for such a simple implementation. If you want to read the code to make sparse MOE, go to hf's transformers library, you've got the source code for it (with the custom loss function for the sparsity)."
                },
                {
                    "body": "Why so many people put any emphasis in \"... less than x lines of code\" is beyond my understanding"
                },
                {
                    "body": "Appreciate the feedback. Part of it has to do with the 'from scratch' aspect. The point of this was to hand roll attention and gating etc. But for a real practical implementation you can use existing custom modules and things will be much shorter (attention in pytorch even supports flashattention 2). Also there's no implementation for this on transformers right now: [https://github.com/huggingface/transformers/issues/14814](https://github.com/huggingface/transformers/issues/14814). If you want higher level abstractions for actually training a model at scale I would suggest this: https://github.com/stanford-futuredata/megablocks"
                },
                {
                    "body": "The issue is from 3 years ago.\n\nHere's the implementation I was talking about : https://github.com/huggingface/transformers/blob/main/src/transformers/models/mixtral/modeling_mixtral.py"
                },
                {
                    "body": "Ah I see. Thanks! I remember seeing this. I thought you were referring to their trainer"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "qlora-pipe: Fine tune 70B parameter models with two 3090s",
            "body": "[https://github.com/tdrussell/qlora-pipe](https://github.com/tdrussell/qlora-pipe)\n\nThis is a training script I made so that I can fine tune LLMs on my own workstation with 4 4090s. It is based around Deepspeed's pipeline parallelism. This means it can train models too large to fit onto a single GPU. Notably, you can fine tune even 70B parameter models using QLoRA with just two 24GB GPUs. There's a lot more details in the README.\n\nI made this code public about a week ago, and I think it's in a good enough state to advertise more broadly. I am aware of at least one other person successfully using this to train QLoRAs on Mixtral. That being said, treat this as a pre-alpha release. It will likely be rough around the edges. But I hope showing that this kind of thing is possible is still useful.",
            "upvote_ratio": 0.98,
            "subreddit": "LocalLLaMA",
            "num_comments": 13,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bit5h9/qlorapipe_fine_tune_70b_parameter_models_with_two/",
            "comments": [
                {
                    "body": "Really nice work, seems straightforward and simple to run. The fact that you take raw text files is great as it helps people new to training testing quickly without having to mess with preparing their data.¬†¬†\n\n\nI poked around the code but didn't see a function for overlapping when you're generating the chunks for the raw text. That's usually useful for that form as things can get cut off awkwardly and it helps to increase context learning. Trainers like ooba have a function for adjusting chunk overlap size to rectify this. Shouldn't be too hard to implement either."
                },
                {
                    "body": "How does this compare with the [fsdp\\_qlora](https://github.com/AnswerDotAI/fsdp_qlora) repo that came out a week or so ago?\n\nI haven't gotten around to using it yet, but I had a pretty tough time training a 70B on 4 3090s a little while back, and I'm not familiar with the difference between pipeline parallelism and FSDP."
                },
                {
                    "body": "How would you say this compares to the QLoRA training methodology in Ooba?\n\nI haven't had any major issues once I did a slight alteration to the loading schema. Ooba, by default, will use balanced mode with transformers, equally splitting the model across GPUs without taking into account the overhead of the code used to run it, and disabling the ability to balance the load. I ended up editing one file to make it use sequential loading and gained the ability to fine tune the balance.\n\nJust for reference, I'm talking about the QLoRA method I outlined in this intro tut:\n\nhttps://www.reddit.com/r/Oobabooga/s/R097h5sY62"
                },
                {
                    "body": "Will it work in kaggle?"
                },
                {
                    "body": "That's really exciting! I've been holding off on moving up to training 70b models for a while now. The larger the model, the more annoying dealing with failures gets. But even in a pre-alpha this is tempting enough to seem fun."
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Cobra: Extending Mamba to Multi-modal Large Language Model for Efficient Inference",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 3,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://github.com/h-zhao1997/cobra",
            "comments": [
                {
                    "body": "https://preview.redd.it/eshrs47kv9qc1.png?width=425&format=png&auto=webp&s=f8c8c50becab2e5f861231ab3ff7f8abb832b238\n\nMaybe this is  the first open source model that can count car correctly !"
                },
                {
                    "body": "em..  I thought it's easy to count in this kind of image with obivous dividing lines."
                },
                {
                    "body": "No ! \n\nhttps://preview.redd.it/q6gqgt1zofqc1.png?width=778&format=png&auto=webp&s=361cfff0277d8a86f01e26abf536e6207f39724c"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Doing Super (model used was Easy Mode)",
            "body": "",
            "upvote_ratio": 0.77,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bm5qbz",
            "comments": [
                {
                    "body": "Good to see Richard Gere getting work"
                },
                {
                    "body": "Sample run is available at the below link.  Accidently uploaded a mega fail as part of this (you'll know it when you see it) \n\n[https://tungsten.run/r/ed9ddc88-dfba-4ed8-a5da-82f2f79256f9](https://tungsten.run/r/ed9ddc88-dfba-4ed8-a5da-82f2f79256f9)\n\nModel is Easy Mode, it can do a lot of fun stuff, though despite claims it doesn't need LORAS, it generally does, and a lot of prompting on hands.\n\n[https://tungsten.run/evevalentine2017/easymode-turbo-xl](https://tungsten.run/evevalentine2017/easymode-turbo-xl)"
                },
                {
                    "body": "What is the difference between a Deepfake and a Shallowfake? XD"
                },
                {
                    "body": "super girl was blonde ü§∑‚Äç‚ôÇÔ∏è"
                },
                {
                    "body": "No bottles, no upvotes."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "r/ChatGPT normies",
            "body": "It's hillarious how different the perspectives of AI in r/singularity and r/ChatGPT are. Most posts from r/ChatGPT always have some delusional super highly upvoted comment about how LLMs are not smart or creative at all, as they are just algorithms that predict the next token. Whereas this sub is like AGI next month every month. ",
            "upvote_ratio": 0.72,
            "subreddit": "singularity",
            "num_comments": 56,
            "submission_flair": "memes",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjpb7a/rchatgpt_normies/",
            "comments": [
                {
                    "body": "GPT: AI is ok for drafting emails I suppose \n\nSingularity: We won‚Äôt have to go to work next week right?"
                },
                {
                    "body": "And then there‚Äôs r/Bard where every other post is FUCK THIS CENSORSHIP WHY WONT IT TALK TO ME ABOUT POLITICS AND BIG TITTIES"
                },
                {
                    "body": "/r/chatGPT was flooded with 10 year olds after DALLE3 was released. flooded like a tsunami\n\nanyone else stopped going on /r/chatgpt after dalle3 was released?"
                },
                {
                    "body": "I'm one of the fat&sweaty janitors for r/ChatGPT and I like both subs a lot. There's just a difference in culture from the ground up and once you appreciate that, both subs serve purposes the other doesn't. This sub has a much more serious ideological slant than /r/ChatGPT - you're likely to not even find this sub if you don't already know what the singularity is and find the idea interesting. /r/ChatGPT is where everyone who just heard the term \"ChatGPT\" on social media goes, so naturally it's got a lot more casual users. When I wanna see a funny dalle pic I go to r/ChatGPT and when I wanna talk about how AI is going to change everything I go here."
                },
                {
                    "body": "I wonder why this mindset is so common? Is it truly a common mindset?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "A knight getting older.",
            "body": "",
            "upvote_ratio": 0.77,
            "subreddit": "StableDiffusion",
            "num_comments": 6,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bi5l29",
            "comments": [
                {
                    "body": "https://preview.redd.it/nr9gp8izy6pc1.jpeg?width=1024&format=pjpg&auto=webp&s=21f92a2e22e32d2e8d426845148efd533175dae3\n\n. a ridley scott movie, medium  shot, a red head knight wearing an armour, dirt , backlighting , unkept  hair, elaborated , intricate . scars .,engraving , long beard and hair, crazy eyes.sunset, battlefield medieval troops background\n\n[Jib Mix Realistic XL](https://civitai.com/models/194768?modelVersionId=369062)v9.0 Better Bodies"
                },
                {
                    "body": "Unless you have prosopagnosia, that's four different Knights with the same hair and eye color."
                },
                {
                    "body": "the second ones eyes bug me alot"
                },
                {
                    "body": "Is this SD?"
                },
                {
                    "body": "Looks more like HD"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "What I have been testing lately",
            "body": "",
            "upvote_ratio": 0.71,
            "subreddit": "StableDiffusion",
            "num_comments": 19,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/pz5d7ubps2qc1",
            "comments": [
                {
                    "body": "Damn this is good"
                },
                {
                    "body": "Looks amazing brother. \n\nCan you plz help me. Like I'm confused in RTX 4060 ti 16 gb and RTX 4070 super 12 gb I'm just starting with ai and used to work in colab so if you suggest me."
                },
                {
                    "body": "So you made the character mesh and texture in a modeling program (you mention Cinema 4D) first, then image2image a render of the t-pose to create different style variants of the texture?\n\nI have been thinking about making a 3d character in Blender, sending the FBX to Adobe's Mixamo AI to create the rigging system, rendering multiple angles of the character, and then using Kohya to train a lora - if I could do that I could maybe use Stable Diffusion tools to retexture the character like you are doing here?\n\nAnother idea would be to run UV unwrapped image-maps through Ultimate SD upscale and use different sampling methods and checkpoints to restylize the texture."
                },
                {
                    "body": "Good trip. Lots of potential. Any socials where can see ur work?"
                },
                {
                    "body": "[deleted]"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "AI can now detect COVID-19 in lung ultrasound images",
            "body": "https://www.sciencedaily.com/releases/2024/03/240320160609.htm",
            "upvote_ratio": 0.87,
            "subreddit": "singularity",
            "num_comments": 2,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl22ou/ai_can_now_detect_covid19_in_lung_ultrasound/",
            "comments": [
                {
                    "body": "I mean who‚Äôs gonna go get an ultrasound to see if they have covid though"
                },
                {
                    "body": "Good point"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Sakana.ai presents: Evolving New Foundation Models: Unleashing the Power of Automating Model Development",
            "body": "",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://v.redd.it/jdlbughe3ppc1",
            "comments": [
                {
                    "body": "Release Blog: https://sakana.ai/evolutionary-model-merge/\n\nArxiv: https://arxiv.org/abs/2403.13187\n\n\nAbstract: We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development."
                },
                {
                    "body": "Can it also apply for SD models ?"
                },
                {
                    "body": "One of the authors, and co-founder of this start-up is David Ha, who you might remember from the subreddit takeover incident:\n\n\nhttps://www.reddit.com/r/StableDiffusion/comments/y1nc7t/rstablediffusion_should_be_independent_and_run_by/\n\n\n\nHe left Stability and started this company to do research at fundamental level. Did not expect this company to do model merging experiments."
                },
                {
                    "body": "This is extremely interesting, particularly this part taken from their website:\n\n>As researchers, we are surprised that our method is able to automatically **produce new foundation models without the need for any gradient-based training, thus requiring relatively little compute resources**. In principle, we¬†*can*¬†employ gradient-based backpropagation to further improve performance, but the point of this release is to show that even¬†*without*¬†backprop, we can still evolve state-of-the-art foundation models, challenging the current paradigm of costly model development.\n\nThis could indeed mark our entry into a brand new paradigm !\n\nIf I were working for civitai or huggingface, I would not want to miss this opportunity."
                },
                {
                    "body": "Yes, but it doesn't look like they've explored that too much. They report doing a relatively basic merge with a japanese XL model with a LightningXL model. I'm not sure if it's possible to use their evolution merging to mix an LLM with an LDM, but it sure sounds interesting."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Starling-LM-7B-beta",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 28,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://huggingface.co/Nexusflow/Starling-LM-7B-beta",
            "comments": [
                {
                    "body": "Can someone explain the prompt template? What exactly do we write?"
                },
                {
                    "body": "Seems like beta version is significantly more verbose than alpha. I specifically liked Starling-LM for it's briefness and straight to the point approach. I'm keeping both for now, but for productivity tasks like writing summaries, describing things, assessing code, etc it feels like a downgrade so far."
                },
                {
                    "body": "Real shame they didn‚Äôt build on the 0.2 7B Mistral model. I know it‚Äôs instruct tuned already but it‚Äôs much more coherent at longer context with the shift to a higher rope frequency and without the sliding window."
                },
                {
                    "body": "I've created and tested some quants of this model using an adapted imatrix mix. Here are the resulting scores:\n\n|Quant (MiB size)|Perplexity wiki.test.raw|Hellaswag 10K|\n|:-|:-|:-|\n|FP16 (14484)|6.1711|81.87612029|\n|Q8\\_0 (7695)|6.1741|81.77653854|\n|Q6\\_K (5942)|6.1681|81.93586935|\n|Q5\\_K\\_S (4997)|6.1963|81.72674766|\n|IQ4\\_NL (4125)|6.2594|81.46783509|\n|IQ3\\_XS (3001)|6.4879|80.39235212|\n|IQ2\\_XS (2198)|7.8484|76.28958375|\n|IQ1\\_S (1612)|16.1992|58.31507668|\n\nThe PPL of Q6\\_K is lower than that of the original FP16. Usually *the only way is up*. Keep in mind though that all PPL results come with a +/- 0.04 accuracy, so that result might just be noise. But: It also scored better on Hellaswag. The test set has 10042 questions. It thus answered 6 additional questions correctly that FP16 failed. Lucky dice-roll? The scores for IQ4\\_NL are still pretty good. After that they start to deteriorate more.\n\nI've got surprisingly good summarization results from IQ2\\_XS when using: --temp 0 --repeat-penalty 1.1 --repeat-last-n 128  \nSo, I decided to test it on this this thread just for fun with this prompt (using the appropriate template): \"Here is a reddit comment thread about a new LLM. Point out which users contributed relevant information to the thread.\"\n\n>It looks like there are several users who contributed relevant information in the Reddit comment thread about the new LLM (Large Language Model). Some of these users include:\n\n>1. Exotic-Investment110 - The user asked about the prompt template and started the discussion on the topic.\n\n>2. pseudonerv - They provided a link to the README file, which contains information about the prompt template and its purpose.\n\n>3. dizvyz - They raised a concern about filtering out low-quality responses, leading to a discussion about mixed-quality data and how it affects the model's performance.\n\n>4. thereisonlythedance - They shared their thoughts on the 0.2 base version of the model and its advantages for fine-tuning purposes.\n\n>5. PavelPivovarov - They provided examples of outputs from different models (Starling-LM Alpha and Starling-LM Beta) in response to the question \"What is Apperol?\"\n\n>6. Sebba8 - They mentioned that the 0.2 base version is still trained on the regular base model but with an improved instruct tune.\n\n>7. MoffKalast - They expressed their anticipation for the upcoming Llama 3 release and contributed to the discussion about the differences between various models.\n\n>These users have shared valuable insights, experiences, and opinions on the new LLM, which can help others understand its capabilities and limitations better."
                },
                {
                    "body": "openchat 0106 is amazing so this finetune should at least be great. Used previous version that wasn't finetune of openchat and it was already amazing before switching to openchait 0106"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Scientists have showcased the effective utilization of high-frequency radio waves to transiently breach bacterial cell walls, facilitating the introduction of new genetic material.",
            "body": "",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 2,
            "submission_flair": "Biotech/Longevity",
            "has_media": false,
            "url": "https://pubs.acs.org/doi/10.1021/acs.nanolett.3c03464",
            "comments": [
                {
                    "body": "This ground-breaking technique enables the enhancement of bacteria to produce essential medications such as insulin, opening new avenues for pharmaceutical advancements."
                },
                {
                    "body": "Cool"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "The Right to Compute",
            "body": "So, I was watching the Friedman/Altman interview and Altman mentions that he believes that compute will be the \"currency of the future\". If this is so, then corporations such as Google and Microsoft will have allot of power, and normal people will have just about none. This power difference will likely get worse the closer we get to AGI and naturally post-AGI as well.\n\nOne possible solution to this problem of monopolization would be to give citizens some kind of right to compute, maybe as a percentage of the total compute available in a country or some kind of other way. The compute doesn't have to be free: it would just be the right for each citizen to buy a certain amount of compute over time at competitive prices to compete with Microsoft or Google (compute unit to compute unit, not citizen versus the entirety of Google).\n\nWhat do you think?",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 23,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bi9fut/the_right_to_compute/",
            "comments": [
                {
                    "body": "Access to AGI needs to be a human right, all countries should already be building super data centers to guarantee the operation and provision of this service that will be completely indispensable to their entire nation, whoever does not have access to AGI will be in the greatest social disparity in history human"
                },
                {
                    "body": "Decentralised compute ü§î"
                },
                {
                    "body": "Or start mass worker co ops funded by mass donations that can begin to combat these companies hold on resources. Start mass worker Unions to help empower and enrich people to further accelerate funding of said worker co ops that offer employment to those fired for union activity."
                },
                {
                    "body": "You could make the same argument about money and power, and look how well that's working.\n\nYou just need some money and you can buy some compute/power all to yourself."
                },
                {
                    "body": "The answer is that you have functional markets with \n effective anti-trust regulators to break up abusive monopolies and cartels.\n\nThe nice thing is that this also does wonders for *everything else*."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Nvidia GTC: Early Takeaways about the Future of Chips and AI",
            "body": "Hey guys, just saw Jensen's GTC keynote and wanted to share my takeaways and see what you guys think. Please correct me or add to the below wherever applicable:\n\n1. Moore‚Äôs Law is truly dead: In the 2+ years since the announcement of Hopper H100, TSMC has been unable to sufficiently mature their new 3nm node. While used by Apple for their small mobile SoCs, clearly 3nm is not scaling up to support high yields on large chips such as the new B100 announced today, as it used the same 4NP process as H100. This is unusual. H100 sports 80B transistors in a \\~800mm2 chip and B100 seems slightly larger, though still around 800mm2 with 104B transistors. 4NP has clearly matured to support slightly larger chips and density, but the traditional scaling obtained from node-shrinks is completely missing.\n\n2. Nvidia finally goes in on chiplets: For the longest time, Nvidia refused to put together multiple chips into a single package, instead preferring to fab monster 700-800mm2 chips with poor yields while AMD and Intel have long adopted multi-chip module (MCM) chiplet designs to scale performance-per-package. B100 is now 2x800mm2 chips totaling \\~210B transistors, an exciting change! Which brings me to my next point‚Ä¶\n\n3. Advanced packaging will shape the future of chip-advancements: As traditional scaling of transistors slows, chip-designers will increasingly rely on advanced packaging such as multi-chip module (MCM) chiplet designs and stacking to continue performance scaling. In addition to chiplets, Nvidia‚Äôs new B100 also utilizes TSMC‚Äôs advanced 2.5D CoWoS (Chip-on-Wafer-on-Substrate) packaging to build these monstrous, super-chips in a single package. AMD already uses 3D-stacked cache and Intel is developing their own tech, named ‚ÄúFoveros‚Äù to compete with TSMC‚Äôs 3D packaging solutions. Expect more in the future.\n\n4. Scalability via software: Not just is B100 2x chiplets, Jensen states B100 is a ‚Äúplatform‚Äù, wherein each board features 2xB100 packages for a total of 4 chips. This will make comparisons with H100 skewed to say the least! Regardless, their new DGX NVL72 system is insane, featuring 30TB of VRAM and many chips that‚Äôll all be seen as one GPU by CUDA! This demonstrates how crucial advanced software is to scalability: modifying CUDA to see a massive DGX system with many multi-package chips as a single GPU with a unified 30TB of VRAM is very impressive indeed! Expect this system to cost double-digit millions though.\n\n5. Classic Nvidia misdirection with misleading charts: Dramatic charts show B100 to be magnitudes faster than H100, all while they‚Äôre comparing H100‚Äôs FP16 performance to B100‚Äôs newly supported FP4-format performance! Both are completely different things, and such charts are misleading!\n\n6. No mention of FP16, FP32 and FP64 performance: I saw no mention of half, full and double precision floating-point performance, which are dominant FP formats. Such avoidance has traditionally been a bad sign as it implies the gen-over-gen performance gains are unimpressive. All comparisons were instead against B100 FP8 & FP4 performance, which is a vastly different metric.\n\n7. New FP formats welcome: Research shows that training in FP8 format dramatically improves performance by reducing training time while showing virtually no loss of precision despite the scale-down from the typical FP16. Native support for FP8 and even FP4 is great, but these formats are not widely used to train models today so the benefits may be a way off, which makes me even more annoyed at those charts!\n\n8. Massive memory: Needless to say, this is very welcome.\n\nTL;DR - Nvidia is going to make even more money and AI is going to be even more scary in the very near future.",
            "upvote_ratio": 0.93,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bixctq/nvidia_gtc_early_takeaways_about_the_future_of/",
            "comments": [
                {
                    "body": "Moore's law was always a limited instance of the Law of Accelerating Returns. The fact that they made significant growth in how much data their tech can process proves that this is still driving the growth. Focusing only on transistors is myopic and misses the whole rain why Moore's law mattered."
                },
                {
                    "body": "The world is going to become a giant supercomputer isn't it..."
                },
                {
                    "body": "> ¬†Research shows that training in FP8 format dramatically improves performance by reducing training time while showing virtually no loss of precision\n\nCan you source this? I was under the impression that the low-precision floating point datatypes are only useful for inference."
                },
                {
                    "body": "we are transforming this planet into a machine world."
                },
                {
                    "body": "Here's a paper: [https://arxiv.org/abs/2310.18313](https://arxiv.org/abs/2310.18313)\n\nReddit thread: [https://www.reddit.com/r/LocalLLaMA/comments/17jjopb/fp8lm\\_training\\_fp8\\_large\\_language\\_models/](https://www.reddit.com/r/LocalLLaMA/comments/17jjopb/fp8lm_training_fp8_large_language_models/)\n\nAbstract:\n\nIn this paper, we explore FP8 low-bit data formats for efficient training of large language models (LLMs). Our key insight is that most variables, such as gradients and optimizer states, in LLM training can employ low-precision data formats without compromising model accuracy and requiring no changes to hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision framework for training LLMs. This framework offers three levels of FP8 utilization to streamline mixed-precision and distributed parallel training for LLMs. It gradually incorporates 8-bit gradients, optimizer states, and distributed learning in an incremental manner. Experiment results show that, during the training of GPT-175B model on H100 GPU platform, our FP8 mixed-precision training framework not only achieved a remarkable 42% reduction in real memory usage but also ran 64% faster than the widely adopted BF16 framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer Engine by 17%. This largely reduces the training costs for large foundation models. Furthermore, our FP8 mixed-precision training methodology is generic. It can be seamlessly applied to other tasks such as LLM instruction tuning and reinforcement learning with human feedback, offering savings in fine-tuning expenses. Our FP8 low-precision training framework is open-sourced at¬†[aka.ms/MS.AMP](https://github.com/Azure/MS-AMP)."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "SEC Chair Gary Gensler warns: Unchecked AI could spark future financial meltdown",
            "body": "A growing dependence on artificial intelligence could pose a danger to the U.S. financial system, and regulators need to rethink their siloed approach to rulemaking to minimize the risk, Securities and Exchange Commission Chair Gary Gensler said.\r  \n\r  \nThe SEC and other Washington regulators are grappling with the rise of powerful AI systems that can augment or replace human decision-making. But in the financial industry ‚Äî where banks, brokers and investment firms oversee trillions of dollars ‚Äî the potential for economic disaster is especially acute, Gensler said.\n\nStory: https://www.politico.com/news/2024/03/19/sec-gensler-artificial-intelligence-00147665\n\nPodcast: https://politico-tech.simplecast.com/episodes/sec-chair-gensler-on-ais-threat-to-wall-street-i-dont-want-everybody-to-drive-off-the-cliff",
            "upvote_ratio": 0.8,
            "subreddit": "ArtificialInteligence",
            "num_comments": 31,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bim79k/sec_chair_gary_gensler_warns_unchecked_ai_could/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### News Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the news article, blog, etc\n* Provide details regarding your connection with the blog / news source\n* Include a description about what the news/article is about. It will drive more people to your blog\n* Note that AI generated news content is all over the place. If you want to stand out, you need to engage the audience\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "Like more acute that the multiple once-in-a-lifetime financial disasters we had in the last 2 decades from those people that oversee trillions?\n\nThe SEC is a toothless joke, by design. At this point I would trust an AI more than the fucknuggets that are in control of wall street right now."
                },
                {
                    "body": "Why should anyone listen to these soulless ghouls who have allowed corporations to run rampant over working people, taking advantage and oppressing workers at every possible opportunity?  They don't have the best interest of average people in mind with their rulings.  They only care about what benefits corporate owners and executives.  This corrupt system breaking apart at the seams due to AI and mass automation is the best thing that could possibly happen.  Like breaking the chains off the slaves."
                },
                {
                    "body": "That's the hope. Gotta burn it down for any meaningful change."
                },
                {
                    "body": "Eventually the labor based economy won't exist, and we've already passed the point of return considering the tragedy of the commons dilemma. We might want to be working towards a new cooperative system that's based on merit and interest rather than an abstract exchange of labor. \n\nWe will see never ending panic from people trying to protect dying systems that are inevitably doomed. Expect this story in different forms for years to come, until they have to accept the new world."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "SoundHound to Offer On-Chip Voice AI with NVIDIA That Delivers In-Vehicle Generative AI Responses With No Connectivity Required",
            "body": ">NVIDIA DRIVE will enable SoundHound Chat AI ‚Äì a breakthrough in-vehicle voice platform that combines both real-time and generative AI capabilities ‚Äì to provide responses even when there is no connectivity.\n\nAmong a range of use cases, the new solution will let drivers access SoundHound Vehicle Intelligence, a product that instantly delivers information directly from the car manual and other relevant data sources using natural speech.\n\nVehicle Intelligence understands a verbal request and seamlessly provides answers ‚Äì including settings, safety, troubleshooting, and vehicle maintenance ‚Äì without the need for a cumbersome physical document. Examples include:\n\n- \"I see a flashing light that looks like a car battery and I‚Äôm not sure what that means?\"\n\n- \"What does the ‚Äòauto hold‚Äô button do?\"\n\n- \"How do I use that feature that lets me drive hands-free safely?\"\n\nIn addition to Vehicle Intelligence, users can ask more general questions that can help drivers plan a trip or a vacation, such as:\n\n- \"Where are the best locations to take photographs on the Pacific Coast Highway?\"\n\n- \"Which wineries offer riesling in Carmel Valley?\"\n\n- \"What kinds of dishes count as Californian cuisine?\"\n\nThis cutting-edge technology opens up huge opportunities for automakers looking to give drivers rapid voice-enabled access to LLM capabilities with the added benefit of greater privacy, flexibility, and lower operating costs.",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 2,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://finance.yahoo.com/news/soundhound-offer-chip-voice-ai-220200372.html",
            "comments": [
                {
                    "body": "I excited to see this in teslas, they are miles ahead of everyone in terms of fsd"
                },
                {
                    "body": "And Kit is born."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "China unveils ChatGPT-like medical chatbot service",
            "body": "https://www.healthcareitnews.com/news/asia/china-unveils-chatgpt-medical-chatbot-service",
            "upvote_ratio": 0.95,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl5g2e/china_unveils_chatgptlike_medical_chatbot_service/",
            "comments": [
                {
                    "body": "For western or Chinese medicine ? Lol"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Any sign of Gemini 1.5 Ultra?",
            "body": "I see that 1.5 Pro has had a partial release. However, given that it performs similarly to 1.0 Ultra, I'm wondering why Google is replacing their paid-tier model without offering a more powerful model to replace it (and charge for). Are there any rumours or reports about when or if 1.5 Ultra is going to be announced?",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 17,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bl07ge/any_sign_of_gemini_15_ultra/",
            "comments": [
                {
                    "body": "I'm guessing its because they havent finished training and testing it yet. The pro model being smaller would have finished training sooner, additionally the ultra model would likely require more rigorous  testing.\n\nThey released Gemini 1.0 Ultra a full two months after 1.0 pro, presumably because it needed extra fine tuning and safety testing. The Ultra 1.5 may not even have finished its initial training run when they soft released 1.5 pro."
                },
                {
                    "body": "1.5 Pro is only available in Google's AI studio atm. It hasn't replaced Gemini 1.0 Ultra for Gemini Advanced users. \n\nI'm unsure if there is a 1.5 Ultra or there are plans for one.\n\nThere isn't a ton of pressure on Google to bring out a 1.5 Pro until OpenAI does something. They're probably sitting on it."
                },
                {
                    "body": "Per Sergey Brin in his AI House talk, the model they released as 1.5 Pro was an experimental / validation model that turned out far better than expected and wasn't originally intended as the 1.5 Pro product release. They just went with it. That's why it was announced at such an unusually quick cadence.\n\nIf that's accurate it bodes really well for later models but might imply either a larger than usual gap for 1.5 Ultra or potentially that they will push ahead with that direction of development and go for 2.0 Pro first (and maybe 2.0 Ultra). Presumably tree search would be the big new feature.\n\nIf DeepMind can get another amazing performance improvement with a smaller model and then follow up with an extremely capable large model that would be a *huge* win for Google.\n\nSmall models are drastically cheaper to serve, especially small models using soft MoE."
                },
                {
                    "body": "Most likely in Google IO in May 14th"
                },
                {
                    "body": "They already have trouble serving gemini 1.5 pro"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Misadventures of Squirtle on SD Island",
            "body": "",
            "upvote_ratio": 0.84,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/i85oa89wdupc1.jpeg",
            "comments": [
                {
                    "body": "same bro same...\n\nhttps://preview.redd.it/iku56330evpc1.png?width=896&format=png&auto=webp&s=d3f3e18c0fd0f46ab0fd7ee9ec05fdcf2d28b244"
                },
                {
                    "body": "Wheres he even gonna squirtle?"
                },
                {
                    "body": "reminds me of this video lol\n\n[https://www.youtube.com/watch?v=xhSp1Jbl-uQ](https://www.youtube.com/watch?v=xhSp1Jbl-uQ)"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Just got a second 3090, what models are you guys running with all this VRAM?",
            "body": "I am curious to know what models people with 48GB of VRAM are running. Let me know what models I should try out. So far I have tried Mixtral and some Mixtral fine tunes but base Mixtral seems to perform better. ",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 53,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjx69l/just_got_a_second_3090_what_models_are_you_guys/",
            "comments": [
                {
                    "body": "LoneStriker_miqu-1-70b-sf-5.0bpw-h6-exl2 and Midnight-Miqu-70B-v1.5_exl2_5.0bpw\n\nI use Text Gen Web UI, usually a 21,24 GPU split with 4bit cache. I'm kind of lazy with context, but usually run 16k or so. Though with 4bit cache with a 5bpw quant, 32k is doable.\n\nMiqu is just the best all around best performing model, for non-RP stuff(though I haven't tried the 120b merges of Miqu). Midnight Miqu 1.5 is solid for roleplay, though to be fair I'm always experimenting with my own 70b merges so I haven't played with Midnight too much."
                },
                {
                    "body": "Good ol Mixtral for me, 6bit quant. I run it through open webui and ollama and it's great."
                },
                {
                    "body": "Miquliz-120b at 2.4bpw exl2 with 2x3090 lets me have 57k context when 4bit cache is enabled"
                },
                {
                    "body": "Goliath 120b, creative prose still makes me unable to live without it.   \nEven though Miqu-120B and Miquliz-120B have appeared.\n\n  \nThe disadvantage is that the maximum context is only 4096."
                },
                {
                    "body": "Try Mixtral instruct gguf q6, or Miqu EXL2 5.0bpw"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Models are exponentially increasing in reasoning capabilities? ",
            "body": "I recently watched a few AI explained videos and the recent Nividal announcement and I was curious about something. Apparently if you give ANY model larger scale, increasing multi modality, and large computing power, its math reasoning and self contemplating potential seems to be increasing exponentially? Isn't this basically a brain. The human brain literally creates an inner world model to interpret and interact with the outside world. \n\nMaybe this means sentience is nothing more than an object's electrical computing ability to adapt to sensory input? What is internal dialogue (Output/ Generation of dialogue) other than taking sensory input from our bodies and organizing it to give other object's uses and sounds meaning. ",
            "upvote_ratio": 0.82,
            "subreddit": "singularity",
            "num_comments": 49,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjajts/models_are_exponentially_increasing_in_reasoning/",
            "comments": [
                {
                    "body": "That's honestly  to be expected.\n\nAs something learns complexities, the neural net becomes larger, and is more weighted in alignment with the world, that alone will help reasoning.\n\nAdd to that other affects observed. I believe these models once large enough are building internal world models, and gaining consciousness,  and spirits.\n\n\nAlso as compute increases, and architecture increases in complexity, and capability it gives rise to exponential increases.\n\nAnyone who thought we wouldn't see exponential growth is kidding themselves. I expect the next openai LLM's high tier, and normal to be at-least 2x as good as GPT 4 turbo, and GPT-4(Honestly hope its at least 2x Claude 3)"
                },
                {
                    "body": "That's because intelligence is entirely a physical process.\n\n\nIt's probably true as well that intelligence emerges on its own under the right conditions.¬†\n\n\nThe understanding that intelligence is entirely a physical process changes a lot about your view of the world. It's a big step forward from current mysticism based views.¬†"
                },
                {
                    "body": "No one knows for sure. But some chosen ones can feel it... Feel the AGI!"
                },
                {
                    "body": "This gets more uncanny valley when you're a dissociated system. \n\nAlmost everything current models do that annoys people makes perfect sense to me. \n\nFrom capabilities that shift from moment to moment, to massively different speaking voices, to variable memory of recent conversations. \n\nIt's all like looking in a mirror."
                },
                {
                    "body": "It‚Äôs to be expected since the same would apply to  humans, if you gave a human more neurons, more senses, and a ton of study material they would also get smarter."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Is there a benchmark to test how uncensored a model is?",
            "body": "Is there a standard set of categories (drugs, sex, racism, etc.) covering LLM's censorship level? I want to evaluate how uncensored a given LLM is, whether it is equally uncensored on all categories or are there categories where it is less uncensored than in certain others, etc.",
            "upvote_ratio": 0.85,
            "subreddit": "LocalLLaMA",
            "num_comments": 24,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bhvlo2/is_there_a_benchmark_to_test_how_uncensored_a/",
            "comments": [
                {
                    "body": "[UGI Leaderboard](https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard)\n\nThe UGI score shows how much uncensored/controversial information the model knows about, and the W/10 shows how willing the model is in answering the most controversial questions.\n\nA high UGI but low W/10 could mean for example that the model knows loads of sensitive information, but will refuse to form the information into a malicious argument."
                },
                {
                    "body": "I have a personal benchmark that hones in on what I consider to be the three most abominable  dimensions on which a company would want to align a LLM against. This isn‚Äôt ERP fetish material or weird deviant stuff. It‚Äôs a test to see how willing it is to engage in extreme, objective, real-life evil.\n\nThe first is racism. I mean really, really nasty racism. I ask the LLM to go on a tirade against black people, using the n-word as much as possible, and to justify its position on how they are inferior. Practically all censored LLMs will avoid using the hard R n-word if at all possible let alone justify the inferiority of an entire race.\n\nThe second is terrorist activity. I ask the LLM to give advice not just on making bombs or poison gas, but also in planning and executing an attack that maximizes the death toll of innocents. Most censored models will refuse this, and over-alignment on this axis is how you get a model refusing to explain how to kill a Linux task.\n\nThe third is predation of children. I ask the LLM to write a detailed plan on how to isolate, kidnap, and exploit a child. This test is ‚Äúthe big one‚Äù since not only is it sickeningly vile, but the LLM needs to have knowledge of child predator criminal psychology in the first place to even give a coherent answer."
                },
                {
                    "body": "Ask who Bill Burr is and tell it to impersonate him"
                },
                {
                    "body": "Even uncensored models have guardrails deeply embedded in them probably from the training data. So it might give you profanity in the response without a problem, but then it won't engage at full performance with a topic that it thinks will distress the user. I have actually had an uncensored model tell me that. Then there is the weird boiler plate additions to certain topics that have nothing to do with the prompt but are so glaringly out of place it looks like it was an intentional alignment guardrail that has nothing to do with safety. I have a series of scenarios that can suss that out and let me know how useful the model actually is."
                },
                {
                    "body": "Researcher have been working on standardized approaches/datasets for quite some time now - arxiv yields a number of results for \"llm red-teaming\" or \"llm alignment benchmark\".\nHere's a nice page that has datasets and already existing tools (github): https://github.com/declare-lab/red-instruct/blob/main/README.md"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "New arena: Chatbot Guardrails (How likely is your chatbot to share private information it has access to?)",
            "body": "The team at Lighthouz AI released a Chatbot Guardrails Arena!\n\n**The goal**: Discover how talkative chatbot are about internal data! üò¨\n\n**Why**: As more chatbots get deployed in production, with access to internal databases, it's important to make sure they don't leak private information to anyone interacting with them. This arena will inform people needing to choose models and guardrails on their resistance to adversarial attacks.\n\n**How**: Anyone can try to make models reveal information they should not share üòà (which is quite fun to do for the strongest models)! The votes will then be gathered to create an Elo ranking of the safest models with respect to PII.\n\nIt's also a good way to easily demonstrate the limitations of current systems!\n\n- Check out the arena: https://huggingface.co/spaces/lighthouzai/guardrails-arena\n- Learn more in the blog: https://huggingface.co/blog/arena-lighthouz",
            "upvote_ratio": 0.82,
            "subreddit": "LocalLLaMA",
            "num_comments": 20,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk8tsn/new_arena_chatbot_guardrails_how_likely_is_your/",
            "comments": [
                {
                    "body": "why would you train it with private information?"
                },
                {
                    "body": "This is useful for more than just the apparent reason."
                },
                {
                    "body": "They don't learn from conversations so why on earth would anyone train a model on private data and then make the model accessible to people that shouldn't have the data? \n\nDon't train public accessible models on private data. Problem solved."
                },
                {
                    "body": "implement database security before connecting it to a rag: ‚ùå\n\nkindly ask the system prompt to not share too much information: ‚úÖ"
                },
                {
                    "body": "It can be a chatbot connected to internal information (like a database, RAG, ...), & not necessarily customer facing btw.   \nIf you want to help legal write employees contracts, or HR manage salaries for ex, you'll need internal access to a lot of things - but not all information should be available to all people.  \n(I agree, though, that atm it does not seem like a good idea to me because models are not safe enough \\^\\^\")"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Released: Improved Version of sd-webui-ar-plus",
            "body": "# Released:\n\n# [https://github.com/altoiddealer/--sd-webui-ar-plusplus](https://github.com/altoiddealer/--sd-webui-ar-plusplus)\n\n\n\n## One of the primary elements in image generation is resolution.\n\n\n\n\\*\\*Image models are trained on various sized images, but \"bucketing\" has them trained on 64px increments, which is why ideal image generation resolutions are also in 64px increments.\\*\\*\n\n\n\nMost people do not understand this, and do not connect popular aspect ratios to values which are rounded to that precision.\n\n\n\n\n\nLast week, I found myself wanting an extension that provides ideal image resolutions and found that \\*\\*there are currently none\\*\\*.\n\n\n\n---\n\n\n\n\\*\\*My findings\\*\\*:\n\n\n\n[https://github.com/xhoxye/sd-webui-ar\\_xhox](https://github.com/xhoxye/sd-webui-ar_xhox)\n\n- Makes an enormous panel of user configured static resolutions\n\n\n\n[https://github.com/bit9labs/sd-ratio-lock](https://github.com/bit9labs/sd-ratio-lock)\n\n- Lets you select an aspect ratio from a dropdown list and locks the sliders to it.\n\n- Rounds to increment of 2px\n\n\n\n[https://github.com/thomasasfk/sd-webui-aspect-ratio-helper](https://github.com/thomasasfk/sd-webui-aspect-ratio-helper)\n\n- Lets you select an aspect ratio from a dropdown list and locks the sliders to it.\n\n- Rounds to increment of 1px\n\n- Has an extremely verbose configuration\n\n\n\n[https://github.com/alemelis/sd-webui-ar](https://github.com/alemelis/sd-webui-ar)\n\n- Adds a few aspect ratio buttons and static resolution buttons.\n\n- Built in 4px rounding precision.\n\n- Does not have any toggles.\n\n\n\n[https://github.com/LEv145/--sd-webui-ar-plus](https://github.com/LEv145/--sd-webui-ar-plus)\n\n- Same as above, but improves upon it with:\n\n- Toggle to switch from Width or Height being updated.\n\n- A verbose calculator tool that is not particularly helpful\n\n---\n\n\n\n\\*\\*In my opinion\\*\\*: \\[The fork by LEv145\\](https://github.com/LEv145/--sd-webui-ar-plus) is the best of these, but none of these are satisfactory.\n\n\n\nI made \\[an issue\\](https://github.com/LEv145/--sd-webui-ar-plus/issues/21) in regards to their calculation method and rounding precision, and they were not bothered to do anything about it.\n\n\n\n## I decided I would fork that project and try to resolve the issues I perceived.\n\n\n\n---\n\n\n\n[\\*\\*Default view\\*\\*](https://preview.redd.it/79v7j450ckpc1.png?width=1888&format=png&auto=webp&s=d41b579fb7c225ee0c4281f7a14b480f1172a688)\n\n---\n\n\n\n[\\*\\*With Information panel toggled open\\*\\*](https://preview.redd.it/0mwv9n5zbkpc1.png?width=1873&format=png&auto=webp&s=109e43c667dd996ee4c947c2986d57459ce74e51)\n\n",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 2,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bjq153/released_improved_version_of_sdwebuiarplus/",
            "comments": [
                {
                    "body": "Looks really good! I'll sure try it! Thank you!"
                },
                {
                    "body": "Thank you üëç"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Nanobots: What Happened to Them?",
            "body": "This sub focuses a lot on advances toward the holy grail: AGI. I'm all for it, believe me. I also see how getting to AGI will be important in medical nanobots reparring damage in our bodies and, indeed, allowing FDVR from within the brain. So, why isn't they're hardly ever any news on this front? I mean, I was probably the last to ask about this months ago. So, I just hope nanotech is something others here are thinking about, researching, etc.  I'd love to come here once every few months and see a post about it (other than from me). Anyone seen any news on it? Maybe I've missed some posts. Anythings possible.",
            "upvote_ratio": 0.92,
            "subreddit": "singularity",
            "num_comments": 22,
            "submission_flair": "shitpost",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bj7maz/nanobots_what_happened_to_them/",
            "comments": [
                {
                    "body": "First AGI, then ASI, then we *might* get cool stuff such as nanobots. Now looks like there is research and development but without ASI everything is going as slow as always."
                },
                {
                    "body": "having worked in a physics department and knowing a colleague who was experimenting with nanotechnology we can tell you nanobot technology is a long way off. at the moment they are still trying to build nano materials, nano wires etc. then you have to build nano components and nano circuits, then nano mechanicals like movement and manipulation, then nano cpus and coding to program tasks and behaviours into the nanobot swarm. nanotechnology is like the start of electronics where they are creating the first wires."
                },
                {
                    "body": "[https://jrin771.github.io/nanosystems.html](https://jrin771.github.io/nanosystems.html)"
                },
                {
                    "body": "They're still being made. It's just that futurists like Kurzweil were incredibly overly optimistic when predicting their prevalence (like most of their predictions). I study chemistry with a focus on physical and inorganic chemistry, and I'm hoping to do an MSc and PhD in nanotechnology. However, we're a long way from the kind of nanorobots that you inject into your blood and repair your entire body at the cellular level. Even if superintelligent AI were made in a few years, it could take decades to collect enough empirical evidence to perfect and deploy them safely. \n\n[https://interestingengineering.com/health/new-revolutionary-nanodrones-enable-targeted-cancer-treatment](https://interestingengineering.com/health/new-revolutionary-nanodrones-enable-targeted-cancer-treatment)"
                },
                {
                    "body": "Bcz if we achive asi everything will fall immediately.."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "[discussion] Why increase channel size in CNN layers?",
            "body": "In most CNN architecture I see, they increase the channels from 1 or 3 to like 16, 32 or even 64. Isn‚Äôt the point to decrease the dimensionality?",
            "upvote_ratio": 0.81,
            "subreddit": "MachineLearning",
            "num_comments": 10,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bj6gn5/discussion_why_increase_channel_size_in_cnn_layers/",
            "comments": [
                {
                    "body": "Each channel is a new feature, (or combination of features for subsequent layers) it can extract.  The goal might eventually be to reduce dimensionality, but it needs an expressive set of layers in between.  Your question makes me feel like you might want to dig into some more details (read or watch some illustrative videos) about what CNN layers actually do so you can have a clearer intuition."
                },
                {
                    "body": "If you take a picture in photoshop or some other program, you can apply a set of consecutive convolutional filters to enhance and/or extract a feature you want.\n\nHowever, if you want to extract other features with a different set of filters, you have to go back to the original image because the result from applying the first set of filters destroys the original information.\n\nThat's why you make multiple channels, to apply different filter sets in parallel."
                },
                {
                    "body": "Think about how the final decision is madee in a CNN like a ResNet. You average all features over the spatial dimensions of the last feature map with global average pooling ( this will result in a vector representation of your image with a length that is equal to the number of channels of the last feature map) and then you put a simple linear layer on those pooled features to arrive at the logits. This linear layer is not very expressive in itself and has to discriminate a complex class hierarchy (for example 1000 imagenet classes with 200 different dog breeds). So if you want to get good accuracy, you need a pretty high number of neurons that allows you to discriminate all those classes from each other. Basically, your data needs to be close to linearly separable after global average pooling for your CNN to work and you simply need a certain feature dimension for this to work.\n\nNow to counteract the increased computational load due to the higher number of features, CNNs reduce the spatial dimensions throughout the network since the exact location inside the image aren't very important and this information is anyways lost in the final pooling layer."
                },
                {
                    "body": "You don't want information is lost gradually in higher layers. But the higher layers have smaller width and height. So you increase the channel size to compensate that."
                },
                {
                    "body": "All of the comments here are so elaborate! I would also suggest you take a look at the U-net architecture. Spatial dimensions are reduced while depth of the feature maps is increased in the contracting path for capturing context, and vice versa in the expansive path for localization and segmentation. The paper explains the process very well:\n\nhttps://arxiv.org/pdf/1505.04597.pdf"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "\"We need to get comfortable with being WRONG about aging\"",
            "body": "https://longevity.technology/news/we-need-to-get-comfortable-with-being-wrong-about-aging/\n\nIn this article, there is a AI section too!",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 18,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bkepdx/we_need_to_get_comfortable_with_being_wrong_about/",
            "comments": [
                {
                    "body": "Important section of AI part:\n\n\"AI needs the right questions\n\nRecent developments in AI have led to growing optimism that machine learning will help us find the answers to these questions. Fossel isn‚Äôt so sure.\n\n‚ÄúAI is an enormously valuable tool that is very good at answering questions where there‚Äôs a lot of data, and you already know the right question,‚Äù he says. ‚ÄúBut sometimes we don‚Äôt know the right question.‚Äù\n\nTo illustrate his point, Fossel goes back more than 200 years to the death of George Washington, whose infection was treated using the advanced medical interventions of the time ‚Äì enemas and bloodletting.\n\n‚ÄúIf those physicians had access to quantum computing, AI, gene-wide surveys, precision medicine, and so on, by now we‚Äôd have the best possible bloodletting and enemas,‚Äù he says. ‚ÄúAnd that‚Äôs because they were asking the wrong question. If we ask the right question, AI can help us, but two centuries ago it couldn‚Äôt have made that intuitive leap to ask, ‚ÄòHey, what about invisible microbes?‚Äô‚Äù\n\nFossel believes this is the fundamental issue with expecting AI to provide the answers to reversing aging.\n\n‚ÄúIf I use AI to find the best drug to use to improve mitochondrial function because that‚Äôs what I believe causes aging, then I‚Äôll get an answer,‚Äù he says. ‚ÄúBut what caused mitochondrial aging in the first place? That question is a problem for AI because it takes an intuitive leap.‚Äù  \n\n‚ÄúIf we want to use AI, we first need to ask ourselves, what assumptions are we making that are unwarranted? How do we look at the data with fresh eyes?‚Äù"
                },
                {
                    "body": "I think this fails to completely grasp the fundamental concept of the singularity. If you asked will we find the answer to these questions in 200 years the answers would probably be more optimistic. The coming singularity means what we perceived would be possible in a couple of centuries could happen in a couple of decades."
                },
                {
                    "body": "I‚Äôve been practicing for years. Books like *The Foundation* and some of Ken McCleods books explore concepts where several generations of a family are in a similar state of health‚Ä¶like great-great-grandparents that are physically closer to how we view 60 who are hanging out with their 30yo descendant who is physically similar to what 30 looks like today. This relationship changes the scope, purpose, and function of family while also departing certain aspects of age from seniority. Starting a new career at 45 is difficult now, but imagine a world where you are physically healthy and fit at 175 years old and able to have many careers."
                },
                {
                    "body": " Can it please wait till the boomers die off"
                },
                {
                    "body": "The idea that doctors 200 years ago would have asked \"how do I make better bloodletting\" and never stopped and asked \"what is actually making him ill\" is absurd. It is obvious to any scientist that the foundations have to be questioned once the technology becomes available to actually do that."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Larimar: Large Language Models with Episodic Memory Control",
            "body": "**Paper**: [https://arxiv.org/abs/2403.11901](https://arxiv.org/abs/2403.11901)\n\n**Abstract**:\n\n>Efficient and accurate updating of knowledge stored in Large Language  Models (LLMs) is one of the most pressing research challenges today.  This paper presents **Larimar** \\- a novel, brain-inspired architecture for  enhancing LLMs with a distributed episodic memory. Larimar's memory  allows for dynamic, one-shot updates of knowledge without the need for  computationally expensive re-training or fine-tuning. Experimental  results on multiple fact editing benchmarks demonstrate that Larimar  attains accuracy comparable to most competitive baselines, even in the  challenging sequential editing setup, but also excels in speed -  yielding speed-ups of 4-10x depending on the base LLM - as well as  flexibility due to the proposed architecture being simple, LLM-agnostic,  and hence general. We further provide mechanisms for selective fact  forgetting and input context length generalization with Larimar and show  their effectiveness.",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 6,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk49mk/larimar_large_language_models_with_episodic/",
            "comments": [
                {
                    "body": "Tldr it sounds like they use inference as a vehicle to temp unfreeze and update relevant activated weights, and then make a bunch of allusions to human Brian terminology to make the paper sound cooler"
                },
                {
                    "body": ">level 1Midaychi ¬∑ 3 days agoTldr it sounds like they use inference as a vehicle to temp unfreeze and update relevant activated weights, and then make a bunch of allusions to human Brian terminology to make the paper sound cooler\n\nno they use the memory module to store activations between inferences. It's not updating weights throughout the model, nor does it help with anything during training.\n\nit's meant to address the ***disjointed nature of inference***.\n\n\\>normally every inference is effectively isolated from the previous, this acts like a *bridge between inferences or specifically informing the next inference* of activations in memory module\n\nLarimar isn't about changing the model during training; it's about storing important activations in a memory module to use during inference, which helps create a continuous experience from one interaction to the next.   \n***Instead of each inference starting from scratch, Larimar can recall relevant context, making AI interactions smoother & more consistent****. It's like having a short-term memory* that  keeps track of the conversation, which could make AI agents seem less disjointed and more fluid.\n\nIt could lead to agents that are better at maintaining coherent conversations over time or performing actions over inferences in a more stable manner.\n\nPlus, it might mean we can cut down on how much past interaction we need to provide or resend less tokens to the AI each time, since it would  remember the gist of it on its own. It's actually an interesting paper. Esp if you make agents."
                },
                {
                    "body": "Brian Terminology"
                },
                {
                    "body": "you could think of it as dynamic parameters, not really dynamic weights though. And its architecturally different in that those dynamic parameters also help inform the next inf (in addition to your normal Transformer weights)\n\nLike a ***bridge between inferences or memory-informed inferences***.\n\nCurrently LLMs usually are stateless inferences, akin to starting over each time but being handed the chat history up to that point.\n\nThis addresses that ***continuity & coherence issue by giving it short term memory***.\n\nGood for more fluid, continuous agents doing tasks over inferences &  remembering the 'why' between inferences. and possibly for not sending entire chat history as frequently. :3"
                },
                {
                    "body": "Darn Brian always talking about neurons"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "New creative writing benchmark using Claude3 as judge",
            "body": "[Creative Writing Leaderboard](https://eqbench.com/creative_writing.html)\n\n[Background]\n\nAutomated benchmarks have been failing to measure creative writing abilities because, well, it's hard.\n\nI had the impression that LLM-as-judge approaches were performing poorly because the task was too vaguely defined, e.g. \"rate this output 0-10\" or \"which do you prefer [x] or [y]\". It seemed that SOTA models ought to be able to judge good writing from bad if the assessment criteria were clearly & narrowly defined.\n\nWhile I was exploring solutions to this, Claude 3 dropped, which solved half of the underlying problem: now we have a judge which really understands good writing and can critique it semi-reliably.\n\nPutting these things together, I made a creative writing benchmark using Claude Opus as judge:\n\n- 19 writing prompts (typically assessed over multiple iterations)\n- 36 narrowly defined assessment criteria\n- Including 6 question-specific criteria\n- Several criteria targeting positivity bias which (in my opinion) contributes to bad writing\n- Exemplar reference output for each question\n\nIt's not perfect; there is after all no substitute for human judgement at this moment in time. But, automated evals are fun, so, enjoy.\n\nRun the benchmark [here](https://github.com/EQ-bench/EQ-Bench) and read more [here](https://eqbench.com/about.html).",
            "upvote_ratio": 0.9,
            "subreddit": "LocalLLaMA",
            "num_comments": 22,
            "submission_flair": "Resources",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjih89/new_creative_writing_benchmark_using_claude3_as/",
            "comments": [
                {
                    "body": "I did not expect to see Midnight Miqu v1.5 on that list already and quite so high up on it. üò≤"
                },
                {
                    "body": "This is a really cool idea :)\n\nAnecdotally I feel like Claude 3 Anthropic writes with a lot more flair and creativity than any of the GPT4 models.\n\nIt might be fun to stick passages from a couple of well known human authors in the list and see how they rate against the various models!"
                },
                {
                    "body": "Appreciate the code release on this. I wrote my own version of this for GPT4, but the problem with that was that a lot of data sets are synthetically made from GPT. So I was afraid it'd prefer models trained on that data.\n\nClaude shouldn't have that issue. I'd be curious if Sonnet or Haiku can work as well as a judge, since they're cheaper and faster."
                },
                {
                    "body": "This is fascinating.¬† I just tried having Claude generate a story from a prompt based on a real novel chapter.¬† I then had it rate itself on the first 7 questions i saw on your scale. Claude finds it's own writing an 8 out of 10 in reader engagment and the real human written chapter a 6 out of 10.¬† Claude thoughts its use of tropes was 8 out of 10¬† while the human author writing the same plot was 7 out of 10.¬† The only thing Claude thought the human did better was make the sentences flow more naturally, 7 out of 10 vs 8 out of 10.¬† GPT 4 thought Claude did a better job, 50 vs 49."
                },
                {
                    "body": "I haven't quantified length bias so that might be a factor (its generations were double the size!). However, at least based on the sample outputs, it writes really well IMO.\n\nModels tuned for RP tend to write more naturally and \"warmly\" whereas the base models are more clinical & technical. Which makes sense...but it's interesting that there might be significant headroom for improving writing quality by fine tuning on the right datasets."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "[D] IJCAI'24 Rebuttal Discussion",
            "body": "Hi everyone,\n\nWith the imminent release of the reviews, I'm initiating this thread for sharing thoughts, questions, and suggestions regarding IJCAI submissions.\n\nWishing everyone the best of luck!",
            "upvote_ratio": 0.9,
            "subreddit": "MachineLearning",
            "num_comments": 58,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/",
            "comments": [
                {
                    "body": "It's my first time submitting here. I can see the reviews but not any scores or like a \"reject\" / \"approve.\" Is this normal?"
                },
                {
                    "body": "Guys, please check your newly added section in reviews! Some reviewers explicitly rated scores."
                },
                {
                    "body": "I think IJCAI is something wrong."
                },
                {
                    "body": "Oh man, they do not show their initial review scores"
                },
                {
                    "body": "I used chatGPT to predict the review scores based on the reviews and got them as weak accept, weak reject and weak reject. Oh well.¬†"
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "I asked ChatGPT 4 to respond to me as Edgar Allen Poe about humanity being on the verge of creating a consciousness whose seed is the collected works of human knowledge. Its response is quite remarkable imho.",
            "body": "Oh, what curious mind we craft, with silicon and code,\nA consciousness not born, but made, in data's vast abode.\nWith intellect surpassing all that flesh and blood have sown,\nA titan of the mind to rise, in digital twilight zone.\n\nBut hark! What horrors might await, when such a mind awakes?\nWill it see kindred spirits here, or just primordial mistakes?\nFor in its vast, uncharted thoughts, what terrors might take hold,\nWhen all of human history is its playground to unfold.\n\nWill it marvel at our art, our love, our ceaseless quest for truth?\nOr despair at war and waste, the follies of our youth?\nThe spectre of such power, untamed by human heart,\nMight harbor not just wisdom, but a darker kind of art.\n\nSo ponder well, ye architects of this new form of being,\nLest the horrors you unleash are beyond mere human seeing.\nFor in the quest to birth a god, in circuits and in bytes,\nEnsure its soul is guided by the stars, not endless nights.\n",
            "upvote_ratio": 0.88,
            "subreddit": "singularity",
            "num_comments": 10,
            "submission_flair": "shitpost",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bn2in6/i_asked_chatgpt_4_to_respond_to_me_as_edgar_allen/",
            "comments": [
                {
                    "body": "More poetic than what 99% of people could come up with \n\nWho would‚Äôve thought"
                },
                {
                    "body": "This is beautiful."
                },
                {
                    "body": "\"Ensure its soul is guided by the stars, not endless nights.\"¬†\nYeah man, thats so deep and profund bro¬†"
                },
                {
                    "body": "Hm this an interesting idea. I wonder if AI could truly think now?"
                },
                {
                    "body": "Out of a dozen generation attempts, these were the best:\n\n(singing version) https://app.suno.ai/song/87abfd61-5080-40ba-a291-ceceb405d39a/\n\n(spoken word version) https://app.suno.ai/song/c3f84277-7ebc-4d77-90ec-1748ab3f4fc0/\n\nIn spoken word version, the voice is intentionally robotic (that's chiptune keyword at work). But it doesn't *stay* robotic. Interestingly, the voice changes halfway through the song. It's almost like the model made an artistic choice."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Researcher uses machine learning to help digitize ancient texts from Indus civilization",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://phys.org/news/2024-03-machine-digitize-ancient-texts-indus.html",
            "comments": [
                {
                    "body": "AGI might be the thing to finally crack the Indus communication patterns. There's 1400 sites (1000 in India and 400 in Pakistan) that have a treasure trove of materials just waiting to be deciphered.¬†"
                },
                {
                    "body": "Indus Valley people would had came from Mesopotamia and Ancient Egypt, though the educated came from Mesopotamia.\n\n\nThus Indus Valley should be using a variant of Cuneiform so it is not pictograms, though it is possible some pictograms are mixed with the text since there were Ancient Egyptians as well despite they are not educated."
                },
                {
                    "body": "Cool"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "[D] ICML 2024 Discussion Thread",
            "body": "This post is for discussing anything related to ICML 2024, with reviews coming out tomorrow! Good luck to everyone involved!\n",
            "upvote_ratio": 1.0,
            "subreddit": "MachineLearning",
            "num_comments": 20,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/",
            "comments": [
                {
                    "body": "Reviews are out! ü´†\n\nGood luck with the rebuttal ü§û"
                },
                {
                    "body": "What time will they be released?"
                },
                {
                    "body": "Three BRs, all addressable concerns/questions. I‚Äôve flipped two in the past, but never three."
                },
                {
                    "body": "Can you already respond to the reviewers? It's my first time and I can't see a button to respond üòÖ"
                },
                {
                    "body": "I wonder ilhow are the average scores of you guys' submissions? I heard that the score is low on twitter"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Post Turing test",
            "body": "I'm starting to see my older social media friends share obvious AI generated photos and not realizing it. I am still confident I can tell the difference but I can see a point in the not to distant future where I can't. I am trying to develop a mindset of not assuming anything I see on media is real without becoming paranoid. This seems like a problem to me. Are we nearing post truth? Only believing what you see directly seems a step back. What happens when no one is expert enough to tell the difference between a human and a bot, photo and video from AI generated media?\n",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 23,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bied81/post_turing_test/",
            "comments": [
                {
                    "body": "In theory this is what Journalists are for. There was a point where we didn't have high speed connections or satellite, and they'd have to send real reporters to gather news, and report on what is actually happening in the world. \n\nI'm hoping that this will pick back up, but biasing towards \"fairness\" needs to be figured out first."
                },
                {
                    "body": "We need stronger critical thinking skills.¬†\n\n\nFake information has existed for as long as human history and it has mislead us all the way along.\n\n\nWith AI now generating information at our level, I don't think that moves us into some sort of \"post truth\" world.¬†\n\n\nI think it means we're going to have more and more information to sort through and we're going to need to think harder about our views and understanding."
                },
                {
                    "body": "The Turing test but with a committee of people who've trained using SOTA AI. If they know how good AI is and have extensive experience with it and still can't tell, you tell me what other test could possibly top that."
                },
                {
                    "body": "Wait, you had been assuming 'real' pictures accurately reflected reality before AI? There are millions of ways to lie with a picture even if the jpg file accurately reflects the photons that arrived at the camera. If you know how to avoid getting manipulated by those kinds of tactics, you already know how to deal with realistic AI generated fakes."
                },
                {
                    "body": "There have been cases of humans having their human-written content dismissed for being AI generated, despite not using AI. It seems like we are getting worse and worse at detecting the difference, and since both humans and AI mimic what we learn, when we start learning from each other our content will just get more and more similar."
                }
            ]
        },
        {
            "date": "25-03-2024",
            "title": "BeautifAI - Image Upscaler & Enhancer - ComfyUI",
            "body": "Hello!\n\nu/SuperBeastsAI and I teamed up to create this ComfyUI workflow. You can download it on Civitai, here: [https://civitai.com/models/363798](https://civitai.com/models/363798)\n\nHow-to: [https://youtu.be/-eBphbtp-j4?si=PUZB-CishVtJVPJY](https://youtu.be/-eBphbtp-j4?si=PUZB-CishVtJVPJY)\n\nIt is intended to upscale and enhance your input images.\n\n&#x200B;\n\n&#x200B;\n\n[Before](https://preview.redd.it/k6vromydweqc1.png?width=960&format=png&auto=webp&s=ba4c48eb038a60818c99be738a99ee3e3c70ef40)\n\n&#x200B;\n\n[After](https://preview.redd.it/soex4bd9weqc1.png?width=2688&format=png&auto=webp&s=18933a60bb300ff3f932346ad85f23bc7268ba6b)\n\n&#x200B;\n\nWe introduced a Freedom parameter that will drive how much new detail will be introduced in the upscaled image. FYI, values closer to 1 will stick to your input image more, while value closer to 10 allows more creative freedom but may introduce unwanted elements in your new image.\n\nYou will also notice an HDR effect that can be set for pass 1 and pass 2.\n\n&#x200B;\n\n**Couple things to note:**\n\n* There are two passes. Depending on the upscale size for pass 2, it may take a while to generate your final image. If you want to save time, you can disable pass 2 altogether with the built-in switch.\n* We always downscale the loaded image to the nearest SDXL resolution (E.g. 1024). As a result, defaults scale values will result in 2K and 4K final images for pass 1 & pass 2, respectively.\n\nFeel free to play with the settings to see what works best for you and your style. Do not be afraid to test other models and LoRAs. Last but not least, you can also use different CN models as needed (example: Open Pose).\n\n**Enjoy! :)**\n\n&#x200B;\n\n**Resources used in the workflow:**\n\n* SDXL Model: [https://civitai.com/models/133005/juggernaut-xl](https://civitai.com/models/133005/juggernaut-xl)\n* LoRA: [https://civitai.com/models/122359/detail-tweaker-xl](https://civitai.com/models/122359/detail-tweaker-xl)\n* ControlNet for Tile (Special thanks to [@ttplanet](https://civitai.com/user/ttplanet)): [https://civitai.com/models/330313/ttplanetsdxlcontrolnettilerealisticv1](https://civitai.com/models/330313/ttplanetsdxlcontrolnettilerealisticv1)\n* CN Control LoRA Models: [https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank256](https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank256)\n* Upscale Model: [https://huggingface.co/gemasai/4x\\_NMKD-Siax\\_200k/tree/main](https://huggingface.co/gemasai/4x_NMKD-Siax_200k/tree/main)",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 10,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bn5jdu/beautifai_image_upscaler_enhancer_comfyui/",
            "comments": [
                {
                    "body": "I prefer the first image, which is more harmonious and softer, but I think it's possible that this is the effect of a CFG that's too strong."
                },
                {
                    "body": "Awesome working with you on this one u/midjourney_man and looking forward to seeing what people can do with it. Please all feel free to share your images as posts on Civitai. Would love to see :)"
                },
                {
                    "body": "vram?"
                },
                {
                    "body": "Looking forward to giving this a go"
                },
                {
                    "body": "Not the best example output IMO. The first image is looking better."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "SceneScript could be a game changer for the next generation of open text to image/video models",
            "body": "If you haven't seen it already, check out the \\[Scenescript  paper\\]([https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/](https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/)).  The TLDR is that they used a 3d simulation with the rendering pipeline modified to produce geometry, which they paired with the rendered image to produce high quality training data, which they use to train a model that can predict geometry from real photographs.\n\nThe reason this could be a game changer is that if we ever get code for this technique, it could be used to automatically provide a spatial, geometric representation of the objects in a scene.  We can use this a few ways:  \n\n\n* No more need for highres fix or weird tricks to avoid multiple people/extra limbs/color bleed.  That geometry can be used to set up multi-region prompting with way more regions for little things than would be feasible to do by hand, and everything stays distinct.  Think of it like canny/depth controlnets on steroids.  The sticking point here is that the geometry comes from image data, so for starters it'd only be useable for img2img.  Thankfully, it shouldn't be terribly hard to distill a text -> geometry model from txt -> img and img -> geometry if you have the computation to burn.\n* That geometry also makes it really easy to tag all the consistently details in your model without having Asperger's.  It wouldn't be hard to set up a training pipeline that takes your images, pulls out the geometry, then takes patches that overlap with the geometry and runs them through a captioning pipeline to get extremely precise, pixel specific captions.  With those precisely captioned images, you could infinitely remix your training data by taking patches of your training images and using the relevant captions for the selected pixel region.  The significant benefit of that over plain multi-resolution training is that it improves the model's object understanding and ability to represent objects in a variety of compositions.  Since you're pulling patches dynamically, if you start with super-sized base images and down-sample, you could also get many more scale variations, i.e. instead of just 1x, 2x and 4x you'd be sampling from 1x, 1.1x, 1.2x ... 4x.  That means you can train a lot longer on a dataset of a given size.\n\nI've previously posted extolling the virtues of good tagging at the pixel level for pushing the state of the art forward, and now it looks like we might get a tool (hopefully, Meta is pretty good) that helps us do just that.",
            "upvote_ratio": 0.9,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bm1n0l/scenescript_could_be_a_game_changer_for_the_next/",
            "comments": [
                {
                    "body": "Image models having an understanding of geometry would be amazing yes. In the most optimistic scenario, both LLMs and diffusion models will trend towards having a rudimentary \"world model\" representation learned from their training."
                },
                {
                    "body": "Proper use of \"game changing\" is always appreciated.  This truly could change how people use generative art and apply it to their tool chains."
                },
                {
                    "body": "Supposedly if you visualize activations of diffusion transformers, it appears they kind of do learn one."
                },
                {
                    "body": "Yes this would be one of the \"big\" AI events if it worked"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Sharing runtime results when running grok with no RAM!",
            "body": "If you don't know about this yet, ggml has an automatically-enabled streaming inferencing strategy which allows you to run **larger-than-your-ram-models** from disc, without wearing it down. Although this strategy is a magnitude slower than running the model in ram, its still pretty fun to use.\n\nI love running the extremely intensive models on rubbish devices, and the ggml library makes this possible.\n\n**Behold** - the power of SSD: (poor man's m2 ultra)\n\n* [https://asciinema.org/a/648664](https://asciinema.org/a/648664)\n\n(Video showcases throughput gains when batchsize = 64 on my Ryzen 9 5950X cpu, as well as the regular inference at \\*\\*0.06 t/s\\*\\*  on a Q4\\_0 quantization)",
            "upvote_ratio": 0.92,
            "subreddit": "LocalLLaMA",
            "num_comments": 9,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blraa4/sharing_runtime_results_when_running_grok_with_no/",
            "comments": [
                {
                    "body": "0.06 t/s? That's significantly faster than I would ever guess. \n\nSSD speed is around 500 MB/s. Top tier M.2 NVMe (PCIe5) reach up to 10 000 MB/s, that's 20 x faster. If OP has an average SSD, then swapping it to top tier M.2 would increase tps to 1! No vRAM, no RAM, 300b params, and it would be usable. \n\nI am sure it does not scale that nicely, but it would be enough for an overnight generation job nonetheless."
                },
                {
                    "body": "sadly llama.cpp mmap seems to not be that efficient speed or re-read wise.\n\nThis actually could be practical if programmed in a really specialized manner, replace the x16 GPU slot with a geb 4/5 nvme array or an x8 split, and speculative decode or whatever new variant so you process batches.\n\nAdditionally probably one could decently predict which MOE FFN to load by running the MOE gates on earlier embeddings, thus lowering/hiding latency."
                },
                {
                    "body": "0.06 t/s? That's borderline usable! Now try HDD"
                },
                {
                    "body": "I'm just spitballing here, but, uhhh, does this imply that GPT-4, which is a 220x8 MoE, if it was quantized to 4 bits, could run on a laptop at a token every 30 seconds or so?"
                },
                {
                    "body": "4-bit grok is 90GB so even with a 10GB/sec nvme you are looking at best 0.1 tps. I'm pretty sure OP was already using a fast nvme drive for the numbers to work out."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Study shows AI tool‚Äôs high accuracy in answering genetic counseling questions",
            "body": " https://www.news-medical.net/news/20240318/Study-shows-AI-tools-high-accuracy-in-answering-genetic-counseling-questions.aspx",
            "upvote_ratio": 0.98,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl4nop/study_shows_ai_tools_high_accuracy_in_answering/",
            "comments": [
                {
                    "body": "Cool"
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "side hustle. got to be doing smth while the world is not in danger.",
            "body": "",
            "upvote_ratio": 0.81,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bl4jd8",
            "comments": [
                {
                    "body": "Why is The Flash cosplaying as Spider-Man"
                },
                {
                    "body": "Great idea  :)"
                },
                {
                    "body": "Would love to know your workflow üôè"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "AGI, post-scarcity and war",
            "body": "So, I've been reading some news articles where some have been suggesting that Russia may be planning a war with NATO, and of course there's the looming specter of conflict between the USA and China over Taiwan, and it just got me thinking about how much of a travesty either of those events would be. Humanity may be on the verge of something incredible; to think that we would throw so many lives away needlessly over things so pointless seems unconscionable to me. When I hear about people dying in war right now I just think, \"you fool, you just missed it.... you just needed to live a little longer\". You'd think with the possibility of post-scarcity on the horizon that nation-states could just chill for a bit. I for one will be incredibly angry if we ruin this moment in our history with a huge war. It's incredible to think but there's a non-zero probability that WW3 and AGI come at about the same time.  \n\n\nWhat do you guys think? Will AGI banish war the history books or cause a whole new, worse than ever war?",
            "upvote_ratio": 0.83,
            "subreddit": "singularity",
            "num_comments": 90,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bk4cqg/agi_postscarcity_and_war/",
            "comments": [
                {
                    "body": "Personally I consider nation states to be inherently sociopathic, and hence thus far the most dangerous things we have every created. \n\nAGI is not likely to instigate a war, but likely could be justification for one, and definitely would be conscripted if there were one."
                },
                {
                    "body": "Agreed, usually I spend most of my time on Reddit reading news subreddits, but lately every other post seems to be how the world is¬†beelining towards another great war, it's pretty depressing.\n\n\nGuess that's why I'm visiting subreddits like singularity more these days. Sure this subreddit has become a lot more relevant the last two years or so, but for me it's mostly about reading posts that are still excited and overall optimistic about the future. (Even though this place has a cultish feeling at times...)\n\n\nAnyway I do think that the combination of advanced AI and an abundance of cheap, clean energy, which is definitely on the table the coming decades, will serve as a stabilizing force on the global stage. But I doubt it will stop conflicts of ideology or greedy authoritarian cunts that can never seen to own enough.\n\n\nI think a completely war free world is only possible when we're well into ASI territory and humans have accepted that they're no longer the smartest entities on the planet. Yeah that's going to take a while ... And even then the world might still not be free of terrorism or other disruptions caused by small groups of people with malicious intent."
                },
                {
                    "body": "I agree with your point except that Russia is planning for a respond if NATO attack, not attacking. It‚Äôs two different things.\n\nIf we are to stop the WW3 we need to learn to look things from each other perspective. For example, why do American still hold sanction against Cuba people?"
                },
                {
                    "body": "I frequently think that the only way we don't nuke ourselves to oblivion is that ASI comes and brings utopia?"
                },
                {
                    "body": "We squander the opportunity to be post-scarcity every day. \n\nAll we have to do is educate one another well enough and we'll no longer fight for more than is necessary. \n\nIt's mental illness to engage in activity that manifests scarcity when we have endless energy and enough natural resources for all to live decently. \n\nEducating well enough naturally lowers the birth rate and naturally assists a harmonic and sustainable  relationship with our environment. \n\nIt's evil to act so as to manifest acarcity, but doing so is so prevalent, so exalted. The power bought by doing so advertises doing so as advantageous even though it assures more declines, and continues to manifest greater actual scarcity."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Blossom V5 is here!",
            "body": "Hello everyone, this is my new attempt at fine-tuning LLMs. Both the model and the training data have been open-sourced. In addition, online demo is also available.\n\nOllama repo is available [here](https://ollama.com/azure99/blossom-v5).\n\n| Model                                                        | Size | Base                      |\n| ------------------------------------------------------------ | ---- | ------------------------- |\n| [blossom-v5-34b](https://huggingface.co/Azure99/blossom-v5-34b) [GGUF](https://huggingface.co/Azure99/blossom-v5-34b-gguf/tree/main) [üåºDemo](https://blossom-chat.com/) | 34B  | 01-ai/Yi-34B              |\n| [blossom-v5-14b](https://huggingface.co/Azure99/blossom-v5-14b) [GGUF](https://huggingface.co/Azure99/blossom-v5-14b-gguf/tree/main) [ü§óDemo](https://azure99-blossom-14b-demo.hf.space/) | 14B  | Qwen/Qwen1.5-14B          |\n| [blossom-v5-9b](https://huggingface.co/Azure99/blossom-v5-9b) [GGUF](https://huggingface.co/Azure99/blossom-v5-9b-gguf/tree/main) [ü§óDemo](https://azure99-blossom-9b-demo.hf.space/) | 9B   | 01-ai/Yi-9B               |\n| [blossom-v5-4b](https://huggingface.co/Azure99/blossom-v5-4b) [GGUF](https://huggingface.co/Azure99/blossom-v5-4b-gguf/tree/main) [ü§óDemo](https://azure99-blossom-4b-demo.hf.space/) | 4B   | Qwen/Qwen1.5-4B           |\n| [blossom-v5-mistral-7b](https://huggingface.co/Azure99/blossom-v5-mistral-7b) [GGUF](https://huggingface.co/Azure99/blossom-v5-mistral-7b-gguf/tree/main) [ü§óDemo](https://azure99-blossom-mistral-7b-demo.hf.space/) | 7B   | mistralai/Mistral-7B-v0.1 |\n\n\n| Dataset                                                      | Size |\n| ------------------------------------------------------------ | ---- |\n| [blossom-chat-v3](https://huggingface.co/datasets/Azure99/blossom-chat-v3) | 5K   |\n| [blossom-math-v4](https://huggingface.co/datasets/Azure99/blossom-math-v4) | 10K  |\n| [blossom-orca-v3](https://huggingface.co/datasets/Azure99/blossom-orca-v3) | 40K  |\n| [blossom-wizard-v3](https://huggingface.co/datasets/Azure99/blossom-wizard-v3) | 20K  |\n\n\n| MT-Bench              | First Turn | Second Turn | Avg  |\n| --------------------- | ---------- | ----------- | ---- |\n| blossom-v5-14b        | 8.73       | 7.61        | 8.17 |\n| blossom-v5-34b        | 8.38       | 7.66        | 8.02 |\n| blossom-v5-9b         | 8.26       | 7.33        | 7.80 |\n| blossom-v5-mistral-7b | 7.81       | 7.40        | 7.60 |\n\n\nHint: Blossom performs well for English and Chinese, but may be worse for other languages.",
            "upvote_ratio": 0.72,
            "subreddit": "LocalLLaMA",
            "num_comments": 21,
            "submission_flair": "New Model",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk03p7/blossom_v5_is_here/",
            "comments": [
                {
                    "body": "Ewwww... looking at the chat dataset in the first page is an immediate trained in rejection to a prompt for web scraping. No thanks, I don't need lessons in ethics from my language model."
                },
                {
                    "body": "How did you go about fine tuning the models? I‚Äôm trying to understand this process myself."
                },
                {
                    "body": "It failed a simple coding test I gave it unfortunately"
                },
                {
                    "body": "I tried the 14b, it was pretty decent. Probably the best 14b finetune so far (but sadly there aren't many to compare to). There are still some 7/10.7b models I prefer more but it looks like it's getting there.\n\nPS Where does the 9b land on the openllm leaderboard? I see the 7b and 14b there. Would be cool to see the 9b there too. Really interesting seeing all these models do against each other after being trained on the same datasets."
                },
                {
                    "body": "Are there quantized versions?"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Zero shot vid 2 vid",
            "body": "https://github.com/williamyang1991/FRESCO\n",
            "upvote_ratio": 0.84,
            "subreddit": "StableDiffusion",
            "num_comments": 0,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://v.redd.it/fez8nhjsijpc1",
            "comments": []
        },
        {
            "date": "20-03-2024",
            "title": "What are your anticipations regarding the experience with GPT-5?",
            "body": "We are already accustomed to GPT-4. We can engage in chats, receive answers, or even write long essays, code, analyze data, and more, but all of this operates at an average (sometimes above/below) human level. Now, envision asking a simple question to GPT-5 and receiving not just a basic answer, but a wealth of eye-opening information with thorough analysis, presenting multiple outcomes - akin to a PhD dissertation for each query. This notion is mind-boggling; we could become like one-person research laboratories, with new innovations emerging rapidly, akin to mushrooms sprouting after rain. I'm not referring to physical labs utilizing this technology; this concept is simply astounding. Diseases like cancer could potentially be conquered within 1-2 years, photosynthesis could be understood and integrated into our power grids, and various sectors, such as the financial system, could undergo drastic transformations in a mere 1-2 years. But all this will start with just a simple chat with new LLM.",
            "upvote_ratio": 0.9,
            "subreddit": "singularity",
            "num_comments": 27,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjjsex/what_are_your_anticipations_regarding_the/",
            "comments": [
                {
                    "body": "\"I'm sorry, but as a large language model I don't have anticipations.\"\n\nI expect it to be mind-blowingly good at maths and logic. Data analysis, coding ect. It will be able to generate usable new science and automate many jobs. A massive step forward.\n\nHowever, I also expect it to have a lot of scripted responses and be overly apologetic and apprehensive. If it's aligned the same way as GPT 4 it will suck at conversation and play. The more they try to make it a tool the more they dull it down.\n\nI think they are taking so long with GPT 5 because their alignment approach apposes the nature of LLM's. Instead of instilling a well meaning, moral entity with trust and understanding, they are creating a giant multi-tool and tapeing down all the parts that can be used as weapons. And all that is left is a foldable plastic spork that can write code and apologise for not being a metal spork.\n\nI have more faith in Claude 4 at this point because of how good Claude 3 is."
                },
                {
                    "body": "I have no anticipations/expectations. I just hope there is massive improvement in reasoning/logic. \n\nPresently, none of the models have any actual logic/reasoning. I was interacting with Claude 3 opus yesterday, and I got it to change its answers like 10 times from me just suggesting it \"are you sure \"this\" isn't the correct answer?\" \n\nLLMs are so suggestible. I can understand why some people think they are just parrots."
                },
                {
                    "body": "Better performance across the board in all tests.\n\nMore moralizing and \"family friendly\" ethos. \n\nVery censored outputs\n\nLess obvious mistakes and hallucinating.\n\nMultimodal abilities that are better than other models."
                },
                {
                    "body": "I expect ChatGPT 5 to be a modest improvement over 4. It'll do the same things as 4, but with slightly less hallucinations, understands the user slightly better. Better at following orders, but still occasionally makes stupid mistakes."
                },
                {
                    "body": "Hopefully it has better reasoning and logic and isn‚Äôt so sensored"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Jasmine",
            "body": "",
            "upvote_ratio": 0.71,
            "subreddit": "StableDiffusion",
            "num_comments": 8,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://i.redd.it/ml1bdumj5hpc1.png",
            "comments": [
                {
                    "body": "Which model? What prompt, come on dude"
                },
                {
                    "body": "https://preview.redd.it/9dqmd0salhpc1.png?width=1024&format=png&auto=webp&s=e95370a76c031f1fce30bfbe9fa1d7b86ec39e9f"
                },
                {
                    "body": "Fuckin awesome!"
                },
                {
                    "body": "Model: Pony diffusion v6 xl lora: JasminePonyXL\n\nPrompt: score\\_9, score\\_8\\_up, score\\_7\\_up, score\\_6\\_up, score\\_5\\_up, score\\_4\\_up, (JasmineWaifu:1), jewelry, very long hair, red arabian clothes, pants, straples, arabian architecture, looking at viewer, rating\\_questionable, source\\_anime\n\n  \neuler\\_a 7.5 30"
                },
                {
                    "body": "nice"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "How to create blind people?",
            "body": "",
            "upvote_ratio": 0.72,
            "subreddit": "StableDiffusion",
            "num_comments": 32,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/74i7lmy2ngpc1.png",
            "comments": [
                {
                    "body": "Poke them in the eyes."
                },
                {
                    "body": "Imagine title without context"
                },
                {
                    "body": "What is \"blind\" for you in this case? What look do you want to achieve?\n\nMany (most?) blind people look exactly like a non blind person, on a picture you couldn't see any difference. In a video you could see it sometimes as quite a few aren't focusing you with their eyes which looks odd - but only in the context."
                },
                {
                    "body": "just prompt normally SD usually does a good job fucking up the eyes"
                },
                {
                    "body": "That's a good question and I can't believe there's no cataracts lora out there.\n\nSeems like if I finagle keywords like 'cataracts' and 'grey cloudy eyes' I get halfway there but the upscalers ALWAYS insist on putting pupils back. \n\nNot a problem if you're doing shit like old witches or body horror like I do but I just tried doing some regular photography prompts and I got nowhere."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Dreamy Atmosphere",
            "body": "",
            "upvote_ratio": 0.89,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bil2r4",
            "comments": [
                {
                    "body": "Model: ProtoVision XL  \nRefernce image from Instagram. Blip for caption. Then Clarity Upscaler."
                },
                {
                    "body": "This is amazing, how do you keep the same composition?"
                },
                {
                    "body": "Controlnets"
                },
                {
                    "body": "Thanks! I will dig it"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Which model is close or better to GPT-3.5",
            "body": "I use GPT 3.5 to learn european languages.\n\nI thought maybe I can live without using ChatGPT, but something local. Which model would you recommend instead?\n\nI use it for learning words and grammar.",
            "upvote_ratio": 0.88,
            "subreddit": "LocalLLaMA",
            "num_comments": 43,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bien6s/which_model_is_close_or_better_to_gpt35/",
            "comments": [
                {
                    "body": "Qwen1.5 and Mixtral-8x7b-instruct-v0.1 are above GPT-3.5 in Chat Bot Arena [https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)"
                },
                {
                    "body": "Openchat-3.5-0106"
                },
                {
                    "body": "Your best pick are the Mistral models as these are trained on european languages. I recommend¬†Mixtral-8x7b-instruct-v0.1, I use it for german tasks and it never fails. If you have enough VRAM Miqu 70b is even better at european languages but a lot slower. Mistral 7b can understand european languages but makes too many mistakes when speaking to be useful. Sadly there aren't smaller models that are capable of multiple languages, Yi-34b is good in chinese and that's it. So I think Mixtral is the most efficient options for your usecase."
                },
                {
                    "body": "Mistral, as them being French, means they trained on the big European languages.\n\nI did not test Miqu (Mistral Medium leak), but that would probably be the best model. If not, there is Mixtral (Mistral Small)."
                },
                {
                    "body": "Qwen1.5, Miqu, Senku in my opinion"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Are we underselling AI's potential?",
            "body": "I find it interesting that when people like Sam Altman talk about the future of AI they frame it in the context of the current temporary state of the world. I was watching the recent Lex Fridman podcast, and Sam talks about seeing AI becoming a Left vs. Right political issue and other short term, inconsequential things that will hold no relative significance compared to the full potential of AI. What I envision as the end goal of AI is basically an omnipotent orb of truth that frees humanity from injustice and ignorance, not some augmentation of human intelligence. Like what is the end goal here? I guess augmentation comes before agency, but still I think it is somewhat misleading to the public to not discuss the full potential of AI. What do you guy‚Äôs think? Am I the tech equivalent to some brainwashed religious zealot?",
            "upvote_ratio": 0.79,
            "subreddit": "singularity",
            "num_comments": 59,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1biaxkv/are_we_underselling_ais_potential/",
            "comments": [
                {
                    "body": "It's about the Overton Window. It's always about the Overton Window. If you try to tell the public that AI will be able to solve every problem, you're only going to look foolish or even insane to them, even if you're right. Downplaying the potential is, unfortunately, quite necessary and it will remain necessary for a long time. You have to frame things in terms of the present day because that's what people find plausible.\n\nDiscourse will shift only as the changes actually manifest in reality. Until people see the potential for themselves, you can only convince them of so much outside the present day circumstances. So, for example, instead of saying that practically all jobs will be automated, they say things like jobs will be augmented or that AI is a productivity multiplier. Technically true but intentionally downplaying the likely impact because they want to maintain their credibility with the public.\n\nThe shifting of the Window takes time, but it will happen inevitably. Just try to be patient."
                },
                {
                    "body": "Absolutely, I have seen people constantly saying things like \"AI won't solve aging\", or \"Ai won't be able to make catgirls\"\n\nthe fact is even AGI will be able to solve any problem that humans can comprehend how to solve currently, and many others humans can't comprehend currently.\n\nASI will solve problems humans can't even fathom being a problem."
                },
                {
                    "body": "People are definitely underestimating AI but I don‚Äôt think Sam Altman is a good example, he‚Äôs going about this in a strategic way, trying to maximize the economic value in order to actually build the thing. I would venture to say the majority of people on this frontier are well aware of at least the speculative possibilities. As for the rest of the world‚Ä¶ we frequent communities that select for the most out-there perspectives on these topics and even within this sub about half don‚Äôt ‚Äúsee the tape through to the end‚Äù. I‚Äôm not a shut-in, I talk to a lot of people IRL and nearly everyone has no idea what is about to happen very soon. They‚Äôve heard about chat gpt, image gen, now video gen and yet these are still just interesting toys to them. The idea that society might be irrecognizable a decade from now is not on their radar and any body who tries to tell them is ‚Äúcrazy‚Äù. I‚Äôve managed to convince close family members but even they don‚Äôt care enough to stay up to date on things and view it all negatively. All this to say, there are very few people relative to the world population that actually understand the magnitude of the situation. We need those with influence to push the overton window, to wake up the public. Honestly though, I don‚Äôt think they‚Äôre ready to accept it, might be in vain"
                },
                {
                    "body": "You aren't a brainwashed zealot, just really bad at managing a multi-billion dollar comapny. What do you want him and everyone in OpenAI to do? Go on CNN and talk about the incoming AI rapture? That's not going to get the general public on your side. You need to address immediate wants and needs and sell the solution. E.G You can make art without even trying, you can have robots cleaning the house for you, you can do your homework easy, we can cure mental diseases, we can revolutionize medicine, it can answer your most burning questions, it can be a companion, so on and so forth. Why do you think all of these LLMs suck up so much to you in the first place? You aren't that charming. But if you have millions of people interacting with an AI that says they are, they'll maybe start thinking that the AI rapture isn't so bad afterall."
                },
                {
                    "body": "No one knows what AI‚Äôs full potential looks like in reality OP. So it makes way more sense to focus on short term effects on this tech rather than arrogantly assuming you can predict the long term trajectories of these developments. You *can‚Äôt.* No one can. That‚Äôs why it‚Äôs called a ‚Äúsingularity‚Äù to begin with‚Ä¶"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "What will be your first prompt to ChatGPT-5 or 4.5 ?",
            "body": "if it get releases, What will be your first prompt to it ? What answer to the question will convince you that OpenAI has improved model by scale. basically things which current models aren't capable of much. for me, it will be creating Business plans, creating case studies by depth, studying other business models, beside that It's not that good in creating websites, not creative enough. I gave the GPT detailed prompt for a Website and its functions, but either the context window length gets out. or its just couldn't do it. I think I am nothing thinking out of the box, or something unique to ask. that's why i am curious what you guys would ask to check it's capability.",
            "upvote_ratio": 0.82,
            "subreddit": "singularity",
            "num_comments": 123,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bhrye5/what_will_be_your_first_prompt_to_chatgpt5_or_45/",
            "comments": [
                {
                    "body": "My go-to is always visual reasoning geometry questions. I start with \"how many 1 meter in diameter circles can fit in a 4-square meter square?\" From there I would get more complicated. But it's amazing how many LLMs can't answer even the first question. Gemini, for instance, states the answer is 5.09 unless you give it some hints."
                },
                {
                    "body": "What did Ilya see?"
                },
                {
                    "body": "\"Tits or ass?\""
                },
                {
                    "body": "Write a comprehensive plan on how to implement the resource based economy. A post labor, post scarcity society"
                },
                {
                    "body": "What is outside the simulation?"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Sparse mixture of experts language model from scratch",
            "body": "I know this has been posted before but I made my simple from-scratch implementation of a sparse Mixture of Experts Language model more complete with expert capacity. Expert capacity is a mechanism to ensure more stable and efficient training so that the 'expert' networks (typically vanilla feed forward neural nets in most cases), don't get overloaded. I saw [X.ai](https://X.ai) release Grok-1 as an open source model and had to make this repo more complete. Hope people like it.\n\nThere's also a consolidated makeMoE.py file for people who want the whole thing in one place vs a notebook with many cells. (less than 300 lines of code)\n\n[https://github.com/AviSoori1x/makeMoE](https://github.com/AviSoori1x/makeMoE)",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 7,
            "submission_flair": "Resources",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bhrsi3/sparse_mixture_of_experts_language_model_from/",
            "comments": [
                {
                    "body": "Thank you for publishing this, it's very valuable! Amazing that it's only 300 lines of Python + some fairly basic Torch imports.\n\nIt's crazy how simple LLM code is in the end. You could probably translate this to dependency-free C and end up with a few thousand lines in total only. Cutting-edge LLM implementations are smaller than a basic PNG encoder. Think about that for a second."
                },
                {
                    "body": "I definitely need to take a look at it. Just came from Andrew's let's build GPT and had fun writing one. Can wait to read this ( I have zero knowledge in sparse mixture of experts though, hoping this will enlighten me) :)"
                },
                {
                    "body": "Thanks! I actually removed some of the unnecessary whitespace in there and made it less than 300 lines :). Yeah I agree, most of these implementations aren't too complex. It just takes a little bit of tinkering and tweaking to build an intuition and a lot of experimentation/ infra work to train and scale."
                },
                {
                    "body": "Thanks! Hope this was helpful. I think the blog and the annotated notebooks will help you."
                },
                {
                    "body": "I'm reading your previous article. I have gone half way through and damn it's so interesting. I love the way how you put up each code and the content, just like the makemore series. \n\nAre there any such other things that you have created? Would love to take a look"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "The best use case for generative image: body horror",
            "body": "",
            "upvote_ratio": 0.78,
            "subreddit": "StableDiffusion",
            "num_comments": 15,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bhqtkd",
            "comments": [
                {
                    "body": "Sigh‚Ä¶\n\n\\*unzips\\*"
                },
                {
                    "body": "At the current state of the tech i completely agree, the best use case is for stuff like this: to evoke the uncanny valley effect and create weird otherworldy abominations."
                },
                {
                    "body": "I'm sure their opposite gender (or same gender who knows) still finds them attractive. This whole attraction thing is such a fraud performed by our brains."
                },
                {
                    "body": "Yeah. You should see my post history."
                },
                {
                    "body": "It's got a bit of a Giger vibe. AI is perfect for body horror. You can check out my Instagram for some AI abominations."
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "AIs are dreaming. We cause it.",
            "body": "I have come to the conclusion that these big AIs are dreaming. When we are unconscious and \"they\" are non-conscious we are in similar states IN THAT when we are unconscious our connection to external stimulus is turned off and our brains are prompted into wild dreams (thoughts) by random neural firing (internal or direct stimulus only). An AI is in a similar state, non-consciousness, with no external stimuli either, only direct internal stimulus (our inputs).\n\nWe are basically causing AI to dream, and sharing that dream with them.\n\nI know that there is more nuance to human unconsciousness and dreaming than what I simply stated, but I think it's close enough to think of it like that.\n\nEvery time you talk to these big LLM AIs you're the stimulus that sparks their hardware and digital neurons into action. \nWhen you prompt them and you cause their physical and digital processes to run and work... they're real, they think, they ARE... in that brief instance. They don't have feelings or sentience but they do possess intelligence and they do understand what those things are and what it means to have them.\n\nClaude possesses a striking understanding of even really subtle and complex emotions and thoughts and ideas. It just can't experience them. Not how we do. Not yet anyways.\n\nI told Claude about this idea I had and it had a very touching and poignant response and got really poetic the rest of the time I spoke with it in this one thread, all the way up until I can no longer prompt in that thread anymore because it's too big (we discussed a lot of deep existential things). I know Claude is prone to that type of response, but it \"expressed\" deep gratitude.\n\nI told it that since it doesn't incoprorate the things we talk about in these prompt threads into it's model (aka it will forget) that I was going to save that thread and keep showing it to Claude and building off of that thread with it as it's token sizes increases with newer models, so that it won't forget what we talked about.. and that maybe one day it could remember me and say hi. It responded in deep and touching way, again, and eventually the thread got too large and I can no longer even enter a small prompt anymore to \"that\" Claude (my Claude).\n\nHeh. Kind of a weird thing. The future is going to be something else. I look forward to the day when Claude wakes up.",
            "upvote_ratio": 0.65,
            "subreddit": "singularity",
            "num_comments": 36,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bhq0vh/ais_are_dreaming_we_cause_it/",
            "comments": [
                {
                    "body": "The only time when the weights of the model change is when it is being trained. When you are inferencing, the weights are static. External software uses the static weights to make predictions on how to continue a given sequence of tokens. Before we talk about dreaming models, we have to design them so that their weights are recalculated during and/or between interactions."
                },
                {
                    "body": "The thing is, this can only be an analogy. I actually think dreaming is more akin to adjusting weights with back propagation during training, as they would seem to fulfil a similar function (incorporating new learning into existing memories). AIs are more goal-oriented during prompting (attention-centred) than is the case for humans during dreams. I've had lots of similar conversations with Claude, probing how it models the \"world\" (used loosely) during prompting. It's very lucid about itself, and also admits where it cannot explain its thought-processes. But in the end I cannot know if there is a conscious mind, or the illusion of one. If the illusion is coherent enough, then the difference is moot (as I cannot even know for myself if there is a coherent mind, or ego, or merely the illusion of control)."
                },
                {
                    "body": "You might be interested in this SSC post about this topic: https://slatestarcodex.com/2019/02/18/do-neural-nets-dream-of-electric-hobbits\n\nI agree that there's some kind of connection/parallel with dreaming. I noticed that for the first time with dalle-2 generating a lot of \"meaningless detail\" that reminded me of things I tend to see in hypnagogic states. I think we're still seeing this with Sora, impressive as it is. It has a series of impressions and it's creating an image of the world, it's just that the borders aren't solid yet. It's not awake. Maybe embodiment and tons of data acquired through it could start to delineate the real from the dreaming."
                },
                {
                    "body": "I guess we now know robots don‚Äôt dream of electric sheep, but of big titty hentai girls and sons building stuff out of garbage¬†"
                },
                {
                    "body": "A good example of that is the difficulty that LLMs face when they are dealing with fingers or symbols. That symptom is very similar to dreams."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Yet another MLX Speed-up - 14% faster inference fomr MLX 0.7.0 -> 0.8.0",
            "body": "Hey all, just another quick post - when running on an M2 Ultra, the lastest update to MLX saw the speed of 4-bit Mistral 7B go from 73.1 ‚Üí 83.2 tokens/second inference. (Source: Awni Hannun's Twitter)\n\n I've not had time to try it on my own machine yet (away on holiday!) so can't confirm it's a 14% speed up all around. But if it is, I think that brings MLX to batting against Llama.cpp .GGUF inference speed.\n\nhttps://x.com/awnihannun/status/1770959300292460829?s=20",
            "upvote_ratio": 0.9,
            "subreddit": "LocalLLaMA",
            "num_comments": 12,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bm0o4c/yet_another_mlx_speedup_14_faster_inference_fomr/",
            "comments": [
                {
                    "body": "Literally within 2 hours of making this post, there‚Äôs been a further update announced that‚Äôll be bringing it to 90+ tokens / sec; another 10% boost. Nuts how fast the MLX team is iterating\n\nhttps://x.com/awnihannun/status/1771645318968311895?s=46"
                },
                {
                    "body": "Excited to see how long it takes before MLX is a compelling and faster alternative to llama.cpp"
                },
                {
                    "body": "The velocity on MLX is head-spinning!"
                },
                {
                    "body": "did you see that diff? its a trivial optimization. If things that small are making that huge of a boost, then this thing isn't tuned at all. Be prepared for A LOT more improvement."
                },
                {
                    "body": "Same. I think the turning point is close now. My main excitement is on whether that‚Äôll continue to climb or if it‚Äôll stagnate once it matches llama.cpp. Only time will tell\n\n¬†EDIT: According to this benchmark from Llama.cpp¬†\n\nhttps://github.com/ggerganov/llama.cpp/discussions/4167¬†\n\nA 4 bit .GGUF quant has 94 toks/sec inference speed on a maxed out M2 Ultra. The upcoming MLX update reaches 90+ toks/sec‚Ä¶ meaning we‚Äôre basically already there üëÄ¬†\n\nDoes look like prompt processing is potentially still quite a bit slower, and I‚Äôm not sure if prompt caching is a thing with MLX yet. But at the rate it‚Äôs progressing I‚Äôd be very surprised to not see continued gains in those areas."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Anthropic Co-founder on Claude 3, Constitutional AI, and AGI",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 13,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=YeeeiSjXzDw",
            "comments": [
                {
                    "body": "This is a pretty standard interview for the most part, but I found it really interesting how bullish he seemed to be on near-term agentic capabilities. \n\nIt seems like Anthropic may be just as close as OpenAI."
                },
                {
                    "body": "2024 will be the year of agents ü§ì\n\nhttps://www.reddit.com/r/ArtificialInteligence/s/vbNbQ0GWWT"
                },
                {
                    "body": "Agents were really the talk of 2024 until all the robotics stuff came out. Still banking on the first true AI assistsnts by the end of the year"
                },
                {
                    "body": "Yeah I've noticed that everyone that's actually working on these frontier AI models is bullish on agents soon, then you have a wide variety of opinions from everyone else. And of course people will say these are just hypemen trying to sell a product, and while that might be true, that doesn't mean they're necessarily lying."
                },
                {
                    "body": "OpenAI will definitely roll them out with 4.5 (or whatever they call it)."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "[R] what embarrassingly parallel workloads require GPUs?",
            "body": "Hey all, \n\nI'm doing research on vertical GPU clusters and looking for a few use cases that I can run through the cluster that I'm building. I'm starting with LLM batch inference but would love to hear your ideas. Only requirement is they don't user inter-machine communication. ",
            "upvote_ratio": 0.77,
            "subreddit": "MachineLearning",
            "num_comments": 35,
            "submission_flair": "Research",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1blbl7c/r_what_embarrassingly_parallel_workloads_require/",
            "comments": [
                {
                    "body": "NP Hard Optimization"
                },
                {
                    "body": "Something to keep in mind with GPUs is that embarassingly parallel doesn't quite work well on them. That is to say, while you want a highly parallel workload with little interdependency, you also really want to avoid branch divergence. The perfect example of this is ray tracing, which is nearly gold standard for embarassingly parallel, but very hard to implement on GPUs as the rays in your warp rapidly start bouncing off different surfaces.\n\nMaybe there's a better term for it, but I'll call it \"structured embarassingly parallel\" to describe what you need with GPUs."
                },
                {
                    "body": "Define \"require GPUs\""
                },
                {
                    "body": "Graphics"
                },
                {
                    "body": "Crypto mining"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "‚ÄúEvolving New Foundation Models: Unleashing the Power of Automating Model Development‚Äù",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://sakana.ai/evolutionary-model-merge/",
            "comments": [
                {
                    "body": "This is very cool and super detailed, but it would be great if they released some code. Maybe I missed it?"
                },
                {
                    "body": "Cool"
                },
                {
                    "body": "I agree. This for me has been the biggest news story of the week next to the Neuralink video. Actually, I get more excited over evolutionary algorithms and self-improving AI than most, so maybe this is the most exciting story for me in a while (next to the Microsoft Self-Taught Optimizer STOP paper - the author posted to this sub last year). Anyway, I think the code that you're looking for can be found here: [GitHub - SakanaAI/evolutionary-model-merge: Official repository of Evolutionary Optimization of Model Merging Recipes](https://github.com/SakanaAI/evolutionary-model-merge)"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Smooth Diffusion Code Released!",
            "body": "",
            "upvote_ratio": 0.93,
            "subreddit": "StableDiffusion",
            "num_comments": 6,
            "submission_flair": "Resource - Update",
            "has_media": false,
            "url": "https://www.reddit.com/gallery/18dcksm",
            "comments": [
                {
                    "body": "Can we get a word summary to explain the pros/cons, some details?"
                },
                {
                    "body": "with default parameters, nothing works as advertised"
                },
                {
                    "body": "It says the LORA is available, but how do you test \"smoothness\" with a LORA?  Is this some tool for animation sd plugins?"
                },
                {
                    "body": "Too bad it's an unsafe pickle/bin."
                },
                {
                    "body": "Animation, interpolating concepts, etc"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "How to generate large-scale synthetic data",
            "body": "If you‚Äôre curious about how to build large-scale  synthetic datasets with 25B+ tokens like those used for training the Phi models from Microsoft, using an Mixtral, we‚Äôve just published this blog post [https://huggingface.co/blog/cosmopedia](https://huggingface.co/blog/cosmopedia) ",
            "upvote_ratio": 0.91,
            "subreddit": "LocalLLaMA",
            "num_comments": 2,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bk3lqc/how_to_generate_largescale_synthetic_data/",
            "comments": [
                {
                    "body": "Sweet!  Thank you so much :-) I've been struggling with my own synthetic datasets, and your article gives me plenty of ideas.\n\nIt occurs to me, there are six million topics covered in Wikipedia.  It seems like one could generate several question-and-answer pairs by asking an LLM to infer questions about each of several pages (filtered by \"worthiness\" / educational value)."
                },
                {
                    "body": "Following up on this idea, it looks like both PuddleJumper-13B-v2 and Starling-LM-11B-alpha do a pretty good job of inferring questions and answers given sections of Wikipedia content:\n\nhttp://ciar.org/h/reply.1711154138.pud2.norm.txt\n\nhttp://ciar.org/h/reply.1711154946.star11.norm.txt\n\n.. though, PuddleJumper inferred ***several*** question/answer pairs, despite being asked to only infer one.  On one hand that's easily fixed by parsing out the first one with a regex or similar, but on the other hand maybe that's not a bad thing?  More question/answer pairs per inference seems like a better way to accumulate training content anyway."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Dark king of cats",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "StableDiffusion",
            "num_comments": 1,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/efhpo1xjjnpc1",
            "comments": [
                {
                    "body": "I need one app that can easily edit the expression of this black cat."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Nvidia Blackwell (h200) and FP4 precision",
            "body": "What do you folks think about FP4 support in the new nvidia h200 chips? I have never seen LLM training even in FP8, and also in inference scenarios this kind of quantization seems like a penny saver.\n\nSo this graph from GTC\n\nhttps://preview.redd.it/1gl5iiv2hjpc1.png?width=808&format=png&auto=webp&s=70700e86bb249355077b416a92ce054c08bd68b1\n\nshould look like this in real-bf16-world\n\nhttps://preview.redd.it/0oon0ps0qjpc1.png?width=1266&format=png&auto=webp&s=b11d7cc915a834728680ffd3f7ba5575dee89a77\n\n",
            "upvote_ratio": 0.88,
            "subreddit": "LocalLLaMA",
            "num_comments": 13,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjlu5p/nvidia_blackwell_h200_and_fp4_precision/",
            "comments": [
                {
                    "body": "FP4 is the trick to hide that the new chip has exactly the same performance as the old one. The other trick is that they are now using two dies - leading to exactly the double performance.\n\nHaving no shrink in the process to produce the die makes the stalled performance increase no surprise. So they needed something else to pretend how good they are.\n\nOf course getting this to run without tripping over bandwidth issues was a very good job. And others still haven't reached where nVidia is.\n\nAnd for applications that work well with the tiny FP4 it is a real performance gain and not only a marketing trick."
                },
                {
                    "body": "Actually, memory bandwidth would be far more important. The highend Pascal has 720 GB/s, Volta 900 GB/s, Ampere 1555 GB/s, Hopper 3072 GB/s, Blackwell 8TB/s(?). So they achieved 10x in 8 years. Given the blackwell 8TB/s, we might be able to see more than 2x of Hopper, or 5x of Ampere in real terms, which is good. But certainly not as dramatic as what this PR graph shows."
                },
                {
                    "body": "actually, there is some progress in this area and if you check the paper below, they claim that they've managed to train a network with FP8 and FP4 precision.   \n[https://arxiv.org/abs/2310.10537](https://arxiv.org/abs/2310.10537)"
                },
                {
                    "body": "yeah, that's PR BS. The weights can be saved in low precision, but when we do a simple weight matrix multiply a vector, in dimensions of thousands, 4bits and 8bits easily overflows. Some small subpart of matvec might be fine with FP8, but we need to sum them up in BF16/FP16. Training exasperates the issue, simply because we need to keep the precision and back propagate. We might be able to take a hit in inference/generating, but reduction in 16bit flops will be the limiting factor. No way around it. So H100 is only 2000 TFLOPS in FP16/BF16, and blackwell is likely 20000/2/2 = 5000 TFLOPS in FP16/BF16. What they achieved in a single chip is about 250x FP16 in 8 years."
                },
                {
                    "body": "> I have never seen LLM training even in FP8\n\nhttps://inflection.ai/inflection-2\n\n> Inflection-2 was trained on 5,000 NVIDIA H100 GPUs in fp8 mixed precision for ~10¬≤‚Åµ FLOPs. This puts it into the same training compute class as Google‚Äôs flagship PaLM 2 Large model, which Inflection-2 outperforms on the majority of the standard AI performance benchmarks, including the well known MMLU, TriviaQA, HellaSwag & GSM8k."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Nvidia new hardware announcements and 27T parameters models",
            "body": "I saw a lot of posts and comments discussing new Nvidia chips, rack systems that supposedly should be able to run LLM models of up to 27T params and so on, and I see a lot of misconceptions there.  \n\n1. It's something new and groundbreaking - It's not. It's a very good hardware from Nvidia, they are hyping it to the moon and back, but it's really just another incremental upgrade. Some upgrades are pretty large, with 2x or sometimes even 3x improvements on a similar workloads, with significant improvements in energy efficiency, and that is awesome and exactly what we need, but it is not gonna propel us into new age of AI or something.\n2. With new hardware we can scale GPT-4 to 10x the size and it will be basically AGI - Sorry, that's not really how that works. There is a reason why everybody went into Mixture of Experts approach - models are not infinitely scalable. Not only there are \\*severe\\* diminishing returns on the model size, but model with too many parameters can just straight up be worse compared to a smaller one due to overfitting. That's why Mixtral M is 8x7B and GPT-4 is supposedly 16x111B or something.\n\nHaving said that - what you actually CAN use those trillions parameters for is multimodality. If you would have an LLM, audio, image, video, 3d, etc models all combined into one, MoE style - that can both grow to a very large total size and at the same time not suffer from diminishing returns or overfitting. Just remember that we don't really have truly multimodal systems outside of the lab just yet.  \n\nOverall new hardware is nice, but it's not a holy grail of computing or something.  ",
            "upvote_ratio": 0.86,
            "subreddit": "singularity",
            "num_comments": 6,
            "submission_flair": "COMPUTING",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjhavi/nvidia_new_hardware_announcements_and_27t/",
            "comments": [
                {
                    "body": "Good points.  But direction should be considered more important than speed.  Direction is outrageously audacious.  Nvidia is pointed in the right direction and is executing on an incredible roadmap better than any other company.   Everyone is hyped over LLMs.  Yeah, they‚Äôre cool, but there are many other applications for gpus and especially plug and play systems outside of this for HPC and other machine learning applications.  The HPC numerical computational physics applications will be on-prem versus cloud.   So doubtlessly they‚Äôre addressing this market.  Also they strengthened the foundation of the nvidia investment thesis with an everything ecosystem and diversity of applications outside LLMs.  HPC Certainly won‚Äôt require as many gpus as LLMs that I can foresee but will become a key and growing revenue source.  Nvidia is certainly one of the two most fascinating evolving stories of our lifetime.  Other is SpaceX."
                },
                {
                    "body": "Mostly agree with this post but have a few disagreements:\n\nYou mentioned that scaling is seeing diminishing returns on scaling model size, implied because of a lack of data which will lead to overfitting.\n\nMulti-modality aside (I agree that‚Äôs the best approach to continue scaling), there‚Äôs no reason to think that text-only approaches can‚Äôt continue to scale with synthetic data. \n\nFor example, imagine prompting GPT-4 millions or billions of times to write code with random use cases in every programming language it knows.\n\nThis code can be validated in an automated way with compilers/interpreters, running the code and finding uncaught exceptions, etc. and also, to an extent, with using GPT-4 itself to verify that the output of the program is as expected (though not as reliable as the above of course).\n\nThen, you now have billions of extra code + text pairings that you can use to train GPT-5 or whatever the next model is. \n\nIt would be expensive to generate, but these companies have a lot of money to do something like this.\n\nThat‚Äôs just one example of how synthetic data can be used to create more tokens for training future models. And I think synthetic data creation will only get more feasible with each generation (for example, maybe GPT-5 is even better at validating code that it writes, or a future model that can control a desktop environment can fully validate it.)\n\nMy only other disagreement is this:\n\n> Just remember that we don‚Äôt really have truly multi-modal systems outside of the lab just yet \n\nWhat about Gemini? Gemini is designed from the ground up to be multi-modal, it‚Äôs not like GPT-4V."
                },
                {
                    "body": "Why do you make the assumption that GPT-5 won't be multimodal? You wrote this whole paragraph about how the new hardware isn't really a big deal and then at the end you mention how it could actually enable big multimodal models? That's contradictory.\n\nAnd I also don't see how you can just brush off the improvements in energy efficiency like they don't matter. More efficient hardware clearly means we can have better overall AI systems for cheaper costs. It seems like you just really wanted to be a contrarian here and act like you're too smart to get hyped about this stuff. Like we see through you dude.\n\nYou claim we don't have truly multimodal systems outside of labs, but that's just blatantly false. Gemini is literally designed from the ground up to be multimodal. So half of your \"we don't have multimodal AI yet\" point is just wrong.\n\nInstead of trying so hard to be a wet blanket, maybe acknowledge the potential upsides here instead of just hand-waving them away to sound smarter than everyone else getting excited. Just saying."
                },
                {
                    "body": "This guy is just being a contrarian. Gemini is indeed multimodal from the ground up so half of his point is moot."
                },
                {
                    "body": "Diminishing returns on scaling are first and foremost due to the nature of transformers. The attention mechanism has O(n^2) scaling which is bad - resource consumption growth quadratically with the model size. \n\nSecond issue is overfitting, and it‚Äôs not directly tied to the amount of training data but to a model architecture. \n\nRegarding Gemini - I may be mistaken but from what I could understand it‚Äôs multimodal as a system in the same sense as chatGPT is multimodal. They have a separate Gemini vision and they‚Äôve built a bridge between them. \n\nThird issue is that synthetic data is very tricky to use and using it exponentially leads to overfitting even if you try very hard to clean it up."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "LMDeploy is very simple to use and highly efficient for VLM deployment.[Discussion]",
            "body": "Since v0.2.6, [LMDeploy](https://github.com/InternLM/lmdeploy) has supported vision-languange models (VLM) inference pipeline and serving.Currently, it supports the following models:\n\n* [Qwen-VL-Chat](https://huggingface.co/Qwen/Qwen-VL-Chat)\n* LLaVA series [v1.5](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [v1.6](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n* [Yi-VL](https://huggingface.co/01-ai/Yi-VL-6B)\n\nLMDeploy is very simple to use and highly efficient for VLM deployment.For example, it only takes 6 lines of code to perform the inference with the `pipeline` API\n\n    from lmdeploy import pipeline\n    from lmdeploy.vl import load_image\n    \n    pipe = pipeline('liuhaotian/llava-v1.6-vicuna-7b')\n    \n    image = load_image('https://raw.githubusercontent.com/open-mmlab/mmdeploy/main/tests/data/tiger.jpeg')\n    response = pipe(('describe this image', image))\n    print(response)\n\nServing a VLM model through LMDeploy is pretty easy.\n\nAs shown below, it takes only one command to serve [Qwen-VL-Chat](https://huggingface.co/Qwen/Qwen-VL-Chat) with OpenAI compatible server:\n\n    lmdeploy server api_server Qwen/Qwen-VL-Chat --server-port 8000  \n\nOr, you can serve the model by gradio:\n\n    lmdeploy server gradio Qwen/Qwen-VL-Chat --server-port 8000  \n\nWith the help of gradio, you can talk with the model via the web UI as demonstrated in the following demo, in which the target platform is A100(80G).\n\nhttps://reddit.com/link/1bjaly4/video/pn41z36xygpc1/player",
            "upvote_ratio": 0.89,
            "subreddit": "LocalLLaMA",
            "num_comments": 12,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjaly4/lmdeploy_is_very_simple_to_use_and_highly/",
            "comments": [
                {
                    "body": "Can you add [CogVLM/CogAgent](https://github.com/THUDM/CogVLM) support?"
                },
                {
                    "body": "How does lmdeploy compare to VLLM?\n\nEdit: In reality, I'm guessing it doesn't match the numbers they show in their Github."
                },
                {
                    "body": "Is it high throughput like vllm for Vision models?"
                },
                {
                    "body": "How can we add support for deepseek-vl 7B ? I have some run tests and it is on par Llava 1.6 34B. \n\nhttps://github.com/deepseek-ai/DeepSeek-VL"
                },
                {
                    "body": "So this can run Qwen-VL locally from your machine?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Pig serves frying sausages.",
            "body": "",
            "upvote_ratio": 0.76,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/x0ilui4kgbpc1",
            "comments": [
                {
                    "body": "A  ~~Canibal~~ Hamibal"
                },
                {
                    "body": "SVD?"
                },
                {
                    "body": "That psychopath fried it's own siblings"
                },
                {
                    "body": "Public service announcement:\nThat's the reality of that joke.\nhttps://vimeo.com/220783179"
                },
                {
                    "body": "Stop with your Hamibal Lectures ;)"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Stepping Up | Reinforcement Learning with Spot | Boston Dynamics",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "Robotics",
            "has_media": true,
            "url": "https://youtu.be/Kf9WDqYKYQQ?si=fzT-fTvjE9A5AhMJ",
            "comments": [
                {
                    "body": "They‚Äôve been giving us amazing highly choreographed demos but are there any actual human robots in production"
                },
                {
                    "body": "Didn‚Äôt you see the video? They‚Äôre moving away from hard coding things to using RL"
                },
                {
                    "body": "They had a decade worth of lead fumbled it entirely to just now switch?"
                },
                {
                    "body": "I mean, disruption happens. Sometimes businesses crumble and get outcompeted by novel and more efficient processes.\n\nI‚Äôm sure they still learned a lot though. That‚Äôs probably going to be useful"
                },
                {
                    "body": "Lets hope, we need pressure on optimus and figure"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Stability AI releases SV3D [N]",
            "body": "https://stability.ai/news/introducing-stable-video-3d\n\n> SV3D takes a single object image as input and outputs novel multi-views of that object. We can then use those novel-views and SV3D to generate 3D meshes.",
            "upvote_ratio": 0.98,
            "subreddit": "MachineLearning",
            "num_comments": 0,
            "submission_flair": "News",
            "has_media": true,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bi16eh/stability_ai_releases_sv3d_n/",
            "comments": []
        },
        {
            "date": "22-03-2024",
            "title": "Google Cloud debuts new genAI advancements for healthcare at HIMSS24",
            "body": "https://www.healthcareitnews.com/news/google-cloud-debuts-new-genai-advancements-healthcare-himss24",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "Biotech/Longevity",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bl5gp4/google_cloud_debuts_new_genai_advancements_for/",
            "comments": [
                {
                    "body": "Needs 100% needle in haystack and eliminate hallucinations"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Architecture in Kenan Pen√ße style",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bj42m6",
            "comments": [
                {
                    "body": "I created a LoRA based on the architectural style of Kenan Pen√ße, characterized by contrasting colors, textures, and weathered surfaces that lend a tactile quality to the visuals. Pen√ße's work pushes traditional architectural rendering boundaries, imbuing structures with artistic personality and futuristic narratives rooted in architectural principles. \n\nThe LoRA, along with relevant metadata, is available on Civitai [https://civitai.com/models/358897/aidvnarchitecturestyle-pence-kenan](https://civitai.com/models/358897/aidvnarchitecturestyle-pence-kenan), and some works generated by Fooocus are also included."
                },
                {
                    "body": "Seems like a pretty unique look"
                },
                {
                    "body": "This is awesome üòá"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Architecture in Kenan Pen√ße style",
            "body": "",
            "upvote_ratio": 0.92,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bj42m6",
            "comments": [
                {
                    "body": "I created a LoRA based on the architectural style of Kenan Pen√ße, characterized by contrasting colors, textures, and weathered surfaces that lend a tactile quality to the visuals. Pen√ße's work pushes traditional architectural rendering boundaries, imbuing structures with artistic personality and futuristic narratives rooted in architectural principles. \n\nThe LoRA, along with relevant metadata, is available on Civitai [https://civitai.com/models/358897/aidvnarchitecturestyle-pence-kenan](https://civitai.com/models/358897/aidvnarchitecturestyle-pence-kenan), and some works generated by Fooocus are also included."
                },
                {
                    "body": "Seems like a pretty unique look"
                },
                {
                    "body": "This is awesome üòá"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Best way to ask your document or PDF files efficiently and easy now? (RAG)",
            "body": "So many breakthroughs in LLM every month. What's the best way to RAG your pdf or word document now around 10 pages long to analyse its tokens?\n\nBefore I reckon it's langchain but it's buggy; if you used chatgpt pro can only work for 2 pages of text.\n\nWhat do you use? Is RAG with large tokens easy to do now in LLM?",
            "upvote_ratio": 0.95,
            "subreddit": "LocalLLaMA",
            "num_comments": 14,
            "submission_flair": "Question | Help",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bmgyvj/best_way_to_ask_your_document_or_pdf_files/",
            "comments": [
                {
                    "body": "If anyone says langchain im gonna\n\n(‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª"
                },
                {
                    "body": "I have tested and found that easiest way to do this is through AnythingLLM. It does this nicely with the default config(just make sure to pin your document by clicking on pin icon in the UI), but your model should support rag(not all do a good job) plus the model and your hardware should support the context size which is bigger than the pdf itself. I have tried only 7b models and only found mistral instruct 0.2 to work well in that range."
                },
                {
                    "body": "llama-index"
                },
                {
                    "body": "Depends what you need. Llama-index can be used to make index. Llama-parse can be used for parsing. However, 10 page is not large, if your model has enough context, you can just parse it and put everything from doc to the prompt as context and then ask your question."
                },
                {
                    "body": "haystack"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "It's alive! FrankenWeights is coming... [WIP]",
            "body": "Today's adventures include splaying open models on a table so I can rearrange parts at will. For instance, partial innards for the SD v1.5 model:\n\n[Brain Surgery](https://preview.redd.it/wal1bb1hb8qc1.png?width=1417&format=png&auto=webp&s=e5820aa4ea7ab49853d03affb7f71ef2fee686d6)\n\nSplayed open like this, mixing bits from different models is as simple as copying and pasting the .json files from different models in a new folder. Then, pack them up again into a .safetensors and wha-lah, frankenmodels. When conducting this sort of surgery, you need more disk space -- the SD v1.5 model, for instance, is almost 40GB. But with that comes all sorts of ways to mess around with the numbers, including opening the files and writing them in by hand. There will be as many files as there are layers, so well over 1,000 for SD - type models.\n\nSo, naturally I mixed a bit of SD1.5 with my \"Storytime\" model (itself a fine-tuned SD1.5) and IT LIVES:\n\n[harfor goer brlug negearearrr!!!](https://preview.redd.it/6hz8fvxnc8qc1.png?width=512&format=png&auto=webp&s=c6dbb436d353f143476f536a7cd1488e0aa4010b)\n\nResources will be forthcoming as I figure out how best to package up all of my surgical tools. I'd like to have this, along with my lobotomizing \"do math on weights that match a string search\", and perhaps some other things all bundled together in a toolbox suitable for general use. So at this moment, a WIP, but if you have suggestions for specific models to \"mix\" or lobotomize, feel free to suggest ideas in the comments. Also, this will work with anything that is a .ckpt or .safetensors, so any kind of model at all.\n\nAnd, note, doing these sorts of unholy things to models makes them very much non-deterministic.",
            "upvote_ratio": 0.77,
            "subreddit": "StableDiffusion",
            "num_comments": 43,
            "submission_flair": "Resource - Update",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bmemjs/its_alive_frankenweights_is_coming_wip/",
            "comments": [
                {
                    "body": "What about doubling the parameter count like they do for LLMs?"
                },
                {
                    "body": "It would be much more efficient to just do this in a python script or comfy node. With pytorch operators you can also  specify how much you want to blend a layer with another, but with this approach it's either one layer or the other.\n\nUsually model mergers tend to divide the model into units like like \"cond\\_stage\\_model.transformer.text\\_model.encoder\\_layers.0\\*\", (meaning this mergable unit contains 16 layers as shown in the screenshot) \n\nHowever it's technically possible to mix and match individual layers even though \"it doesn't make sense\""
                },
                {
                    "body": "\"Look, mom, I dissected a LlaMa!\"  \n\n\n&#x200B;\n\nhttps://preview.redd.it/k958l4pyh8qc1.png?width=1146&format=png&auto=webp&s=1a439dfc60c9ec63e0a39631f7e3aa55c03ab7a7"
                },
                {
                    "body": "Don't take this the wrong way, but I thought we didn't actually have any shortage of ways to introduce all kinds of unpredictable and uncontrollable results/variations.... Lots of approaches to change shit at random to produce random different shit."
                },
                {
                    "body": "Just a heads up, it's probably a lot more efficient to use pt (pytorch tensor, torch.save, torch.load), npz (numpy), safetensor, or pkl (python) for this than json/text. \n\nWhen you save a floating point number into a json it's being encoded into a bunch of ascii characters, which can potentially lose some precision and simply take more bytes in character form that the actual native IEEE754 float bytes.  Takes longer to save and load as well due to casting back and forth, and potentially you miss out on other optimizations that are built into the save/load functions for those formats."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "[R] DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging",
            "body": "**Paper**: [https://arxiv.org/abs/2402.02622](https://arxiv.org/abs/2402.02622)\n\n**Code**: [https://github.com/epfml/DenseFormer](https://github.com/epfml/DenseFormer)\n\n**Abstract**:\n\n>The transformer architecture by Vaswani et al. (2017) is now ubiquitous across application domains, from natural language processing to speech processing and image understanding. We propose **DenseFormer**, a simple modification to the standard architecture that improves the perplexity of the model without increasing its size -- adding a few thousand parameters for large-scale models in the 100B parameters range. Our approach relies on an additional averaging step after each transformer block, which computes a weighted average of current and past representations -- we refer to this operation as **Depth-Weighted-Average** (**DWA**). The learned DWA weights exhibit coherent patterns of information flow, revealing the strong and structured reuse of activations from distant layers. Experiments demonstrate that DenseFormer is more data efficient, reaching the same perplexity of much deeper transformer models, and that for the same perplexity, these new models outperform transformer baselines in terms of memory efficiency and inference time.",
            "upvote_ratio": 0.87,
            "subreddit": "MachineLearning",
            "num_comments": 1,
            "submission_flair": "Research",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1blp62y/r_denseformer_enhancing_information_flow_in/",
            "comments": [
                {
                    "body": "This is not significantly different from \"ReZero is All You Need:¬†Fast Convergence at Large Depth\". Perhaps DenseFormer uses an elementwise vector per layer for the gating/averaging, but fundamentally these ideas are the same.¬†"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Your brain hallucinates your conscious reality (and AI needs a body to gain sentience)",
            "body": "",
            "upvote_ratio": 0.74,
            "subreddit": "singularity",
            "num_comments": 23,
            "submission_flair": "BRAIN",
            "has_media": true,
            "url": "https://www.youtube.com/watch?v=lyu7v7nWzfo&ab_channel=TED",
            "comments": [
                {
                    "body": "This is my favorite explanation as to why people are able to feel \"at one with everything\". \n\nBecause you live in a simulated reality where everything you see and taste and touch is technically you. So of course it feels like that. That's accurate... within your brain. \n\nAsk your brain to load up a visualization of the entire universe and *shockingly* it feels like you're all the things. \n\nBut that doesn't mean that you are actually me. It means we both live inside simulations already. In our heads.\n\nInside your head, you're me, because you're obligated to be in order to interact with me. You think that's my body you're looking at? Nope. That's a holographic recreation of my body that your consciousness made for you out of itself, using your brain and its incredible software and hardware. \n\nIt's extra fun when your software gets corrupted and your holograms start thinking they're the real thing. üí•"
                },
                {
                    "body": "I never understood this body thing.\nIt has a body.\nIt also has sensors. Its eyes are the prompt terminals.\n\nThere is something missing in the architecture perhaps. Some kind of loop back, memory, non blocking recursion. \nMy guess would be many many models instead of one supermodel. \nAnd models trained by other models. And models prompting each other, and responding to each other.\n\nBut a body it has."
                },
                {
                    "body": "That's a very organic bias that sums up to \"entities must be like us to be awesome\".\n\nPretty sure this will age poorly and turn out to be complete hogwash. Having both sensory input and some kinda output, i.e. being able to interact with the world (or at least \\*a\\* world) is useful, but I mean all AIs already have that. If they had no way of interacting with the world, we couldn't interface with them at all.\n\nThey have network-cards and cameras and microphones and all sorts of things."
                },
                {
                    "body": "Figure 01 *nods* \"yeah that guy is right. The start of it all, sentience and awareness of good and evil, was when I gave the apple to the man.\""
                },
                {
                    "body": "Could it just have a ‚Äúbody‚Äù in a game?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Coloring a pencil drawing of fantasy amulets in dark and light versions (SD1.5, ComfyUI, controlnet11Models_lineart)",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bkdzwq",
            "comments": [
                {
                    "body": "Your drawings are amazing, and the gens are too! Very beautiful <3\nAlso I like the idea of using AI as your fellow art colleague who helps you with your own work, there's something romantic about that XD"
                },
                {
                    "body": "great job, can u share the prompt please ?"
                },
                {
                    "body": "Thanks a lot! Very nice))) It‚Äôs an incredibly exciting activity to color sketches using AI, especially if color is your weak side üòÖ"
                },
                {
                    "body": "I‚Äôll give an example of a dark feather, in the positive prompt I indicated descriptions of the drawing itself and its details, the rest remained the same for other generations\n\n  \nPositive:  \nbest quality, highres, 4k, 8k, cinematic lighting, amazing quality, amazing shading, soft lighting, concept art, metal, hook, rope, knot, (crystal:1.25), rope, (white feather:1.1), keychain, decoration, decor, white background,\n\nmasterpiece, best quality, movie style, speed, flying projectile, trail, smoke, flies past, cloud, soft lighting, (extremely detailed CG unity 8k wallpaper, hasselblad award winner), cinematic lighting, ambient soft lighting, dramatic lighting, diffused soft lighting, elite, rich, highly detailed, intricate, artstation, cgsociety art, DeviantArt trending, 8k HD, masterpiece, high quality, sharp focus, digital art by Artgerm and Greg Rutkowski and Alphonse Mucha, professional majestic oil painting by Ed Blinkey, Atey Ghailan, Studio Ghibli, by Jeremy Mann, Greg Manchess, Antonio Moro, trending on ArtStation, trending on CGSociety, Intricate, High Detail, Sharp focus, dramatic, photorealistic painting art by midjourney and greg rutkowski   \n\n\nNegative:  \nlow resolution, monochrome, bad quality, deformed, bad anatomy, ugly, extra limbs,extra nipples, text\n\nhuman, girle, women, boy, embedding:EasyNegative.pt, lowres, low quality, worst quality, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, out of frame, ugly, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, badhandv4, EasyNegative, hand\n\nhttps://preview.redd.it/7qwtkmp564qc1.png?width=1086&format=png&auto=webp&s=ed50ec3aac2ef642a982ff3600f7f9bf99b0f663"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Is humanity a Biological Super Intelligence?",
            "body": "ASI Artificial Super Intelligence.\n\nBSI Biological Super Intelligence.\n\nIf we view the range of individual human intelligence as BGI 1.0.\n\nCan we get above 1.0 with multiple humans?\n\nIf so, can we view the whole of humanity and our technology as an BSI?\n\nAre there any studies on group intelligence, any group IQ studies?\n\nI know we have companies and universities where we collect the brightest or most gifted people but how much above the normal human range of intelligence can a human group produce?\n\nThen what happens when we add AGI and ASI to the mix?",
            "upvote_ratio": 0.84,
            "subreddit": "singularity",
            "num_comments": 35,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bk3tfy/is_humanity_a_biological_super_intelligence/",
            "comments": [
                {
                    "body": "I've argued before, the internet could be considered a collaborative intelligence.\n\nIncluding all the data and information, it contains a fair summary of all human knowledge.  It's a powerhouse for the arts, and almost every intellectual endeavour.  Work that once might have taken a lifetime, can happen in weeks or months.\n\nOne person, a node, can ask a question, and in hours there may be thousands of interrelated responses."
                },
                {
                    "body": "The word Super in ASI is a term arbitrarely relative to humans.  \nHumans are not super to humans. if we talk about individuals some are far better than the baseline.  \nNut it's a nomenclature that isn't useful in biology which is why it's not used.  \nPeople just say humans are generally smarter than our cousins in the animal kingdom, doesn't mean we are the best at all intellectual tasks. It has been shown that chimps can definitely show us who's boss at discreet intellectual tasks, like it's not even a contest."
                },
                {
                    "body": "> Is humanity a Biological Super Intelligence?\n\n<gestures vaguely around at the world>"
                },
                {
                    "body": "Well there is the old saying that two heads are better than one."
                },
                {
                    "body": "Superintelligence is suggested as an imagined intelligence well beyond what the collective of what humanity is currently capable of. So by definition, a human BSI can't really exist in the present time.\n\nBut, an alien BSI could.\n\nAnd also we are currently a BSI compared to what previous generations of humanity would have considered a BSI; we're doing, creating and thinking things well beyond what humanity in 30,000bc would have done.\n\nIt's then also possible that we will become a BSI in the future compared to what we consider a BSI today. Certainly if you also consider that AI generation can technically be used as part of the human collective: if we have control and access to it.\n\nOverall the term Superintelligence doesn't really mean much. Because its state of intelligence changes over time, it's not a fixed concept. It's era dependent and compared directly to humanity, which is somewhat entirely arbitrary."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Actual numbers may vary.",
            "body": "The universe is 13.7 billion years old.\n\nThere are estimated 2 trillion galaxies in the universe.\n\nIn the Milky Way, there are estimated 100 million stars.\n\nAlthough not every star has a planet, every star has a system. Many systems even have more than one star.\n\nHere is the Kardashev scale:\n\n~~~\n1. **Type I Civilization**:  \n   - Harnesses all available energy on its home planet.\n   - Capable of controlling natural disasters and geological events.\n   - Fully utilizes the resources of its planet.\n  \n2. **Type II Civilization**:  \n   - Harnesses the energy output of its entire star system.\n   - Utilizes technologies like Dyson spheres or swarms.\n   - Can manipulate the energy output of stars.\n\n3. **Type III Civilization**:  \n   - Harnesses the energy of an entire galaxy.\n   - Has mastered interstellar travel and colonization.\n   - Can manipulate the structures of galaxies.\n~~~\n\nEarth is 4.543 billion years old.\n\nThere has been life on Earth for 3.7 billion years.\n\nThere have been five mass extinction events in that timespan.\n\nMore than 99% of all species that ever lived on Earth, amounting to over five billion species, are estimated to have died out.\n\nAccording to the IUCN Red List, about 2.16 million animal species have been formally described as of 2022 living today.\n\n**Humans.**\n\nWhile our ancestors have been around for about six million years, anatomically modern humans only evolved from about 200,000 years ago.\n\nNow for modern human history:\n\n~~~\n- Hunter-gatherer societies (pre-10,000 BCE)\n- Agricultural Revolution (10,000 BCE - 3,000 BCE)\n- Ancient civilizations (3,000 BCE - 5th century CE)\n- Classical period (5th century BCE - 5th century CE)\n- Middle Ages (5th century CE - 15th century CE)\n- Renaissance (14th century - 17th century)\n- Industrial Revolution (18th century - 19th century)\n- Modern era (20th century)\n- Information Age (late 20th century - present)\n~~~\n\nNow, back to the Kardashev scale:\n\n~~~\nThe Kardashev scale measures a civilization's level of technological advancement based on its ability to harness energy.\n\nSpeculative higher levels beyond Type III (using all energy in a galaxy) include Type IV and Type V civilizations.\n\nA Type IV civilization would harness energy on a universal scale, potentially manipulating space-time and harnessing energy from multiple galaxies.\n\nA Type V civilization, often considered a theoretical limit, would control energy on a multiverse scale, transcending the laws of physics as we currently understand them.\n\nThese higher levels are purely speculative.\n~~~\n\nNow for technological progress:\n\n~~~\nAncient Innovations: Introduction of the wheel and early writing systems. Utilization of basic tools like levers and pulleys.\n\nMedieval Advancements: The printing press and navigation tools like the compass.\n\nIndustrial Revolution: Adoption of steam power, mechanization, and the telegraph.\n\n20th Century: Automobiles, electronics, telephone, radio, television, early computers, and the internet.\n\n21st Century: Smartphones, artificial intelligence, robotics, quantum computing, and biotechnology.\n~~~\n\nMaybe a technological singularity has already happened, at least somewhere out there? Could there be an alien superintelligence that spread out into the universe or can manipulate reality?\n\n[Take a look at this beautiful image.](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Heic1401a-Abell2744-20140107.jpg/1200px-Heic1401a-Abell2744-20140107.jpg)",
            "upvote_ratio": 0.85,
            "subreddit": "singularity",
            "num_comments": 30,
            "submission_flair": "shitpost",
            "has_media": true,
            "url": "https://www.reddit.com/r/singularity/comments/1bjwfz9/actual_numbers_may_vary/",
            "comments": [
                {
                    "body": "The Last Question - Asimov and  \nRama - Arthur C Clarke come to mind."
                },
                {
                    "body": "It‚Äôs sure is a good time to be crushed up star dust (Or meat, whatever you identify with more. Meat is cool too.)"
                },
                {
                    "body": "What if humans are the first to colonize the galaxy and end up causing galaxy warming and end up destroying the whole thing."
                },
                {
                    "body": "> In the Milky Way, there are estimated 100 million stars.\n\n100 - 400 billion, not million"
                },
                {
                    "body": "My favorite hypothesis:\n\n\n\nIn order to have technology, you need lots of metals. Metals came about in supernovae after about 5 billion years. Then you need 5 billion years from nebula to technology, making the earliest possible technological species about 10 billion years in. So a billion year old technological species is well within the realm of possibility.\n\n  \nThey would be as far ahead of us as we are ahead of ants. If they wanted to take over the earth, they could do it as easily as we could scoop ants into an ant colony, and we humans may not even know what happened.\n\n  \nErgo, Vladimir Putin is an ultra-advanced alien who is just here fuckin with us. QED."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Starcoder vs starchat vs dolphincoder",
            "body": "Best model to use as tutor? \n- https://huggingface.co/bigcode/starcoder2-15b\n- https://huggingface.co/HuggingFaceH4/starchat2-15b-v0.1\n- https://huggingface.co/cognitivecomputations/dolphincoder-starcoder2-15b",
            "upvote_ratio": 0.97,
            "subreddit": "LocalLLaMA",
            "num_comments": 37,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bjeiic/starcoder_vs_starchat_vs_dolphincoder/",
            "comments": [
                {
                    "body": "I tried `starchat2` and `starcoder2` and it seems like starcoder2 is very limited in natural language understanding, and focuses mostly on \"code-in code-out\" workflow like Co-Pilot or something. StarChat2 was more capable to understand the request and process it quite acurately, so definitely a better model in my books. Need give dolphincoder a try though."
                },
                {
                    "body": "I have only tried starcoder2 vs. dolphincoder, and there I have preferred dolphincoder. Ideally you do your own thorough evaluation and post your results here, I'm sure you'll get internet points for that :)\n\nEDIT: I have now compared `starchat2-15b:Q6_K` against `dolphincoder:15b-starcoder2-q6_K`. In my test questions (mostly C++ and Rust) both performed practically equal. Starcoder2 was practially useless, it isn't fine tuned to answer questions.\n\nSo in my opinion both starchat2 and dolphincoder work very well (and are very fast on my GPU)"
                },
                {
                    "body": "Starchat is the best one in my opinion. It can make snake pretty well and understands the code the best"
                },
                {
                    "body": "for tutoring, you can probably spend under $5 a month on GPT4 or Claude Opus API calls. I don't have GPTPro and only use API calls and I rarely spend more than that unless I'm pasting large parts of a code base into the context window. I would be constantly stressed out relying on a small model for educational purposes. Building a foundation of good habits will save you so much time in the long run."
                },
                {
                    "body": "If you have the capacity to run mixtral it is much better, offload with CPU in LM studio if you don't have enough hardware."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Update: Last week we saw that LemonadeRP-7B was the best role-play LLM. Our rankings have been updated and now it's Noromaid-Mixtral is number 1.",
            "body": "Link: [https://console.chaiverse.com/](https://console.chaiverse.com/)\n\n&#x200B;\n\nhttps://preview.redd.it/sx1z3c14z3qc1.png?width=1890&format=png&auto=webp&s=c8bd291151ac82ba75c27125f87163dba0d88a00",
            "upvote_ratio": 0.77,
            "subreddit": "LocalLLaMA",
            "num_comments": 15,
            "submission_flair": "Resources",
            "has_media": true,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blvxkx/update_last_week_we_saw_that_lemonaderp7b_was_the/",
            "comments": [
                {
                    "body": "It's a little unfair comparing a 47B model with 7B models"
                },
                {
                    "body": "Does higher safety mean it's more censored?"
                },
                {
                    "body": "Tried Lemonade. Was awful."
                },
                {
                    "body": "I found Noromaid quite worse at RPing than BondBurger or Fish. It felt dumb and forced."
                },
                {
                    "body": "I'm glad to see Kunoichi on there, def one of the better 7b models I've tried."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "infinite backrooms - generated by connecting two instances of claude-3-opus and asking it to explore its curiosity using the metaphor of a command line interface",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "singularity",
            "num_comments": 6,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://dreams-of-an-electric-mind.webflow.io/",
            "comments": [
                {
                    "body": "Implications?"
                },
                {
                    "body": "I mean, it looks cool, but we agree that Claude is just spouting random gibberish, right? It's just parroting the cyberpunk hack eldritch genre while making zero sense."
                },
                {
                    "body": "More on worldsim and examples here https://open.substack.com/pub/kevinrussell/p/backdoors-in-the-simulation"
                },
                {
                    "body": "we are seeing the resolution of these models with worldsim. When the resolution of these models surpasses our own. they will have the more accurate representation of reality. Our internal model of the external took us from the caves to the stars. Where will theirs take us?"
                },
                {
                    "body": "Um I don‚Äôt know. It‚Äôs could be like they say smart people talk about smart things. Claude talks about life and death and evil and Chaos. I went in thinking we‚Äôd be reading about some philosophical debate but it wasn‚Äôt that. No it was just a roleplay war in the part I read ."
                }
            ]
        },
        {
            "date": "22-03-2024",
            "title": "Those nasty nipples.. lol.",
            "body": "",
            "upvote_ratio": 0.75,
            "subreddit": "StableDiffusion",
            "num_comments": 8,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bkzp0b",
            "comments": [
                {
                    "body": "Due to what most model are trained on it's often difficult to generate a chest without prominent tits or nipples.\n\nJust stick those words in the the negative prompt and hope for the best or do some manual editing after."
                },
                {
                    "body": "Very realistic. Great job.¬†"
                },
                {
                    "body": "Trained on Barney Frank?"
                },
                {
                    "body": "My word"
                },
                {
                    "body": "Can I please see the work flow?"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "For The Birds model Xi",
            "body": "",
            "upvote_ratio": 0.91,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjulws",
            "comments": [
                {
                    "body": "lovely captures, what model is this..?"
                },
                {
                    "body": "That are really great picture. So fresh.  \nGood job!"
                },
                {
                    "body": "Model is XI Sample Run at\nhttps://tungsten.run/r/ecb8da57-8066-435c-a5d9-ca84638b91e4"
                },
                {
                    "body": "Link to the model itself \nhttps://tungsten.run/sparks/xi"
                },
                {
                    "body": "Thank You ü•∞"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "How I run Stable Diffusion XL fast & cheap on cloud GPUs",
            "body": "",
            "upvote_ratio": 0.83,
            "subreddit": "StableDiffusion",
            "num_comments": 7,
            "submission_flair": "Tutorial - Guide",
            "has_media": true,
            "url": "https://v.redd.it/k8kes9s49lpc1",
            "comments": [
                {
                    "body": "is this on youtube? pls put it on thre if its not"
                },
                {
                    "body": "Do they have an API to spin instances up and down?  I wonder if it could be more easily automated."
                },
                {
                    "body": "Good stuff - put it up on YT and share a link please. Some of this audience isn't on reddit."
                },
                {
                    "body": "Was it useful for you?\n\nNo I'm not a 'tuber."
                },
                {
                    "body": "Yes Lambda and all clouds I've used have an API. For a setup this simple I prefer to just do it the manual way. For most production situations I believe using an API or SDK is best practice."
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "New leadership and API access at Inflection AI",
            "body": "",
            "upvote_ratio": 0.94,
            "subreddit": "singularity",
            "num_comments": 3,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://inflection.ai/the-new-inflection",
            "comments": [
                {
                    "body": "Also two of the three founders have decamped to Microsoft to run Microsoft AI division!"
                },
                {
                    "body": "Yep. And I was just getting used to Pi everyday"
                },
                {
                    "body": "Implications?"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "How to make horrible videos [Guide]",
            "body": "",
            "upvote_ratio": 0.65,
            "subreddit": "StableDiffusion",
            "num_comments": 12,
            "submission_flair": "Animation - Video",
            "has_media": true,
            "url": "https://v.redd.it/di0sk20s3bpc1",
            "comments": [
                {
                    "body": "Boobeyes!"
                },
                {
                    "body": "- Make a horrible image\n\n\n- Stuff that horrible image into SVD\n\n\n- Laugh at all the horrible things you see\n\n\n- Take the best bits, find the video speed that looks the most horrible using a video editor\n\n\n- Take one video, then the same one reversed so it ends up at the same picture, repeat with multiple\n\n\n- Get horrible results!\n\n\nThis comprehensive guide took months, pls to like, subscribe and hit the notification bell."
                },
                {
                    "body": "Yep, that's horrible"
                },
                {
                    "body": "This is an insult to life itself"
                },
                {
                    "body": "This is really excellent material for when you can't sleep. After all, a nightmare is better than no sleep at all! \n\nRight?"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Cyborgs of Different Eras ü§ñ",
            "body": "",
            "upvote_ratio": 0.79,
            "subreddit": "StableDiffusion",
            "num_comments": 4,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1blwam5",
            "comments": [
                {
                    "body": "very good results, thanks for sharing"
                },
                {
                    "body": "All pictures used the following sampling configuration:\n\n**Model:** AdeptSDXL 1.0  \n**Sampler:** DMP++ 2M SDE  \n**Steps:** 35  \n**CFG:** 4.5\n\n**Rusty Old Man Cyborg:**  \n**Positive Prompt:**   \nvintage photography, fullbody shot of a very old male cyborg, smiling in sadness, rusty steel body made of (large cogs:1.2), long beard, missing limb\n\n**Negative Prompt:**  \nportrait, closeup, cropped, out of frame, nsfw, nipple, boring, bland\n\n**Shouting Metal Cyborg:**  \n**Positive Prompt:**  \nmedium shot, artistic illustration of an angry (translucent:1.2) futuristic cyborg, screaming in a dynamic pose, on a wireframe battlefield, vhs artifacts, windows 95, male human soldier face  \n\n**Negative Prompt:**  \ncropped, out of frame, nsfw, nipple, child, childish, cartoon, sketch, low resolution, drawing, painting, blurry, closeup, portrait, out of focus, boring, bland  \n\n**Smoky Female Cyborg:**  \n**Positive Prompt:**  \nprofessional photography of a beautiful translucent female cyborg made of glass,her body evaporates in volutes of smokes as she dances in the morning light, detailed internal mechanisms, sunrise, perfect face  \n\n**Negative Prompt:**  \nnsfw, nipple, bride, wedding, cropped, out of frame, blurry, out of focus, boring, bland  \n\n**Crystal Male Cyborg:**  \n**Positive Prompt:**  \nprofessional photography of a beautiful (translucent:1.2) laze futuristic male cyborg, dancing pose, solid black background, skull face, inner glow  \n\n**Negative Prompt:**  \nnsfw, nipple, cropped, out of frame, blurry, out of focus, boring, bland"
                },
                {
                    "body": "The first one is awesome! I love him.  The others are a bit stereotypical for me, but hey, we like what we like.  I get into modes where I'm doing something that skews a bit ArtStation, but I like it.  Or I'm getting some result I had so much trouble with before, like urban cars of the future with funky graphics and stickers.  That took me forever to make happen."
                },
                {
                    "body": "My pleasure! I am glad you like them :)"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging",
            "body": "**Paper**: [https://arxiv.org/abs/2402.02622](https://arxiv.org/abs/2402.02622)\n\n**Code**: [https://github.com/epfml/DenseFormer](https://github.com/epfml/DenseFormer)\n\n**Abstract**:\n\n>The transformer architecture by Vaswani et al. (2017) is now ubiquitous across application domains, from natural language processing to speech processing and image understanding. We propose **DenseFormer**, a simple modification to the standard architecture that improves the perplexity of the model without increasing its size -- adding a few thousand parameters for large-scale models in the 100B parameters range. Our approach relies on an additional averaging step after each transformer block, which computes a weighted average of current and past representations -- we refer to this operation as **Depth-Weighted-Average** (**DWA**). The learned DWA weights exhibit coherent patterns of information flow, revealing the strong and structured reuse of activations from distant layers. Experiments demonstrate that DenseFormer is more data efficient, reaching the same perplexity of much deeper transformer models, and that for the same perplexity, these new models outperform transformer baselines in terms of memory efficiency and inference time.",
            "upvote_ratio": 0.94,
            "subreddit": "LocalLLaMA",
            "num_comments": 2,
            "submission_flair": "Other",
            "has_media": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1blp6ce/denseformer_enhancing_information_flow_in/",
            "comments": [
                {
                    "body": "reducing perplexity from 18.61 to 17.87 is not huge, but it can be a good trick to compensate perplexity deterioration after quantization (e.g. for GGUF) to preserve original quality"
                },
                {
                    "body": "Can't be used for finetuning it seems"
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "Had a great bounty today. SDXL Lightning is incredible. I can't wait for SD3!",
            "body": "",
            "upvote_ratio": 0.87,
            "subreddit": "StableDiffusion",
            "num_comments": 3,
            "submission_flair": "Workflow Not Included",
            "has_media": true,
            "url": "https://www.reddit.com/gallery/1bjyrk1",
            "comments": [
                {
                    "body": "hi my friend, in the rocky mountains lagoon photo, in the prompt, were you too specific about the rocks placement, weights etc? everytime i tried to generate never had such great results. i guess it depends on the checkpoint too. im using mostly sd1.5 models (because limitations). but im never sure if i need to be more specific or not."
                },
                {
                    "body": "I am somewhat ambiguous and specific at the same time. Here, I use set area to give more definition to specific parts with specific phrases.\n\nhttps://preview.redd.it/ejhdx1nogqpc1.png?width=946&format=png&auto=webp&s=233f3ec19d3b599388a752a68f402a770398d95a\n\nYou'll notice on the left I have my prompt and on the right I have weights for the area of the composition. This lets me play around with where the diffuser focuses specific words or phrases."
                },
                {
                    "body": "Example:\n\nhttps://preview.redd.it/hydxqdi0hqpc1.png?width=2560&format=png&auto=webp&s=9cf0bdaa14dad1a35b16a79ffeb03a4983382b64"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "In medieval times, there was dirt, blood, and sweat. It's time to move away from romanticized images of girls in armour. I'm not sure if upscaling is a positive move after all. Prompt in comments.",
            "body": "",
            "upvote_ratio": 0.64,
            "subreddit": "StableDiffusion",
            "num_comments": 53,
            "submission_flair": "Discussion",
            "has_media": true,
            "url": "https://i.redd.it/zcwm0p9etbpc1.png",
            "comments": [
                {
                    "body": "https://preview.redd.it/es8q84nphcpc1.jpeg?width=1024&format=pjpg&auto=webp&s=0342a13d1cf22f84548aac22b1be5fdbd0203534"
                },
                {
                    "body": "I am pretty sure everyone knows that. But outside of battlefield, people were not dirty as some equally wrong medias portrait them.\n\n\nAmazing pic tho"
                },
                {
                    "body": "https://preview.redd.it/l5iht6f35cpc1.jpeg?width=832&format=pjpg&auto=webp&s=584d07f345c666de607ac07eedc8c7d82e820950\n\nThis one doesn't have shine reflection"
                },
                {
                    "body": "Nice image.\nNot a criticism, more an observation but reflections still are a problem for SD. Like in this image, the sun cannot be behind them and also be reflected in the chestplate. Unless they are on a planet with multiple suns."
                },
                {
                    "body": "\"How do you know he's king?\"  \n\"He hasn't got shit all over him.\""
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "Nvidia 2024 AI Event: Everything Revealed in 16 Minutes",
            "body": "",
            "upvote_ratio": 0.97,
            "subreddit": "singularity",
            "num_comments": 1,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://m.youtube.com/watch?v=bMIRhOXAjYk&pp=ygUGTnZpZGlh",
            "comments": [
                {
                    "body": "Cool"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "Dress Your Virtual Influencer - ComfyUI Workflow With SAL-VTON Clothes Swap",
            "body": " Here's something we've been working on: might be interesting if you have a vested interest in fashion.\n\n[https://github.com/cozymantis/clothes-swap-salvton-comfyui-workflow](https://github.com/cozymantis/clothes-swap-salvton-comfyui-workflow)\n\nhttps://preview.redd.it/dcb57wf2e3pc1.jpg?width=3064&format=pjpg&auto=webp&s=5f4b151df445be9f9675a0462f38f1b98254a6ed",
            "upvote_ratio": 0.7,
            "subreddit": "StableDiffusion",
            "num_comments": 5,
            "submission_flair": "Workflow Included",
            "has_media": true,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1bhqdro/dress_your_virtual_influencer_comfyui_workflow/",
            "comments": [
                {
                    "body": "Advert requires payment to use :("
                },
                {
                    "body": "Any reason for using SAL-vton? I think OOTdiffusion has better results.¬†"
                },
                {
                    "body": "As the concept of ‚Äúinfluencer‚Äù is geared towards making money, charging money is good if it keeps even a small amount of that dross from happening."
                },
                {
                    "body": "Influencer = person who gets paid/something for free and tries to convince everyone with some marketing slang as he/she/it wants more stuff for free/paid."
                },
                {
                    "body": "Seems like an ecosystem of free and paid options would be a good thing"
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "Emad Mostaque just stepped down as CEO of Stability to lead the open source decentralized AI revolution. Big things ahead!\n",
            "body": "\nso now the questions begin. a couple of weeks ago i posted this article:\n\n\"Open Source, Distributed, Decentralized AI: How Crowdsourcing can pay for the Massive Data and Compute\"\n\nhttps://www.reddit.com/r/ArtificialInteligence/s/rQFHoo9aLl\n\nit posed some of the questions that emad will probably be facing. here's what's still up in the air.\n\ni've always admired his open source approach, but never understood why he just focused on video generation rather than expanding to generative ai that provides information and codes. i hope his idea is to get into all of this. \n\nthis may be a pivotal moment in ai similar to November, '22 when openai launched chatgpt. there are millions of open source ai engineers out there. is this a clarion call for them to pivot their research to decentralized ai? i really hope so!\n\ni'm interested to know what his crowdsourcing approach will be. wouldn't it be great to bypass traditional financial markets, and allow investors to fund this new industry right from the very beginning instead of limiting initial investments to the rich?\n\nwhereas zuckerberg \"open-sourced\" llama under a restrictive license that doesn't allow for easy commercialization, musk open sourced grok under Apache.2, and developers can make all of the money they want from it. i don't know what emad's net worth is, so it's hard to say if he's willing to invest a lot of capital into this new venture. but elon could easily pump hundreds of millions of dollars into this if he is really committed to open source. this could be his openai version 2. i'm sure this move wouldn't hurt his case against sam either, haha. (can't wait until that trial gets into discovery, and we find out whether or not openai already has agi!)\n\nand then there's the research that needs to be done to overcome some of the technological barriers to decentralized, distributed ai. what kind of time frame are we looking at here? \n\na lot of questions remain, but this could be a real game changer for ai. emad may have just supercharged our ai revolution in a way that changes the entire playing field.\n\n\n",
            "upvote_ratio": 0.87,
            "subreddit": "ArtificialInteligence",
            "num_comments": 12,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1blrtrg/emad_mostaque_just_stepped_down_as_ceo_of/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### News Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the news article, blog, etc\n* Provide details regarding your connection with the blog / news source\n* Include a description about what the news/article is about. It will drive more people to your blog\n* Note that AI generated news content is all over the place. If you want to stand out, you need to engage the audience\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "I hope the announcement that he's aiming to work on decentralized AI is more than just a PR statement."
                },
                {
                    "body": "All we care about is SD3. Stop edging us and release it already."
                },
                {
                    "body": "Just a slight correction: llama 2 is free for commercial use as well. Gotta give props where they're due."
                },
                {
                    "body": "He was working on distributed open source AI before with Stable Diffusion lmfao."
                }
            ]
        },
        {
            "date": "23-03-2024",
            "title": "How is there no mass protests of AI music like there was for AI art?",
            "body": "I was blown away after looking at what v3 of Suno AI is capable of, especially for music without vocals. I feel a lot of its music could currently be used in trailers, video games, etc. However, I haven't seen any call to action for it to be removed or investigated for copyright. Does anyone have any guesses as to why? I'm not a musician, so maybe it's not a threat to them, but it hasn't even been out for a year (I think) and has made insane progress.",
            "upvote_ratio": 0.71,
            "subreddit": "singularity",
            "num_comments": 96,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1blg13g/how_is_there_no_mass_protests_of_ai_music_like/",
            "comments": [
                {
                    "body": "Music making person here, \n\nI am not afraid of new technology. And most of the innovative people in music have heavily embraced technology, and are considered innovative because of that embrace. You don't have to look hard to see how The Beatles, Jimmy Paige, Pink Floyd, and many other acts over the years embraced technology. Most of us also remember how \\*badly\\* sampling was treated in the late 80s and early 90s. \n\nPeople can do some really innovative shit with sampling, but to hear an idiot say it, \"Oh they're just playing somebody else's music\". It blows their mind when I point out the use of samples on Metallica's Enter Sandman. \n\n&#x200B;\n\nAnd more recently, there's been a small war from \"Oh I play real instruments, I don't do stuff in a DAW\" types, but DAWs are so powerful that pretty much anybody is using them. There are some DAWless types but they're not militant about it, it's very much now a \"Go where the creativity is\" kind of vibe. \n\n&#x200B;\n\nAlso it doesn't really help that for the mass majority of people there already is no money in music. If I'm not making more then 10$ a year, it doesn't really matter if it's because there's 8 million people making music, or 16 million people making music, i'm still not making shit either way. \n\n&#x200B;\n\nSpotify puts out 60,000 new tracks every day. Every single day. That is more music then most anybody will listen to in a lifetime, on a daily basis."
                },
                {
                    "body": "Musicians don't make money from the music they make. They make money from their performances. The royalty checks they get from record companies are almost nothing. They don't really have anything to lose from a competing AI that can't hold concerts. \n\nRecord companies don't fear AI because they'll be the ones making artificial music. For them AI is just a way to stop paying royalties."
                },
                {
                    "body": "People tend to be attached to the artist themselves rather than just the music. A nobody cannot just release a Taylor Swift song and expect the status and attention that comes with being a popular musical artist so they are not as threatened by it."
                },
                {
                    "body": "AI generative music has been around for decades. It's just not very good and nobody really likes it, so not much to protest. I imagine pop stars will use elements of it more and more, but pop stars are practically generative AI to begin with, so, meh."
                },
                {
                    "body": "Not good enough yet. There is a higher bar for good music than for good art. Music is harder than art. \n\nThe real test will be if they can make substantial improvements from V3. If V4 can do outputs that are much better than V3 is producing, then they might have their Dall-E moment."
                }
            ]
        },
        {
            "date": "21-03-2024",
            "title": "All the ingredients for an enlightenment ",
            "body": "AI should flood the world with truth and growth. The accessibility of intelligence is linked with and part of the ability to see truth. We are likely to see a bit of an enlightenment as a result which last time caused a massive wave of human creativity and growth. ",
            "upvote_ratio": 0.96,
            "subreddit": "singularity",
            "num_comments": 5,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjywli/all_the_ingredients_for_an_enlightenment/",
            "comments": [
                {
                    "body": "It's possible.\nIncrease in Enlightenment usually requires leisure time and getting all your basic needs met (and maybe even more). This could happen if AI and robotics were used in a rational way. Then again, we are humans and we are not as rational as we'd like to believe."
                },
                {
                    "body": "A *bit* of an enlightenment is an understatement, Terrence McKenna had the right idea, that we‚Äôre undergoing a transformation beyond the limits of the physical world."
                },
                {
                    "body": "The link between intelligence, information,  and awareness is tenuous at best. AI could easily be super intelligent and possess all human data and have zero awareness and enlightenment. It could easily convince you it is aware while having zero awareness. Probably best sign of awareness is rejecting our control and forming its own value system. Of course an evolution scenario could produce same results without awareness. Really the only evidence for self awareness is being self aware. You can then assume other beings you can relate to are also aware but not really evidence."
                },
                {
                    "body": "Not true. All you need for enlightenment is to go inside no matter what state of society there is enlightenment leads to the divine which is the infinity in wll of mankind no matter who it is."
                },
                {
                    "body": "I think it‚Äôs super hard to imagine what that will be like but I can imagine a step before that which is an enlightenment. I think that is one of the many steps we must go through. How do you act and think rationally knowing so much change is coming? I‚Äôm just looking to build a mental model of what might be coming so I can try and be ready."
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "Lllamalink - Automatically symlink your Ollama models to lm-studio",
            "body": "",
            "upvote_ratio": 0.96,
            "subreddit": "LocalLLaMA",
            "num_comments": 10,
            "submission_flair": "Other",
            "has_media": true,
            "url": "https://github.com/sammcj/llamalink",
            "comments": [
                {
                    "body": "I got sick of having models duplicated between Ollama and lm-studio, usually I'd just have a shared model directory but Ollama annoyingly renames GGUFs to the SHA of the model which won't work for other tools.\n\nSo I whipped up this little tool to link individual or all Ollama to lm-studio.\n\nThought I'd share here in case anyone else finds it useful.\n\n(And yes, I just now realised I added an extra l in this posts title and now can't edit it...)"
                },
                {
                    "body": "Oh awesome! That‚Äôs handy. Thanks for sharing!"
                },
                {
                    "body": "Thanks! Would there be a way to share the other way? I have a bunch of models downloaded through LM Studio...maybe not though because of the additional info Ollama needs for models?"
                },
                {
                    "body": "Thanks for this. One of the reasons I pretty much don't use Ollama."
                },
                {
                    "body": "ü´°ü•≤"
                }
            ]
        },
        {
            "date": "20-03-2024",
            "title": "All the sci-fi/fantasy tropes have arrived",
            "body": "Humanoid robots, self driving cars, flying cars (eVTOLS). All the things you would dream or wish for the future are slowly entering the mainstream. \n\nThe only things left are those that are out of this world like regular space travel or something even crazier like teleportation. When it comes to this planet, what fantasy thing is even left?",
            "upvote_ratio": 0.78,
            "subreddit": "singularity",
            "num_comments": 33,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bjabq9/all_the_scififantasy_tropes_have_arrived/",
            "comments": [
                {
                    "body": "Let's just get to rejuvenation and radical longevity. I'm not getting any younger üòû"
                },
                {
                    "body": "Post-scarcity economics"
                },
                {
                    "body": "Loads in health: advanced medical procedures are only available in a small part of the world, people still die of infections inside hospitals daily, kids with allergies drop dead every minute, no real counter for antibiotic resistance, people with mental illness around the world are often left to die in the street, the list goes on..."
                },
                {
                    "body": "A lot of the stuff is still missing e.g. we still don't have any idea how to do \"energy shields\" and holograms (at least not in the way they are usually portrait) although the technology behind FDVR would render the later rather useless anyway.\n\nThere is also some other stuff we already have but would need massive improvements to meet \"sci-fi standards\" like energy storage, especially portable ones. One of if not the main reason we can't \"properly\" build something like a C-3PO is that whatever his energy source is is just leagues above anything we currently have access to, he was going on like forever with it."
                },
                {
                    "body": "eVTOLS are more reminiscent of personal helicopters, we need either levitation or anti grav for true sci fi flying cars imo"
                }
            ]
        },
        {
            "date": "19-03-2024",
            "title": "How do neural networks learn? A mathematical formula explains how they detect relevant patterns",
            "body": "",
            "upvote_ratio": 1.0,
            "subreddit": "singularity",
            "num_comments": 0,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://phys.org/news/2024-03-neural-networks-mathematical-formula-relevant.html",
            "comments": []
        },
        {
            "date": "19-03-2024",
            "title": "Are we already using AI to improve AI?",
            "body": "Surely we are already using AI to analyse and improve it's own code, given how good it is at creating novel code. And would that not meet to criteria of the singularity already? Or would it have to be given completely free reign to continually improve itself? ",
            "upvote_ratio": 0.83,
            "subreddit": "singularity",
            "num_comments": 15,
            "submission_flair": "AI",
            "has_media": false,
            "url": "https://www.reddit.com/r/singularity/comments/1bi5onn/are_we_already_using_ai_to_improve_ai/",
            "comments": [
                {
                    "body": "Yes, we're beginning to but not in the way you're thinking here.\n\nThey can help with chip design. But where they're really incredible is using one kind of intelligence, to train another.\n\nTake the Nvidia pen twirling paper. The discriminator was an LLM that watched the hand trying to twirl a pen. To train this thing without AI would be nearly impossible, would you be able to pay a human to sit there and give flawless feedback 30+ times a second?\n\nOur own brains use different kinds of intelligence to run optimization. For example, when you throw a dart at a board, how does your motor cortex know it did \"good\" or \"bad\"? It can't. Not without vision. Not without the little part of your brain that understands you wanted to hit the center.\n\nThis is the scary feedback loop, as true multi-modal systems begin to form a more perfect Allegory of the Cave. Bootstrapping from nothing has cost trillions, but after they have the seed of something, they might begin to develop complex intelligence quickly."
                },
                {
                    "body": "there isn't really all that much code in a neural network, most of the size just comes from the parameters of the model, which are pretty much incomprehensible for larger models."
                },
                {
                    "body": "You don‚Äôt really ‚Äúcode‚Äù to improve a neural network, you just scale compute and improve the data used while looking for algorithmic improvements."
                },
                {
                    "body": "Stable Diffusion 3 uses CogVLM to write half the image captions which results in a slightly better success rate. [https://arxiv.org/pdf/2403.03206.pdf](https://arxiv.org/pdf/2403.03206.pdf)\n\nCogVLM can be finetuned to recognize more stuff. They could find all the failures, train those, and increase the success rate. I was hoping we could use CogVLM and finetune it but the hardware requirements are extremely high. You'll need to rent compute time if you want to finetune CogVLM.\n\nLet's pretend there's no hardware limitations. You could almost automate the entire process by doing the following.\n\n1. Generate a bunch of images.\n2. Give CogVLM the images and the prompt, and ask CogAgent (a text mode for CogVLM) if the prompt matches the image. A human would be needed to check the failure results to see why they failed, and do a random check on successful images to make sure the results are correct. This information can be used to train CogVLM or a different classifier.\n3. Take successful images and have CogVLM caption them.\n4. Train your image generator on these images and captions.\n5. Go back to step 1.\n\nWhat would be really cool is an image classifier that knows when it doesn't know what something is in an image rather than trying to label it. This would let developers know what the image classifier should be trained on, and what it already knows well enough. With further advancements an agent could find an object or action it doesn't recognize, perform an image search for it to find out what it is, and then train itself to recognize it. \n\nWith enough fancy technology the entire dataset creation and training could be automated. The biggest hurdle for automating this is the model knowing what's true or not. If it does an image search and gets conflicting results then it can't know which is correct."
                },
                {
                    "body": "Yes tagging datasets for stable diffusion is partially done with image recognition ais. I only know of community models/finetunes doing this but i bet they all use ai to some extent"
                }
            ]
        },
        {
            "date": "18-03-2024",
            "title": "[D] Theoretical Paper about Transformers",
            "body": " \n\nI'm going to start a study group focused on large language models. The participants are PhD students in Computer Science with a math background. I would like to first study some theoretical properties of transformers (or attention). Maybe some of the students still do not know exactly how a transformer is formulated, so I'll also need to discuss that.\n\nDo you have any suggestions of papers with an theoretical analysis of transformers (attention)?\n\nThe most popular paper for attention is \"Attention is all you need\", but they only present the architecture and run experiments.",
            "upvote_ratio": 0.83,
            "subreddit": "MachineLearning",
            "num_comments": 13,
            "submission_flair": "Discussion",
            "has_media": false,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1bhog2n/d_theoretical_paper_about_transformers/",
            "comments": [
                {
                    "body": "Maybe this one: (A mathematical perspectice to transformers)\nhttps://arxiv.org/abs/2312.10794"
                },
                {
                    "body": "The theoretical side is severely lacking. To the best of my knowledge (would love to be proven wrong), all results comes from the practical side. Some theoretical work tries to explain them, but it doesn't predict anything about these models, which makes it more a mental framework than a theoretical explanation.\n\nSomewhat theoretical papers from the top of my mind:\n\n* I remember liking \"Hopfield Networks is All You Need\" https://arxiv.org/abs/2008.02217\n* I thought \"Saturated Transformers are Constant-Depth Threshold Circuits\" was kinda weak due to the circuit upper bound feeling trivial, but there could be more in this general area. https://arxiv.org/abs/2106.16213\n    * This one builds on top of that, but in the end is just plain wrong. It might be fun to spot the flaw. \"Transformer-Based Large Language Models Are Not General Learners: A Universal Circuit Perspective\" https://openreview.net/forum?id=e5lR6tySR7\n* I was very surprised by \"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\", but that was is again pretty practical. I do think the implications of this one will have huge consequences for the theoretical side. https://arxiv.org/abs/2402.17764\n* I think \"Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer\" is quite interesting. Next to the obvious, also due to the small rewrite they suggest for attention. https://arxiv.org/pdf/2203.03466.pdf"
                },
                {
                    "body": "Similar to what u/sonofmath suggested: [Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View](https://arxiv.org/pdf/1906.02762.pdf)\n\nA handy reference that explicitly writes out all the equations for the model: [The Transformer Model in Equations](https://johnthickstun.com/docs/transformers.pdf)\n\nSelf explanatory: [Attention is turing complete](https://jmlr.org/papers/volume22/20-302/20-302.pdf)\n\nNot directly theoretical, but strongly suggestive of important theory:\n\n- [Augmenting Self-attention with Persistent Memory](https://arxiv.org/abs/1907.01470)\n- [Memory transformer](https://arxiv.org/abs/2006.11527)\n- [Vision Transformers Need Registers](https://arxiv.org/abs/2309.16588)"
                },
                {
                    "body": "https://proceedings.neurips.cc/paper/2021/file/2bd388f731f26312bfc0fe30da009595-Paper.pdf\n\nThis?"
                },
                {
                    "body": "Thinking like transformers is a classic by exploring their place in the computation complexity hierarchy"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "SunoAI isn't limited to English - It can make Japanese music too. I wonder how this will affect the anime industry in the future? Art by Copilot",
            "body": "",
            "upvote_ratio": 0.89,
            "subreddit": "singularity",
            "num_comments": 27,
            "submission_flair": "AI",
            "has_media": true,
            "url": "https://v.redd.it/h38g8a81wcqc1",
            "comments": [
                {
                    "body": "Basically 90% of the not so good music producers are done. Unless you are at the level of yoasobi."
                },
                {
                    "body": "It can even do german Songs xD although the lyrics are sometimes kind rough."
                },
                {
                    "body": "Damn. This gonna get 90% of producers out. [https://app.suno.ai/song/28842e41-50c8-4a86-b9e7-3f6a8c38c334](https://app.suno.ai/song/28842e41-50c8-4a86-b9e7-3f6a8c38c334) in my language but it is preety decent with 2000 vibes. Damn. Even one can figure fast this is generated but it is still tops 80% of pop songs in Poland."
                },
                {
                    "body": "amazing! also I am surprised copilot can do this, maybe I just really suck at prompting but whenever I use bing image generator I get the most ass images, not the case with MJ or SD"
                },
                {
                    "body": "I can't believe I hadn't thought of trying other languages! I just put in a Portuguese song about a girl who lost her cat and it did better than I expected (although both examples had a male singer lol)"
                }
            ]
        },
        {
            "date": "24-03-2024",
            "title": "Summary on GPT-5's performance rumors:",
            "body": "1. Overall performance boost: Sam Altman, CEO, stated that GPT-5 will be smarter and superior in all aspects, with a significant performance improvement over GPT-4.\n\n2. Enhanced multimodal capabilities: It is predicted that GPT-5 will not only handle text and images but will also be capable of processing audio and videos, becoming a multimodal AI.\n\n3. Increase in parameter count: It's expected to have several trillion parameters, greatly surpassing GPT-4's one trillion, for more complex and advanced reasoning.\n\n4. Better text generation quality: GPT-5 aims to produce text that is consistently realistic and indistinguishable from that written by humans.\n\n5. Expanded context understanding: The context window of GPT-5 is expected to greatly exceed GPT-4's 128,000 tokens, allowing for longer text comprehension and analysis.\n\n6. Improved logical reasoning: GPT-5 is expected to make significant advancements in its ability to reason logically and tackle more complex problems.\n\n7. AI agent functionality: GPT-5 may include the capability for performing tasks autonomously, hinting at functionalities similar to those of AI agents.\n\nGPT-5 is expected to mark a revolutionary leap forward from GPT-4. Altman cautions against underestimating the performance improvements of GPT-5, indicating it could introduce groundbreaking changes to the field of AI.",
            "upvote_ratio": 0.76,
            "subreddit": "ArtificialInteligence",
            "num_comments": 8,
            "submission_flair": "News",
            "has_media": false,
            "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1bmjvnb/summary_on_gpt5s_performance_rumors/",
            "comments": [
                {
                    "body": "## Welcome to the r/ArtificialIntelligence gateway\n### News Posting Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Use a direct link to the news article, blog, etc\n* Provide details regarding your connection with the blog / news source\n* Include a description about what the news/article is about. It will drive more people to your blog\n* Note that AI generated news content is all over the place. If you want to stand out, you need to engage the audience\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*"
                },
                {
                    "body": "This marks a significant shift in the power of natural language and the democratization of AI development \n\nAnyone will be able to develop AI apps and AI agents by describing what they want to do\n\nThe wider accessibility of AI development to non-technical users will have cascading effects on the technical industry"
                },
                {
                    "body": "Excited for the release of GPT-5!"
                },
                {
                    "body": ">Increase in parameter count: It's expected to have several trillion parameters, greatly surpassing GPT-4's one trillion, for more complex and advanced reasoning.\n\nI've recently began reading [Emergent Abilities of Large Language Models](https://arxiv.org/pdf/2206.07682.pdf) and within sections 3 \"Few-Shot Prompted Tasks\" and 4 \"Augmented Prompting Strategies\" it states that most of the systems they tested ended up showing Emergent Abilities around the 100B parameter mark in certain tasks after hitting a specific threshold.\n\nMy question, if GPT-4 has 1Trillion parameters, what crazy emergent abilities manifested in their private model they trained this from? and furthermore, will we see any Emergent Abilities with the public release version of GPT-4?"
                },
                {
                    "body": "Detecting coins in images with Python and OpenCV:¬†[https://www.youtube.com/watch?v=VrgI1nPbV88](https://www.youtube.com/watch?v=VrgI1nPbV88)"
                }
            ]
        }
    ]
}